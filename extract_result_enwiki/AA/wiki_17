{"id": "2348", "revid": "1455149", "url": "https://en.wikipedia.org/wiki?curid=2348", "title": "Anointing of the sick", "text": "Anointing of the sick, known also by other names, is a form of religious anointing or \"unction\" (an older term with the same meaning) for the benefit of a sick person. It is practiced by many Christian churches and denominations.\nAnointing of the sick was a customary practice in many civilizations, including among the ancient Greeks and early Jewish communities. The use of oil for healing purposes is referred to in the writings of Hippocrates.\nAnointing of the sick should be distinguished from other religious anointings that occur in relation to other sacraments, in particular baptism, confirmation and ordination, and also in the coronation of a monarch.\nNames.\nSince 1972, the Roman Catholic Church has used the name \"Anointing of the Sick\" both in the English translations issued by the Holy See of its official documents in Latin and in the English official documents of Episcopal conferences. It does not, of course, forbid the use of other names, for example the more archaic term \"Unction of the Sick\" or the term \"Extreme Unction\". Cardinal Walter Kasper used the latter term in his intervention at the 2005 Assembly of the Synod of Bishops. However, the Church declared that \"'Extreme unction' ... may also and more fittingly be called 'anointing of the sick'\", and has itself adopted the latter term, while not outlawing the former. This is to emphasize that the sacrament is available, and recommended, to all those suffering from any serious illness, and to dispel the common misconception that it is exclusively for those at or very near the point of death.\nExtreme Unction was the usual name for the sacrament in the West from the late twelfth century until 1972, and was thus used at the Council of Trent and in the 1913 Catholic Encyclopedia. Peter Lombard (died 1160) is the first writer known to have used the term, which did not become the usual name in the West till towards the end of the twelfth century, and never became current in the East. The word \"extreme\" (final) indicated either that it was the last of the sacramental unctions (after the anointings at Baptism, Confirmation and, if received, Holy Orders) or because at that time it was normally administered only when a patient was \"in extremis\".\nOther names used in the West include the unction or blessing of consecrated oil, the unction of God, and the office of the unction. Among some Protestant bodies, who do not consider it a sacrament, but instead as a practice suggested rather than commanded by Scripture, it is called anointing with oil.\nIn the Greek Church the sacrament is called Euchelaion (Greek \u0395\u1f50\u03c7\u03ad\u03bb\u03b1\u03b9\u03bf\u03bd, from \u03b5\u1f50\u03c7\u03ae, \"prayer\", and \u1f14\u03bb\u03b1\u03b9\u03bf\u03bd, \"oil\"). Other names are also used, such as \u1f05\u03b3\u03b9\u03bf\u03bd \u1f14\u03bb\u03b1\u03b9\u03bf\u03bd (holy oil), \u1f21\u03b3\u03b9\u03b1\u03c3\u03bc\u03ad\u03bd\u03bf\u03bd \u1f14\u03bb\u03b1\u03b9\u03bf\u03bd (consecrated oil), and \u03c7\u03c1\u1fd6\u03c3\u03b9\u03c2 or \u03c7\u03c1\u1fd6\u03c3\u03bc\u03b1 (anointing).\nThe Community of Christ uses the term administration to the sick.\nThe term \"last rites\" refers to administration to a dying person not only of this sacrament but also of Penance and Holy Communion, the last of which, when administered in such circumstances, is known as \"Viaticum\", a word whose original meaning in Latin was \"provision for the journey\". The normal order of administration is: first Penance (if the dying person is physically unable to confess, absolution, conditional on the existence of contrition, is given); next, Anointing; finally, Viaticum (if the person can receive it).\nBiblical texts.\nThe chief biblical text concerning the rite is James 5:14\u201315: \"Is any among you sick? Let him call for the elders of the church, and let them pray over him, anointing him with oil in the name of the Lord; and the prayer of faith will save the sick man, and the Lord will raise him up; and if he has committed sins, he will be forgiven\" (RSV).\nMatthew 10:8, Luke 10:8\u20139 and Mark 6:13 are also quoted in this context.\nSacramental beliefs.\nThe Catholic, Eastern Orthodox and Coptic and Old Catholic Churches consider this anointing to be a sacrament. Other Christians too, in particular, Lutherans, Anglicans and some Protestant and other Christian communities use a rite of anointing the sick, without necessarily classifying it as a sacrament.\nIn the Churches mentioned here by name, the oil used (called \"oil of the sick\" in both West and East) is blessed specifically for this purpose.\nRoman Catholic Church.\nAn extensive account of the teaching of the Catholic Church on Anointing of the Sick is given in \"Catechism of the Catholic Church\".\nAnointing of the Sick is one of the seven Sacraments recognized by the Catholic Church, and is associated with not only bodily healing but also forgiveness of sins. Only ordained priests can administer it, and \"any priest may carry the holy oil with him, so that in a case of necessity he can administer the sacrament of anointing of the sick.\"\nSacramental graces.\nThe Catholic Church sees the effects of the sacrament as follows. As the sacrament of Marriage gives grace for the married state, the sacrament of Anointing of the Sick gives grace for the state into which people enter through sickness. Through the sacrament a gift of the Holy Spirit is given, that renews confidence and faith in God and strengthens against temptations to discouragement, despair and anguish at the thought of death and the struggle of death; it prevents from losing Christian hope in God's justice, truth and salvation.\nThe special grace of the sacrament of the Anointing of the Sick has as its effects:\nSacramental oil.\nThe duly blessed oil used in the sacrament is, as laid down in the Apostolic Constitution, Sacram unctionem infirmorum, pressed from olives or from other plants. It is blessed by the bishop of the diocese at the Chrism Mass he celebrates on Holy Thursday or on a day close to it. If oil blessed by the bishop is not available, the priest administering the sacrament may bless the oil, but only within the framework of the celebration.\nOrdinary Form of the Roman Rite (1972).\nThe Roman Rite Anointing of the Sick, as revised in 1972, puts greater stress than in the immediately preceding centuries on the sacrament's aspect of healing, primarily spiritual but also physical, and points to the place sickness holds in the normal life of Christians and its part in the redemptive work of the Church. Canon law permits its administration to a Catholic who has reached the age of reason and is beginning to be put in danger by illness or old age, unless the person in question obstinately persists in a manifestly grave sin. \"If there is any doubt as to whether the sick person has reached the use of reason, or is dangerously ill, or is dead, this sacrament is to be administered\". There is an obligation to administer it to the sick who, when they were in possession of their faculties, at least implicitly asked for it. A new illness or a renewal or worsening of the first illness enables a person to receive the sacrament a further time.\nThe ritual book on pastoral care of the sick provides three rites: anointing outside Mass, anointing within Mass, and anointing in a hospital or institution. The rite of anointing outside Mass begins with a greeting by the priest, followed by sprinkling of all present with holy water, if deemed desirable, and a short instruction. There follows a penitential act, as at the beginning of Mass. If the sick person wishes to receive the sacrament of penance, it is preferable that the priest make himself available for this during a previous visit; but if the sick person must confess during the celebration of the sacrament of anointing, this confession replaces the penitential rite A passage of Scripture is read, and the priest may give a brief explanation of the reading, a short litany is said, and the priest lays his hands on the head of the sick person and then says a prayer of thanksgiving over the already blessed oil or, if necessary, blesses the oil himself.\nThe actual anointing of the sick person is done on the forehead, with the prayer:\nIt is permitted, in accordance with local culture and traditions and the condition of the sick person, to anoint other parts of the body in addition, such as the area of pain or injury, but without repeating the sacramental form. In case of emergency, a single anointing, if possible but not absolutely necessary if not possible on the forehead, is sufficient.\nExtraordinary Form of the Roman Rite.\nFrom the early Middle Ages until after the Second Vatican Council the sacrament was administered, within the Latin Church, only when death was approaching and, in practice, bodily recovery was not ordinarily looked for, giving rise, as mentioned above to the name \"Extreme Unction\" (i.e. final anointing). The extraordinary form of the Roman Rite includes anointing of seven parts of the body while saying in Latin: \nAnointing in the extraordinary form is still permitted under the conditions mentioned in article 9 of the 2007 motu proprio \"Summorum Pontificum\".\nIn the case of necessity when only a single anointing on the forehead is possible, it suffices for valid administration of the sacrament to use the shortened form:\nWhen it become opportune, all the anointings are to be supplied together with their respective forms for the integrity of the sacrament. \nIf the sacrament is conferred conditionally, for example, if a person is unconscious, \"Si es capax (If you are capable)\u201d is added to the beginning of the form, not \"Si dispositus es (if you are disposed).\" In doubt if the soul has left the body through death, the priest adds, \"Si vivis (If you are alive).\"\nOther Western historical forms.\nLiturgical rites of the Catholic Church, both Western and Eastern, other than the Roman, have a variety of other forms for celebrating the sacrament. For example, according to Giovanni Diclich who cites De Rubeis, \"De Ritibus vestutis\" &amp;c. cap. 28 p.\u00a0381, the Aquileian Rite, also called \"Rito Patriarchino\", had twelve anointings, namely, of the head, forehead, eyes, ears, nose, lips, throat, chest, heart, shoulders, hands, and feet. The form used to anoint is the first person plural indicative, except for the anointing on the head which could be either in the first person singular or plural.\nFor example, the form is given as:\nThe other anointings all mention an anointing with oil and are all made \"through Christ our Lord,\" and \"in the name of the Father, and of the Son, and of the Holy Spirit,\" except the anointing of the heart which, as in the second option for anointing of the head, is \"in the name of the Holy and Undivided Trinity.\" the Latin forms are as follows:\nEastern Orthodox Church.\nThe teaching of the Eastern Orthodox Church on the Holy Mystery (sacrament) of Unction is similar to that of the Roman Catholic Church. However, the reception of the Mystery is not limited to those who are enduring physical illness. The Mystery is given for healing (both physical and spiritual) and for the forgiveness of sin. For this reason, it is normally required that one go to confession before receiving Unction. Because it is a Sacred Mystery of the Church, only Orthodox Christians may receive it.\nThe solemn form of Eastern Christian anointing requires the ministry of seven priests. A table is prepared, upon which is set a vessel containing wheat. Into the wheat has been placed an empty shrine-lamp, seven candles, and seven anointing brushes. Candles are distributed for all to hold during the service. The rite begins with reading Psalm 50 (the great penitential psalm), followed by the chanting of a special canon. After this, the senior priest (or bishop) pours pure olive oil and a small amount of wine into the shrine lamp, and says the \"Prayer of the Oil\", which calls upon God to \"...sanctify this Oil, that it may be effectual for those who shall be anointed therewith, unto healing, and unto relief from every passion, every malady of the flesh and of the spirit, and every ill...\" Then follow seven series of epistles, gospels, long prayers, Ektenias (litanies) and anointings. Each series is served by one of the seven priests in turn. The afflicted one is anointed with the sign of the cross on seven places: the forehead, the nostrils, the cheeks, the lips, the breast, the palms of both hands, and the back of the hands. After the last anointing, the Gospel Book is opened and placed with the writing down upon the head of the one who was anointed, and the senior priest reads the \"Prayer of the Gospel\". At the end, the anointed kisses the Gospel, the Cross and the right hands of the priests, receiving their blessing.\nAnointing is considered to be a public rather than a private sacrament, and so as many of the faithful who are able are encouraged to attend. It should be celebrated in the church when possible, but if this is impossible, it may be served in the home or hospital room of the afflicted.\nUnction in the Greek Orthodox Church and Churches of Hellenic custom (Antiochian Eastern Orthodox, Melkite, etc.) is usually given with a minimum of ceremony.\nAnointing may also be given during Forgiveness Vespers and Great Week, on Great and Holy Wednesday, to all who are prepared. Those who receive Unction on Holy Wednesday should go to Holy Communion on Great Thursday. The significance of receiving Unction on Holy Wednesday is shored up by the hymns in the Triodion for that day, which speak of the sinful woman who anointed the feet of Christ. Just as her sins were forgiven because of her penitence, so the faithful are exhorted to repent of their sins. In the same narrative, Jesus says, \"in that she hath poured this ointment on my body, she did it for my burial\" (Id., v. 12), linking the unction with Christ's death and resurrection.\nIn some dioceses of the Russian Orthodox Church it is customary for the bishop to visit each parish or region of the diocese some time during Great Lent and give Anointing for the faithful, together with the local clergy.\nHussite Church.\nThe Hussite Church regards anointing of the sick as one of the seven sacraments.\nLutheran churches.\nAnointing of the sick has been retained in Lutheran churches since the Reformation. Although it is not considered a sacrament like baptism, confession and the Eucharist, it is known as a ritual in the same respect as confirmation, holy orders, and matrimony.\nLiturgy.\nAfter the penitent has received absolution following confession, the presiding minister recites James 5:14-16. He goes on to recite the following:\n[Name], you have confessed your sins and received Holy Absolution. In remembrance of the grace of God given by the Holy Spirit in the waters of Holy Baptism, I will anoint you with oil. Confident in our Lord and in love for you, we also pray for you that you will not lose faith. Knowing that in Godly patience the Church endures with you and supports you during this affliction. We firmly believe that this illness is for the glory of God and that the Lord will both hear our prayer and work according to His good and gracious will.\nHe anoints the person on the forehead and says this blessing:\nAlmighty God, the Father of our Lord Jesus Christ, who has given you the new birth of water and the Spirit and has forgiven you all your sins, strengthen you with His grace to life everlasting. Amen.\nAnglican churches.\nThe 1552 and later editions of the Book of Common Prayer omitted the form of anointing given in the original (1549) version in its Order for the Visitation of the Sick, but most twentieth-century Anglican prayer books do have anointing of the sick. The Book of Common Prayer (1662) and the proposed revision of 1928 include the \"visitation of the sick\" and \"communion of the sick\" (which consist of various prayers, exhortations and psalms).\nSome Anglicans accept that anointing of the sick has a sacramental character and is therefore a channel of God's grace, seeing it as an \"outward and visible sign of an inward and spiritual grace\" which is the definition of a sacrament. The Catechism of the Episcopal Church of the United States of America includes Unction of the Sick as among the \"other sacramental rites\" and it states that unction can be done with oil or simply with laying on of hands. The rite of anointing is included in the Episcopal Church's \"Ministration to the Sick\" \nArticle 25 of the Thirty-Nine Articles, which are one of the historical formularies of the Church of England (and as such, the Anglican Communion), speaking of the sacraments, says: \"Those five commonly called Sacraments, that is to say, Confirmation, Penance, Orders, Matrimony, and extreme Unction, are not to be counted for Sacraments of the Gospel, being such as have grown partly of the corrupt following of the Apostles, partly are states of life allowed in the Scriptures; but yet have not like nature of Sacraments with Baptism, and the Lord's Supper, for that they have not any visible sign or ceremony ordained of God.\"\nOther Protestant communities.\nProtestants provide anointing in a wide variety of formats. Protestant communities generally vary widely on the sacramental character of anointing. Most Mainline Protestants recognize only two sacraments, the eucharist and baptism, deeming anointing only a humanly-instituted rite. Non-traditional Protestant communities generally use the term ordinance rather than \"sacrament\".\nMainline beliefs.\nLiturgical or Mainline Protestant communities (e.g. Presbyterian, Congregationalist/United Church of Christ, Methodist, etc.) all have official yet often optional liturgical rites for the anointing of the sick partly on the model of Western pre-Reformation rites. Anointing need not be associated with grave illness or imminent danger of death.\nCharismatic and Pentecostal beliefs.\nIn Charismatic and Pentecostal communities, anointing of the sick is a frequent practice and has been an important ritual in these communities since the respective movements were founded in the 19th and 20th centuries. These communities use extemporaneous forms of administration at the discretion of the minister, who need not be a pastor. There is minimal ceremony attached to its administration. Usually, several people physically touch (laying on of hands) the recipient during the anointing. It may be part of a worship service with the full assembly of the congregation present, but may also be done in more private settings, such as homes or hospital rooms. Some Pentecostals believe that physical healing is within the anointing and so there is often great expectation or at least great hope that a miraculous cure or improvement will occur when someone is being prayed over for healing.\nEvangelical and fundamentalist beliefs.\nIn Evangelical and Fundamentalist communities, anointing of the sick is performed with varying degrees of frequency, although laying on of hands may be more common than anointing. The rite would be similar to that of Pentecostals in its simplicity, but would usually not have the same emotionalism attached to it. Unlike some Pentecostals, Evangelicals and Fundamentalists generally do not believe that physical healing is within the anointing. Therefore, God may or may not grant physical healing to the sick. The healing conferred by anointing is thus a spiritual event that may not result in physical recovery.\nThe Church of the Brethren practices Anointing with Oil as an ordinance along with Baptism, Communion, Laying on of Hands, and the Love Feast.\nEvangelical Protestants who use anointing differ about whether the person doing the anointing must be an ordained member of the clergy, whether the oil must necessarily be olive oil and have been previously specially consecrated, and about other details. Several Evangelical groups reject the practice so as not to be identified with charismatic and Pentecostal groups, which practice it widely.\nUse of Catholic rite among Protestants.\nSome Protestant US military chaplains carry the Roman Rite version of the Anointing of the Sick with them for use if called upon to assist wounded or dying soldiers who are Catholics. The Catholic and Orthodox Churches consider invalid \"as a sacrament\" the administration of Anointing of the Sick by such chaplains, who in the eyes of those Churches are not validly ordained priests. The rite performed by them is thus seen as having the same, but by no means negligible, value of any other form of prayer offered for the sick or dying.\nLatter Day Saint movement.\nThe Church of Jesus Christ of Latter-day Saints.\nLatter-day Saints, who consider themselves restorationists, also practice ritual anointing of the sick, as well as other forms of anointing. Members of The Church of Jesus Christ of Latter-day Saints (LDS Church) consider anointing to be an ordinance.\nMembers of the LDS Church who hold the Melchizedek priesthood may use consecrated oil in performing the ordinance of blessing of the \"sick or afflicted\", though oil is not required if it is unavailable. The priesthood holder anoints the recipient's head with a drop of oil, then lays hands upon that head and declare their act of anointing. Then another priesthood holder joins in, if available, and pronounces a \"sealing\" of the anointing and other words of blessing, as he feels inspired. Melchizedek priesthood holders are also authorized to consecrate any pure olive oil and often carry a personal supply in case they have need to perform a blessing. Oil is not used in other blessings, such as for people seeking comfort or counsel.\nIn addition to the James 5:14-15 reference, the Doctrine and Covenants contains numerous references to the anointing and healing of the sick by those with authority to do so.\nCommunity of Christ.\nAdministration to the sick is one of the eight sacraments of the Community of Christ, in which it has also been used for people seeking spiritual, emotional or mental healing.\nExternal links.\nWestern\nEastern"}
{"id": "2349", "revid": "16849003", "url": "https://en.wikipedia.org/wiki?curid=2349", "title": "Abstract data type", "text": "In computer science, an abstract data type (ADT) is a mathematical model for data types. An abstract data type is defined by its behavior (semantics) from the point of view of a \"user\", of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This mathematical model contrasts with data structures, which are concrete representations of data, and are the point of view of an implementer, not a user.\nFormally, an ADT may be defined as a \"class of objects whose logical behavior is defined by a set of values and a set of operations\"; this is analogous to an algebraic structure in mathematics. What is meant by \"behavior\" varies by author, with the two main types of formal specifications for behavior being \"axiomatic (algebraic) specification\" and an \"abstract model;\" these correspond to axiomatic semantics and operational semantics of an abstract machine, respectively. Some authors also include the computational complexity (\"cost\"), both in terms of time (for computing operations) and space (for representing values). In practice, many common data types are not ADTs, as the abstraction is not perfect, and users must be aware of issues like arithmetic overflow that are due to the representation. For example, integers are often stored as fixed-width values (32-bit or 64-bit binary numbers), and thus experience integer overflow if the maximum value is exceeded.\nADTs are a theoretical concept, in computer science, used in the design and analysis of algorithms, data structures, and software systems, and do not correspond to specific features of computer languages\u2014mainstream computer languages do not directly support formally specified ADTs. However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract. ADTs were first proposed by Barbara Liskov and Stephen N. Zilles in 1974, as part of the development of the CLU language.\nExamples.\nFor example, integers are an ADT, defined as the values ..., \u22122, \u22121, 0, 1, 2, ..., and by the operations of addition, subtraction, multiplication, and division, together with greater than, less than, etc., which behave according to familiar mathematics (with care for integer division), independently of how the integers are represented by the computer. Explicitly, \"behavior\" includes obeying various axioms (associativity and commutativity of addition, etc.), and preconditions on operations (cannot divide by zero). Typically integers are represented in a data structure as binary numbers, most often as two's complement, but might be binary-coded decimal or in ones' complement, but the user is abstracted from the concrete choice of representation, and can simply use the data as data types.\nAn ADT consists not only of operations but also of values of the underlying data and of constraints on the operations. An \"interface\" typically refers only to the operations, and perhaps some of the constraints on the operations, notably pre-conditions and post-conditions, but not other constraints, such as relations between the operations.\nFor example, an abstract stack, which is a last-in-first-out structure, could be defined by three operations: push, that inserts a data item onto the stack; pop, that removes a data item from it; and peek or top, that accesses a data item on top of the stack without removal. An abstract queue, which is a first-in-first-out structure, would also have three operations: enqueue, that inserts a data item into the queue; dequeue, that removes the first data item from it; and front, that accesses and serves the first data item in the queue. There would be no way of differentiating these two data types unless a mathematical constraint is introduced that for a stack specifies that each pop always returns the most recently pushed item that has not been popped yet. When analyzing the efficiency of algorithms that use stacks, one may also specify that all operations take the same time no matter how many data items have been pushed into the stack, and that the stack uses a constant amount of storage for each element.\nIntroduction.\nAbstract data types are purely theoretical entities, used (among other things) to simplify the description of abstract algorithms, to classify and evaluate data structures, and to formally describe the type systems of programming languages. However, an ADT may be implemented by specific data types or data structures, in many ways and in many programming languages; or described in a formal specification language. ADTs are often implemented as modules: the module's interface declares procedures that correspond to the ADT operations, sometimes with comments that describe the constraints. This information hiding strategy allows the implementation of the module to be changed without disturbing the client programs.\nThe term abstract data type can also be regarded as a generalized approach of a number of algebraic structures, such as lattices, groups, and rings. The notion of abstract data types is related to the concept of data abstraction, important in object-oriented programming and design by contract methodologies for software development.\nDefining an abstract data type.\nAn abstract data type is defined as a mathematical model of the data objects that make up a data type as well as the functions that operate on these objects.\nThere are no standard conventions for defining them. A broad division may be drawn between \"imperative\" and \"functional\" definition styles.\nImperative-style definition.\nIn the philosophy of imperative programming languages, an abstract data structure is conceived as an entity that is \"mutable\"\u2014meaning that it may be indifferent \"states\" at different times. Some operations may change the state of the ADT; therefore, the order in which operations are evaluated is important, and the same operation on the same entities may have different effects if executed at different times\u2014just like the instructions of a computer, or the commands and procedures of an imperative language. To underscore this view, it is customary to say that the operations are \"executed\" or \"applied\", rather than \"evaluated\". The imperative style is often used when describing abstract algorithms. (See The Art of Computer Programming by Donald Knuth for more details)\nAbstract variable.\nImperative-style definitions of ADT often depend on the concept of an \"abstract variable\", which may be regarded as the simplest non-trivial ADT. An abstract variable \"V\" is a mutable entity that admits two operations:\nwith the constraint that\nAs in so many programming languages, the operation store(\"V\", \"x\") is often written \"V\" \u2190 \"x\" (or some similar notation), and fetch(\"V\") is implied whenever a variable \"V\" is used in a context where a value is required. Thus, for example, \"V\" \u2190 \"V\" + 1 is commonly understood to be a shorthand for store(\"V\",fetch(\"V\") + 1).\nIn this definition, it is implicitly assumed that storing a value into a variable \"U\" has no effect on the state of a distinct variable \"V\". To make this assumption explicit, one could add the constraint that\nMore generally, ADT definitions often assume that any operation that changes the state of one ADT instance has no effect on the state of any other instance (including other instances of the same ADT) \u2014 unless the ADT axioms imply that the two instances are connected (aliased) in that sense. For example, when extending the definition of an abstract variable to include abstract records, the operation that selects a field from a record variable \"R\" must yield a variable \"V\" that is aliased to that part of \"R\".\nThe definition of an abstract variable \"V\" may also restrict the stored values \"x\" to members of a specific set \"X\", called the \"range\" or \"type\" of \"V\". As in programming languages, such restrictions may simplify the description and analysis of algorithms, and improve their readability.\nNote that this definition does not imply anything about the result of evaluating fetch(\"V\") when \"V\" is \"un-initialized\", that is, before performing any store operation on \"V\". An algorithm that does so is usually considered invalid because its effect is not defined. (However, there are some important algorithms whose efficiency strongly depends on the assumption that such a fetch is legal, and returns some arbitrary value in the variable's range.)\nInstance creation.\nSome algorithms need to create new instances of some ADT (such as new variables, or new stacks). To describe such algorithms, one usually includes in the ADT definition a create() operation that yields an instance of the ADT, usually with axioms equivalent to\nThis axiom may be strengthened to exclude also partial aliasing with other instances. On the other hand, this axiom still allows implementations of create() to yield a previously created instance that has become inaccessible to the program.\nExample: abstract stack (imperative).\nAs another example, an imperative-style definition of an abstract stack could specify that the state of a stack \"S\" can be modified only by the operations\nwith the constraint that\nSince the assignment \"V\" \u2190 \"x\", by definition, cannot change the state of \"S\", this condition implies that \"V\" \u2190 pop(\"S\") restores \"S\" to the state it had before the push(\"S\", \"x\"). From this condition and from the properties of abstract variables, it follows, for example, that the sequence\nwhere \"x\", \"y\", and \"z\" are any values, and \"U\", \"V\", \"W\" are pairwise distinct variables, is equivalent to\nHere it is implicitly assumed that operations on a stack instance do not modify the state of any other ADT instance, including other stacks; that is,\nAn abstract stack definition usually includes also a Boolean-valued function empty(\"S\") and a create() operation that returns a stack instance, with axioms equivalent to\nSingle-instance style.\nSometimes an ADT is defined as if only one instance of it existed during the execution of the algorithm, and all operations were applied to that instance, which is not explicitly notated. For example, the abstract stack above could have been defined with operations push(\"x\") and pop(), that operate on \"the\" only existing stack. ADT definitions in this style can be easily rewritten to admit multiple coexisting instances of the ADT, by adding an explicit instance parameter (like \"S\" in the previous example) to every operation that uses or modifies the implicit instance.\nOn the other hand, some ADTs cannot be meaningfully defined without assuming multiple instances. This is the case when a single operation takes two distinct instances of the ADT as parameters. For an example, consider augmenting the definition of the abstract stack with an operation compare(\"S\", \"T\") that checks whether the stacks \"S\" and \"T\" contain the same items in the same order.\nFunctional-style definition.\nAnother way to define an ADT, closer to the spirit of functional programming, is to consider each state of the structure as a separate entity. In this view, any operation that modifies the ADT is modeled as a mathematical function that takes the old state as an argument and returns the new state as part of the result. Unlike the imperative operations, these functions have no side effects. Therefore, the order in which they are evaluated is immaterial, and the same operation applied to the same arguments (including the same input states) will always return the same results (and output states).\nIn the functional view, in particular, there is no way (or need) to define an \"abstract variable\" with the semantics of imperative variables (namely, with fetch and store operations). Instead of storing values into variables, one passes them as arguments to functions.\nExample: abstract stack (functional).\nFor example, a complete functional-style definition of an abstract stack could use the three operations:\nIn a functional-style definition there is no need for a create operation. Indeed, there is no notion of \"stack instance\". The stack states can be thought of as being potential states of a single stack structure, and two-stack states that contain the same values in the same order are considered to be identical states. This view actually mirrors the behavior of some concrete implementations, such as linked lists with hash cons.\nInstead of create(), a functional-style definition of an abstract stack may assume the existence of a special stack state, the \"empty stack\", designated by a special symbol like \u039b or \"()\"; or define a bottom() operation that takes no arguments and returns this special stack state. Note that the axioms imply that\nIn a functional-style definition of a stack one does not need an empty predicate: instead, one can test whether a stack is empty by testing whether it is equal to \u039b.\nNote that these axioms do not define the effect of top(\"s\") or pop(\"s\"), unless \"s\" is a stack state returned by a push. Since push leaves the stack non-empty, those two operations are undefined (hence invalid) when \"s\" = \u039b. On the other hand, the axioms (and the lack of side effects) imply that push(\"s\", \"x\") = push(\"t\", \"y\") if and only if \"x\" = \"y\" and \"s\" = \"t\".\nAs in some other branches of mathematics, it is customary to assume also that the stack states are only those whose existence can be proved from the axioms in a finite number of steps. In the abstract stack example above, this rule means that every stack is a \"finite\" sequence of values, that becomes the empty stack (\u039b) after a finite number of pops. By themselves, the axioms above do not exclude the existence of infinite stacks (that can be poped forever, each time yielding a different state) or circular stacks (that return to the same state after a finite number of pops). In particular, they do not exclude states \"s\" such that pop(\"s\") = \"s\" or push(\"s\", \"x\") = \"s\" for some \"x\". However, since one cannot obtain such stack states with the given operations, they are assumed \"not to exist\".\nWhether to include complexity.\nAside from the behavior in terms of axioms, it is also possible to include, in the definition of an ADT operation, their algorithmic complexity. Alexander Stepanov, designer of the C++ Standard Template Library, included complexity guarantees in the STL specification, arguing:\nAdvantages of abstract data typing.\nEncapsulation.\nAbstraction provides a promise that any implementation of the ADT has certain properties and abilities; knowing these is all that is required to make use of an ADT object.\nLocalization of change.\nCode that uses an ADT object will not need to be edited if the implementation of the ADT is changed. Since any changes to the implementation must still comply with the interface, and since code using an ADT object may only refer to properties and abilities specified in the interface, changes may be made to the implementation without requiring any changes in code where the ADT is used.\nFlexibility.\nDifferent implementations of the ADT, having all the same properties and abilities, are equivalent and may be used somewhat interchangeably in code that uses the ADT. This gives a great deal of flexibility when using ADT objects in different situations. For example, different implementations of the ADT may be more efficient in different situations; it is possible to use each in the situation where they are preferable, thus increasing overall efficiency.\nTypical operations.\nSome operations that are often specified for ADTs (possibly under other names) are\nIn imperative-style ADT definitions, one often finds also\nThe free operation is not normally relevant or meaningful, since ADTs are theoretical entities that do not \"use memory\". However, it may be necessary when one needs to analyze the storage used by an algorithm that uses the ADT. In that case, one needs additional axioms that specify how much memory each ADT instance uses, as a function of its state, and how much of it is returned to the pool by free.\nExamples.\nSome common ADTs, which have proved useful in a great variety of applications, are\nEach of these ADTs may be defined in many ways and variants, not necessarily equivalent. For example, an abstract stack may or may not have a count operation that tells how many items have been pushed and not yet popped. This choice makes a difference not only for its clients but also for the implementation.\nAn extension of ADT for computer graphics was proposed in 1979: an abstract graphical data type (AGDT). It was introduced by Nadia Magnenat Thalmann, and Daniel Thalmann. AGDTs provide the advantages of ADTs with facilities to build graphical objects in a structured way.\nImplementation.\nImplementing an ADT means providing one procedure or function for each abstract operation. The ADT instances are represented by some concrete data structure that is manipulated by those procedures, according to the ADT's specifications.\nUsually there are many ways to implement the same ADT, using several different concrete data structures. Thus, for example, an abstract stack can be implemented by a linked list or by an array.\nIn order to prevent clients from depending on the implementation, an ADT is often packaged as an \"opaque data type\" in one or more modules, whose interface contains only the signature (number and types of the parameters and results) of the operations. The implementation of the module\u2014namely, the bodies of the procedures and the concrete data structure used\u2014can then be hidden from most clients of the module. This makes it possible to change the implementation without affecting the clients. If the implementation is exposed, it is known instead as a \"transparent data type.\"\nWhen implementing an ADT, each instance (in imperative-style definitions) or each state (in functional-style definitions) is usually represented by a handle of some sort.\nModern object-oriented languages, such as C++ and Java, support a form of abstract data types. When a class is used as a type, it is an abstract type that refers to a hidden representation. In this model an ADT is typically implemented as a class, and each instance of the ADT is usually an object of that class. The module's interface typically declares the constructors as ordinary procedures, and most of the other ADT operations as methods of that class. However, such an approach does not easily encapsulate multiple representational variants found in an ADT. It also can undermine the extensibility of object-oriented programs. In a pure object-oriented program that uses interfaces as types, types refer to behaviors not representations.\nExample: implementation of the abstract stack.\nAs an example, here is an implementation of the abstract stack above in the C programming language.\nImperative-style interface.\nAn imperative-style interface might be:\ntypedef struct stack_Rep stack_Rep; // type: stack instance representation (opaque record)\ntypedef stack_Rep* stack_T; // type: handle to a stack instance (opaque pointer)\ntypedef void* stack_Item; // type: value stored in stack instance (arbitrary address)\nstack_T stack_create(void); // creates a new empty stack instance\nvoid stack_push(stack_T s, stack_Item x); // adds an item at the top of the stack\nstack_Item stack_pop(stack_T s); // removes the top item from the stack and returns it\nbool stack_empty(stack_T s); // checks whether stack is empty\nThis interface could be used in the following manner:\nstack_T s = stack_create(); // creates a new empty stack instance\nint x = 17;\nstack_push(s, &amp;x); // adds the address of x at the top of the stack\nvoid* y = stack_pop(s); // removes the address of x from the stack and returns it\nif (stack_empty(s)) { } // does something if stack is empty\nThis interface can be implemented in many ways. The implementation may be arbitrarily inefficient, since the formal definition of the ADT, above, does not specify how much space the stack may use, nor how long each operation should take. It also does not specify whether the stack state \"s\" continues to exist after a call \"x\" \u2190 pop(\"s\").\nIn practice the formal definition should specify that the space is proportional to the number of items pushed and not yet popped; and that every one of the operations above must finish in a constant amount of time, independently of that number. To comply with these additional specifications, the implementation could use a linked list, or an array (with dynamic resizing) together with two integers (an item count and the array size).\nFunctional-style interface.\nFunctional-style ADT definitions are more appropriate for functional programming languages, and vice versa. However, one can provide a functional-style interface even in an imperative language like C. For example:\ntypedef struct stack_Rep stack_Rep; // type: stack state representation (opaque record)\ntypedef stack_Rep* stack_T; // type: handle to a stack state (opaque pointer)\ntypedef void* stack_Item; // type: value of a stack state (arbitrary address)\nstack_T stack_empty(void); // returns the empty stack state\nstack_T stack_push(stack_T s, stack_Item x); // adds an item at the top of the stack state and returns the resulting stack state\nstack_T stack_pop(stack_T s); // removes the top item from the stack state and returns the resulting stack state\nstack_Item stack_top(stack_T s); // returns the top item of the stack state\nADT libraries.\nMany modern programming languages, such as C++ and Java, come with standard libraries that implement several common ADTs, such as those listed above.\nBuilt-in abstract data types.\nThe specification of some programming languages is intentionally vague about the representation of certain built-in data types, defining only the operations that can be done on them. Therefore, those types can be viewed as \"built-in ADTs\". Examples are the arrays in many scripting languages, such as Awk, Lua, and Perl, which can be regarded as an implementation of the abstract list."}
{"id": "2351", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=2351", "title": "Acquired Immunodeficiency Syndrome", "text": ""}
{"id": "2357", "revid": "30879071", "url": "https://en.wikipedia.org/wiki?curid=2357", "title": "American Football League", "text": "The American Football League (AFL) was a major professional American football league that operated for ten seasons from 1960 until 1970, when it merged with the older National Football League (NFL), and became the American Football Conference. The upstart AFL operated in direct competition with the more established NFL throughout its existence. It was more successful than earlier rivals to the NFL with the same name, the 1926, 1936 and 1940 leagues, and the later All-America Football Conference (which existed between 1944 and 1950 but only played between 1946 and 1949).\nThis fourth version of the AFL was the most successful, created by a number of owners who had been refused NFL expansion franchises or had minor shares of NFL franchises. The AFL's original lineup consisted of an Eastern division of the New York Titans, Boston Patriots, Buffalo Bills, and the Houston Oilers, and a Western division of the Los Angeles Chargers, Denver Broncos, Oakland Raiders, and Dallas Texans. The league first gained attention by signing 75% of the NFL's first-round draft choices in 1960, including Houston's successful signing of college star and Heisman Trophy winner Billy Cannon.\nWhile the first years of the AFL saw uneven competition and low attendance, the league was buttressed by a generous television contract with the American Broadcasting Company (ABC) (followed by a contract with the competing National Broadcasting Company [NBC] for games starting with the 1965 season) that broadcast the more offense-oriented football league nationwide. Continuing to attract top talent from colleges and the NFL by the mid-1960s, as well as successful franchise shifts of the Chargers from L.A. south to San Diego and the Texans north to Kansas City (becoming the Kansas City Chiefs), the AFL established a dedicated following. The transformation of the struggling Titans into the New York Jets under new ownership, including the signing of University of Alabama star quarterback Joe Namath, further solidified the league's reputation among the major media.\nAs fierce competition made player salaries skyrocket in both leagues, especially after a series of \"raids\", the leagues agreed to a merger in 1966. Among the conditions were a common draft and a championship game played between the two league champions first played in early 1967, which would eventually become known as the Super Bowl.\nThe AFL and NFL operated as separate leagues until 1970, with separate regular season and playoff schedules except for the championship game. NFL Commissioner Pete Rozelle also became chief executive of the AFL from July 26, 1966, through the completion of the merger. During this time the AFL expanded, adding the Miami Dolphins and Cincinnati Bengals. After losses by the Kansas City Chiefs and Oakland Raiders in the first two AFL-NFL World Championship Game to the Green Bay Packers (1966\u201367), the New York Jets and Chiefs won Super Bowls III and IV (1968\u201369) respectively, cementing the league's claim to being an equal to the NFL.\nIn 1970, the AFL was absorbed into the NFL and the league reorganized with the ten AFL franchises along with three existing NFL teams: the Baltimore Colts, the Cleveland Browns, and the Pittsburgh Steelers, becoming part of the newly formed American Football Conference.\nLeague history.\nDuring the 1950s, the National Football League had grown to rival Major League Baseball as one of the most popular professional sports leagues in the United States. One franchise that did not share in this newfound success of the league was the Chicago Cardinals \u2013 owned by the Bidwill family \u2013 who had become overshadowed by the more popular Chicago Bears. The Bidwills hoped to move their franchise, preferably to St. Louis, but could not come to terms with the league, which demanded money before it would approve the move. Needing cash, the Bidwills began entertaining offers from would-be investors, and one of the men who approached the Bidwills was Lamar Hunt, son and heir of millionaire oilman H. L. Hunt. Hunt offered to buy the Cardinals and move them to Dallas, where he had grown up. However, these negotiations came to nothing, since the Bidwills insisted on retaining a controlling interest in the franchise and were unwilling to move their team to a city where a previous NFL franchise had failed in . While Hunt negotiated with the Bidwills, similar offers were made by Bud Adams, Bob Howsam, and Max Winter.\nWhen Hunt, Adams, and Howsam were unable to secure a controlling interest in the Cardinals, they approached NFL commissioner Bert Bell and proposed the addition of expansion teams. Bell, wary of expanding the 12-team league and risking its newfound success, rejected the offer. On his return flight to Dallas, Hunt conceived the idea of an entirely new league and decided to contact the others who had shown interest in purchasing the Cardinals. In addition to Adams, Howsam, and Winter, Hunt reached out to Bill Boyer, Winter's business partner, to gauge their interest in starting a new league. Hunt's first meeting with Adams was held in March 1959. Hunt, who felt a regional rivalry would be critical for the success of the new league, convinced Adams to join and found his team in Houston. Hunt next secured an agreement from Howsam to bring a team to Denver.\nAfter Winter and Boyer agreed to start a team in Minneapolis-Saint Paul, the new league had its first four teams. Hunt then approached Willard Rhodes, who hoped to bring pro football to Seattle. However, not wanting to undermine its own brand, the University of Washington was unwilling to let the fledgling league use Husky Stadium, and Rhodes' effort came to nothing (Seattle would later get a pro football team of its own). Hunt also sought franchises in Los Angeles, Buffalo and New York City. During the summer of 1959, he sought the blessings of the NFL for his nascent league, as he did not seek a potentially costly rivalry. Within weeks of the July 1959 announcement of the league's formation, Hunt received commitments from Barron Hilton and Harry Wismer to bring teams to Los Angeles and New York, respectively. His initial efforts for Buffalo, however, were rebuffed, when Hunt's first choice of owner, Pat McGroder, declined to take part; McGroder had hoped that the threat of the AFL would be enough to prompt the NFL to expand to Buffalo.\nOn August 14, 1959, the first league meeting was held in Chicago, and charter memberships were given to Dallas, New York, Houston, Denver, Los Angeles, and Minneapolis-Saint Paul. On August 22, the league officially was named the American Football League at a meeting in Dallas. The NFL's initial reaction was not as openly hostile as it had been with the earlier All-America Football Conference (AAFC), as Bell had even given his public approval; but he died suddenly in October 1959, and individual NFL owners soon began a campaign to undermine the new league. AFL owners were approached with promises of new NFL franchises or ownership stakes in existing ones. Only the party from Minneapolis-Saint Paul accepted, and with the addition of Ole Haugsrud and Bernie Ridder the Minnesota group joined the NFL in 1961 as the Minnesota Vikings. The older league also announced on August 29 that it had conveniently reversed its position against expansion, and planned to bring new NFL teams to Houston and Dallas, to start play in 1961. (The NFL did not expand to Houston at that time, the promised Dallas team \u2013 the Dallas Cowboys \u2013 actually started play in 1960, and the Vikings began play in 1961.) Finally, the NFL quickly came to terms with the Bidwills and allowed them to relocate the struggling Cardinals to St. Louis, eliminating that city as a potential AFL market.\nRalph Wilson, who owned a minority interest in the NFL's Detroit Lions at the time, initially announced he was placing a team in Miami, but like the Seattle situation, was also rebuffed by local ownership (like Seattle, Miami would later get a pro football team of its own as well); given five other choices, Wilson negotiated with McGroder and brought the team that became the Bills to Buffalo. Buffalo was officially awarded its franchise on October 28. During a league meeting on November 22, a 10-man ownership group from Boston (led by Billy Sullivan) was awarded the AFL's eighth team. On November 30, 1959, Joe Foss, a World War II Marine fighter ace and former governor of South Dakota, was named the AFL's first commissioner. Foss commissioned a friend of Harry Wismer's to develop the AFL's eagle-on-football logo. Hunt was elected President of the AFL on January 26, 1960.\nThe AFL draft.\nThe AFL's first draft took place the same day Boston was awarded its franchise, and lasted 33 rounds. The league held a second draft on December 2, which lasted for 20 rounds. Because the Oakland Raiders joined after the AFL draft, they inherited Minnesota's selections. A special \"allocation draft\" was held in January 1960, to allow the Raiders to stock their team, as some of the other AFL teams had already signed some of Minneapolis' original draft choices.\nCrisis and success (1960\u201361).\nIn November 1959, Minneapolis-Saint Paul owner Max Winter announced his intent to leave the AFL to accept a franchise offer from the NFL. In 1961, his team began play in the NFL as the Minnesota Vikings. Los Angeles Chargers owner Barron Hilton demanded that a replacement for Minnesota be placed in California, to reduce his team's operating costs and to create a rivalry. After a brief search, Oakland was chosen and an ownership group led by F. Wayne Valley and local real estate developer Chet Soda was formed. After initially being called the Oakland \"Se\u00f1ores\", the Oakland Raiders officially joined the AFL on January 30, 1960.\nThe AFL's first major success came when the Houston Oilers signed Billy Cannon, the All-American and 1959 Heisman Trophy winner from LSU. Cannon signed a $100,000 contract to play for the Oilers, despite having already signed a $50,000 contract with the NFL's Los Angeles Rams. The Oilers filed suit and claimed that Rams general manager Pete Rozelle had unduly manipulated Cannon. The court upheld the Houston contract, and with Cannon the Oilers appeared in the AFL's first three championship games (winning two).\nOn June 9, 1960, the league signed a five-year television contract with ABC, which brought in revenues of approximately $2.125 million per year for the entire league. On June 17, the AFL filed an antitrust lawsuit against the NFL, which was dismissed in 1962 after a two-month trial. The AFL began regular-season play (a night game on Friday, September 9, 1960) with eight teams in the league \u2013 the Boston Patriots, Buffalo Bills, Dallas Texans, Denver Broncos, Houston Oilers, Los Angeles Chargers, New York Titans, and Oakland Raiders. Raiders' co-owner Wayne Valley dubbed the AFL ownership \"The Foolish Club\", a term Lamar Hunt subsequently used on team photographs he sent as Christmas gifts.\nThe Oilers became the first-ever league champions by defeating the Chargers, 24\u201316, in the AFL Championship on January 1, 1961. Attendance for the 1960 season was respectable for a new league, but not nearly that of the NFL. In 1960, the NFL averaged attendance of more than 40,000 fans per game and more popular NFL teams in 1960 regularly saw attendance figures in excess of 50,000 per game, while CFL attendances averaged approximately 20,000 per game. By comparison, AFL attendance averaged about 16,500 per game and generally hovered between 10,000 and 20,000 per game. Professional football was still primarily a gate-driven business in 1960, so low attendance meant financial losses. The Raiders, with a league-worst average attendance of just 9,612, lost $500,000 in their first year and only survived after receiving a $400,000 loan from Bills owner Ralph Wilson. In an early sign of stability, however, the AFL did not lose any teams after its first year of operation. In fact, the only major change was the Chargers' move from Los Angeles to nearby San Diego (they would return to Los Angeles in 2017).\nOn August 8, 1961, the AFL challenged the Canadian Football League to an exhibition game that would feature the Hamilton Tiger-Cats and the Buffalo Bills, which was attended by 24,376 spectators. Playing at Civic Stadium in Hamilton, Ontario, the Tiger-Cats defeated the Bills 38\u201321 playing a mix of AFL and CFL rules.\nMovement and instability (1962\u201363).\nWhile the Oilers found instant success in the AFL, other teams did not fare as well. The Oakland Raiders and New York Titans struggled on and off the field during their first few seasons in the league. Oakland's eight-man ownership group was reduced to just three in 1961, after heavy financial losses in their first season. Attendance for home games was poor, partly due to the team playing in the San Francisco Bay Area\u2014which already had an established NFL team (the San Francisco 49ers)\u2014but the product on the field was also to blame. After winning six games in their debut season, the Raiders won a total of three times in the 1961 and 1962 seasons. Oakland took part in a 1961 supplemental draft meant to boost the weaker teams in the league, but it did little good. They participated in another such draft in 1962.\nThe Titans fared a little better on the field but had their own financial troubles. Attendance was so low for home games that team owner Harry Wismer had fans move to seats closer to the field to give the illusion of a fuller stadium on television. Eventually Wismer could no longer afford to meet his payroll, and on November 8, 1962, the AFL took over operations of the team. The Titans were sold to a five-person ownership group headed by Sonny Werblin on March 28, 1963, and in April the new owners changed the team's name to the New York Jets.\nThe Raiders and Titans both finished last in their respective divisions in the 1962 season. The Texans and Oilers, winners of their divisions, faced each other for the 1962 AFL Championship on December 23. The Texans dethroned the two-time champion Oilers, 20\u201317, in a double-overtime contest that was, at the time, professional football's longest-ever game.\nIn 1963, the Texans became the second AFL team to move to a new city. Lamar Hunt felt that despite winning the league championship in 1962, the Texans could not sufficiently profit in the same market as the Dallas Cowboys, which entered the NFL as an expansion franchise in 1960. After meetings with New Orleans, Atlanta, and Miami, Hunt announced on May 22 that the Texans' new home would be Kansas City, Missouri. Kansas City mayor Harold Roe Bartle (nicknamed \"Chief\") was instrumental in his city's success in attracting the team. Partly to honor Bartle, the franchise officially became the Kansas City Chiefs on May 26.\nThe San Diego Chargers, under head coach Sid Gillman, won a decisive 51\u201310 victory over the Boston Patriots for the 1963 AFL Championship. Confident that his team was capable of beating the NFL-champion Chicago Bears (he had the Chargers' rings inscribed with the phrase \"World Champions\"), Gillman approached NFL Commissioner Pete Rozelle and proposed a final championship game between the two teams. Rozelle declined the offer; however, the game would be instituted three seasons later.\nWatershed years (1964\u201365).\nA series of events throughout the next few years demonstrated the AFL's ability to achieve a greater level of equality with the NFL. On January 29, 1964, the AFL signed a lucrative $36\u00a0million television contract with NBC (beginning in the 1965 season), which gave the league money it needed to compete with the NFL for players. Pittsburgh Steelers owner Art Rooney was quoted as saying to NFL Commissioner Pete Rozelle that \"They don't have to call us 'Mister' anymore\". A single-game attendance record was set on November 8, 1964, when 61,929 fans packed Shea Stadium to watch the New York Jets and Buffalo Bills.\nThe bidding war for players between the AFL and NFL escalated in 1965. The Chiefs drafted University of Kansas star Gale Sayers in the first round of the 1965 AFL draft (held November 28, 1964), while the Chicago Bears did the same in the NFL draft. Sayers eventually signed with the Bears. A similar situation occurred when the New York Jets and the NFL's St. Louis Cardinals both drafted University of Alabama quarterback Joe Namath. In what was viewed as a key victory for the AFL, Namath signed a $427,000 contract with the Jets on January 2, 1965 (the deal included a new car). It was the highest amount of money ever paid to a collegiate football player, and is cited as the strongest contributing factor to the eventual merger between the two leagues.\nAfter the 1963 season, the Newark Bears of the Atlantic Coast Football League expressed interest in joining the AFL; concerns over having to split the New York metro area with the still-uncertain Jets were a factor in the Bears' bid being rejected. In 1965, Milwaukee officials tried to lure an expansion team to play at Milwaukee County Stadium where the Green Bay Packers had played parts of their home schedule after an unsuccessful attempt to lure the Packers there full-time, but Packers head coach Vince Lombardi invoked the team's exclusive lease, and additionally, signed an extension to keep some home games in Milwaukee until 1976. In early 1965, the AFL awarded its first expansion team to Rankin Smith of Atlanta. The NFL quickly counteroffered Smith a franchise, which Smith accepted; the Atlanta Falcons began play as an NFL franchise. In March 1965, Joe Robbie had met with Commissioner Foss to inquire about an expansion franchise for Miami. On May 6, after Atlanta's exit, Robbie secured an agreement with Miami mayor Robert King High to bring a team to Miami. League expansion was approved at a meeting held on June 7, and on August 16 the AFL's ninth franchise was officially awarded to Robbie and television star Danny Thomas. The Miami Dolphins joined the league for a fee of $7.5\u00a0million and started play in the AFL's Eastern Division in 1966. The AFL also planned to add two more teams by 1967.\nEscalation and merger (1966\u201367).\nIn 1966, the rivalry between the AFL and NFL reached an all-time peak. On April 7, Joe Foss resigned as AFL commissioner. His successor was Oakland Raiders head coach and general manager Al Davis, who had been instrumental in turning around the fortunes of that franchise. No longer content with trying to outbid the NFL for college talent, the AFL under Davis started to recruit players already on NFL squads. Davis's strategy focused on quarterbacks in particular, and in two months he persuaded seven NFL quarterbacks to sign with the AFL. Although Davis's intention was to help the AFL win the bidding war, some AFL and NFL owners saw the escalation as detrimental to both leagues. Alarmed with the rate of spending in the league, Hilton Hotels forced Barron Hilton to relinquish his stake in the Chargers as a condition of maintaining his leadership role with the hotel chain.\nThe same month Davis was named commissioner, several NFL owners, headed by Dallas Cowboys general manager Tex Schramm, secretly approached Lamar Hunt and other AFL owners and started negotiations with the AFL to merge. A series of secret meetings commenced in Dallas to discuss the concerns of both leagues over rapidly increasing player salaries, as well as the practice of player poaching. Hunt and Schramm completed the basic groundwork for a merger of the two leagues by the end of May, and on June 8, 1966, the merger was officially announced. Under the terms of the agreement, the two leagues would hold a common player draft. The agreement also called for a title game to be played between the champions of the respective leagues. The two leagues would be fully merged by 1970, NFL commissioner Pete Rozelle would remain as commissioner of the merged league, which would be named the NFL. Additional expansion teams would eventually be awarded by 1970 or soon thereafter to bring it to a 28-team league. (The additional expansion would not happen until 1976.) The AFL also agreed to pay indemnities of $18\u00a0million to the NFL over 20 years. In protest, Davis resigned as AFL commissioner on July 25 rather than remain until the completion of the merger, and Milt Woodard was named president of the AFL, with the \"commissioner\" title vacated because of Rozelle's expanded role.\nOn January 15, 1967, the first-ever championship game between the two separate professional football leagues, the \"AFL-NFL World Championship Game\" (retroactively referred to as Super Bowl I), was played in Los Angeles. After a close first half, the NFL champion Green Bay Packers overwhelmed the AFL champion Kansas City Chiefs, 35\u201310. The loss reinforced for many the notion that the AFL was an inferior league. Packers head coach Vince Lombardi stated after the game, \"I do not think they are as good as the top teams in the National Football League.\"\nThe second AFL-NFL Championship (Super Bowl II) yielded a similar result. The Oakland Raiders\u2014who had easily beaten the Houston Oilers to win their first AFL championship\u2014were overmatched by the Packers, 33\u201314. The more experienced Packers capitalized on a number of Raiders miscues and never trailed. Green Bay defensive tackle Henry Jordan offered a compliment to Oakland and the AFL, when he said, \"...\u00a0the AFL is becoming much more sophisticated on offense. I think the league has always had good personnel, but the blocks were subtler and better conceived in this game.\"\nThe AFL added its tenth and final team on May 24, 1967, when it awarded the league's second expansion franchise to an ownership group from Cincinnati, Ohio, headed by NFL legend Paul Brown. Although Brown had intended to join the NFL, he agreed to join the AFL when he learned that his team would be included in the NFL once the merger was completed. The Cincinnati Bengals began play in the 1968 season, finishing last in the Western Division.\nLegitimacy and the end of an era (1968\u20131970).\nWhile many AFL players and observers believed their league was the equal of the NFL, their first two Super Bowl performances did nothing to prove it. However, on November 17, 1968, when NBC cut away from a game between the Jets and Raiders to air the children's movie \"Heidi\", the ensuing uproar helped disprove the notion that fans still considered the AFL an inferior product. The perception of AFL inferiority forever changed on January 12, 1969, when the AFL Champion New York Jets shocked the heavily favored NFL Champion Baltimore Colts in Super Bowl III. The Colts, who entered the contest favored by as many as 18 points, had completed the 1968 NFL season with a 13\u20131 record, and won the NFL title with a convincing 34\u20130 win over the Cleveland Browns. Led by their stalwart defense\u2014which allowed a record-low 144 points\u2014the 1968 Colts were considered one of the best-ever NFL teams.\nBy contrast, the Jets had allowed 280 points, the highest total for any division winner in the two leagues. They had also only narrowly beaten the favored Oakland Raiders 27\u201323 in the AFL championship game. Jets quarterback Joe Namath recalled that in the days leading up to the game, he grew increasingly angry when told New York had no chance to beat Baltimore. Three days before the game, a frustrated Namath responded to a heckler at the Touchdown Club in Miami by declaring, \"We're going to win Sunday, I'll guarantee you.\"\nNamath and the Jets made good on his guarantee as they held the Colts scoreless until late in the fourth quarter. The Jets won, 16\u20137, in what is considered one of the greatest upsets in American sports history. With the win, the AFL finally achieved parity with the NFL and legitimized the merger of the two leagues. That notion was reinforced one year later in Super Bowl IV, when the AFL champion Kansas City Chiefs upset the NFL champion Minnesota Vikings, 23\u20137, in the last championship game to be played between the two leagues. The Vikings, favored by 12\u00bd points, were held to just 67 rushing yards.\nThe last game in AFL history was the AFL All-Star Game, held in Houston's Astrodome on January 17, 1970. The Western All-Stars, led by Chargers quarterback John Hadl, defeated the Eastern All-Stars, 26\u20133. Buffalo rookie running back O.J. Simpson carried the ball for the last play in AFL history. Hadl was named the game's Most Valuable Player.\nPrior to the start of the 1970 NFL season, the merged league was organized into two conferences of three divisions each. All ten AFL teams made up the bulk of the new American Football Conference. To avoid having an inequitable number of teams in each conference, the leagues voted to move three NFL teams to the AFC. Motivated by the prospect of an intrastate rivalry with the Bengals as well as by personal animosity toward Paul Brown, Cleveland Browns owner Art Modell quickly offered to include his team in the AFC. He helped persuade the Pittsburgh Steelers (the Browns' archrivals) and Baltimore Colts (who shared the Baltimore-Washington market with the Washington Redskins) to follow suit, and each team received US$3\u00a0million to make the switch. The remaining 13 NFL teams became part of the National Football Conference.\nPro Football Hall of Fame receiver Charlie Joiner, who started his career with the Houston Oilers (1969), was the last AFL player active in professional football, retiring after the 1986 season, when he played for the San Diego Chargers.\nLegacy.\nOverview.\nThe American Football League stands as the only professional football league to successfully compete against the NFL. When the two leagues merged in 1970, all ten AFL franchises and their statistics became part of the new NFL. Every other professional league that had competed against the NFL before the AFL\u2013NFL merger had folded completely: the three previous leagues named \"American Football League\" and the All-America Football Conference. From an earlier AFL (1936\u20131937), only the Cleveland Rams (now the Los Angeles Rams) joined the NFL and are currently operating, as are the Cleveland Browns and the San Francisco 49ers from the AAFC. A third AAFC team, the Baltimore Colts (not related to the 1953\u20131983 Baltimore Colts or to the current Indianapolis Colts franchise), played only one year in the NFL, disbanding at the end of the 1950 season. The league resulting from the merger was a 26-team juggernaut (since expanded to 32) with television rights covering all of the Big Three television networks and teams in close proximity to almost all of the top 40 metropolitan areas, a fact that has precluded any other competing league from gaining traction since the merger; failed attempts to mimic the AFL's success included the World Football League (1974\u201375), United States Football League (1983\u201385), the United Football League (2009\u20132012) and the AAF (2019), and two iterations of the XFL (2001 and 2020).\nThe AFL was also the most successful of numerous upstart leagues of the 1960s and 1970s that attempted to challenge a major professional league's dominance. All nine teams that were in the AFL at the time the merger was agreed upon were accepted into the league intact (as was the tenth team added between the time of the merger's agreement and finalization), and none of the AFL's teams have ever folded. For comparison, the World Hockey Association (1972\u201379) managed to have four of its six remaining teams merged into the National Hockey League, which actually caused the older league to contract a franchise, but WHA teams were forced to disperse the majority of their rosters and restart as expansion teams. The merged WHA teams were also not financially sound (in large part from the hefty expansion fees the NHL imposed on them), and three of the four were forced to relocate within 20 years. Like the WHA, The American Basketball Association (1967\u201376) also managed to have only four of its teams merged into the National Basketball Association, and the rest of the league was forced to fold. Both the WHA and ABA lost several teams to financial insolvency over the course of their existences. The Continental League, a proposed third league for Major League Baseball that was to begin play in 1961, never played a single game, largely because MLB responded to the proposal by expanding to four of that league's proposed cities. Historically, the only other professional sports league in the United States to exhibit a comparable level of franchise stability from its inception was the American League of Major League Baseball, which made its debut in the early 20th century.\nRule changes.\nThe NFL adopted some of the innovations introduced by the AFL immediately and a few others in the years following the merger. One was including the names on player jerseys. The older league also adopted the practice of using the stadium scoreboard clocks to keep track of the official game time, instead of just having a stopwatch used by the referee. The AFL played a 14-game schedule for its entire existence, starting in 1960. The NFL, which had played a 12-game schedule since 1947, changed to a 14-game schedule in 1961, a year after the American Football League instituted it. The AFL also introduced the two-point conversion to professional football thirty-four years before the NFL instituted it in 1994 (college football had adopted the two-point conversion in the late 1950s). All of these innovations pioneered by the AFL, including its more exciting style of play and colorful uniforms, have essentially made today's professional football more like the AFL than like the old-line NFL. The AFL's challenge to the NFL also laid the groundwork for the Super Bowl, which has become the standard for championship contests in the United States of America.\nTelevision.\nThe NFL also adapted how the AFL used the growing power of televised football games, which were bolstered with the help of major network contracts (first with ABC and later with NBC). With that first contract with ABC, the AFL adopted the first-ever cooperative television plan for professional football, in which the proceeds were divided equally among member clubs. It featured many outstanding games, such as the classic 1962 double-overtime American Football League championship game between the Dallas Texans and the defending champion Houston Oilers. At the time it was the longest professional football championship game ever played. The AFL also appealed to fans by offering a flashier style of play (just like the ABA in basketball), compared to the more conservative game of the NFL. Long passes (\"bombs\") were commonplace in AFL offenses, led by such talented quarterbacks as John Hadl, Daryle Lamonica and Len Dawson.\nDespite having a national television contract, the AFL often found itself trying to gain a foothold, only to come up against roadblocks. For example, CBS-TV, which broadcast NFL games, ignored and did not report scores from the innovative AFL, on orders from the NFL. It was only after the merger agreement was announced that CBS began to give out AFL scores.\nExpanding and reintroducing the sport to more cities.\nThe AFL took advantage of the burgeoning popularity of football by locating teams in major cities that lacked NFL franchises. Hunt's vision not only brought a new professional football league to California and New York, but introduced the sport to Colorado, restored it to Texas and later to fast-growing Florida, as well as bringing it to New England for the first time in 12 years. Buffalo, having lost its original NFL franchise in 1929 and turned down by the NFL at least twice (1940 and 1950) for a replacement, returned to the NFL with the merger. The return of football to Kansas City was the first time that city had seen professional football since the NFL's Kansas City Blues of the 1920s; the arrival of the Chiefs, and the contemporary arrival of the St. Louis Football Cardinals, brought professional football back to Missouri for the first time since the temporary St. Louis Gunners of 1934. St. Louis would later regain an NFL franchise in 1995 with the relocation of the LA Rams to the city. The Rams moved back in 2016.\nIn the case of the Dallas Cowboys, the NFL had long sought to return to the Dallas area after the Dallas Texans folded in 1952, but was originally met with strong opposition by Washington Redskins owner George Preston Marshall, who had enjoyed a monopoly as the only NFL team to represent the American South. Marshall later changed his position after future-Cowboys owner Clint Murchison bought the rights to Washington's fight song \"Hail to the Redskins\" and threatened to prevent Marshall from playing it at games. By then, the NFL wanted to quickly award the new Dallas franchise to Murchison so the team could immediately begin play and compete with the AFL's Texans. As a result, the Cowboys played its inaugural season in 1960 without the benefit of the NFL draft.\nAs part of the merger agreement, additional expansion teams would be awarded by 1970 or soon thereafter to bring the league to 28 franchises; this requirement was fulfilled when the Seattle Seahawks and the Tampa Bay Buccaneers began play in 1976. In addition, had it not been for the existence of the Oilers from 1960 to 1996, the Houston Texans also would likely not exist today; the 2002 expansion team restored professional football in Houston after the original charter AFL member Oilers relocated to become the Tennessee Titans.\nKevin Sherrington of \"The Dallas Morning News\" has argued that the presence of AFL and the subsequent merger radically altered the fortunes of the Pittsburgh Steelers, saving the team \"from stinking\". Before the merger, the Steelers had long been one of the NFL's worst teams. Constantly lacking the money to build a quality team, the Steelers had only posted eight winning seasons, and just one playoff appearance, since their first year of existence in 1933 until the end of the 1969 season. They also finished with a 1\u201313 record in 1969, tied with the Chicago Bears for the worst record in the NFL. The $3\u00a0million indemnity that the Steelers received for joining the AFC with the rest of the former AFL teams after the merger helped them rebuild into a contender, drafting eventual-Pro Football Hall of Famers like Terry Bradshaw and Joe Greene, and ultimately winning four Super Bowls in the 1970s. Since the 1970 merger, the Steelers have the NFL's highest winning percentage, the most total victories, the most trips to either conference championship game, are tied for the second most trips to the Super Bowl (tied with the Dallas Cowboys and Denver Broncos, trailing only the New England Patriots), and have won six Super Bowl championships, tied with the Patriots for the most in NFL history.\nEffects on players.\nPerhaps the greatest social legacy of the AFL was the domino effect of its policy of being more liberal than the entrenched NFL in offering opportunity for black players. While the NFL was still emerging from thirty years of segregation influenced by Washington Redskins' owner George Preston Marshall, the AFL actively recruited from small and predominantly black colleges. The AFL's color-blindness led not only to the explosion of black talent on the field, but to the eventual entry of blacks into scouting, coordinating, and ultimately head coaching positions, long after the league ceased to exist.\nThe AFL's free agents came from several sources. Some were players who could not find success playing in the NFL, while another source was the Canadian Football League. In the late 1950s, many players released by the NFL, or un-drafted and unsigned out of college by the NFL, went North to try their luck with the CFL, and later returned to the states to play in the AFL.\nIn the league's first years, players such as Oilers' George Blanda, Chargers/Bills' Jack Kemp, Texans' Len Dawson, the NY Titans' Don Maynard, Raiders/Patriots/Jets' Babe Parilli, Pats' Bob Dee proved to be AFL standouts. Other players such as the Broncos' Frank Tripucka, the Pats' Gino Cappelletti, the Bills' Cookie Gilchrist and the Chargers' Tobin Rote, Sam DeLuca and Dave Kocourek also made their mark to give the fledgling league badly needed credibility. Rounding out this mix of potential talent were the true \"free agents\", the walk-ons and the \"wanna-be's\", who tried out in droves for the chance to play professional American football.\nAfter the AFL\u2013NFL merger agreement in 1966, and after the AFL's Jets defeated an extremely strong Baltimore Colts team, a popular misconception fostered by the NFL and spread by media reports was that the AFL defeated the NFL because of the Common Draft instituted in 1967. This apparently was meant to assert that the AFL could not achieve parity as long as it had to compete with the NFL in the draft. But the 1968 Jets had less than a handful of \"common draftees\". Their stars were honed in the AFL, many of them since the Titans days.\nPlayers who chose the AFL to develop their talent included Lance Alworth and Ron Mix of the Chargers, who had also been drafted by the NFL's San Francisco 49ers and Baltimore Colts respectively. Both eventually were elected to the Pro Football Hall of Fame after earning recognition during their careers as being among the best at their positions. Among specific teams, the 1964 Buffalo Bills stood out by holding their opponents to a pro football record 913 yards rushing on 300 attempts, while also recording fifty quarterback sacks in a 14-game schedule.\nIn 2009, a five-part series, \"\", on the \"Showtime Network\", refuted many of the long-held misconceptions about the AFL. In it, Abner Haynes tells of how his father forbade him to accept being drafted by the NFL, after drunken scouts from that league had visited the Haynes home; the NFL Cowboys' Tex Schramm is quoted as saying that if his team had ever agreed to play the AFL's Dallas Texans, they would very likely have lost; George Blanda makes a case for more AFL players being inducted to the Pro Football Hall of Fame by pointing out that Hall of Famer Willie Brown was cut by the Houston Oilers because he couldn't cover Oilers flanker Charlie Hennigan in practice. Later, when Brown was with the Broncos, Hennigan needed nine catches in one game against the Broncos to break Lionel Taylor's Professional Football record of 100 catches in one season. Hennigan caught the nine passes and broke the record, even though he was covered by Brown.\nInfluence on professional football coaching.\nThe AFL also spawned coaches whose style and techniques have profoundly affected the play of professional football to this day. In addition to AFL greats like Hank Stram, Lou Saban, Sid Gillman and Al Davis were eventual hall of fame coaches such as Bill Walsh, a prot\u00e9g\u00e9 of Davis with the AFL Oakland Raiders for one season; and Chuck Noll, who worked for Gillman and the AFL LA/San Diego Chargers from 1960 through 1965. Others include Buddy Ryan (AFL's New York Jets), Chuck Knox (Jets), Walt Michaels (Jets), and John Madden (AFL's Oakland Raiders). Additionally, many prominent coaches began their pro football careers as players in the AFL, including Sam Wyche (Cincinnati Bengals), Marty Schottenheimer (Buffalo Bills), Wayne Fontes (Jets), and two-time Super Bowl winner Tom Flores (Oakland Raiders). Flores also has a Super Bowl ring as a player (1969 Kansas City Chiefs).\nAFL 50th Anniversary Celebration.\nAs the influence of the AFL continues through the present, the 50th anniversary of its launch was celebrated during 2009. The season-long celebration began in August with the 2009 Pro Football Hall of Fame Game in Canton, Ohio, between two AFC teams (as opposed to the AFC-vs-NFC format the game first adopted in 1971). The opponents were two of the original AFL franchises, the Buffalo Bills and Tennessee Titans (the former Houston Oilers). Bills' owner Ralph C. Wilson Jr. (a 2009 Hall of Fame inductee) and Titans' owner Bud Adams were the only surviving members of the Foolish Club at the time (both are now deceased; Wilson's estate sold the team in 2014), the eight original owners of AFL franchises. (As of the season, the Titans and Chiefs are still owned by descendants of the original eight owners.)\nThe Hall of Fame Game was the first of several \"Legacy Weekends\", during which each of the \"original eight\" AFL teams sported uniforms from their AFL era. Each of the 8 teams took part in at least two such \"legacy\" games. On-field officials also wore red-and-white-striped AFL uniforms during these games.\nIn the fall of 2009, the Showtime pay-cable network premiered \"\", a 5-part documentary series produced by NFL Films that features vintage game film and interviews as well as more recent interviews with those associated with the AFL.\nThe NFL sanctioned a variety of \"Legacy\" gear to celebrate the AFL anniversary, such as \"throwback\" jerseys, T-shirts, signs, pennants and banners, including items with the logos and colors of the Dallas Texans, Houston Oilers, and New York Titans, the three of the Original Eight AFL teams which have changed names or venues. A December 5, 2009, story by Ken Belson in \"The New York Times\" quotes league officials as stating that AFL \"Legacy\" gear made up twenty to thirty percent of the league's annual $3\u00a0billion merchandise income. Fan favorites were the Denver Broncos' vertically striped socks, which could not be re-stocked quickly enough.\nAFL franchises.\nToday, two of the NFL's eight divisions are composed entirely of former AFL teams, the AFC West (Broncos, Chargers, Chiefs, and Raiders) and the AFC East (Bills, Dolphins, Jets, and Patriots). Additionally, the Bengals now play in the AFC North and the Tennessee Titans (formerly the Oilers) play in the AFC South.\nAll of the stadiums used in the AFL have since been retired by the NFL. The stadiums are either being used for other uses (the former San Diego Stadium, Oakland\u2013Alameda County Coliseum, Los Angeles Memorial Coliseum, Fenway Park, Nickerson Field, Alumni Stadium, Nippert Stadium, the Cotton Bowl, Balboa Stadium and Kezar Stadium), still standing but currently vacant (Houston Astrodome), or demolished.\nAFL playoffs.\nFrom 1960 to 1968, the AFL determined its champion via a single-elimination playoff game between the winners of its two divisions. The home teams alternated each year by division, so in 1968 the Jets hosted the Raiders, even though Oakland had a better record (this was changed in 1969). In 1963, the Buffalo Bills and Boston Patriots finished tied with identical records of 7\u20136\u20131 in the AFL East Division. There was no tie-breaker protocol in place, so a one-game playoff was held in War Memorial Stadium in December. The visiting Patriots defeated the host Bills 26\u20138. The Patriots traveled to San Diego as the Chargers completed a three-game season sweep over the weary Patriots with a 51\u201310 victory. A similar situation occurred in the 1968 season, when the Oakland Raiders and the Kansas City Chiefs finished the regular season tied with identical records of 12\u20132 in the AFL West Division. The Raiders beat the Chiefs 41\u20136 in a division playoff to qualify for the AFL Championship Game. In 1969, the final year of the independent AFL, Professional Football's first \"wild card\" playoffs were conducted. A four-team playoff was held, with the second-place teams in each division playing the winner of the other division. The Chiefs upset the Raiders in Oakland 17\u20137 in the league's Championship, the final AFL game played. The Kansas City Chiefs were the first Super Bowl champion to win two road playoff games and the first wildcard team to win the Super Bowl, although the term \"wildcard\" was coined by the media, and not used officially until several years later.\nAFL All-Star games.\nThe AFL did not play an All-Star game after its first season in 1960, but did stage All-Star games for the 1961 through 1969 seasons. All-Star teams from the Eastern and Western divisions played each other after every season except 1965. That season, the league champion Buffalo Bills played all-stars from the other teams.\nAfter the 1964 season, the AFL All-Star game had been scheduled for early 1965 in New Orleans' Tulane Stadium. After numerous black players were refused service by a number of area hotels and businesses, black and white players alike called for a boycott. Led by Bills players such as Cookie Gilchrist, the players successfully lobbied to have the game moved to Houston's Jeppesen Stadium.\nAll-Time AFL Team.\nAs chosen by 1969 AFL Hall of Fame Selection committee members:\nAFL records.\nThe following is a sample of some records set during the existence of the league. The NFL considers AFL statistics and records equivalent to its own."}
{"id": "2358", "revid": "27506221", "url": "https://en.wikipedia.org/wiki?curid=2358", "title": "A.S. Roma", "text": "Associazione Sportiva Roma (, ; \"Rome Sport Association\"), commonly referred to as Roma (), is an Italian professional football club based in Rome. Founded by a merger in 1927, Roma have participated in the top-tier of Italian football for all of their existence except for 1951\u201352 season. Roma have won Serie A three times, in 1941\u201342, 1982\u201383 and 2000\u201301, as well as winning nine Coppa Italia titles and two Supercoppa Italiana titles. In European competitions, Roma won the Inter-Cities Fairs Cup in 1960\u201361 and were runners-up in the 1983\u201384 European Cup and the 1990\u201391 UEFA Cup.\nFifteen players have won the FIFA World Cup while playing at Roma: Ferraris, Guaita and Masetti (1934); Donati, Monzeglio and Serantoni (1938); Bruno Conti (1982); Rudi Voller and Berthold (1990); Aldair (1994); Candela (1998); Cafu (2002); Daniele De Rossi, Simone Perrotta and Francesco Totti (2006).\nSince 1953, Roma have played their home matches at the Stadio Olimpico, a venue they share with city rivals Lazio. With a capacity of over 72,000, it is the second-largest of its kind in Italy, with only the San Siro able to seat more. The club plan to move to a new stadium, though this is yet to start construction.\nThe club's home colours are carmine red and golden yellow, which gives Roma their nickname \"I Giallorossi\" (\"The Yellow and Reds\"). These colours have often been combined with white shorts. Their club badge features a she-wolf, an allusion to the founding myth of Rome.\nHistory.\nA.S. Roma was founded in the spring of 1927 when Italo Foschi initiated the merger of three older Italian Football Championship clubs from the city of Rome: Roman FC, SS Alba-Audace and Fortitudo-Pro Roma SGS. Italo Foschi was an important Roman representative of the ruling National Fascist Party.\nThe purpose of the merger was to give the Italian capital a strong club to rival that of the more dominant Northern Italian clubs of the time. The only major Roman club to resist the merger was Lazio because of the intervention of the army General Vaccaro, a member of the club and executive of Italian Football Federation.\nAll three founding clubs were relegated, but the fascist-aligned FIGC bet over the capacity of the new team to give a stronger representation to the capital of Italy, and they were awarded a wild card for the Divisione Nazionale, the Serie A forerunner. The club played its earliest seasons at the Motovelodromo Appio stadium, before settling in the working-class streets of Testaccio, where it built an all-wooden ground Campo Testaccio; this was opened in November 1929. An early season in which Roma made a large mark was the 1930\u201331 championship, where the club finished as runners-up behind Juventus. Captain Attilio Ferraris, along with Guido Masetti, Fulvio Bernardini and Rodolfo Volk, were highly important players during this period.\nFirst title victory and decline.\nAfter a slump in league form and the departure of high key players, Roma eventually rebuilt their squad adding goalscorers such as the Argentine Enrique Guaita. Under the management of Luigi Barbesino, the Roman club came close to their first title in 1935\u201336, finishing just one point behind champions Bologna.\nRoma returned to form after being inconsistent for much of the late 1930s. Roma recorded an unexpected title triumph in the 1941\u201342 season by winning their first \"Scudetto\" title. The 18 goals scored by local player Amedeo Amadei were essential to the Alfr\u00e9d Schaffer-coached Roma side winning the title. At the time, Italy was involved in World War II and Roma were playing at the Stadio del Partito Nazionale Fascista.\nIn the years just after the war, Roma were unable to recapture their league stature from the early 1940s. Roma finished in the lower half of Serie A for five seasons in a row, before eventually succumbing to their only ever relegation to Serie B at the end of the 1950\u201351 season, around a decade after their championship victory. Under future Italy national team manager Giuseppe Viani, promotion straight back up was achieved.\nAfter returning to the Serie A, Roma managed to stabilise themselves as a top-half club again with players such as Egisto Pandolfini, Dino Da Costa and Dane Helge Bron\u00e9e. Their best finish of this period was under the management of Englishman Jesse Carver, when in 1954\u201355, they finished as runners-up after Udinese, who originally finished second were relegated for corruption. Although Roma were unable to break into the top four during the following decade, they did achieve some measure of cup success. Their first honour outside of Italy was recorded in 1960\u201361 when Roma won the Inter-Cities Fairs Cup by defeating Birmingham City 4\u20132 in the finals. A few years later, Roma won their first Coppa Italia trophy in 1963\u201364 after defeating Torino 1\u20130.\nTheir lowest point came during the 1964\u201365 season, when manager Juan Carlos Lorenzo announced the club could not pay its players and was unlikely to be able to afford to travel to Vicenza to fulfil its next fixture. Supporters kept the club going with a fundraiser at the Sistine Theatre and bankruptcy was avoided with the election of a new club president Franco Evangelisti.\nTheir second Coppa Italia trophy was won in 1968\u201369, when it competed in a small, league-like system. Giacomo Losi set a Roma appearance record in 1969 with 450 appearances in all competitions, a record that would last 38 years.\nTime of mixed fortunes.\nRoma were able to add another cup to their collection in 1972, with a 3\u20131 victory over Blackpool in the Anglo-Italian Cup. During much of the 1970s, Roma's appearance in the top half of Serie A was sporadic. The best place the club were able to achieve during the decade was third in 1974\u201375. Notable players who turned out for the club during this period included midfielders Giancarlo De Sisti and Francesco Rocca.\nThe dawning of a newly successful era in Roma's footballing history was brought in with another Coppa Italia victory, they defeated Torino on penalties to win the 1979\u201380 edition. Roma would reach heights in the league which they had not touched since the 1940s by narrowly and controversially finishing as runners-up to Juventus in 1980\u201381. Former Milan player Nils Liedholm was the manager at the time, with players such as Bruno Conti, Agostino Di Bartolomei, Roberto Pruzzo and Falc\u00e3o.\nThe second \"Scudetto\" did not elude Roma for much longer. In 1982\u201383, the Roman club won the title for the first time in 41 years, amidst celebrations in the capital. The following season, Roma finished as runners-up in Italy and collected a Coppa Italia title, they also finished as runners-up in the European Cup final of 1984. The European Cup final with Liverpool ended in a 1\u20131 draw with a goal from Pruzzo, but Roma eventually lost in the penalty shoot-out. Roma's successful run in the 1980s would finish with a runners-up spot in 1985\u201386 and a Coppa Italia victory, beating out Sampdoria 3\u20132.\nAfter, a comparative decline began in the league, one of the few league highs from the following period being a third-place finish in 1987\u201388. At the start of the 1990s, the club was involved in an all-Italian UEFA Cup final, where they lost 2\u20131 to Internazionale in 1991. The same season, the club won its seventh Coppa Italia and ended runners-up to Sampdoria in the Supercoppa Italiana. Aside from finishing runners-up to Torino in a Coppa Italia final, the rest of the decade was largely sub-par in the history of Roma, particularly in the league, where the highest they could manage was fourth in 1997\u201398. The early 1990s also saw the emergence of homegrown striker Francesco Totti, who would go on to be an important member of the team and the club's iconic captain.\nIn the new millennium.\n2000\u20132010.\nRoma returned to form in the 2000s, beginning the decade in great style by winning their third Serie A title in 2000\u201301. The \"Scudetto\" was won on the last day of the season after defeating Parma 3\u20131, edging Juventus by two points. The club's captain, Francesco Totti, was a large reason for the title victory and he would become one of the main heroes in the club's history, going on to break several club records. Other important players during this period included Aldair, Cafu, Gabriel Batistuta and Vincenzo Montella.\nThe club attempted to defend the title in the following season but ended as runners-up to Juventus by one point. This would be the start of Roma finishing as runners-up several times in both Serie A and Coppa Italia during the 2000s \u2013 they lost out 4\u20132 to Milan in the Coppa Italia final of 2003 and lost to Milan again by finishing second in Serie A for the 2003\u201304 season. The club also re-capitalized several time in 2003\u201304 season. In November 2003, \u20ac37.5\u00a0million was injected by \"Roma 2000\" to cover the half-year loss and loss carried from previous year. and again on 30 June for \u20ac44.57\u00a0million. Through stock market, a further \u20ac19.850\u00a0million of new shares issued, and at the year end, the share capital was \u20ac19.878\u00a0million, which was unchanged . The following season also saw the departure of Walter Samuel for \u20ac25\u00a0million and Emerson for \u20ac28\u00a0million, which decreased the strength of the squad. The \"Giallorossi\" therefore finished in eighth place, one of the worst of recent seasons.\nOn 9 July 2006, Roma's Francesco Totti, Daniele De Rossi and Simone Perrotta were part of the Italy national team which defeated France in the 2006 FIFA World Cup Final. A Serie A scandal was revealed during 2006; Roma were not one of the teams involved. After punishments were issued, Roma was re-classified as runners-up for 2005\u201306, the same season they finished second in the Coppa Italia losing to Internazionale. In the two following seasons, 2006\u201307 and 2007\u201308, Roma finished as Serie A runners-up, meaning that in the 2000s, Roma have finished in the top two positions more than any other decade in their history. Meanwhile, in the UEFA Champions League during both of these seasons, they reached the quarter-finals before going out to Manchester United. Despite the sloppy start in the 2008\u201309 Champions League, Roma managed to reach the knockout stage ahead of Chelsea in their group, thus finishing for the first time in their history as winners of the group stage. However, the \"Giallorossi\", would lose to Arsenal in the knockout stage on penalty kicks, ending their Champions League campaign.\nAfter a disappointing start to the 2009\u201310 season, Claudio Ranieri replaced Luciano Spalletti as head coach. At the time of the switch, Roma lay bottom of the Serie A table after losses to Juventus and Genoa. Despite this setback, Roma would later embark on an incredible unbeaten streak of 24 matches in the league \u2013 with the last of the 24 being a 2\u20131 win over rivals Lazio, whereby Roma came from 1\u20130 down at half-time to defeat their city rivals after Ranieri courageously substituted both Totti and De Rossi at the interval. The \"Giallorossi\" were on top of the table at one point, before a loss to Sampdoria later in the season. Roma would finish runners-up to Internazionale yet again in both Serie A and the Coppa Italia. This rounded out a highly successful decade in Roma's history, following somewhat mediocre results of the 1990s. During the 2000s, Roma had finally recaptured the \"Scudetto\", two Coppa Italia trophies, and their first two Supercoppa Italiana titles. Other notable contributions to the club's history have included a return to the Champions League quarter-finals (in the 2006\u201307 and 2007\u201308 editions) since 1984, six runners up positions in the league, four Coppa Italia finals and three Supercoppa finals \u2013 marking Roma's greatest ever decade.\nThe \"AS Roma SPV LLC\" era.\nIn the summer of 2010, the Sensi family agreed to relinquish their control of Roma as part of a debt-settlement agreement. This brought an end to the presidential reign of the Sensi family, who had presided over the club since 1993. Until a new owner was appointed, Rosella Sensi would continue her directorial role of the club. The 2010\u201311 season had once again seen Roma start off with mixed fortunes on both a domestic and European level. These included losses against Cagliari, Brescia and a 2\u20130 defeat against Bayern Munich in the group stages of the Champions League, a match which saw manager Claudio Ranieri openly criticized by his players. However, these were accompanied by victories against Inter and a sensational victory against Bayern Munich in the return fixture, which saw Roma fight back from 0\u20132 down at half-time to emerge as 3\u20132 winners. Following a series of poor results that saw Roma engage in a winless-streak of five consecutive matches, Ranieri resigned as head coach in February 2011, and former striker Vincenzo Montella was appointed as caretaker manager until the end of the season. It was also during this season that Roma icon Francesco Totti scored his 200th Serie A goal against Fiorentina in March 2011, becoming only the sixth player to achieve such a feat.\nOn 16 April 2011, the takeover contract was closed with an American investment group led by Thomas R. DiBenedetto, with James Pallotta, Michael Ruane and Richard D'Amore as partners. DiBenedetto became the 22nd president of the club, serving from 27 September 2011 to 27 August 2012 and was succeeded by Pallotta. The new intermediate holding company, NEEP Roma Holding, was 60% owned by American's \"AS Roma SPV, LLC\" and the rest (40%) was retained by the creditor of Sensi, UniCredit. In turn, NEEP owned all shares held previously by Sensi (about 67%) with the rest free float in the stock market. UniCredit later disinvested NEEP Roma Holding to sell to \"AS Roma SPV, LLC\" and Pallotta.\nThe new ownership immediately went into effect by making significant changes in the club, hiring Walter Sabatini as director of football and former Spanish international and Barcelona B coach Luis Enrique as manager. The first high-profile player signings from the duo were attacking midfielder Erik Lamela from River Plate, forward Bojan from Barcelona, goalkeeper Maarten Stekelenburg from Ajax and unattached defender Gabriel Heinze. The club also sold and released defender John Arne Riise, goalkeeper Doni and forwards J\u00e9r\u00e9my M\u00e9nez and Mirko Vu\u010dini\u0107. At the financial level, the company had recapitalised for more than \u20ac100\u00a0million, the last recapitalisation occurring in the early 2000s.\nRoma, however, was eliminated from 2011\u201312 UEFA Europa League play-off round. After the formal takeover on 18 August, Roma bought forward Dani Osvaldo, midfielders Miralem Pjani\u0107 and Fernando Gago and defender Simon Kj\u00e6r, as well as youngster Fabio Borini, which cost the club more than \u20ac40\u00a0million. In 2012, Pallotta became the new president.\nThe 2012\u201313 pre-season started with the June hiring of former manager Zden\u011bk Zeman. Zeman replaced Luis Enrique who resigned at the end of the 2011\u201312 season. Luis Enrique's lone season reign had seen the disappointing loss to Slovan Bratislava in the UEFA Europa League, as well as the inability to qualify for international competitions for the 2012\u201313 season. Roma eventually finished seventh, losing the Europa League chase to rivals Lazio, Napoli and Internazionale. Zeman brought back his high-scoring 4\u20133\u20133 formation and his hard working ethic which successfully guided former team Pescara to the Serie A. However, he was sacked on 2 February 2013. He was replaced by caretaker manager Aurelio Andreazzoli, whose reign saw the continuation of a disappointing season, with the team ending up in sixth place in Serie A, while also losing 1\u20130 to rivals Lazio in the Coppa Italia final. As a result, Roma missed out on European competition for the second-straight season.\nOn 12 June 2013, Pallotta announced that Rudi Garcia had been appointed the new manager of Roma. He enjoyed a fantastic start to his Roma career, winning his first ten matches (an all-time Serie A record) including a 2\u20130 derby win against Lazio, a 0\u20133 victory away to Internazionale and a 2\u20130 home win over title rivals Napoli. During this run, Roma scored 24 times while conceding just once, away to Parma. The 2013\u201314 season saw one of Roma's best in Serie A, the club tallying an impressive 85 points and finishing second to Juventus, who won the league with a record-breaking 102 points. Roma's defence was significantly better than in previous seasons, with only 25 goals conceded and a total of 21 clean sheets, including nine in their first ten matches.\nIn 2014\u201315, Roma finished second behind Juventus for the second consecutive season after a poor run of form in 2015. At the end of season, the club was sanctioned for loss making and breaking UEFA Financial Fair Play Regulations.\nOn 12 August 2015, and after months of speculation during the 2015 summer transfer market, Roma acquired Bosnia international, Edin D\u017eeko, from Manchester City on a \u20ac4\u00a0million loan with an \u20ac11\u00a0million option to buy clause, which is activated on 1 October 2015, making a star striker permanent addition to the club.\nD\u017eeko made his Serie A debut ten days later, playing the entirety of a 1\u20131 draw at Hellas Verona, and scored his first goal for the club in his second appearance on 30 August, the winning goal in the 79th minute to defeat reigning champions Juventus 2\u20131 at the Stadio Olimpico.\nOn 13 January 2016, Garcia was sacked after a run of one win in seven Serie A matches. Luciano Spalletti was subsequently appointed manager of Roma for his second spell. On 21 February, Totti publicly criticised Spalletti due to his own lack of playing-time since returning from injury. Consequently, Totti was subsequently dropped by Spalletti for Roma's 5\u20130 win over Palermo, with the decision causing an uproar among the fans and in the media. After their initial disagreements, Spalletti began to use Totti as an immediate impact substitute, which proved to be an effective decision, as the Roma number 10 rediscovered his form and contributed with four goals and one assist after coming off the bench in five consecutive Serie A matches. As a result, Spalletti was able to lead Roma from a mid-table spot to a third-place finish in Serie A, clinching the UEFA Champions League play-off spot.\nDuring the summer of 2016, Roma lost star midfielder Miralem Pjani\u0107 to rivals Juventus to improve its financial position. On 27 April 2017, Roma appointed Sevilla FC's Sporting director Monchi as their new sporting director. On 28 May 2017, on the last day of the 2016\u201317 season, Francesco Totti made his 786th and final appearance for Roma before retiring in a 3\u20132 home win against Genoa, coming on as a substitute for Mohamed Salah in the 54th minute and received a standing ovation from the fans. The win saw Roma finish second in Serie A behind Juventus. Following Totti's retirement, Daniele De Rossi became club captain and signed a new two-year contract.\nOn 13 June 2017, former Roma player Eusebio Di Francesco was appointed as the club's new manager, replacing Spalletti, who had left the club to take charge of Internazionale. Roma again lost a key player during the summer transfer window, with Mohamed Salah joining Liverpool F.C. for a fee of 39m euro (\u00a334m). Several new players joined the club, including a club-record deal for Sampdoria striker Patrik Schick and Aleksandar Kolarov in a \u20ac5m (\u00a34.4m) move from Manchester City Di Francesco also brought in Gregoire Defrel from his previous club Sassuolo in an \u20ac18 million deal. On 5 December 2017 the Stadio della Roma project, after experiencing five years worth of delays due to conflicting interests from various parties in the Roman city government, was given the go-ahead to begin construction. It is slated to open in time for the 2020\u201321 season and will replace the Stadio Olimpico as Roma's ground. In the 2017\u201318 UEFA Champions League group stage, Roma were drawn in a tough Group C with Chelsea, Atletico Madrid and Qarabag. However, after performing strongly in the group stage, including a 3\u20130 home victory against Chelsea, Roma progressed to the knockout stages as Group C winners after Diego Perotti's lone goal in a 1\u20130 win over Qarabag. After progressing past Shakhtar Donetsk in the Round of 16, Roma were drawn against FC Barcelona in the quarter-finals. On 4 April 2018, Roma were defeated 4\u20131 away to Barcelona at the Camp Nou in the first leg, after own goals from Daniele De Rossi and Kostas Manolas, although Edin D\u017eeko provided a late glimmer of hope by scoring an away goal. On 10 April, Roma pulled off a sensational second-leg comeback at the Stadio Olimpico to beat Barcelona 3-0 and reach the Champions League semi-finals on away goals. An early goal from Edin D\u017eeko and a 58th-minute penalty from De Rossi had left the \"Giallorossi\" needing to score one more goal to progress before Manolas scored the crucial third goal, heading in at the near post with eight minutes remaining. By doing so, Roma became only the third team in Champions League history to overturn a first-leg defeat of three goals or more and reached the final four of the competition for the first time since 1984. Roma were subsequently drawn against Liverpool, the team that had defeated them in the 1984 European Cup Final, in the semi-finals. Liverpool would go on to win the tie 7\u20136 on aggregate. Roma ended the 2017\u20132018 season in 3rd place on 77 points, qualifying for the following seasons Champions League.\nIn the summer of 2018, Roma were busy in the transfer market, in large parts thanks to the \u20ac83 million they received from reaching the Champions League semi finals, as well as selling Alisson for a world record \u20ac72 million including bonuses to Liverpool. In a very busy window, Roma spent \u20ac150 million to sign the likes of Shick, Nzonzi, Pastore, Kluivert, Defrel and more, while selling their 2 starting midfielders from the previous season, Nainggolan and Strootman. The 2018-2019 Serie A season was a disappointment for Roma as they spent the first half of the season bouncing between 6th and 10th place. This was compounded by the fact that many of the new signings failed to make an impact. After Roma were eliminated against Porto 4\u20133 on aggregate in the Champions League round of 16, Di Francesco was sacked and replaced by Claudio Ranieri who served as caretaker manager. The following day, sporting director Monchi stepped down. He stated: \u201cI left Roma for a simple reason: I realized that the owners\u2019 ideas were different to mine. The President thought it was better to go to the right, I thought it was better to go to the left\u201d. James Pallotta hit back saying \u201cI gave him [Monchi] 100 percent control to appoint the coach he wanted, to employ the assistant coaches and the performance staff, to manage the scouting and to bring in the players he wanted. If you look at our results and our performances, it's clear that this hasn't worked. He asked me to trust him and let him do it his way. We gave him complete control and now we have more injuries than we\u2019ve ever had and are in danger of missing out on finishing in the top 3 for the first time since 2014.\" In Monchi's 2 years at the club, he spent \u00a3208 million on 21 signings, however within 2 years, only 12 of his signings remained at the club. Under Ranieri results improved, however Roma failed to qualify for the Champions League, finishing in 6th place on 66 points.\nOn 11 June 2019, Roma appointed Paulo Fonseca as their new manager.\nIn December 2019, AS Roma SPV LLC was in final negotiations to sell the team for $872 million, to American businessman Dan Friedkin, however negotiations stalled during the COVID-19 pandemic. On 6 August 2020, Friedkin signed the preliminary contract to agree to pay $591 million to Pallotta, the main shareholder of Roma.\nOn May 4, 2021, the club announced that Fonseca would leave at the end of the 2020-21 season. The same day, Jose Mourinho was announced as Fonseca's replacement on a 3-year contract set to begin in the 2021-22 season.\nColours, kits, crests and nicknames.\nRoma's colours of carmine red with a golden yellow trim represents the traditional colours of Rome, the official seal of the Comune di Roma features the same colours. The gold and the purple-red represent Roman imperial dignity. White shorts and black socks are usually worn with the red shirt. However, in particularly high key matches, the shorts and socks are the same colour as the home shirt.\nThe kit itself was originally worn by \"Roman Football Club\"; one of the three clubs who merged to form the current incarnation in 1927. Because of the colours they wear, Roma are often nicknamed \"i giallorossi\" meaning the yellow-reds. Roma's away kit is traditionally white, with a third kit changing colour from time to time.\nA popular nickname for the club is \"i lupi\" (\"the wolves\") \u2013 the animal has always featured on the club's badge in different forms throughout their history. The emblem of the team is currently the one which was used when the club was first founded. It portrays the female wolf with the two infant brothers Romulus and Remus, illustrating the myth of the founding of Rome, superimposed on a bipartite golden yellow over a maroon red shield. In the myth from which the club takes their nickname and logo, the twins (sons of Mars and Rhea Silvia) are thrown into the river Tiber by their uncle Amulius. A she-wolf then saved the twins and looked after them. Eventually, the two twins took revenge on Amulius before falling-out themselves \u2013 Romulus killed Remus and was thus made king of a new city named in his honour, Rome.\nFacilities.\nStadiums.\nThe first sport facility Roma used was the Motovelodromo Appio, previously used by Alba-Audace. Roma only played the 1927\u201328 season there until they moved to Campo Testaccio the very next season. Campo Testaccio was used through 1929 to 1940. The team moved later to the Stadio Nazionale del PNF, where they spent 13 years before moving once again.\nIn the 1953\u201354 season, Roma moved to the Olympic arena, Stadio Olimpico, which it shares with Lazio. The arena has undergone several changes over the years. The most significant change took place in the nineties when Stadio Olimpico was demolished and then reconstructed for the 1990 FIFA World Cup, held in Italy. Roma have played almost every season since 1953\u201354, with exception of the 1989\u201390 seasons due to the reconstruction of Stadio Olimpico. That year, Roma played its home matches at Stadio Flaminio.\nOn 30 December 2012, Roma club president James Pallotta announced the construction of a new stadium in the Tor di Valle area of Rome. The new stadium, Stadio della Roma, will have a capacity of 52,500 spectators. On 2 February 2017, the Region of Lazio and the mayor of Rome rejected the proposal to build a new stadium. However, it was later approved on 24 February after final review of the stadium's design adjustments. In August 2017, the stadium suffered another delay, forcing Roma to renew their lease with the Stadio Olimpico until 2020. It is presently uncertain when the stadium will open. On 5 December 2017 the Stadio della Roma project, after experiencing five years worth of delays due to conflicting interests from various parties in the Roman city government, was given the go-ahead to begin construction, with the stadium expected to be ready to open for the 2020\u201321 season. On 26 February 2021, it was announced that the stadium project was halted.\nTrigoria.\nA sports centre located in at kilometre 3600 in south-east of Rome was purchased on 22 July 1977 by then club president Gaetano Anzalone. It was opened on 23 July 1979 as Anzalone's final act as president. The complex had its first expansion in 1984 when the club was handled by Dino Viola and another in 1998 under the chairmanship of Franco Sensi. The centre's official name is the Fulvio Bernardini di Trigoria, named after club icon Fulvio Bernardini.\nOn 4 September 2019, the Trigoria training ground began to serve also as a private school named 'Liceo Scientifico Sportivo A.S. Roma' exclusively educating only the team's youth players in a renovated building on the training ground premises. 80 students are currently enrolled in the school which features its own cafeteria and gym.\nThe centre is also known for hosting the Argentina national team during the 1990 FIFA World Cup, held in Italy.\nSupporters.\nRoma is the fifth-most supported football club in Italy \u2013 behind Juventus, Internazionale, A.C. Milan and Napoli \u2013 with approximately 7% of Italian football fans supporting the club, according to the Doxa Institute-L'Espresso's research of April 2006. Historically, the largest section of Roma supporters in the city of Rome have come from the inner-city, especially Testaccio.\nThe traditional ultras group of the club was \"Commando Ultr\u00e0 Curva Sud\" commonly abbreviated as \"CUCS\". This group was founded by the merger of many smaller groups and was considered one of the most historic in the history of European football. However, by the mid-1990s, \"CUCS\" had been usurped by rival factions and ultimately broke up. Since that time, the \"Curva Sud\" of the Stadio Olimpico has been controlled by more right-wing groups, including \"A.S. Roma Ultras\", \"Boys\" and \"Giovinezza\", among others. However, the oldest group, \"Fedayn\", is apolitical, and politics is not the main identity of Roma, just a part of their overall identity. Besides ultras groups, it is believed Roma fans support the left as opposed to Lazio supporters, which are notoriously proud of their right-wing affiliation.\nIn November 2015, Roma's ultras and their Lazio counterparts boycotted Roma's 1\u20130 victory in the \"Derby della Capitale\" in protest at new safety measures imposed at the Stadio Olimpico. The measures \u2013 imposed by Rome's prefect, Franco Gabrielli \u2013 had involved plastic glass dividing walls being installed in both the Curva Sud and Curva Nord, splitting the sections behind each goal in two. Both sets of ultras continued their protests for the rest of the season, including during Roma's 4\u20131 victory in the return fixture. Lazio's ultras returned to the Curva Nord for Roma's 1\u20134 victory in December 2016, but the Roma ultras continue to boycott matches.\nThe most known club anthem is \"Roma (non-si discute, si ama)\", also known as \"Roma Roma\", by singer Antonello Venditti. The title roughly means, \"Roma is not to be questioned, it is to be loved,\" and it is sung before each match. The song \"Grazie Roma\", by the same singer, is played at the end of victorious home matches. Recently, the main riff of The White Stripes' song \"Seven Nation Army\" has also become widely popular at matches.\nRivalries.\nIn Italian football, Roma is a club with many rivalries; first and foremost is their rivalry with Lazio, the club with whom they share the Stadio Olimpico. The derby between the two is called the \"Derby della Capitale\", it is amongst the most heated and emotional footballing rivalries in the world. The fixture has seen some occasional instances of violence in the past, including the death of Lazio fan Vincenzo Paparelli in 1979\u201380 as a result of an emergency flare fired from the Curva Sud, and the abandonment of a match in March 2004 following unfounded rumours of a fatality which led to violence outside the stadium.\nAgainst Napoli, Roma also compete in the \"Derby del Sole\", meaning the \"Derby of the Sun\". Nowadays, fans also consider other Serie A giants like Juventus (a rivalry born especially in the 1980s), Milan and Internazionale (increased in recent years) among their rivals, as these four compete for the top four spots in the league table to secure a spot in the UEFA Champions League.\nHooliganism.\nRivalries with other teams have escalated into serious violence. A group of ultras who label themselves the Fedayn \u2014 'the devotees' \u2014 after a group of long-forgotten Iranian guerrilla fighters are regarded to be responsible for the organised hooliganism. In 2014 Daniele De Santis, a Roma ultra, was convicted of shooting Ciro Esposito and two others during clashes with Napoli fans who were in Rome for their club's Coppa Italia final against Fiorentina. Esposito died of his wounds. De Santis was sentenced to 26 years in prison, later reduced to 16 years on appeal. Roma ultras have displayed banners celebrating De Santis.\nThere have been multiple instances of Roma ultras attacking supporters of foreign clubs when playing in Rome. These attacks have regularly featured the Roma ultras using knives, poles, flares, bottles and stones on unarmed foreign supporters, resulting in multiple hospitalisations. Home games against Liverpool in 1984 and 2001, Middlesbrough in 2006, Manchester United in 2007, Arsenal in 2009, Tottenham Hotspur in 2012, and Chelsea in 2017 have all resulted in multiple stabbings and other injuries to foreign supporters. In 2018 Roma ultras travelling to an away game at Liverpool attacked home supporters, resulting in a home supporter being critically injured.\nChairmen history.\nRoma have had numerous chairmen ( or ) over the course of their history, some of which have been the owners and co-owners of the club, some of them were nominated by the owners. Franco Sensi was the chairman until his death in 2008, with his daughter, Roma CEO Rosella Sensi taking his place as chairman. Here is a complete list of Roma chairmen from 1927 until the present day.\nManagerial history.\nRoma have had many managers and trainers running the team during their history, here is a chronological list of them from 1927 onwards.\nHonours.\nNational titles.\nSerie A\nCoppa Italia\nSupercoppa Italiana\nSerie B\nEuropean titles.\nInter-Cities Fairs Cup\nHall of Fame.\nOn 7 October 2012, the AS Roma Hall of Fame was announced.\nThe Hall of Fame players were voted via the club's official website and a special Hall of Fame panel. In 2013 four players were voted in. In 2014, the third year of AS Roma Hall of Fame four more players were voted in.\nAdded in 2012:\nAdded in 2013:\nAdded in 2014:\nAdded in 2015:\nAdded in 2016:\nAdded in 2017:\nClub records and statistics.\nFrancesco Totti currently holds Roma's official appearance record, having made 786 appearances in all competitions, over the course of 25 seasons from 1993 until 2017. He also holds the record for Serie A appearances with 619, as he passed Giacomo Losi on 1 March 2008 during a home match against Parma.\nIncluding all competitions, Totti is the all-time leading goalscorer for Roma with 307 goals since joining the club, 250 of which were scored in Serie A (another Roma record). Roberto Pruzzo, who was the all-time topscorer since 1988, comes in second in all competitions with 138. In 1930\u201331, Rodolfo Volk scored 29 goals in Serie A over the course of a single season. Not only was Volk the league's top scorer that year, he also set a Roma record for most goals scored in a season which would later be matched by Edin D\u017eeko in 2016\u201317.\nIts major founders Fortitudo and Alba having been relegated at the end of 1926\u201327 campaign, new-founded Roma had to take part to Southern First Division championship (Serie B) for its inaugural season. Nevertheless, the FIGC decided on a special enlargement of first level division re-admitting AS Roma and SSC Napoli. The first ever official matches participated in by Roma was in the National Division, the predecessor of Serie A, of 1927\u201328, against Livorno, a 2\u20130 Roma win. The biggest ever victory recorded by Roma was 9\u20130 against Cremonese during the 1929\u201330 Serie A season. The heaviest defeat Roma have ever suffered is 1\u20137, which has occurred five times; against Juventus in 1931\u201332, Torino in 1947\u201348, Manchester United in 2006\u201307, Bayern Munich in 2014\u201315 and Fiorentina in 2018\u201319.\nAs a company.\nSince 1999, during Franco Sensi's period in charge, Associazione Sportiva Roma has been a listed Societ\u00e0 per azioni on Borsa Italiana. From 2004 to 2011, Roma's shares are distributed between; 67.1% to Compagnia Italpetroli SpA (the Sensi family \"holding\"; Banca di Roma later acquired 49% stake on Italpetroli due to debt restructuring) and 32.9% to other public shareholders.\nAlong with Lazio and Juventus, Roma is one of only three quotated Italian clubs. According to The Football Money League published by consultants Deloitte, in the 2010\u201311 season, Roma was the 15th highest-earning football club in the world with an estimated revenue of \u20ac143.5\u00a0million.\nIn April 2008, after months of speculation, George Soros was confirmed by Rosella Sensi, CEO of Italian Serie A association football club A.S. Roma, to be bidding for a takeover. The takeover bid was successively rejected by the Sensi family, who instead preferred to maintain the club's ownership. On 17 August 2008 club chairman and owner Franco Sensi died after a long illness; his place at the chairmanship of the club was successively taken by his daughter Rosella.\nSince the takeover in 2011, NEEP Roma Holding S.p.A. has owned all shares Sensi previously hold. NEEP, itself a joint venture, was held by DiBenedetto AS Roma LLC (later renamed to AS Roma SPV, LLC) and Unicredit in 60\u201340 ratio from 2011 to 2013, which the former had four real person shareholders in equal ratio, led by future Roma president Thomas R. DiBenedetto (2011\u201312). The takeover also activated a mandatory bid of shares from the general public, however not all minority shareholders were willing to sell their shares. The mandatory bid meant NEEP held 78.038% of shares of AS Roma (increased from 67.1% of the Sensi). On 1 August 2013, the president of Roma as well as one of the four American shareholders of AS Roma SPV, LLC, James Pallotta, bought an additional 9% shares of NEEP Roma Holding from Unicredit (through Raptor Holdco LLC), as the bank was not willing to fully participate in the capital increase of NEEP from \u20ac120,000 to \u20ac160,008,905 (excluding share premium). On 4 April 2014 Starwood Capital Group also became the fifth shareholder of AS Roma SPV, as well as forming a strategic partnership with AS Roma SpA to develop real estate around the new stadium. The private investment firm was represented by Zsolt Kohalmi in AS Roma SPV, who was appointed on 4 April as a partner and head of European acquisitions of the firm. On 11 August 2014, UniCredit sold the remain shares on NEEP (of 31%) for \u20ac33\u00a0million which meant AS Roma SPV LLC (91%) and Raptor Holdco LLC (9%) were the sole intermediate holding company of AS Roma SpA.\nSince re-capitalization in 2003\u201304, Roma had a short-lived financial self-sustainability, until the takeover in 2011. The club had set up a special amortisation fund using Articolo 18-bis Legge 91/1981 mainly for the abnormal signings prior 2002\u201303 season, (such as Davide Bombardini for \u20ac11\u00a0million account value in June 2002, when the flopped player exchange boosted 2001\u201302 season result) and the tax payment of 2002\u201303 was rescheduled. In 2004\u201305, Roma made a net profit of \u20ac10,091,689 and followed by \u20ac804,285 in 2005\u201306. In 2006\u201307 season the accounting method changed to IFRS, which meant that the 2005\u201306 result was reclassified as net loss of \u20ac4,051,905 and 2006\u201307 season was net income of \u20ac10,135,539 (\u20ac14.011\u00a0million as a group). Moreover, the special fund (\u20ac80,189,123) was removed from the asset and co-currently for the equity as scheduled, meant Roma group had a negative equity of \u20ac8.795\u00a0million on 30 June 2007. Nevertheless, the club had sold the brand to a subsidiary which boost the profit in a separate financial statement, which \"La Repubblica\" described as \"doping\". In 2007\u201308, Roma made a net income of \u20ac18,699,219. (\u20ac19\u00a0million as a group) However, 2008\u201309 saw the decrease of gate and TV income, co-currently with finishing sixth in Serie A, which saw Roma made a net loss of \u20ac1,894,330. (\u20ac1.56\u00a0million as a group) The gate and TV income further slipped in 2009\u201310 with a net loss of \u20ac21,917,292 (already boosted by the sale of Alberto Aquilani; \u20ac22\u00a0million as a group) despite sporting success (finishing in second place in 2009\u201310). Moreover, despite a positive equity as a separate company (\u20ac105,142,589), the AS Roma Group had a negative equity on the consolidated balance sheet, and fell from +\u20ac8.8\u00a0million to \u2212\u20ac13.2\u00a0million. In the 2010\u201311 season, Roma was administrated by UniCredit as the Sensi family failed to repay the bank and the club was put on the market, and were expected to have a quiet transfer window. Concurrently with no selling profit on the players, Roma's net loss rose to \u20ac30,589,137 (\u20ac30.778\u00a0million as a group) and the new owner already planned a re-capitalization after the mandatory bid on the shares. On the positive side, TV income was increased from \u20ac75,150,744 to \u20ac78,041,642, and gate income increased from \u20ac23,821,218 to \u20ac31,017,179. This was because Roma entered 2010\u201311 Champions League, which counter-weighed the effect of the new collective agreement of Serie A. In 2011\u201312, the renewal of squad and participation in 2011\u201312 UEFA Europa League had worsened the financial result, which the \u20ac50\u00a0million capital increase (in advance) was counter-weighted totally by the net loss. In the 2012\u201313 season, the participation in domestic league only, was not only not harmful to the revenue but increase in gate income as well as decrease in wage bill, however Roma still did not yet break even (\u20ac40.130\u00a0million net loss in consolidated accounts). NEEP Roma also re-capitalized AS Roma in advance for another \u20ac26,550,000 during 2012\u201313. A proposed capital increase by \u20ac100\u00a0million for Roma was announced on 25 June 2014; however, until 22 May 2014, NEEP already injected \u20ac108\u00a0million into the club, which depends on public subscription; more than \u20ac8\u00a0million would convert to medium-long-term loan from shareholder instead of becoming share capital. Another capital increase was carried in 2018.\nA joint venture of Roma, which was owned by Roma (37.5%), S.S. Lazio (37.5%) and Parma F.C.(25%), Societ\u00e0 Diritti Sportivi S.r.l., was in the process of liquidation since 2005. The company was a joint-venture of four football clubs, including Fiorentina. After the bankruptcy of the old \"Viola\", however, both Roma and Lazio had increased their shares ratio from 25% to 37.5%. Another subsidiary, \"Soccer S.A.S. di Brand Management S.r.l.\", was a special-purpose entity (SPV) that Roma sold their brand to the subsidiary in 2007. In February 2015, another SPV, \"ASR Media and Sponsorship S.r.l\", was set up to secure a five-year bank loan of \u20ac175\u00a0million from Goldman Sachs, for three-month Euribor (min. 0.75%) + 6.25% spread (i.e. min. 7% interests rate p.a.).\nIn 2015, Inter and Roma were the only two Italian clubs that were sanctioned by UEFA for breaking UEFA Financial Fair Play Regulations, which they signed settlement agreements with UEFA. It was followed by Milan in 2018.\nRoma had compliance with the requirements and overall objective of the settlement agreement in 2018, which the club exited from settlement regime.\nSuperleague Formula.\nA.S. Roma had a team in the Superleague Formula race car series where teams were sponsored by football clubs. Roma's driver was ex-IndyCar Series driver Franck Perera. The team had posted three podiums and was operated by Alan Docking Racing."}
{"id": "2360", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=2360", "title": "Abu Nidal Organization", "text": "The Abu Nidal Organization (ANO) is the most common name for the Palestinian nationalist militant group Fatah \u2013 The Revolutionary Council (\"Fatah al-Majles al-Thawry\"). The ANO is named after its founder Abu Nidal. It was created by a split from Yasser Arafat's Fatah faction of the PLO in 1974. The group has been designated as a terrorist organization by the United States, the United Kingdom, Japan, Israel and the European Union.\nThe ANO was secular and anti-Western, but was not particularly associated with any ideology, or at least no such foundation was communicated. The organization was strongly linked with Abu Nidal's personal agenda. The group carried out hijackings, assassinations and kidnappings of diplomats, and attacks on synagogues \u2013 90 attacks during the period 1974\u20131992. Nidal died in Baghdad in 2002.\nFormation and background.\nThe ANO was originally formed as a result of the 1974 Rejectionist Front split in the PLO, after Arafat's Fatah had pushed through amendments of the PLO's goals, which were seen as a step towards compromise with Israel. Abu Nidal then moved to Ba'athist Iraq where he set up the ANO, which soon began a vicious string of terrorist attacks.\nIt hasn't clearly defined its ideological position, but was clearly opposed to any form of compromise or negotiation with Israel. It is known as one of the most uncompromisingly militant Palestinian groups ever. It had an estimated membership of several hundred, but its strength today is not known.\nANO attacks.\nThe ANO carried out attacks in 20 countries, killing or injuring almost 1,650 persons. Targets include the United States, the United Kingdom, France, Israel, moderate Palestinians, the PLO, and various Arab and European countries. The group has not attacked Western targets since the late 1980s.\nMajor attacks included the Rome and Vienna Airport Attacks in December 1985, the Neve Shalom synagogue in Istanbul and the Pan Am Flight 73 hijacking in Karachi in September 1986, and the \"City of Poros\" day-excursion ship attack in Greece in July 1988.\nThe ANO has been especially noted for its uncompromising stance on negotiation with Israel, treating anything less than all-out military struggle against Israel as treachery. This led the group to perform numerous attacks against the PLO, which had made clear it accepted a negotiated solution to the conflict. Fatah-RC is believed to have assassinated PLO deputy chief Abu Iyad and PLO security chief Abul Hul in Tunis in January 1991. It assassinated a Jordanian diplomat in Lebanon in January 1994 and has been linked to the killing of the PLO representative there. Noted PLO moderate Issam Sartawi was killed by the Fatah-RC in 1983. In the late 1970s, the group also made a failed assassination attempt on the present Palestinian president and PLO chairman, Mahmoud Abbas. These attacks, and numerous others, led to the PLO issuing a death sentence \"in absentia\" against Abu Nidal. In the early 1990s, it made an attempt to gain control of a refugee camp in Lebanon, but this was thwarted by PLO organizations."}
{"id": "2362", "revid": "2532392", "url": "https://en.wikipedia.org/wiki?curid=2362", "title": "Antibody", "text": "An antibody (Ab), also known as an immunoglobulin (Ig), is a large, Y-shaped protein used by the immune system to identify and neutralize foreign objects such as pathogenic bacteria and viruses. The antibody recognizes a unique molecule of the pathogen, called an antigen. Each tip of the \"Y\" of an antibody contains a paratope (analogous to a lock) that is specific for one particular epitope (analogous to a key) on an antigen, allowing these two structures to bind together with precision. Using this binding mechanism, an antibody can \"tag\" a microbe or an infected cell for attack by other parts of the immune system, or can neutralize it directly (for example, by blocking a part of a virus that is essential for its invasion).\nTo allow the immune system to recognize millions of different antigens, the antigen-binding sites at both tips of the antibody come in an equally wide variety.\nIn contrast, the remainder of the antibody is relatively constant. It only occurs in a few variants, which define the antibody's \"class\" or \"isotype\": IgA, IgD, IgE, IgG, or IgM.\nThe constant region at the trunk of the antibody includes sites involved in interactions with other components of the immune system. The class hence determines the function triggered by an antibody after binding to an antigen, in addition to some structural features.\nAntibodies from different classes also differ in where they are released in the body and at what stage of an immune response.\nTogether with B and T cells, antibodies are the most important part of the adaptive immune system.\nThey occur in two forms: attached to a B cell or in soluble form in extracellular fluids such as blood plasma.\nInitially, antibodies are attached to the surface of a B cell \u2013 they are then referred to as B-cell receptors (BCR).\nAfter an antigen binds to a BCR, the B cell activates to proliferate and differentiate into either plasma cells, which secrete soluble antibodies with the same paratope, or memory B cells, which survive in the body to enable long-lasting immunity to the antigen.\nSoluble antibodies are released into the blood and tissue fluids, as well as many secretions.\nBecause these fluids were traditionally known as humors, antibody-mediated immunity is sometimes known as, or considered a part of, humoral immunity. \nThe soluble Y-shaped units can occur individually as monomers, or in complexes of two to five units.\nAntibodies are glycoproteins belonging to the immunoglobulin superfamily.\nThe terms antibody and immunoglobulin are often used interchangeably, though the term 'antibody' is sometimes reserved for the secreted, soluble form, i.e. excluding B-cell receptors.\nStructure.\nAntibodies are heavy (~150\u00a0kDa) proteins of about 10 nm in size,\narranged in three globular regions that roughly form a Y shape.\nIn humans and most mammals, an antibody unit consists of four polypeptide chains; two identical \"heavy chains\" and two identical \"light chains\" connected by disulfide bonds.\nEach chain is a series of domains: somewhat similar sequences of about 110 amino acids each.\nThese domains are usually represented in simplified schematics as rectangles.\nLight chains consist of one variable domain VL and one constant domain CL, while heavy chains contain one variable domain VH and three to four constant domains CH1, CH2, ...\nStructurally an antibody is also partitioned into two antigen-binding fragments (Fab), containing one VL, VH, CL, and CH1 domain each, as well as the crystallisable fragment (Fc), forming the trunk of the Y shape.\nIn between them is a hinge region of the heavy chains, whose flexibility allows antibodies to bind to pairs of epitopes at various distances, to form complexes (dimers, trimers, etc.), and to bind effector molecules more easily.\nIn an electrophoresis test of blood proteins, antibodies mostly migrate to the last, gamma globulin fraction.\nConversely, most gamma-globulins are antibodies, which is why the two terms were historically used as synonyms, as were the symbols Ig and \u03b3.\nThis variant terminology fell out of use due to the correspondence being inexact and due to confusion with \u03b3 heavy chains which characterize the IgG class of antibodies.\nAntigen-binding site.\nThe variable domains can also be referred to as the FV region. It is the subregion of Fab that binds to an antigen.\nMore specifically, each variable domain contains three \"hypervariable regions\" \u2013 the amino acids seen there vary the most from antibody to antibody.\nWhen the protein folds, these regions give rise to three loops of \u03b2-strands, localised near one another on the surface of the antibody.\nThese loops are referred to as the complementarity-determining regions (CDRs), since their shape complements that of an antigen.\nThree CDRs from each of the heavy and light chains together form an antibody-binding site whose shape can be anything from a pocket to which a smaller antigen binds, to a larger surface, to a protrusion that sticks out into a groove in an antigen.\nTypically however only a few residues contribute to most of the binding energy.\nThe existence of two identical antibody-binding sites allows antibody molecules to bind strongly to multivalent antigen (repeating sites such as polysaccharides in bacterial cell walls, or other sites at some distance apart), as well as to form antibody complexes and larger antigen-antibody complexes. The resulting cross-linking plays a role in activating other parts of the immune system.\nThe structures of CDRs have been clustered and classified by Chothia et al.\nand more recently by North et al.\nand Nikoloudis et al.\nIn the framework of the immune network theory, CDRs are also called idiotypes. According to immune network theory, the adaptive immune system is regulated by interactions between idiotypes.\nFc region.\nThe Fc region (the trunk of the Y shape) is composed of constant domains from the heavy chains. Its role is in modulating immune cell activity: it is where effector molecules bind to, triggering various effects after the antibody Fab region binds to an antigen.\nEffector cells (such as macrophages or natural killer cells) bind via their Fc receptors (FcR) to the Fc region of an antibody, while the complement system is activated by binding the C1q protein complex.\nAnother role of the Fc region is to selectively distribute different antibody classes across the body. In particular, the neonatal Fc receptor (FcRn) binds to the Fc region of IgG antibodies to transport it across the placenta, from the mother to the fetus.\nAntibodies are glycoproteins, that is, they have carbohydrates (glycans) added to conserved amino acid residues. \nThese conserved glycosylation sites occur in the Fc region and influence interactions with effector molecules.\nProtein structure.\nThe N-terminus of each chain is situated at the tip.\nEach immunoglobulin domain has a similar structure, characteristic of all the members of the immunoglobulin superfamily:\nit is composed of between 7 (for constant domains) and 9 (for variable domains) \u03b2-strands, forming two beta sheets in a Greek key motif.\nThe sheets create a \"sandwich\" shape, the immunoglobulin fold, held together by a disulfide bond.\nAntibody complexes.\nSecreted antibodies can occur as a single Y-shaped unit, a monomer.\nHowever, some antibody classes also form dimers with two Ig units (as with IgA), tetramers with four Ig units (like teleost fish IgM), or pentamers with five Ig units (like mammalian IgM, which occasionally forms hexamers as well, with six units).\nAntibodies also form complexes by binding to antigen: this is called an antigen-antibody complex or \"immune complex\".\nSmall antigens can cross-link two antibodies, also leading to the formation of antibody dimers, trimers, tetramers, etc. \nMultivalent antigens (cells with multiple epitopes) can form larger complexes with antibodies.\nAn extreme example is the clumping, or agglutination, of red blood cells with antibodies in the Coombs test to determine blood groups: the large clumps become insoluble, leading to visually apparent precipitatation.\nB cell receptors.\nThe membrane-bound form of an antibody may be called a \"surface immunoglobulin\" (sIg) or a \"membrane immunoglobulin\" (mIg). It is part of the \"B cell receptor\" (BCR), which allows a B cell to detect when a specific antigen is present in the body and triggers B cell activation. The BCR is composed of surface-bound IgD or IgM antibodies and associated Ig-\u03b1 and Ig-\u03b2 heterodimers, which are capable of signal transduction. A typical human B cell will have 50,000 to 100,000 antibodies bound to its surface. Upon antigen binding, they cluster in large patches, which can exceed 1 micrometer in diameter, on lipid rafts that isolate the BCRs from most other cell signaling receptors.\nThese patches may improve the efficiency of the cellular immune response. In humans, the cell surface is bare around the B cell receptors for several hundred nanometers, which further isolates the BCRs from competing influences.\nClasses.\nAntibodies can come in different varieties known as \"isotypes\" or \"classes\". In placental mammals there are five antibody classes known as IgA, IgD, IgE, IgG, and IgM, which are further subdivided into subclasses such as IgA1, IgA2.\nThe prefix \"Ig\" stands for \"immunoglobulin\", while the suffix denotes the type of heavy chain the antibody contains: the heavy chain types \u03b1 (alpha), \u03b3 (gamma), \u03b4 (delta), \u03b5 (epsilon), \u03bc (mu) give rise to IgA, IgG, IgD, IgE, IgM, respectively.\nThe distinctive features of each class are determined by the part of the heavy chain within the hinge and Fc region.\nThe classes differ in their biological properties, functional locations and ability to deal with different antigens, as depicted in the table.\nFor example, IgE antibodies are responsible for an allergic response consisting of histamine release from mast cells, contributing to asthma. The antibody's variable region binds to allergic antigen, for example house dust mite particles, while its Fc region (in the \u03b5 heavy chains) binds to Fc receptor \u03b5 on a mast cell, triggering its degranulation: the release of molecules stored in its granules.\nThe antibody isotype of a B cell changes during cell development and activation. Immature B cells, which have never been exposed to an antigen, express only the IgM isotype in a cell surface bound form. The B lymphocyte, in this ready-to-respond form, is known as a \"naive B lymphocyte.\" The naive B lymphocyte expresses both surface IgM and IgD. The co-expression of both of these immunoglobulin isotypes renders the B cell ready to respond to antigen. B cell activation follows engagement of the cell-bound antibody molecule with an antigen, causing the cell to divide and differentiate into an antibody-producing cell called a plasma cell. In this activated form, the B cell starts to produce antibody in a secreted form rather than a membrane-bound form. Some daughter cells of the activated B cells undergo isotype switching, a mechanism that causes the production of antibodies to change from IgM or IgD to the other antibody isotypes, IgE, IgA, or IgG, that have defined roles in the immune system.\nLight chain types.\nIn mammals there are two types of immunoglobulin light chain, which are called lambda (\u03bb) and kappa (\u03ba). However, there is no known functional difference between them, and both can occur with any of the five major types of heavy chains. Each antibody contains two identical light chains: both \u03ba or both \u03bb. Proportions of \u03ba and \u03bb types vary by species and can be used to detect abnormal proliferation of B cell clones. Other types of light chains, such as the iota (\u03b9) chain, are found in other vertebrates like sharks (Chondrichthyes) and bony fishes (Teleostei).\nIn animals.\nIn most placental mammals the structure of antibodies is generally the same.\nJawed fish appear to be the most primitive animals that are able to make antibodies similar to those of mammals, although many features of their adaptive immunity appeared somewhat earlier.\nCartilaginous fish (such as sharks) produce heavy-chain-only antibodies (lacking light chains) which moreover feature longer chains, with five constant domains each.\nCamelids (such as camels, llamas, alpacas) are also notable for producing heavy-chain-only antibodies.\nAntibody\u2013antigen interactions.\nThe antibody's paratope interacts with the antigen's epitope. An antigen usually contains different epitopes along its surface arranged discontinuously, and dominant epitopes on a given antigen are called determinants.\nAntibody and antigen interact by spatial complementarity (lock and key). The molecular forces involved in the Fab-epitope interaction are weak and non-specific \u2013 for example electrostatic forces, hydrogen bonds, hydrophobic interactions, and van der Waals forces. This means binding between antibody and antigen is reversible, and the antibody's affinity towards an antigen is relative rather than absolute. Relatively weak binding also means it is possible for an antibody to cross-react with different antigens of different relative affinities.\nFunction.\nThe main categories of antibody action include the following:\nMore indirectly, an antibody can signal immune cells to present antibody fragments to T cells, or downregulate other immune cells to avoid autoimmunity.\nActivated B cells differentiate into either antibody-producing cells called plasma cells that secrete soluble antibody or memory cells that survive in the body for years afterward in order to allow the immune system to remember an antigen and respond faster upon future exposures.\nAt the prenatal and neonatal stages of life, the presence of antibodies is provided by passive immunization from the mother. Early endogenous antibody production varies for different kinds of antibodies, and usually appear within the first years of life. Since antibodies exist freely in the bloodstream, they are said to be part of the humoral immune system. Circulating antibodies are produced by clonal B cells that specifically respond to only one antigen (an example is a virus capsid protein fragment). Antibodies contribute to immunity in three ways: They prevent pathogens from entering or damaging cells by binding to them; they stimulate removal of pathogens by macrophages and other cells by coating the pathogen; and they trigger destruction of pathogens by stimulating other immune responses such as the complement pathway. Antibodies will also trigger vasoactive amine degranulation to contribute to immunity against certain types of antigens (helminths, allergens).\nActivation of complement.\nAntibodies that bind to surface antigens (for example, on bacteria) will attract the first component of the complement cascade with their Fc region and initiate activation of the \"classical\" complement system. This results in the killing of bacteria in two ways. First, the binding of the antibody and complement molecules marks the microbe for ingestion by phagocytes in a process called opsonization; these phagocytes are attracted by certain complement molecules generated in the complement cascade. Second, some complement system components form a membrane attack complex to assist antibodies to kill the bacterium directly (bacteriolysis).\nActivation of effector cells.\nTo combat pathogens that replicate outside cells, antibodies bind to pathogens to link them together, causing them to agglutinate. Since an antibody has at least two paratopes, it can bind more than one antigen by binding identical epitopes carried on the surfaces of these antigens. By coating the pathogen, antibodies stimulate effector functions against the pathogen in cells that recognize their Fc region.\nThose cells that recognize coated pathogens have Fc receptors, which, as the name suggests, interact with the Fc region of IgA, IgG, and IgE antibodies. The engagement of a particular antibody with the Fc receptor on a particular cell triggers an effector function of that cell; phagocytes will phagocytose, mast cells and neutrophils will degranulate, natural killer cells will release cytokines and cytotoxic molecules; that will ultimately result in destruction of the invading microbe. The activation of natural killer cells by antibodies initiates a cytotoxic mechanism known as antibody-dependent cell-mediated cytotoxicity (ADCC) \u2013 this process may explain the efficacy of monoclonal antibodies used in biological therapies against cancer. The Fc receptors are isotype-specific, which gives greater flexibility to the immune system, invoking only the appropriate immune mechanisms for distinct pathogens.\nNatural antibodies.\nHumans and higher primates also produce \"natural antibodies\" that are present in serum before viral infection. Natural antibodies have been defined as antibodies that are produced without any previous infection, vaccination, other foreign antigen exposure or passive immunization. These antibodies can activate the classical complement pathway leading to lysis of enveloped virus particles long before the adaptive immune response is activated. Many natural antibodies are directed against the disaccharide galactose \u03b1(1,3)-galactose (\u03b1-Gal), which is found as a terminal sugar on glycosylated cell surface proteins, and generated in response to production of this sugar by bacteria contained in the human gut. Rejection of xenotransplantated organs is thought to be, in part, the result of natural antibodies circulating in the serum of the recipient binding to \u03b1-Gal antigens expressed on the donor tissue.\nImmunoglobulin diversity.\nVirtually all microbes can trigger an antibody response. Successful recognition and eradication of many different types of microbes requires diversity among antibodies; their amino acid composition varies allowing them to interact with many different antigens. It has been estimated that humans generate about 10\u00a0billion different antibodies, each capable of binding a distinct epitope of an antigen. Although a huge repertoire of different antibodies is generated in a single individual, the number of genes available to make these proteins is limited by the size of the human genome. Several complex genetic mechanisms have evolved that allow vertebrate B cells to generate a diverse pool of antibodies from a relatively small number of antibody genes.\nDomain variability.\nThe chromosomal region that encodes an antibody is large and contains several distinct gene loci for each domain of the antibody\u2014the chromosome region containing heavy chain genes (IGH@) is found on chromosome 14, and the loci containing lambda and kappa light chain genes (IGL@ and IGK@) are found on chromosomes 22 and 2 in humans. One of these domains is called the variable domain, which is present in each heavy and light chain of every antibody, but can differ in different antibodies generated from distinct B cells. Differences, between the variable domains, are located on three loops known as hypervariable regions (HV-1, HV-2 and HV-3) or complementarity-determining regions (CDR1, CDR2 and CDR3). CDRs are supported within the variable domains by conserved framework regions. The heavy chain locus contains about 65 different variable domain genes that all differ in their CDRs. Combining these genes with an array of genes for other domains of the antibody generates a large cavalry of antibodies with a high degree of variability. This combination is called V(D)J recombination discussed below.\nV(D)J recombination.\nSomatic recombination of immunoglobulins, also known as \"V(D)J recombination\", involves the generation of a unique immunoglobulin variable region. The variable region of each immunoglobulin heavy or light chain is encoded in several pieces\u2014known as gene segments (subgenes). These segments are called variable (V), diversity (D) and joining (J) segments. V, D and J segments are found in Ig heavy chains, but only V and J segments are found in Ig light chains. Multiple copies of the V, D and J gene segments exist, and are tandemly arranged in the genomes of mammals. In the bone marrow, each developing B cell will assemble an immunoglobulin variable region by randomly selecting and combining one V, one D and one J gene segment (or one V and one J segment in the light chain). As there are multiple copies of each type of gene segment, and different combinations of gene segments can be used to generate each immunoglobulin variable region, this process generates a huge number of antibodies, each with different paratopes, and thus different antigen specificities. The rearrangement of several subgenes (i.e. V2 family) for lambda light chain immunoglobulin is coupled with the activation of microRNA miR-650, which further influences biology of B-cells.\nRAG proteins play an important role with V(D)J recombination in cutting DNA at a particular region. Without the presence of these proteins, V(D)J recombination would not occur.\nAfter a B cell produces a functional immunoglobulin gene during V(D)J recombination, it cannot express any other variable region (a process known as allelic exclusion) thus each B cell can produce antibodies containing only one kind of variable chain.\nSomatic hypermutation and affinity maturation.\nFollowing activation with antigen, B cells begin to proliferate rapidly. In these rapidly dividing cells, the genes encoding the variable domains of the heavy and light chains undergo a high rate of point mutation, by a process called \"somatic hypermutation\" (SHM). SHM results in approximately one nucleotide change per variable gene, per cell division. As a consequence, any daughter B cells will acquire slight amino acid differences in the variable domains of their antibody chains.\nThis serves to increase the diversity of the antibody pool and impacts the antibody's antigen-binding affinity. Some point mutations will result in the production of antibodies that have a weaker interaction (low affinity) with their antigen than the original antibody, and some mutations will generate antibodies with a stronger interaction (high affinity). B cells that express high affinity antibodies on their surface will receive a strong survival signal during interactions with other cells, whereas those with low affinity antibodies will not, and will die by apoptosis. Thus, B cells expressing antibodies with a higher affinity for the antigen will outcompete those with weaker affinities for function and survival allowing the average affinity of antibodies to increase over time. The process of generating antibodies with increased binding affinities is called \"affinity maturation\". Affinity maturation occurs in mature B cells after V(D)J recombination, and is dependent on help from helper T cells.\nClass switching.\nIsotype or class switching is a biological process occurring after activation of the B cell, which allows the cell to produce different classes of antibody (IgA, IgE, or IgG). The different classes of antibody, and thus effector functions, are defined by the constant (C) regions of the immunoglobulin heavy chain. Initially, naive B cells express only cell-surface IgM and IgD with identical antigen binding regions. Each isotype is adapted for a distinct function; therefore, after activation, an antibody with an IgG, IgA, or IgE effector function might be required to effectively eliminate an antigen. Class switching allows different daughter cells from the same activated B cell to produce antibodies of different isotypes. Only the constant region of the antibody heavy chain changes during class switching; the variable regions, and therefore antigen specificity, remain unchanged. Thus the progeny of a single B cell can produce antibodies, all specific for the same antigen, but with the ability to produce the effector function appropriate for each antigenic challenge. Class switching is triggered by cytokines; the isotype generated depends on which cytokines are present in the B cell environment.\nClass switching occurs in the heavy chain gene locus by a mechanism called class switch recombination (CSR). This mechanism relies on conserved nucleotide motifs, called \"switch (S) regions\", found in DNA upstream of each constant region gene (except in the \u03b4-chain). The DNA strand is broken by the activity of a series of enzymes at two selected S-regions. The variable domain exon is rejoined through a process called non-homologous end joining (NHEJ) to the desired constant region (\u03b3, \u03b1 or \u03b5). This process results in an immunoglobulin gene that encodes an antibody of a different isotype.\nSpecificity designations.\nAn antibody can be called \"monospecific\" if it has specificity for the same antigen or epitope, or bispecific if they have affinity for two different antigens or two different epitopes on the same antigen. A group of antibodies can be called \"polyvalent\" (or \"unspecific\") if they have affinity for various antigens or microorganisms. Intravenous immunoglobulin, if not otherwise noted, consists of a variety of different IgG (polyclonal IgG). In contrast, monoclonal antibodies are identical antibodies produced by a single B cell.\nAsymmetrical antibodies.\nHeterodimeric antibodies, which are also asymmetrical antibodies, allow for greater flexibility and new formats for attaching a variety of drugs to the antibody arms. One of the general formats for a heterodimeric antibody is the \"knobs-into-holes\" format. This format is specific to the heavy chain part of the constant region in antibodies. The \"knobs\" part is engineered by replacing a small amino acid with a larger one. It fits into the \"hole\", which is engineered by replacing a large amino acid with a smaller one. What connects the \"knobs\" to the \"holes\" are the disulfide bonds between each chain. The \"knobs-into-holes\" shape facilitates antibody dependent cell mediated cytotoxicity. Single chain variable fragments (scFv) are connected to the variable domain of the heavy and light chain via a short linker peptide. The linker is rich in glycine, which gives it more flexibility, and serine/threonine, which gives it specificity. Two different scFv fragments can be connected together, via a hinge region, to the constant domain of the heavy chain or the constant domain of the light chain. This gives the antibody bispecificity, allowing for the binding specificities of two different antigens. The \"knobs-into-holes\" format enhances heterodimer formation but doesn't suppress homodimer formation.\nTo further improve the function of heterodimeric antibodies, many scientists are looking towards artificial constructs. Artificial antibodies are largely diverse protein motifs that use the functional strategy of the antibody molecule, but aren't limited by the loop and framework structural constraints of the natural antibody. Being able to control the combinational design of the sequence and three-dimensional space could transcend the natural design and allow for the attachment of different combinations of drugs to the arms.\nHeterodimeric antibodies have a greater range in shapes they can take and the drugs that are attached to the arms don't have to be the same on each arm, allowing for different combinations of drugs to be used in cancer treatment. Pharmaceuticals are able to produce highly functional bispecific, and even multispecific, antibodies. The degree to which they can function is impressive given that such a change of shape from the natural form should lead to decreased functionality.\nHistory.\nThe first use of the term \"antibody\" occurred in a text by Paul Ehrlich. The term \"Antik\u00f6rper\" (the German word for \"antibody\") appears in the conclusion of his article \"Experimental Studies on Immunity\", published in October 1891, which states that, \"if two substances give rise to two different \"Antik\u00f6rper\", then they themselves must be different\". However, the term was not accepted immediately and several other terms for antibody were proposed; these included \"Immunk\u00f6rper\", \"Amboceptor\", \"Zwischenk\u00f6rper\", \"substance sensibilisatrice\", \"copula\", \"Desmon\", \"philocytase\", \"fixateur\", and \"Immunisin\". The word \"antibody\" has formal analogy to the word \"antitoxin\" and a similar concept to \"Immunk\u00f6rper\" (\"immune body\" in English). As such, the original construction of the word contains a logical flaw; the antitoxin is something directed against a toxin, while the antibody is a body directed against something.\nThe study of antibodies began in 1890 when Emil von Behring and Kitasato Shibasabur\u014d described antibody activity against diphtheria and tetanus toxins. Von Behring and Kitasato put forward the theory of humoral immunity, proposing that a mediator in serum could react with a foreign antigen. His idea prompted Paul Ehrlich to propose the side-chain theory for antibody and antigen interaction in 1897, when he hypothesized that receptors (described as \"side-chains\") on the surface of cells could bind specifically to toxins\u00a0\u2013 in a \"lock-and-key\" interaction\u00a0\u2013 and that this binding reaction is the trigger for the production of antibodies. Other researchers believed that antibodies existed freely in the blood and, in 1904, Almroth Wright suggested that soluble antibodies coated bacteria to label them for phagocytosis and killing; a process that he named opsoninization.\nIn the 1920s, Michael Heidelberger and Oswald Avery observed that antigens could be precipitated by antibodies and went on to show that antibodies are made of protein. The biochemical properties of antigen-antibody-binding interactions were examined in more detail in the late 1930s by John Marrack. The next major advance was in the 1940s, when Linus Pauling confirmed the lock-and-key theory proposed by Ehrlich by showing that the interactions between antibodies and antigens depend more on their shape than their chemical composition. In 1948, Astrid Fagraeus discovered that B cells, in the form of plasma cells, were responsible for generating antibodies.\nFurther work concentrated on characterizing the structures of the antibody proteins. A major advance in these structural studies was the discovery in the early 1960s by Gerald Edelman and Joseph Gally of the antibody light chain, and their realization that this protein is the same as the Bence-Jones protein described in 1845 by Henry Bence Jones. Edelman went on to discover that antibodies are composed of disulfide bond-linked heavy and light chains. Around the same time, antibody-binding (Fab) and antibody tail (Fc) regions of IgG were characterized by Rodney Porter. Together, these scientists deduced the structure and complete amino acid sequence of IgG, a feat for which they were jointly awarded the 1972 Nobel Prize in Physiology or Medicine. The Fv fragment was prepared and characterized by David Givol. While most of these early studies focused on IgM and IgG, other immunoglobulin isotypes were identified in the 1960s: Thomas Tomasi discovered secretory antibody (IgA); David S. Rowe and John L. Fahey discovered IgD; and Kimishige Ishizaka and Teruko Ishizaka discovered IgE and showed it was a class of antibodies involved in allergic reactions. In a landmark series of experiments beginning in 1976, Susumu Tonegawa showed that genetic material can rearrange itself to form the vast array of available antibodies.\nMedical applications.\nDisease diagnosis.\nDetection of particular antibodies is a very common form of medical diagnostics, and applications such as serology depend on these methods. For example, in biochemical assays for disease diagnosis, a titer of antibodies directed against Epstein-Barr virus or Lyme disease is estimated from the blood. If those antibodies are not present, either the person is not infected or the infection occurred a \"very\" long time ago, and the B cells generating these specific antibodies have naturally decayed.\nIn clinical immunology, levels of individual classes of immunoglobulins are measured by nephelometry (or turbidimetry) to characterize the antibody profile of patient. Elevations in different classes of immunoglobulins are sometimes useful in determining the cause of liver damage in patients for whom the diagnosis is unclear. For example, elevated IgA indicates alcoholic cirrhosis, elevated IgM indicates viral hepatitis and primary biliary cirrhosis, while IgG is elevated in viral hepatitis, autoimmune hepatitis and cirrhosis.\nAutoimmune disorders can often be traced to antibodies that bind the body's own epitopes; many can be detected through blood tests. Antibodies directed against red blood cell surface antigens in immune mediated hemolytic anemia are detected with the Coombs test. The Coombs test is also used for antibody screening in blood transfusion preparation and also for antibody screening in antenatal women.\nPractically, several immunodiagnostic methods based on detection of complex antigen-antibody are used to diagnose infectious diseases, for example ELISA, immunofluorescence, Western blot, immunodiffusion, immunoelectrophoresis, and magnetic immunoassay. Antibodies raised against human chorionic gonadotropin are used in over the counter pregnancy tests.\nNew dioxaborolane chemistry enables radioactive fluoride (18F) labeling of antibodies, which allows for positron emission tomography (PET) imaging of cancer.\nDisease therapy.\nTargeted monoclonal antibody therapy is employed to treat diseases such as rheumatoid arthritis, multiple sclerosis, psoriasis, and many forms of cancer including non-Hodgkin's lymphoma, colorectal cancer, head and neck cancer and breast cancer.\nSome immune deficiencies, such as X-linked agammaglobulinemia and hypogammaglobulinemia, result in partial or complete lack of antibodies. These diseases are often treated by inducing a short term form of immunity called passive immunity. Passive immunity is achieved through the transfer of ready-made antibodies in the form of human or animal serum, pooled immunoglobulin or monoclonal antibodies, into the affected individual.\nPrenatal therapy.\nRh factor, also known as Rh D antigen, is an antigen found on red blood cells; individuals that are Rh-positive (Rh+) have this antigen on their red blood cells and individuals that are Rh-negative (Rh\u2013) do not. During normal childbirth, delivery trauma or complications during pregnancy, blood from a fetus can enter the mother's system. In the case of an Rh-incompatible mother and child, consequential blood mixing may sensitize an Rh- mother to the Rh antigen on the blood cells of the Rh+ child, putting the remainder of the pregnancy, and any subsequent pregnancies, at risk for hemolytic disease of the newborn.\nRho(D) immune globulin antibodies are specific for human RhD antigen. Anti-RhD antibodies are administered as part of a prenatal treatment regimen to prevent sensitization that may occur when a Rh-negative mother has a Rh-positive fetus. Treatment of a mother with Anti-RhD antibodies prior to and immediately after trauma and delivery destroys Rh antigen in the mother's system from the fetus. It is important to note that this occurs before the antigen can stimulate maternal B cells to \"remember\" Rh antigen by generating memory B cells. Therefore, her humoral immune system will not make anti-Rh antibodies, and will not attack the Rh antigens of the current or subsequent babies. Rho(D) Immune Globulin treatment prevents sensitization that can lead to Rh disease, but does not prevent or treat the underlying disease itself.\nResearch applications.\nSpecific antibodies are produced by injecting an antigen into a mammal, such as a mouse, rat, rabbit, goat, sheep, or horse for large quantities of antibody. Blood isolated from these animals contains \"polyclonal antibodies\"\u2014multiple antibodies that bind to the same antigen\u2014in the serum, which can now be called antiserum. Antigens are also injected into chickens for generation of polyclonal antibodies in egg yolk. To obtain antibody that is specific for a single epitope of an antigen, antibody-secreting lymphocytes are isolated from the animal and immortalized by fusing them with a cancer cell line. The fused cells are called hybridomas, and will continually grow and secrete antibody in culture. Single hybridoma cells are isolated by dilution cloning to generate cell clones that all produce the same antibody; these antibodies are called \"monoclonal antibodies\". Polyclonal and monoclonal antibodies are often purified using Protein A/G or antigen-affinity chromatography.\nIn research, purified antibodies are used in many applications. Antibodies for research applications can be found directly from antibody suppliers, or through use of a specialist search engine. Research antibodies are most commonly used to identify and locate intracellular and extracellular proteins. Antibodies are used in flow cytometry to differentiate cell types by the proteins they express; different types of cell express different combinations of cluster of differentiation molecules on their surface, and produce different intracellular and secretable proteins. They are also used in immunoprecipitation to separate proteins and anything bound to them (co-immunoprecipitation) from other molecules in a cell lysate, in Western blot analyses to identify proteins separated by electrophoresis, and in immunohistochemistry or immunofluorescence to examine protein expression in tissue sections or to locate proteins within cells with the assistance of a microscope. Proteins can also be detected and quantified with antibodies, using ELISA and ELISpot techniques.\nAntibodies used in research are some of the most powerful, yet most problematic reagents with a tremendous number of factors that must be controlled in any experiment including cross reactivity, or the antibody recognizing multiple epitopes and affinity, which can vary widely depending on experimental conditions such as pH, solvent, state of tissue etc. Multiple attempts have been made to improve both the way that researchers validate antibodies and ways in which they report on antibodies. Researchers using antibodies in their work need to record them correctly in order to allow their research to be reproducible (and therefore tested, and qualified by other researchers). Less than half of research antibodies referenced in academic papers can be easily identified. Papers published in F1000 in 2014 and 2015 provide researchers with a guide for reporting research antibody use. The RRID paper, is co-published in 4 journals that implemented the RRIDs Standard for research resource citation, which draws data from the antibodyregistry.org as the source of antibody identifiers (see also group at Force11).\nRegulations.\nProduction and testing.\nTraditionally, most antibodies are produced by hybridoma cell lines through immortalization of antibody-producing cells by chemically-induced fusion with myeloma cells. In some cases, additional fusions with other lines have created \"triomas\" and \"quadromas\". The manufacturing process should be appropriately described and validated. Validation studies should\nat least include:\nStructure prediction and computational antibody design.\nThe importance of antibodies in health care and the biotechnology industry demands knowledge of their structures at high resolution. This information is used for protein engineering, modifying the antigen binding affinity, and identifying an epitope, of a given antibody. X-ray crystallography is one commonly used method for determining antibody structures. However, crystallizing an antibody is often laborious and time-consuming. Computational approaches provide a cheaper and faster alternative to crystallography, but their results are more equivocal, since they do not produce empirical structures. Online web servers such as \"Web Antibody Modeling\" (WAM) and \"Prediction of Immunoglobulin Structure\" (PIGS) enables computational modeling of antibody variable regions. Rosetta Antibody is a novel antibody FV region structure prediction server, which incorporates sophisticated techniques to minimize CDR loops and optimize the relative orientation of the light and heavy chains, as well as homology models that predict successful docking of antibodies with their unique antigen.\nThe ability to describe the antibody through binding affinity to the antigen is supplemented by information on antibody structure and amino acid sequences for the purpose of patent claims. Several methods have been presented for computational design of antibodies based on the structural bioinformatics studies of antibody CDRs.\nThere are a variety of methods used to sequence an antibody including Edman degradation, cDNA, etc.; albeit one of the most common modern uses for peptide/protein identification is liquid chromatography coupled with tandem mass spectrometry (LC-MS/MS). High volume antibody sequencing methods require computational approaches for the data analysis, including de novo sequencing directly from tandem mass spectra and database search methods that use existing protein sequence databases. Many versions of shotgun protein sequencing are able to increase the coverage by utilizing CID/HCD/ETD fragmentation methods and other techniques, and they have achieved substantial progress in attempt to fully sequence proteins, especially antibodies. Other methods have assumed the existence of similar proteins, a known genome sequence, or combined top-down and bottom up approaches. Current technologies have the ability to assemble protein sequences with high accuracy by integrating de novo sequencing peptides, intensity, and positional confidence scores from database and homology searches.\nAntibody mimetic.\nAntibody mimetics are organic compounds, like antibodies, that can specifically bind antigens. They are usually artificial peptides or proteins with a molar mass of about 3 to 20 kDa. Nucleic acids and small molecules are sometimes considered antibody mimetics, but not artificial antibodies, antibody fragments, and fusion proteins are composed from these. Common advantages over antibodies are better solubility, tissue penetration, stability towards heat and enzymes, and comparatively low production costs. Antibody mimetics such as the Affimer and the DARPin have being developed and commercialised as research, diagnostic and therapeutic agents."}
{"id": "2363", "revid": "41169523", "url": "https://en.wikipedia.org/wiki?curid=2363", "title": "Alessandro Scarlatti", "text": "Pietro Alessandro Gaspare Scarlatti (2 May 1660 \u2013 22 October 1725) was an Italian Baroque composer, known especially for his operas and chamber cantatas. He is considered the most important representative of the Neapolitan school of opera. He was the father of two other composers, Domenico Scarlatti and Pietro Filippo Scarlatti.\nLife.\nScarlatti was born in Palermo (or in Trapani), then part of the Kingdom of Sicily. He is generally said to have been a pupil of Giacomo Carissimi in Rome, and some theorize that he had some connection with northern Italy because his early works seem to show the influence of Stradella and Legrenzi. The production at Rome of his opera \"Gli equivoci nel sembiante\" (1679) gained him the support of Queen Christina of Sweden (who at the time was living in Rome), and he became her \"maestro di cappella\". In February 1684 he became \"maestro di cappella\" to the viceroy of Naples, perhaps through the influence of his sister, an opera singer, who might have been the mistress of an influential Neapolitan noble. Here he produced a long series of operas, remarkable chiefly for their fluency and expressiveness, as well as other music for state occasions.\nIn 1702 Scarlatti left Naples and did not return until the Spanish domination had been superseded by that of the Austrians. In the interval he enjoyed the patronage of Ferdinando de' Medici, for whose private theatre near Florence he composed operas, and of Cardinal Ottoboni, who made him his \"maestro di cappella\", and procured him a similar post at the Basilica di Santa Maria Maggiore in Rome in 1703.\nAfter visiting Venice and Urbino in 1707, Scarlatti took up his duties in Naples again in 1708, and remained there until 1717. By this time Naples seems to have become tired of his music; the Romans, however, appreciated it better, and it was at the Teatro Capranica in Rome that he produced some of his finest operas (\"Telemaco\", 1718; \"Marco Attilio Regol\u00f2\", 1719; \"La Griselda\", 1721), as well as some noble specimens of church music, including a \"Messa di Santa Cecilia\" for chorus and orchestra, composed in honor of Saint Cecilia for Cardinal Francesco Acquaviva in 1721. His last work on a large scale appears to have been the unfinished \"Erminia\" serenata for the marriage of the prince of Stigliano in 1723. He died in Naples in 1725 and is entombed there at the church of Santa Maria di Montesanto.\nScarlatti's music.\nScarlatti's music forms an important link between the early Baroque Italian vocal styles of the 17th century, with their centers in Florence, Venice and Rome, and the classical school of the 18th century. Scarlatti's style, however, is more than a transitional element in Western music; like most of his Naples colleagues he shows an almost modern understanding of the psychology of modulation and also frequently makes use of the ever-changing phrase lengths so typical of the Napoli school.\nHis early operas\u2014\"Gli equivoci nel sembiante\" 1679; \"L'honest\u00e0 negli amori\" 1680, containing the famous aria \"Gi\u00e0 il sole dal Gange\"; \"Il Pompeo\" 1683, containing the well-known airs \"O cessate di piagarmi\" and \"Toglietemi la vita ancor,\" and others down to about 1685\u2014retain the older cadences in their recitatives, and a considerable variety of neatly constructed forms in their charming little arias, accompanied sometimes by the string quartet, treated with careful elaboration, sometimes with the continuo alone. By 1686, he had definitely established the \"Italian overture\" form (second edition of \"Dal male il bene\"), and had abandoned the ground bass and the binary form air in two stanzas in favour of the ternary form or da capo type of air. His best operas of this period are \"La Rosaura\" (1690, printed by the Gesellschaft f\u00fcr Musikforschung), and \"Pirro e Demetrio\" (1694), in which occur the arias \"Le Violette\", and \"Ben ti sta, traditor\".\nFrom about 1697 onwards (\"La caduta del Decemviri\"), influenced partly perhaps by the style of Giovanni Bononcini and probably more by the taste of the viceregal court, his opera arias become more conventional and commonplace in rhythm, while his scoring is hasty and crude, yet not without brilliance (\"L'Eraclea\", 1700), the oboes and trumpets being frequently used, and the violins often playing in unison. The operas composed for Ferdinando de' Medici are lost; they might have given a more favourable idea of his style as his correspondence with the prince shows that they were composed with a very sincere sense of inspiration.\n\"Mitridate Eupatore\", accounted his masterpiece, composed for Venice in 1707, contains music far in advance of anything that Scarlatti had written for Naples, both in technique and in intellectual power. The later Neapolitan operas (\"L'amor volubile e tiranno\" 1709; \"La principessa fedele\" 1710; \"Tigrane\", 1714, &amp;c.) are showy and effective rather than profoundly emotional; the instrumentation marks a great advance on previous work, since the main duty of accompanying the voice is thrown upon the string quartet, the harpsichord being reserved exclusively for the noisy instrumental \"ritornelli\". In his opera \"Teodora\" (1697) he originated the use of the orchestral \"ritornello\".\nHis last group of operas, composed for Rome, exhibit a deeper poetic feeling, a broad and dignified style of melody, a strong dramatic sense, especially in accompanied recitatives, a device which he himself had been the first to use as early as 1686 (\"Olimpia vendicata\") and a much more modern style of orchestration, the horns appearing for the first time, and being treated with striking effect.\nBesides the operas, oratorios (\"Agar et Ismaele esiliati\", 1684; \"La Maddalena\", 1685; \"La Giuditta\", 1693; \"Christmas Oratorio\", c. 1705; \"S. Filippo Neri\", 1714; and others) and serenatas, which all exhibit a similar style, Scarlatti composed upwards of five hundred chamber-cantatas for solo voice. These represent the most intellectual type of chamber-music of their period, and it is to be regretted that they have remained almost entirely in manuscript, since a careful study of them is indispensable to anyone who wishes to form an adequate idea of Scarlatti's development.\nHis few remaining Masses (the story of his having composed two hundred is hardly credible) and church music in general are comparatively unimportant, except the great \"Saint Cecilia Mass\" (1721), which is one of the first attempts at the style which reached its height in the great Masses of Johann Sebastian Bach and Ludwig van Beethoven. His instrumental music, though not without interest, is curiously antiquated as compared with his vocal works."}
{"id": "2367", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=2367", "title": "Acquired immunodeficiency syndrome", "text": ""}
{"id": "2369", "revid": "3306290", "url": "https://en.wikipedia.org/wiki?curid=2369", "title": "Aston Martin", "text": "Aston Martin Lagonda is a British independent manufacturer of luxury sports cars and grand tourers. Its predecessor was founded in 1913 by Lionel Martin and Robert Bamford. Steered from 1947 by David Brown, it became associated with expensive grand touring cars in the 1950s and 1960s, and with the fictional character James Bond following his use of a DB5 model in the 1964 film \"Goldfinger\". Their sports cars are regarded as a British cultural icon. Aston Martin has held a Royal Warrant as purveyor of motorcars to the Prince of Wales since 1982, and has over 160 car dealerships in 53 countries making it a global automobile brand. The company is traded at the London Stock Exchange and is a constituent of the FTSE 250 Index. In 2003 it received the Queen's Award for Enterprise for outstanding contribution to international trade. The company has gone bankrupt seven times in its history.\nThe headquarters and main production of its sports cars and grand tourers are in a 22-hectare (55-acre) facility in Gaydon, Warwickshire, England on the former site of RAF Gaydon, adjacent to the Jaguar Land Rover Gaydon Centre. The old plant in Newport Pagnell, Buckinghamshire is the present home of the \"Aston Martin Works\" classic car department which focuses on heritage sales, service, spares and restoration operations. The 36-hectare (90-acre) factory in St Athan, Wales features three converted 'super-hangars' from MOD St Athan, and serves as the production site of Aston Martin's first-ever SUV the DBX. Aston Martin plans on building electric vehicles on both its Gaydon and St Athan factories by 2025.\nIts Formula One team is headquartered in Silverstone, with a new facility set to be operational by 2022. The new facility will be based directly opposite the Silverstone circuit on the 29 acres of land at Litchlake Farm. The Aston Martin brand is increasingly being used, mostly through licensing, on other products including a submarine, real estate development, and aircraft.\nHistory.\nFounding.\nAston Martin was founded in 1913 by Lionel Martin and Robert Bamford. The two had joined forces as Bamford &amp; Martin the previous year to sell cars made by Singer from premises in Callow Street, London where they also serviced GWK and Calthorpe vehicles. Martin raced specials at Aston Hill near Aston Clinton, and the pair decided to make their own vehicles. The first car to be named \"Aston Martin\" was created by Martin by fitting a four-cylinder Coventry-Simplex engine to the chassis of a 1908 Isotta Fraschini.\nThey acquired premises at Henniker Mews in Kensington and produced their first car in March 1915. Production could not start because of the outbreak of the first World War, when Martin joined the Admiralty and Bamford joined the Army Service Corps.\nInter\u2013war years.\nAfter the war they found new premises at Abingdon Road, Kensington and designed a new car. Bamford left in 1920 and Bamford &amp; Martin was revitalised with funding from Count Louis Zborowski. In 1922, Bamford &amp; Martin produced cars to compete in the French Grand Prix, which went on to set world speed and endurance records at Brooklands. Three works Team Cars with 16-valve twin cam engines were built for racing and record-breaking: chassis number 1914, later developed as the Green Pea; chassis number 1915, the Razor Blade record car; and chassis number 1916, later developed as the Halford Special.\nApproximately 55 cars were built for sale in two configurations; long chassis and short chassis. Bamford &amp; Martin went bankrupt in 1924 and was bought by Dorothea, Lady Charnwood who put her son John Benson on the board. Bamford &amp; Martin got into financial difficulty again in 1925 and Martin was forced to sell the company (Bamford had already left).\nLater that year, Bill Renwick, Augustus (Bert) Bertelli and investors including Lady Charnwood took control of the business. They renamed it Aston Martin Motors and moved it to the former Whitehead Aircraft Limited Hanworth works in Feltham. Renwick and Bertelli had been in partnership some years and had developed an overhead-cam four-cylinder engine using Renwick's patented combustion chamber design, which they had tested in an Enfield-Allday chassis. The only \"Renwick and Bertelli\" motor car made, it was known as \"Buzzbox\" and still survives.\nThe pair had planned to sell their engine to motor manufacturers, but having heard that Aston Martin was no longer in production realised they could capitalise on its reputation to jump-start the production of a completely new car.\nBetween 1926 and 1937 Bertelli was both technical director and designer of all new Aston Martins, since known as \"Bertelli cars\". They included the 1\u00bd-litre \"T-type\", \"International\", \"Le Mans\", \"MKII\" and its racing derivative, the \"Ulster\", and the 2-litre 15/98 and its racing derivative, the \"Speed Model\". Most were open two-seater sports cars bodied by Bert Bertelli's brother , with a small number of long-chassis four-seater tourers, dropheads and saloons also produced.\nBertelli was a competent driver keen to race his cars, one of few owner/manufacturer/drivers. The \"LM\" team cars were very successful in national and international motor racing including at Le Mans.\nFinancial problems reappeared in 1932. Aston Martin was rescued for a year by Lance Prideaux Brune before passing it on to Sir Arthur Sutherland. In 1936, Aston Martin decided to concentrate on road cars, producing just 700 until World War II halted work. Production shifted to aircraft components during the war.\n1947\u20131972: David Brown.\nIn 1947, old-established (1860) privately owned Huddersfield gear and machine tools manufacturer David Brown Limited bought Aston Martin putting it under control of its Tractor Group. David Brown became Aston Martin's latest saviour. He also acquired without its factory Lagonda's business for its 2.6-litre W. O. Bentley-designed engine. Lagonda moved operations to Newport Pagnell and shared engines, resources and workshops. Aston Martin began to build the classic \"DB\" series of cars.\nIn April 1950, they announced planned production of their Le Mans prototype to be called the DB2, followed by the DB2/4 in 1953, the DB2/4 MkII in 1955, the DB Mark III in 1957 and the Italian-styled 3.7\u00a0L DB4 in 1958.\nWhile these models helped Aston Martin establish a good racing pedigree, the DB4 stood out and yielded the famous DB5 in 1963. Aston stayed true to its grand touring style with the DB6 (1965\u201370), and DBS (1967\u20131972).\nThe six-cylinder engines of these cars from 1954 up to 1965 were designed by Tadek Marek.\n1972\u20131975: William Willson.\nAston Martin was often financially troubled. In 1972, David Brown paid off all its debts, said to be \u00a35\u00a0million or more, and handed it for \u00a3101 to Company Developments, a Birmingham-based investment bank consortium chaired by accountant William Willson. More detail on this period may be read at Willson's biography. The worldwide recession, lack of working capital and the difficulties of developing an engine to meet California's exhaust emission requirements \u2013 it stopped the company's US sales \u2013 again pulled Aston Martin into receivership at the end of 1974. The company had employed 460 workers when the manufacturing plant closed.\n1975\u20131981: Sprague and Curtis.\nThe receiver sold the business in April 1975 for \u00a31.05\u00a0million to North American businessmen Peter Sprague of National Semiconductor, Toronto hotelier George Minden, and Jeremy Turner, a London businessman, who insisted to reporters Aston Martin remained a British controlled business. Sprague later claimed he had fallen in love with the factory, not the cars, the workforce's craftsmanship dedication and intelligence. At this point, he and Minden had brought in investor, Alan Curtis, a British office property developer together with George Flather, a retired Sheffield steel magnate.\nSix months later, in September 1975, the factory \u2013 shut-down the previous December \u2013 re-opened under its new owner as Aston Martin Lagonda Limited with 100 employees and plans to lift staff to 250 by the end of 1975. In January 1976, AML revealed that it now held orders for 150 cars for the US, 100 for other markets and another 80 from a Japanese importing agency. At the Geneva Motor Show, Fred Hartley, managing director and sales director for 13 years before that, announced he had resigned over \"differences in marketing policy\".\nThe new owners pushed Aston Martin into modernising its line, introducing the V8 Vantage in 1977, the convertible Volante in 1978, and the one-off Bulldog styled by William Towns in 1980. Towns also styled the futuristic new Lagonda saloon, based on the V8 model.\nCurtis, who had a 42% stake in Aston Martin, also brought about a change in direction from the usual customers who were Aston Martin fanatics (fans) to successful young married businessmen. Prices had been increased by 25%. There was speculation that AML was about to buy Italian automobile manufacturer Lamborghini. At the end of the 1970s, there was widespread debate about running MG into the Aston Martin consortium. 85 Tory MPs formed themselves into a pressure group to get British Leyland to release their grip and hand it over. CH Industrials plc (car components) bought a 10% share in AML. But in July 1980, blaming a recession, AML cut back their workforce of 450 by more than 20% making those people redundant.\n1981\u20131987: Victor Gauntlett.\nIn January 1981, there having been no satisfactory revival partners, Alan Curtis and Peter Sprague announced they had never intended to maintain a long-term financial stake in Aston Martin Lagonda and it was to be sold to Pace Petroleum's Victor Gauntlett. Sprague and Curtis pointed out that under their ownership AML finances had improved to where an offer for MG might have been feasible.\nGauntlett bought a 12.5% stake in Aston Martin for \u00a3500,000 via Pace Petroleum in 1980, with Tim Hearley of CH Industrials taking a similar share. Pace and CHI took over as joint 50/50 owners at the beginning of 1981, with Gauntlett as executive chairman. Gauntlett also led the sales team, and after some development and publicity when the Lagonda became the world's fastest four-seater production car, was able to sell the car in Oman, Kuwait, and Qatar.\nIn 1982, Aston Martin was granted a Royal Warrant of Appointment by the Prince of Wales.\nUnderstanding that it would take some time to develop new Aston Martin products, they created an engineering service subsidiary to develop automotive products for other companies. It was decided to use a trade name of Salmons &amp; Son, their in-house coachbuilder, Tickford, which Aston Martin had bought in 1955. Tickford's name had been long associated with expensive high-quality carriages and cars along with their folding roofs. New products included a Tickford Austin Metro, a Tickford Ford Capri and even Tickford train interiors, particularly on the Jaguar XJS. Pace continued sponsoring racing events, and now sponsored all Aston Martin Owners Club events, taking a Tickford-engined Nimrod Group C car owned by AMOC President Viscount Downe, which came third in the Manufacturers Championship in both 1982 and 1983. It also finished seventh in the 1982 24 Hours of Le Mans race. However, sales of production cars were now at an all-time low of 30 cars produced in 1982.\nAs trading became tighter in the petroleum market, and Aston Martin was requiring more time and money, Gauntlett agreed to sell Hays/Pace to the Kuwait Investment Office in September 1983. As Aston Martin required greater investment, he also agreed to sell his share holding to American importer and Greek shipping tycoon Peter Livanos, who invested via his joint venture with Nick and John Papanicolaou, ALL Inc. Gauntlett remained chairman of AML, 55% of the stake was owned by ALL, with Tickford a 50/50 venture between ALL and CHI. The uneasy relationship was ended when ALL exercised options to buy a larger share in AML; CHI's residual shares were exchanged for CHI's complete ownership of Tickford, which retained the development of existing Aston Martin projects. In 1984, Papanicolaou's Titan shipping business was in trouble so Livanos's father George bought out the Papanicolaou's shares in ALL, while Gauntlett again became a shareholder with a 25% holding in AML. The deal valued Aston Martin/AML at \u00a32\u00a0million, the year it built its 10,000th car.\nAlthough as a result Aston Martin had to make 60 members of the workforce redundant, Gauntlett bought a stake in Italian styling house Zagato, and resurrected its collaboration with Aston Martin.\nIn 1986, Gauntlett negotiated the return of the fictional British secret agent James Bond to Aston Martin. Cubby Broccoli had chosen to recast the character using actor Timothy Dalton, in an attempt to re-root the Bond-brand back to a more Sean Connery-like feel. Gauntlett supplied his personal pre-production Vantage for use in the filming of \"The Living Daylights\", and sold a Volante to Broccoli for use at his home in America. Gauntlett turned down the role of a KGB colonel in the film, however: \"I would have loved to have done it but really could not afford the time.\"\n1987\u20132007: Ford Motor Company.\nAs Aston Martin needed funds to survive in the long term, Ford bought a 75% stake in the company in 1987, and bought the rest later. In May of that year, Victor Gauntlett and Prince Michael of Kent were staying at the home of Contessa Maggi, the wife of the founder of the original Mille Miglia, while watching the revival event. Another house guest was Walter Hayes, vice-president of Ford of Europe. Despite problems over the previous acquisition of AC Cars, Hayes saw the potential of the brand and the discussion resulted in Ford taking a share holding in September 1987. In 1988, having produced some 5,000 cars in 20 years, a revived economy and successful sales of limited edition Vantage, and 52 Volante Zagato coup\u00e9s at \u00a386,000 each; Aston Martin finally retired the ancient V8 and introduced the Virage range.\nAlthough Gauntlett was contractually to stay as chairman for two years, his racing interests took the company back into sports car racing in 1989 with limited European success. However, with engine rule changes for the 1990 season and the launch of the new Volante model, Ford provided the limited supply of Cosworth engines to the Jaguar cars racing team. As the entry-level DB7 would require a large engineering input, Ford agreed to take full control of Aston Martin, and Gauntlett handed over Aston Martin's chairmanship to Hayes in 1991. In 1992, the high-performance variant of the Virage called the Vantage was announced, and the following year Aston Martin renewed the DB range by announcing the DB7.\nFord placed Aston Martin in the Premier Automotive Group, invested in new manufacturing and ramped up production. In 1994, Ford opened a new factory at Banbury Road in Bloxham to manufacture the DB7. In 1995, Aston Martin produced a record 700 cars. Until the Ford era, cars had been produced by hand coachbuilding craft methods, such as the English wheel. In 1998, the 2,000th DB7 was built, and in 2002, the 6,000th, exceeding production of all of the previous DB series models. The DB7 range was revamped by the addition of more powerful V12 Vantage models in 1999, and in 2001, Aston Martin introduced the V12-engined flagship model called the Vanquish which succeeded the aging Virage (now called the V8 Coup\u00e9).\nAt the North American International Auto Show in Detroit, Michigan in 2003, Aston Martin introduced the AMV8 Vantage concept car. Expected to have few changes before its introduction in 2005, the Vantage brought back the classic V8 engine to allow Aston Martin to compete in a larger market. 2003 also saw the opening of the Gaydon factory, the first purpose-built factory in Aston Martin's history. The facility sits on a 22-hectare (55-acre) site of a former RAF V Bomber airbase, with an front building for offices, meeting rooms and customer reception, and a production building. Also introduced in 2003 was the DB9 coup\u00e9, which replaced the ten-year-old DB7. A convertible version of the DB9, the DB9 Volante, was introduced at the 2004 Detroit auto show.\nIn October 2004, Aston Martin set up the dedicated AMEP engine production plant within the Ford Germany Niehl, Cologne plant. With the capacity to produce up to 5,000 engines a year by 100 specially trained personnel, like traditional Aston Martin engine production from Newport Pagnell, assembly of each unit was entrusted to a single technician from a pool of 30, with V8 and V12 variants assembled in under 20 hours. By bringing engine production back to within Aston Martin, the promise was that Aston Martin would be able to produce small runs of higher performance variants' engines. This expanded engine capacity allowed the entry-level V8 Vantage sports car to enter production at the Gaydon factory in 2006, joining the DB9 and DB9 Volante.\nIn December 2003, Aston Martin announced it would return to motor racing in 2005. A new division was created, called Aston Martin Racing, which became responsible, together with Prodrive, for the design, development, and management of the DBR9 program. The DBR9 competes in the GT class in sports car races, including the world-famous 24 Hours of Le Mans.\nIn 2006, an internal audit led Ford to consider divesting itself of parts of its Premier Automotive Group. After suggestions of selling Jaguar Cars, Land Rover, or Volvo Cars were weighed, Ford announced in August 2006 it had engaged UBS AG to sell all or part of Aston Martin at auction.\n2007\u20132018: Private Limited Company.\nOn 12 March 2007, a consortium led by Prodrive chairman David Richards purchased Aston Martin for \u00a3475\u00a0million (US$848\u00a0million). The group included American investment banker John Singers and two Kuwaiti companies namely Investment Dar and Adeem Investment; Prodrive had no financial involvement in the deal. Ford kept a stake in Aston Martin valued at \u00a340\u00a0million (US$70\u00a0million).\nTo demonstrate the V8 Vantage's durability across hazardous terrain and promote the car in China, the first east\u2013west crossing of the Asian Highway was undertaken between June and August 2007. A pair of Britons drove from Tokyo to Istanbul before joining the European motorway network for another to London. The promotion was so successful Aston Martin opened dealerships in Shanghai and Beijing within three months.\nOn 19 July 2007, the Newport Pagnell plant rolled out the last of nearly 13,000 cars made there since 1955, a Vanquish S. The Tickford Street facility was converted to \"Aston Martin Works\" which focuses on heritage sales, service, spares and restoration operations. UK production is now concentrated on the 22-hectare (55-acre) facility in Gaydon on the former RAF V Bomber airbase. In March 2008, Aston Martin announced a partnership with Magna Steyr to outsource manufacture of over 2,000 cars annually to Graz, Austria, reassuringly stating: \"The continuing growth and success of Aston Martin is based upon Gaydon as the focal point and heart of the business, with the design and engineering of all Aston Martin products continuing to be carried out there.\"\nMore dealers in Europe and the new pair in China brought the total to 120 in 28 countries. On 1 September 2008, Aston Martin announced the revival of the Lagonda marque, proposing a concept car to be shown in 2009 to coincide with the brand's 100th anniversary. The first production cars were slated for production in 2012. In December 2008, Aston Martin announced it would cut its workforce from 1,850 to 1,250 due to the economic recession.\nThe first four-door Rapide grand tourers rolled out of the Magna Steyr factory in Graz, Austria in 2010. The contract manufacturer provides dedicated facilities to ensure compliance with the exacting standards of Aston Martin and other marques, including Mercedes-Benz. Then CEO of the company, Dr. Ulrich Bez had publicly speculated about outsourcing all of Aston Martin's operations with the exception of marketing. In September 2011, it was announced that production of the Rapide would be returned to Gaydon in the second half of 2012, restoring all of the company's automobile manufacture there.\nItalian private equity fund Investindustrial signed a deal on 6 December 2012 to buy a 37.5% stake in Aston Martin, investing \u00a3150 million as a capital increase. This was confirmed by Aston Martin in a press release on 7 December 2012. David Richards left Aston Martin in 2013, returning to concentrate on Prodrive.\nIn April 2013, it was reported that Dr. Ulrich Bez would be leaving his role as the chief executive officer to take up a more ambassadorial position. On 2 September 2014, Aston Martin announced it had appointed the Nissan executive Andy Palmer as the new CEO with Ulrich Bez retaining a position as non-executive chairman. As sales had been declining from 2015, Aston Martin sought new customers (particularly wealthy female buyers) with introducing concept cars like the DBX SUV along with track focused cars like the Vulcan. According to Palmer, the troubles started when sales of the DB9 failed to generate sufficient fund to develop next-generation models which led to a downward spiral of declining sales and profitability.\nPalmer outlined that the company plans to develop two new platforms, add a crossover, refresh its supercar lineup and leverage its technology alliance with Daimler as part of its six-year plan to make the 100-year-old British brand consistently profitable. He stated, \"In the first century we went bankrupt seven times. The second century is about making sure that is not the case.\" In preparation for its next-generation of sports cars, the company invested \u00a320 million ($33.4 million) to expand its manufacturing plant in Gaydon. The expansion at the Gaydon plant includes a new chassis and pilot build facility, as well as an extension of the parts and logistics storage area, and new offices. In total, Aston Martin will add 10,000 square-meters (107,639 square-feet) to the plant.\nIn 2014, Aston Martin suffered a pre-tax loss of \u00a372\u00a0million, almost triple of the amount of 2013 selling 3,500 cars during the year, well below the 7,300 cars sold in 2007 and 4,200 sold in 2013 respectively. In March 2014, Aston Martin issued \"payment in kind\" notes of US$165\u00a0million, at 10.25% interest, in addition to the \u00a3304\u00a0million of senior secured notes at 9.25% issued in 2011. Aston Martin also had to secure an additional investment of \u00a3200\u00a0million from its shareholders to fund development of new models. It was reported that Aston Martin's pre-tax losses for 2016 increased by 27% to \u00a3162.8\u00a0million, the sixth year it continued to suffer a loss.\nIn 2016, the company selected a 36-hectare (90-acre) site in St Athan, South Wales for its new factory. The Welsh facility was unanimously chosen by Aston's board despite fierce competition from other locations as far afield as the Americas, Eastern Europe, the Middle East, Europe, as well as two other sites in the UK, believed to be Bridgend and Birmingham. The facility featured three existing \u2018super-hangars\u2019 of MOD St Athan. Construction work of converting the hangars commenced in 2017. Aston Martin returned to profit in 2017 after selling over 5,000 cars. The company made a pre-tax profit of \u00a387\u00a0million compared with a \u00a3163\u00a0million loss in 2016. 2017 also marked the return of production of the Newport Pagnell facility ten years after it originally ceased.\n2013\u2013present: Partnership with Daimler AG.\nIn 2013, Aston Martin signed a deal with Daimler AG, which owned a 5% stake in Aston Martin, to supply the next generation of Aston Martin cars with Mercedes-AMG engines. Mercedes-AMG also was to supply Aston Martin with electrical systems. This technical partnership was intended to support Aston Martin's launch of a new generation of models that would incorporate new technology and engines. The first model to sport the Mercedes-Benz technology was the DB11, announced at the 2016 Geneva Motor Show which also has Mercedes-Benz electronics for the entertainment, navigation and other systems. The 2018 V8 Vantage, unveiled in late 2017, employed a Mercedes-Benz twin-turbocharged V8 engine and infotainment systems. Mercedes will increase its holding \"in stages\" from 5% to 20%.\n2018\u2013present: Listed on the London Stock Exchange.\nAfter \"completing a turnaround for the once perennially loss-making company that could now be valued at up to 5\u00a0billion pounds ($6.4\u00a0billion),\" and now reporting a full-year pre-tax profit of \u00a387\u00a0million (compared with a \u00a3163\u00a0million loss in 2016) Aston Martin in August 2018 announced plans to float the company at the London Stock Exchange as Aston Martin Lagonda Global Holdings plc. The company was the subject of an initial public offering on the London Stock Exchange on 3 October 2018. In June 2019, Aston Martin opened its new 36-hectare (90-acre) factory in St Athan for the production of its first-ever SUV the DBX. The factory was finally completed and officially opened on 6 December 2019. When full production begins in the second quarter of 2020, around 600 people will be employed at the factory, rising to 750 when peak production is reached.\nOn 31 January 2020 it was announced that Canadian billionaire and investor Lawrence Stroll was leading a consortium who will pay \u00a3182\u00a0million in return for 25% stake in the company. The re-structuring includes a \u00a3318\u00a0million cash infusion through a new rights issue, generating a total of \u00a3500\u00a0million for the company. Stroll will also be named as chairman, replacing Penny Hughes. Swiss pharmaceutical magnate Ernesto Bertarelli and Mercedes-AMG Petronas Motorsport team principal and CEO Toto Wolff have also joined the consortium, acquiring 3.4% and 4.8% stakes, respectively. On 26 May 2020, Aston Martin announced that Andy Palmer had stepped down as CEO. Tobias Moers of Mercedes-AMG will succeed him starting 1 August, with Keith Stanton as interim chief operating officer. In June 2020, the company announced that it cut out 500 jobs as a result of the poor sales, an outcome of the COVID-19 pandemic lockdown. In March 2021, chairman Lawrence Stroll stated that the company plans on building electric vehicles by 2025.\nNotable events.\nIn August 2017, a 1956 Aston Martin DBR1/1 sold at a Sotheby's auction at the Pebble Beach, California Concours d'Elegance for US$22,550,000, which made it the most expensive British car ever sold at an auction, according to Sotheby's. The car was previously driven by Carroll Shelby and Stirling Moss.\nBrand expansion.\nSince 2015, Aston Martin has sought to increase its appeal to women as a luxury lifestyle brand. A female advisory panel was established to adapt the design of the cars to the taste of women. In September 2016, a 37-foot-long Aston Martin speedboat was unveiled called the Aston Martin AM37 powerboat. In September 2017, Aston Martin announced that they had partnered with submarine building company Triton Submarines to build a submarine called Project Neptune. Aston Martin has collaborated with the luxury clothing company Hackett London to deliver items of clothing. In November 2017, Aston Martin unveiled a special limited edition bicycle after collaborating with bicycle manufacturer Storck.\nAston Martin and global property developer G&amp;G Business Developments are currently building a 66-storey luxury condominium tower called Aston Martin Residences at 300 Biscayne Boulevard Way in Miami, Florida, which is set for completion in 2021.\nIn July 2018, Aston Martin unveiled the Volante Vision Concept, a luxury concept aircraft with vertical take-off and landing capabilities. Also in July, a Lego version of James Bond's DB5 car was put on sale and an Aston Martin-branded watch was released in collaboration with TAG Heuer.\nIn October 2018, Aston Martin announced it was opening a design and brand studio in Shanghai.\nMotorsport.\nFormula One.\nAston Martin participated as a Formula One constructor in and entering six races over the two years but failing to score any points. In January 2020, it was announced that the Racing Point F1 Team is due to be rebranded as Aston Martin for the 2021 season, as a result of a funding investment led by Racing Point owner Lawrence Stroll.\nSponsorships.\nAston Martin sponsors 2. Bundesliga club 1860 Munich."}
{"id": "2371", "revid": "1019389176", "url": "https://en.wikipedia.org/wiki?curid=2371", "title": "Albert Pike", "text": "Albert Pike (December 29, 1809April 2, 1891) was an American author, poet, orator, editor, lawyer, jurist, and prominent member of the Freemasons. Pike was a senior officer of the Confederate States Army who commanded the District of Indian Territory in the Trans-Mississippi Theater of the American Civil War. He then served as an associate justice of the confederate Arkansas Supreme Court from 1864 until the surrender of the Trans-Mississippi Department of the Confederation in May 1865.\nEarly life and education.\nAlbert Pike was born in Boston, Massachusetts, on December 29, 1809, the son of Benjamin and Sarah (Andrews) Pike, and spent his childhood in Byfield and Newburyport, Massachusetts. His colonial ancestors settled the area in 1635, and included John Pike (1613\u20131688/1689), the founder of Woodbridge, New Jersey. He attended school in Newburyport and Framingham until he was 15. In August 1825, he passed entrance exams at Harvard University, though when the college requested payment of tuition fees for the first two years, he chose not to attend. He began a program of self-education, later becoming a schoolteacher in Gloucester, North Bedford, Fairhaven and Newburyport.\nPike was an imposing figure; tall and with hair that reached his shoulders and a long beard. In 1831, he left Massachusetts to travel west, first stopping in Nashville, Tennessee, and later moving to St. Louis, Missouri.\nThere he joined a hunting and trading expedition to Taos, New Mexico. En route his horse broke and ran, forcing Pike to walk the remaining to Taos. After this, he joined a trapping expedition to the Llano Estacado in New Mexico and Texas. Trapping was minimal and, after traveling about , half of it on foot, he finally arrived at Fort Smith, Arkansas.\nCareer.\nSettling in Arkansas in 1833, Pike taught in a school and wrote a series of articles for the Little Rock \"Arkansas Advocate\" under the pen name of \"Casca.\" The articles were sufficiently well received for him to be asked to join the newspaper's staff. Under Pike's administration, the \"Advocate\" promoted the viewpoint of the Whig Party in a politically volatile and divided Arkansas in December 1832. After marrying Mary Ann Hamilton in 1834, he purchased the newspaper.\nHe was the first reporter for the Arkansas Supreme Court. He wrote a book (published anonymously), titled \"The Arkansas Form Book\", which was a guidebook for lawyers. Pike began to study law and was admitted to the bar in 1837, selling the \"Advocate\" the same year. He proved to be a highly effective lawyer, representing clients in courts at every level, which continued after he received permission to practice before the United States Supreme Court in 1849.\nHe also made several contacts among the Native American tribes in the area. He specialized in claims on behalf of Native Americans against the federal government. In 1852, he represented Creek Nation before the Supreme Court in a claim regarding ceded tribal land. In 1854 he advocated for the Choctaw and Chickasaw, although compensation later awarded to the tribes in 1856 and 1857 was insufficient. These relationships were to influence the course of his Civil War service.\nHe also began a campaign of newspaper essays urging support for the construction of a transcontinental railroad extending from New Orleans to the Pacific coast, moving to New Orleans in 1853 and preparing to pass the state bar in furtherance of his campaign, and was ultimately able to secure a charter from the Louisiana State Legislature for a project, following which he returned to Little Rock in 1857.\nHe joined the anti-Catholic Know Nothing Party at its founding, and, in the summer of 1854, helped introduce the party in Arkansas. He attended the national convention in 1856, but walked out when it failed to adopt a pro-slavery platform. In the lead-up to the Civil War, Pike signed a pamphlet which proposed expelling all free African Americans from Arkansas. It said that the \"evil is the existence among us of a class of free colored persons\".\nAdditionally, Pike wrote on several legal subjects. He also continued writing poetry, a hobby he had begun in his youth in Massachusetts. His poems were highly regarded in his day, but are now mostly forgotten. Several volumes of his works were privately published posthumously by his daughter. In 1859, he received an honorary Master of Arts degree from Harvard.\nPoetry.\nAs a young man of letters, Pike wrote poetry, and he continued to do so for the rest of his life. At 23, he published his first poem, \"Hymns to the Gods.\" Later work was printed in literary journals such as \"Blackwood's Edinburgh Magazine\" and local newspapers. His first collection of poetry, \"Prose Sketches and Poems Written in the Western Country\", was published in 1834. He later gathered many of his poems and republished them in \"Hymns to the Gods and Other Poems\" (1872). After his death these were published again in \"Gen. Albert Pike's Poems\" (1900) and \"Lyrics and Love Songs\" (1916).\nThe authorship of \"The Old Canoe\" was attributed to Pike. He was suggested as author because about the time of its publication, when it was going the rounds of the press, probably without any credit, a doggerel called \"The Old Canoe\" was composed about Pike by one of his political foes. The subject was a canoe in which he left Columbia, Tennessee, when a young man practicing law in that place. Pike told Senator Edward W. Carmack that he was not the author of \"The Old Canoe,\" and could not imagine how he ever got the credit for it. The rightful author was Emily Rebecca Page.\nFreemasonry.\nPike first joined the fraternal Independent Order of Odd Fellows in 1840. He next joined a Masonic Lodge, where he became extremely active in the affairs of the organization. In 1859 he was elected Sovereign Grand Commander of the Scottish Rite's Southern Jurisdiction. He remained Sovereign Grand Commander for the rest of his life, devoting a large amount of his time to developing the rituals of the order.\nHe published a book called \"Morals and Dogma of the Ancient and Accepted Scottish Rite of Freemasonry\" in 1871, the first of several editions. This helped the Order grow during the nineteenth century. He also researched and wrote the seminal treatise \"Indo-Aryan Deities and Worship as Contained in the Rig-Veda\". In the United States, Pike is still considered an eminent and influential Freemason, primarily in the Scottish Rite Southern Jurisdiction.\nMilitary service.\nMexican\u2013American War.\nWhen the Mexican\u2013American War started, Pike joined the Regiment of Arkansas Mounted Volunteers (a cavalry regiment) and was commissioned as a troop commander with the rank of captain in June 1846. With his regiment, he fought in the Battle of Buena Vista. Pike was discharged in June 1847. He and his commander, Colonel John Selden Roane, had several differences of opinion. This situation led finally to an \"inconclusive\" duel between Pike and Roane on July 29, 1847, near Fort Smith, Arkansas. Although several shots were fired in the duel, nobody was injured, and the two were persuaded by their seconds to discontinue it.\nAfter the war, Pike returned to the practice of law, moving to New Orleans for a time beginning in 1853. He wrote another book, \"Maxims of the Roman Law and Some of the Ancient French Law, as Expounded and Applied in Doctrine and Jurisprudence\". Although unpublished, this book increased his reputation among his associates in law. He returned to Arkansas in 1857, gaining some amount of prominence in the legal field.\nAt the Southern Commercial Convention of 1854, Pike said the South should remain in the Union and seek equality with the North, but if the South \"were forced into an inferior status, she would be better out of the Union than in it.\" His stand was that state's rights superseded national law and he supported the idea of a Southern secession. This stand is made clear in his pamphlet of 1861, \"State or Province, Bond or Free?\"\nAmerican Civil War.\nIn 1861, Pike penned the lyrics to \"Dixie to Arms!\" At the beginning of the war, Pike was appointed as Confederate envoy to Native American nations. In this capacity he negotiated several treaties, one of the most important being with Cherokee chief John Ross, which was concluded in 1861. At the time, Ross agreed to support the Confederacy, which promised the tribes a Native American state if it won the war. Ross later changed his mind and left Indian Territory, but the succeeding Cherokee government maintained the alliance.\nPike was commissioned as a brigadier general in the Confederate States Army on November 22, 1861, and given a command in the Indian Territory. With Brig. Gen. Ben McCulloch, Pike trained three Confederate regiments of Indian cavalry, most of whom belonged to the \"civilized tribes\", whose loyalty to the Confederacy was variable. Although initially victorious at the Battle of Pea Ridge (Elkhorn Tavern) in March 1862, Pike's unit was defeated later in a counterattack, after falling into disarray. When Pike was ordered in May 1862 to send troops to Arkansas, he resigned in protest. As in the previous war, Pike came into conflict with his superior officers, at one time drafting a letter to Jefferson Davis complaining about his direct superior.\nAfter Pea Ridge, Pike was faced with charges that his Native American troops had scalped soldiers in the field. Maj. Gen. Thomas C. Hindman also charged Pike with mishandling of money and material, ordering his arrest. Both these charges were later found to be considerably lacking in evidence; nevertheless Pike, facing arrest, escaped into the hills of Arkansas, submitting his resignation from the Confederate States Army on July 12, 1862. He was arrested on November 3 on charges of insubordination and treason, and held briefly in Warren, Texas. His resignation was accepted on November 11, and he was allowed to return to Arkansas.\nAs Union troops advanced toward the state capital in September 1863, the State Supreme Court retreated to Washington, Arkansas, which was made the new Confederate state capital. Associate Justice Hulbert F. Fairchild resigned because the new location was too far from his family, and Pike was appointed as his replacement.\nIn the wake of the war, Pike moved to New York City, then for a short time to Canada. On June 24, 1865, Pike applied to President Andrew Johnson for a pardon, disowning his earlier interpretation of the U.S. Constitution. He said he now planned \"to pursue the arts of peace, to practice my profession, to live among my books, and to labour to benefit my fellows and my race by other than political courses\". President Johnson pardoned him on April 23, 1866.\nLater life.\nDuring the Arkansas political conflict known as the Brooks-Baxter War, Pike was one of the lawyers to speak on behalf of Elisha Baxter.\nDeath and legacy.\nPike died on April 2, 1891, in Charleston, South Carolina, at the age of 81, and was buried at Oak Hill Cemetery, despite the fact that he had left instructions for his body to be cremated. In 1944, his remains were moved to the House of the Temple, headquarters of the Southern Jurisdiction of the Scottish Rite. The House of the Temple contains numerous memorials and artifacts related to Pike, including his personal library.\nA memorial to Pike was erected in 1901 in the Judiciary Square neighborhood of Washington, D.C. He was the only Confederate military officer with an outdoor statue in Washington, D.C., and in 2019 Delegate Eleanor Holmes Norton called for its removal. On June 19, 2020, protestors tore down the statue and set it ablaze, in connection with the George Floyd protests because of Pike's association with the Confederacy and the Ku Klux Klan.\nThe Albert Pike Memorial Temple is an historic Masonic lodge in Little Rock, Arkansas; the structure is listed on the National Register of Historic Places.\nControversies.\nIn the aftermath of the Civil War, as former Confederates found themselves barred from the ballot box, Pike remained deeply opposed to black suffrage, insisting that \"the white race, and that race alone, shall govern this country. It is the only one that is fit to govern, and it is the only one that shall.\" Regarding membership in the Freemasons, Pike is quoted as saying, \"I took my obligation to White men, not to Negroes. When I have to accept Negroes as brothers or leave Masonry, I shall leave it!\"\nVarious histories of the Ku Klux Klan published in the early 20th century identify Pike as a high-ranking official of the order. Walter Lynwood Fleming, in 1905's \"Ku Klux Klan: Its Origin, Growth and Disbandment\", lists Pike as the Klan's \"chief judicial officer\". Susan Lawrence Davis, whose father was a founding member of the Klan in Alabama, writes in her sympathetic account titled \"Authentic History: Ku Klux Klan, 1865-1877\", published in 1924, that Pike was personally chosen by Nathan Bedford Forrest to serve as the Klan's \"Chief Judicial Officer\" and to head the Klan in Arkansas. In 1939's \"Invisible Empire: The Story of the Ku Klux Klan, 1866-1871\", Stanley Horn also reports that Forrest appointed Pike and credits him with a surge of local Klan activity in April 1868. Horn says that a pro-Klan poem, \"Death's Brigade\", is attributed to Pike. Southern Agrarian poet John Gould Fletcher, who grew up in Little Rock in a house that Pike built, also believed Pike was the poem's author.\nHowever, Walter Lee Brown in his 1997 biography, found a lack of evidence that Pike was a member of the Klan. He cites Allen W. Trelease, author of 1971's \"White Terror: The Ku Klux Klan Conspiracy and Southern Reconstruction\", as being doubtful of Pike's membership, as the offices Pike allegedly held are not mentioned in \"The Prescript\", the Klan constitution.\nPike's only known writing on the Klan, an 1868 editorial in the \"Memphis Daily Appeal\", indicates that his main problems lay not with its aims, but with its methods and leadership. Later in this editorial, he proposed \"one great Order of Southern Brotherhood,\" a secret society which would have been a larger and more centrally organized version of the Klan: \"If it were in our power, if it could be effected, we would unite every white man in the South, who is opposed to negro suffrage, into one great Order of Southern Brotherhood, with an organization complete, active, vigorous, in which a few should execute the concentrated will of all, and whose very existence should be concealed from all but its members.\""}
{"id": "2372", "revid": "1018200267", "url": "https://en.wikipedia.org/wiki?curid=2372", "title": "ALF Tales", "text": "ALF Tales is a 30-minute Saturday morning animated series that aired on NBC from September 10, 1988 to December 9, 1989. The show is a spin-off of \"\" which featured characters from that series playing various characters from fairy tales. The fairy tale was usually altered for comedic effect in a manner akin to Jay Ward's \"Fractured Fairy Tales\".\nEach story typically spoofs a film genre, such as the \"Cinderella\" episode done as an Elvis Presley film. Some episodes featured a \"fourth wall\" effect where ALF is backstage preparing for the episode, and Rob Cowan would appear drawn as a TV executive (who introduced himself as \"Roger Cowan, network executive\") to try to brief ALF on how to improve this episode. For instance Cowan once told ALF who was readying for a medieval themed episode that \"less than 2% of our audience lives in the Dark Ages\".\nHome media.\nThe first seven episodes were released on DVD on May 30, 2006 in Region 1 from Lionsgate Home Entertainment in a single-disc release entitled \"ALF and The Beanstalk and Other Classic Fairy Tales\"."}
{"id": "2376", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=2376", "title": "Abdul Rashid Dostum", "text": "Abdul Rashid Dostum ( ; , Uzbek Latin: Abdul Rashid Do\u2018stum, Uzbek Cyrillic: \u0410\u0431\u0434\u0443\u043b \u0420\u0430\u0448\u0438\u0434 \u0414\u045e\u0441\u0442\u0443\u043c; born 25 March 1954) is an Afghan politician and Marshal in the Afghan National Army who has served as Vice President of Afghanistan from 2014 to 2020. An ethnic Uzbek, he fought for the communist government and the Soviets and in 2001 was the key indigenous ally to US Special Forces and the CIA during the campaign to topple the Taliban government after the 9/11 attacks. He is regarded as a warlord and is known for siding with winners during different wars in Afghanistan. He is the founder of the political party Junbish-e Milli (National Islamic Movement of Afghanistan).\nDostum has been widely accused of committing atrocities, war crimes, massacres (Dasht-i-Leili massacre) in Afghanistan since 1980s. In 2018, the International Criminal Court (ICC) was reported to be considering launching an inquiry into whether Dostum had engaged in war crimes in Afghanistan.\nDuring the Soviet\u2013Afghan War in the 1980s, Dostum was part of the Afghan National Army and the regional commander of the country's north, commanding about 20,000 mostly Uzbek soldiers participating in battles against mujahideen rebels. In 1992, he deserted the Mohammad Najibullah government shortly before its collapse, joining the mujahideen, forming his Junbish-e Milli party and militia and becoming an independent warlord. He subsequently became the \"de facto\" leader of Afghanistan's Uzbek community, controlling the country's northern provinces and Mazar-i-Sharif, effectively creating his own proto-state with an army of up to 40,000 men with tanks supplied by Uzbekistan and Russia and jets. He initially supported the new government of Burhanuddin Rabbani in Kabul but in 1994 switched sides and allied with Gulbuddin Hekmatyar. In 1995, he switched sides again and backed Rabbani. In 1997, he was forced to flee after his former aide Abdul Malik Pahlawan took Mazar-i-Sharif, before he fought back and regained control. In 1998, the city was overrun by the Taliban and he fled again. Dostum returned to Afghanistan in 2001 and joined the Northern Alliance after the US invasion, leading his faction in the Fall of Mazar-i-Sharif.\nAfter the fall of the Taliban, he joined Hamid Karzai's presidential administration but spent most of his time in Turkey. He also served as chairman Joint Chiefs of Staff of the Afghan Army, a role often viewed as ceremonial. From 2011, he was part of the leadership council of the National Front of Afghanistan along with Ahmad Zia Massoud and Mohammad Mohaqiq. In 2014, he joined Ashraf Ghani's presidential administration as a vice president, but was forced to flee again in 2017 after being accused of sexually assaulting a man named, Ahmad Eshchi. In 2018, he narrowly escaped a suicide bombing by ISIL-KP as he returned to Afghanistan at Kabul airport. In 2019, he escaped an hours-long attack by the Taliban on a convoy he was travelling in. Dostum is set to be promoted to marshal rank in 2020 after a political agreement between President Ghani and former CEO Abdullah Abdullah.\nEarly life.\nDostum was born in 1954 in Khwaja Du Koh near Sheberghan in Jowzjan Province, Afghanistan. Coming from an impoverished Uzbek family, he received a very basic traditional education as he was forced to drop out of school at a young age. From there, he took up work in the village's major gas fields.\nCareers.\nDostum began working in 1970 in a state-owned gas refinery in Sheberghan, participating in union politics, as the new government started to arm the staff of the workers in the oil and gas refineries. The reason for this was to create \"groups for the defense of the revolution\". Because of the new communist ideas entering Afghanistan in the 1970s, he enlisted in the Afghan National Army in 1978. Dostum received his basic military training in Jalalabad. His squadron was deployed in the rural areas around Sheberghan, under the auspices of the Ministry of National Security.\nSoviet\u2013Afghan War.\nBy the mid-1980s, he commanded around 20,000 militia men and controlled the northern provinces of Afghanistan. While the unit recruited throughout Jowzjan and had a relatively broad base, many of its early troops and commanders came from Dostum's home village. He left the army after the purge of Parchamites, but returned after the Soviet occupation began.\nDuring the Soviet\u2013Afghan War, Dostum was commanding a militia battalion to fight and rout mujahideen forces; he had been appointed an officer due to prior military experience. This eventually became a regiment and later became incorporated into the defense forces as the 53rd Infantry Division. Dostum and his new division reported directly to President Mohammad Najibullah. Later on he became the commander of the military unit 374 in Jowzjan. He defended the Soviet-backed Afghan government against the mujahideen forces throughout the 1980s. While he was only a regional commander, he had largely raised his forces by himself. The Jowzjani militia Dostum controlled was one of the few in the country which was able to be deployed outside its own region. They were deployed in Kandahar in 1988 when Soviet forces were withdrawing from Afghanistan.\nDue to his efforts in the army, Dostum was awarded the title \"Hero of the Republic of Afghanistan\" by President Najibullah.\nCivil war and northern Afghanistan autonomous state.\nDostum's men would become an important force in the fall of Kabul in 1992. In April 1992, the opposition forces began their march to Kabul against the government of Najibullah. Dostum had allied himself with the opposition commanders Ahmad Shah Massoud and Sayed Jafar Naderi, the head of the Isma'ili community, and together they captured the capital city. He and Massoud fought in a coalition against Gulbuddin Hekmatyar. Massoud and Dostum's forces joined together to defend Kabul against Hekmatyar. Some 4000\u20135000 of his troops, units of his Sheberghan-based 53rd Division and Balkh-based Guards Division, garrisoning Bala Hissar fort, Maranjan Hill, and Khwaja Rawash Airport, where they stopped Najibullah from entering to flee.\nDostum then left Kabul for his northern stronghold Mazar-i-Sharif, where he ruled, in effect, an independent region (or 'proto-state'), often referred as the Northern Autonomous Zone. He printed his own Afghan currency, ran a small airline named Balkh Air, and formed relations with countries like Uzbekistan. While the rest of the country was in chaos, his region remained prosperous and functional, and it won him the support from people of all ethnic groups. Many people fled to his territory to escape the violence and fundamentalism imposed by the Taliban later on. In 1994, Dostum allied himself with Gulbuddin Hekmatyar against the government of Burhanuddin Rabbani and Ahmad Shah Massoud, but in 1995 sided with the government again.\nTaliban era.\nFollowing the rise of the Taliban and their capture of Kabul, Dostum aligned himself with the Northern Alliance (United Front) against the Taliban. The Northern Alliance was assembled in late 1996 by Dostum, Massoud and Karim Khalili against the Taliban. At this point he is said to have had a force of some 50,000 men supported by both aircraft and tanks.\nMuch like other Northern Alliance leaders, Dostum also faced infighting within his group and was later forced to surrender his power to General Abdul Malik Pahlawan. Malik entered into secret negotiations with the Taliban, who promised to respect his authority over much of northern Afghanistan, in exchange for the apprehension of Ismail Khan, one of their enemies. Accordingly, on 25 May 1997, Malik arrested Khan, handed him over and let the Taliban enter Mazar-e-Sharif, giving them control over most of northern Afghanistan. Because of this, Dostum was forced to flee to Turkey. However, Malik soon realized that the Taliban were not sincere with their promises as he saw his men being disarmed. He then rejoined the Northern Alliance, and turned against his erstwhile allies, driving them from Mazar-e-Sharif. In October 1997, Dostum returned from exile and retook charge. After Dostum briefly regained control of Mazar-e-Sharif, the Taliban returned in 1998 and he again fled to Turkey.\nOperation Enduring Freedom.\nDostum returned to Afghanistan in May 2001 to open up a new front before the U.S.-led campaign against the Taliban joined him, along with Commander Massoud, Ismail Khan and Mohammad Mohaqiq. In November 2001, with the beginning of the U.S. invasion of Afghanistan, and against the wishes of the CIA who distrusted Dostum, a team including Johnny Micheal Spann landed to set up communications in Dar-e-Suf. A few hours later 12 men of Operational Detachment Alpha (ODA) 595 landed to begin the war.\nOn 24 November 2001, 15,000 Taliban soldiers surrendered after the Siege of Kunduz to American and Northern Alliance forces. The Taliban laid down their weapons a few kilometres from the city of Mazar-i-Sharif, and eventually surrendered to Dostum. A small group of armed foreign fighters were transferred to the 19th century garrison fortress, Qala-i-Jangi. The Taliban used concealed weapons to start the Battle of Qala-i-Jangi against the guards. The uprising was eventually brought under control.\nDasht-i-Leili massacre.\nGeneral Dostum has been accused by Western journalists of responsibility for the suffocating or otherwise killing of 2,000 Taliban prisoners in December 2001. Dostum denied the accusations in 2009. US President Obama in 2009 ordered an investigation into the matter, which as yet has yielded no (published) results.\nKarzai administration.\nIn the aftermath of Taliban's removal from northern Afghanistan, forces loyal to Dostum frequently clashed with Tajik forces loyal to Atta Muhammad Nur. Atta's men kidnapped and killed a number of Dostum's men, and constantly agitated to gain control of Mazar-e-Sharif. Through the political mediations of the Karzai administration, the International Security Assistance Force (ISAF) and the United Nations, the Dostum-Atta feud has gradually declined. They are now aligned in a new political party\nDostum served as deputy defense minister the early period of the Karzai administration. On 20 May 2003, Dostum narrowly escaped an assassination attempt. He was often residing outside Afghanistan, mainly in Turkey. In February 2008, he was suspended after the apparent kidnapping and torture of a political rival.\nTime in Turkey.\nSome media reports in 2008 stated earlier that Dostum was \"seeking political asylum\" in Turkey while others said he was exiled. One Turkish media outlet said Dostum was visiting after flying there with then Turkey's Foreign Minister Ali Babacan during a meeting of the Organization for Security and Cooperation in Europe (OSCE).\nOn 16 August 2009, Dostum was asked to return from exile to Afghanistan to support President Hamid Karzai in his bid for re-election. He later flew by helicopter to his northern stronghold of Sheberghan, where he was greeted by thousands of his supporters in the local stadium. He subsequently made overtures to the United States, promising he could \"destroy the Taliban and al Qaeda\" if supported by the U.S., saying that \"the U.S. needs strong friends like Dostum.\"\nGhani administration.\nOn 7 October 2013, the day after filing his nomination for the 2014 general elections as running mate of Ashraf Ghani, Dostum issued a press statement that some news media were willing to welcome as \"apologies\": \"Many mistakes were made during the civil war (\u2026) It is time we apologize to the Afghan people who were sacrificed due to our negative policies (\u2026) I apologize to the people who suffered from the violence and civil war (\u2026)\".\nDostum was directly chosen as First Vice President of Afghanistan in the April\u2013June 2014 Afghan presidential election, next to Ashraf Ghani as president and Sarwar Danish as second vice president.\nIn July 2016, Human Rights Watch accused Abdul Rashid Dostum's National Islamic Movement of Afghanistan of killing, abusing and looting civilians in the northern Faryab Province during June. Militia forces loyal to Dostum stated that the civilians they targeted \u2013 at least 13 killed and 32 wounded \u2013 were supporters of the Taliban.\nIn November 2016, at a buzkashi match, he punched his political rival Ahmad Ischi, and then his bodyguards beat Ischi. In 2017, he was accused of having Ischi kidnapped in that incident and raped with a gun on camera during a five-day detention, claims that Dostum denies but that nevertheless forced him into exile in Turkey.\nOn 26 July 2018, he narrowly escaped a suicide bombing by ISIL-KP as he returned to Afghanistan at Kabul airport. Just after Dostum's convoy departed the airport, an attacker armed with a suicide vest bombed a crowd of several hundred people celebrating his return at the entrance to the airport. The attack killed 14 and injured 50, including civilians and armed security.\nOn 30 March 2019, Dostum again escaped an expected assassination attempt while traveling from Mazar-e-Sharif to Jawzjan Province, though two of his bodyguards were killed. The Taliban claimed responsibility for the attack, the second in eight months.\nPolitical and social views.\nDostum is considered to be liberal and somewhat leftist. Being ethnic Uzbek, he has worked on the battlefield with leaders from all other major ethnic groups, Hazaras, Tajiks and Pashtuns. When Dostum was ruling his northern Afghanistan proto-state before the Taliban took over in 1998, women were able to go about unveiled, girls were allowed to go to school and study at the University of Balkh, cinemas showed Indian films, music played on television, and Russian vodka and German beer were openly available \u2013 activities which were all banned by the Taliban.\nHe viewed the ISAF forces attempt to crush the Taliban as ineffective and has gone on record saying in 2007 that he could mop up the Taliban \"in six months\" if allowed to raise a 10,000 strong army of Afghan veterans. Senior Afghan government officials do not trust Dostum as they are concerned that he might be secretly rearming his forces."}
{"id": "2377", "revid": "18821312", "url": "https://en.wikipedia.org/wiki?curid=2377", "title": "Andhra Pradesh", "text": "Andhra Pradesh (; Telugu: ) is a state in the south-eastern coastal region of India. It is the seventh-largest state by area covering an area of and tenth-most populous state with 49,386,799 inhabitants. It is bordered by Telangana to the north-west, Chhattisgarh to the north, Odisha to the north-east, Tamil Nadu to the south, Karnataka to the west and the Bay of Bengal to the east. It has the second longest coastline in India after Gujarat, of about . Andhra Pradesh is the first state to be formed on a linguistic basis in India on 1 October 1953. The state was once a major Buddhist pilgrimage site in the country and a Buddhist learning center which can be seen in many sites in the state in the form of ruins, chaityas and stupas It is also known as the land of the world-famous diamond Koh-i-Noor and many other global known diamonds due to their source in its Kollur Mine. It is also known as the \"rice bowl of India\" for being a major producer of rice in India. Its official language is Telugu; one of the classical languages of India, the fourth most spoken language in India and the 11th-most spoken language in the world.\nEarly inhabitants were known as the Andhras, tracing their history to the Vedic period when they were mentioned in the 8th century BCE Rigvedic text Aitareya Brahmana. According to the Aitareya Brahmana, the Andhras left North India from the banks of river Yamuna and migrated to South India.&lt;ref name=\"Devi 1990 https://archive.org/details/dancedialectsofi0000ragi/page/n241 66\"&gt;&lt;/ref&gt; The Assaka Mahajanapada (700\u2013300\u00a0BCE) was an ancient kingdom located between the Godavari and Krishna rivers in southeastern India accounts that people in the region are descended from the Viswamitra are found in the \"Ramayana\", the \"Mahabharata\" and the Puranas. The region also derives its name from Satavahanas who are also known as Andhras, the earliest kings of Andhra Pradesh and India. Early peoples supported local art culture by building temples and sculptures of the Buddhist monuments in the state. It was ruled by Mauryan Empire, Satavahana dynasty, Salankayanas, Andhra Ikshvakus, Pallavas, Vishnukundinas, Eastern Chalukyas, Rashtrakutas, Cholas, Kakatiyas, Vijayanagara Empire, Gajapati Empire, Mughal Empire, Deccan sultanates, Qutb Shahi dynasty, Asaf Jahis. In the 3rd century BCE, Andhra was a vassal kingdom of Ashoka but after his death Andhra became powerful and extended its empire to the whole of Maratha country and beyond.\nAndhra Pradesh comprises two major regions, namely Rayalaseema in the south-west and Coastal Andhra bordering the Bay of Bengal in the east and north-east. The state has thirteen districts, nine located in Coastal Andhra and four in Rayalaseema. The state also has a union territory, Yanam \u2013 a district of Puducherry which lies to the south of Kakinada in the Godavari delta on the eastern side of the state. It is the only state with three capitals (proposed). The largest city and commercial hub of the state, Visakhapatnam being the executive capital while Amaravati and Kurnool are legislative and judicial capitals, respectively. The economy of Andhra Pradesh is the seventh-largest state economy in India with in gross domestic product and a higher than national average per capita GDP of . Andhra Pradesh ranks 27th among Indian states in Human Development Index (HDI). It has a jurisdiction over almost of territorial waters.\nAndhra Pradesh hosted 121.8 million visitors in 2015, a 30% growth in tourist arrivals over the previous year, making it the third most-visited state in India. The Tirumala Venkateswara Temple in Tirupati is one of the world's most visited religious sites, with 18.25 million visitors per year. The region is also home to a variety of other pilgrimage centres, such as the Pancharama Kshetras, Mallikarjuna Jyotirlinga and Kodanda Rama Temple. The state's natural attractions include the beaches of Visakhapatnam, hill stations such as the Araku Valley and Horsley Hills, and the deltas of Konaseema in the Godavari river, and Diviseema in the Krishna river.\nHistory.\nToponomy.\nA group of people named Andhras was mentioned in Sanskrit texts such as Aitareya Brahmana (800\u2013500 BCE). According to \"Aitareya Brahmana\" of the Rig Veda, the Andhras left north India from banks of River Yamuna and settled in south India. The Satavahanas have been mentioned by the names \"Andhra\", \"Andhrara-jateeya\" and \"Andhrabhrtya\" in the Puranic literature. They did not refer themselves as \"Andhra\" in any of their coins or inscriptions; it is possible that they were termed as Andhras because of their ethnicity or because their territory included the Andhra region.\nEarly and medieval history.\nThe Assaka Mahajanapada, one of the sixteen Vedic Mahajanapadas, included Andhra, Maharashtra and Telangana. Archaeological evidence from places such as Amaravati, Dharanikota, and Vaddamanu suggests that the Andhra region was part of the Mauryan Empire. Amaravati might have been a regional centre for the Mauryan rule. After the death of Emperor Ashoka, Mauryan rule weakened around 200\u00a0BCE and was replaced by several smaller kingdoms in the Andhra region.\nThe Satavahana dynasty dominated the Deccan region from the 1st century BCE to the 3rd century CE. The later Satavahanas made Dharanikota and Amaravathi their capital, which according to the Buddhists is the place where Nagarjuna, the philosopher of Mahayana lived in the 2nd and 3rd centuries. The Andhra Ikshvakus, with their capital at Vijayapuri, succeeded the Satavahanas in the Krishna River valley in the latter half of the 2nd century. Pallavas, who were originally executive officers under the Satavahana kings, were not a recognised political power before the 2nd century CE and were swept away by the Western Chalukyan invasion, led by Pulakesin II in the first quarter of the 7th century CE. After the downfall of the Ikshvakus, the Vishnukundinas were the first great dynasty in the 5th and 6th centuries, and held sway over the entire Andhra country, including Kalinga and parts of Telangana. They played an important role in the history of Deccan during the 5th and 6th century CE, with Eluru, Amaravathi and Puranisangam.\nThe Salankayanas were an ancient dynasty that ruled the Andhra region between Godavari and Krishna with their capital at Vengi (modern Pedavegi) from 300 to 440\u00a0CE. The Eastern Chalukyas of Vengi, whose dynasty lasted for around five hundred years from the 7th century until 1130\u00a0CE, eventually merged with the Chola dynasty. They continued to rule under the protection of the Chola dynasty until 1189\u00a0CE when the kingdom succumbed to the Hoysalas and the Yadavas. The roots of the Telugu language have been seen on inscriptions found near the Guntur district and from others dating to the rule of Renati Cholas in the fifth century CE.\nKayastha chiefs descended from North Indian Kayasthas ruled over vast swathes of land in Andhra country, and they are recorded in Andhra history dating back to the 13th century . Kakatiyas ruled Andhra Pradesh state for nearly two hundred years and constructed several forts. They were succeeded by the Musunuri Nayaks. Musunuri Nayaks led a confederation of Nayakas to overthrow the rule of the Delhi Sultanate in Telugu lands.\nThe Reddi kingdom (1325\u20131448\u00a0CE) was established by Prolaya Vema Reddi in the early 14th century, who ruled from present day Kondaveedu. Prolaya Vema Reddi was part of the confederation of states that started a movement against the invading Turkic Muslim armies of the Delhi Sultanate. They constructed Kondaveedu Fort , which they ruled between 1328 and 1428, before it was taken over by the Gajpathis of Orissa, and later ravaged by the Muslim rulers of the Bahmani kingdom in 1458. The Vijayanagara emperor Krishnadevaraya captured it in 1516. The Golconda Sultans fought for the fort in 1531, 1536 and 1579, and Sultan Quli Qutb Shah captured it in 1579, renaming it \"Murtuzanagar\". It was reconquered by Vijayanagara who overthrew sultanate rule across the entirety of modern-day Andhra Pradesh (excluding Telangana). After this rebellion, the Bahmani sultans launched no further military campaigns outside their kingdoms, because the Maratha empire soon emerged as the strongest power in India. Efforts are in progress to classify Kondaveedu Fort as a UNESCO World Heritage Site.\nThe Vijayanagara Empire originated in the Deccan Plateau region in the early 14th century. It was established in 1336 by Harihara Raya I and his brother Bukka Raya I of the Sangama Dynasty. The empire's patronage enabled fine arts and literature to reach new heights in Kannada, Telugu, Tamil, and Sanskrit, while Carnatic music evolved into its current form. During the Vijayanagara Empire, the Pemmasani Nayaks controlled parts of Andhra Pradesh and had large mercenary armies that were the vanguard of the Vijayanagara Empire in the sixteenth century. The Lepakshi group of monuments are culturally and archaeologically significant as it is the location of shrines dedicated to Shiva, Vishnu, and Veerabhadra which were built during the Vijayanagara Kings' period (1336\u20131646). The temples are the location of mural paintings of the Vijayanagara kings, Dravidian art, and inscriptions. Near the temple complex is a large granite Nandi bull. On a hillock known as \"Kurma Saila\" ('tortoise-shaped hill') are other temples to Papanatheswara, Raghunatha, Srirama, and Durga.\nThe Government of Andhra Pradesh has taken the initiative for including the \"Lepakshi Group of Monuments\" among the UNESCO World Heritage sites in India.\nModern history.\nHarihara and Bukka, who served as treasury officers of the Kakatiyas of Warangal, founded the Vijayanagara Empire. In 1347 CE, an independent Muslim state, the Bahmani Sultanate, was established in south India by Ala-ud-Din Bahman Shah in a revolt against the Delhi Sultanate. The Qutb Shahi dynasty held sway over the Andhra country after the resolution of Vijayanagar empire by joint action of Mughals, Bijapur and Golconda sultanates.\nIn the early nineteenth century, Northern Circars was ceded to the British East India Company and became part of the Madras Presidency. Eventually, this region emerged as the Coastal Andhra region. Later the Nizam rulers of Hyderabad ceded five territories to the British that eventually became the Rayalaseema region. The Nizams retained control of the interior provinces as the princely state of Hyderabad, acknowledging British rule in return for local autonomy. However, Komaram Bheem, a tribal leader, started his fight against the erstwhile Asaf Jahi Dynasty for the liberation of Hyderabad State. Meanwhile, the French occupied Yanam, in the Godavari delta, and (save for periods of British control) would hold it until 1954. In 1947, Vizianagaram was the largest Hindu princely state in Andhra Pradesh.\nIndia became independent from the United Kingdom in 1947. The Nizam wanted to retain the independence of the Princely Hyderabad State from India, but the people of the region launched a movement to join the Indian Union. The state of Hyderabad was integrated into the Indian Union with Operation Polo in 1948.\nPost-independence.\nIn an effort to gain an independent state based on linguistic identity, and to protect the interests of the Telugu-speaking people of Madras State, Potti Sreeramulu fasted to death in 1952. As Madras became a bone of contention, in 1949 a JVP committee report stated: \"Andhra Province could be formed provided the Andhras give up their claim on the city of Madras [now Chennai]\". After Potti Sreeramulu's death, the Telugu-speaking area of Andhra State was carved out of Madras State on 1 October 1953, with Kurnool as its capital city. On the basis of the gentlemen's agreement of 1 November 1956, the States Reorganisation Act formed combined Andhra Pradesh by merging Andhra State with the Telugu-speaking areas of the already existing Hyderabad State. Hyderabad was made the capital of the new state. The Marathi-speaking areas of Hyderabad State merged with Bombay State and the Kannada-speaking areas were merged with Mysore State.\nIn February 2014, the Andhra Pradesh Reorganisation Act, 2014 bill was passed by the Parliament of India for the formation of the Telangana state comprising ten districts. Hyderabad will remain as a joint capital for not exceeding ten years. The new state of Telangana came into existence on 2 June 2014 after approval from the President of India. Number of petitions questioning the validity of Andhra Pradesh Reorganisation Act, 2014 is long pending for the verdict since April 2014 before the Supreme Court constitutional bench.\nIn 2017, Andhra Pradesh Government began operating from the newly planned capital city Amaravati. In August 2020, Andhra Pradesh Legislative Assembly passed Andhra Pradesh Decentralisation and Inclusive Development of All Regions Act, 2020. According to its provisions, Visakhapatnam is the executive capital while Amaravati and Kurnool serve as legislative and judicial capitals, respectively. The decision resulted in widespread protests by the farmers of Amaravati. The act has been challenged in Andhra Pradesh High Court, which ordered to maintain status quo until the court completes its hearing.\nGeography.\nThe state has varied topography ranging from the hills of Eastern Ghats and Nallamala Hills to the shores of Bay of Bengal that support varied ecosystems, the rich diversity of flora and fauna. There are two main rivers namely, Krishna and Godavari, that flow through the state. The coastline of the state extends along the Bay of Bengal from Srikakulam to Nellore district with a length of 975\u00a0km (606\u00a0mi). The plains to the east of Eastern Ghats form the Eastern Coastal plains. The coastal plains are for the most part of delta regions formed by the Godavari, Krishna, and Penna rivers. The Eastern Ghats are discontinuous and individual sections have local names. The Eastern Ghats are a major dividing line in the state's geography. The Kadapa Basin formed by two arching branches of the Eastern Ghats is a mineral-rich area. The Ghats become more pronounced towards the south and extreme north of the coast. Most of the coastal plains are put to intense agricultural use. The Rayalaseema region has semi-arid conditions.\nNatural vegetation and conservation.\nThe Andhra Pradesh Forest Department deals with protection, conservation and management of forests. The total forest cover of the state after the bifurcation is left with an area of . The forest in the state can be broadly divided into four major biotic provinces. They are:\nEastern Ghats region is home to dense tropical forests, while the vegetation becomes sparse as the Ghats give way to the Deccan Plateau, where shrub vegetation is more common. The vegetation found in the state is largely of dry deciduous types with a mixture of teak, \"Terminalia\", \"Dalbergia\", \"Pterocarpus\", \"Anogeissus\", etc.\nThe state has many sanctuaries, national parks and zoological parks, such as Coringa, Krishna Wildlife Sanctuary, Nagarjunsagar-Srisailam Tiger Reserve, Kambalakonda Wildlife Sanctuary, Sri Venkateswara Zoological Park and Indira Gandhi Zoological Park. Atapaka Bird Sanctuary, Nelapattu Bird Sanctuary, Telineelapuram and Telukunchi Bird Sanctuaries and Pulicat Lake Bird Sanctuary attract many migratory birds. The state possesses some rare and endemic plants like \"Cycas beddomei\", \"Pterocarpus santalinus\", \"Terminalia pallida\", \"Syzygium alternifolium\", \"Shorea talura\", \"Shorea tumburgia\", \"Psilotum nudum\", etc. The diversity of fauna includes tigers, panthers, hyenas, black bucks, cheetals, sambars, sea turtles and a number of birds and reptiles. The estuaries of the Godavari and Krishna rivers support rich mangrove forests with fishing cats and otters as keystone species.\nClimate.\nThe climate of Andhra Pradesh varies considerably, depending on the geographical region. Summers last from March to June. In the coastal plain, the summer temperatures are generally higher than the rest of the state, with temperature ranging between . July to September is the season for tropical rains. About one-third of the total rainfall is brought by the northeast monsoon. October and November see low-pressure systems and tropical cyclones form in the Bay of Bengal which, along with the northeast monsoon, bring rains to the southern and coastal regions of the state.\nNovember, December, January, and February are the winter months in Andhra Pradesh. Since the state has a long coastal belt the winters are not very cold. The range of winter temperature is generally . Lambasingi in Visakhapatnam district is also nicknamed as the \"Kashmir of Andhra Pradesh\" due to its relatively cool climate as compared to others and the temperature ranges from .\nDemographics.\n Census of India, the residual state had a population of with a population density of . According to the Polavaram ordinance bill 2014, 7 mandals of Khammam district in Telangana state merged with Andhra Pradesh to facilitate Polavaram project, due to which population of added to Andhra Pradesh. Thus the final population of Andhra Pradesh in the year 2014, as per census 2011 is , with a density of .\nThe total population constitute, 70.4% of rural population with inhabitants and 29.6% of urban population with inhabitants. Children in the age group of 0\u20136 years are , constituting 10.6% of the total population, among them are boys and are girls. Visakhapatnam district has the largest urban population of 47.5% and Srikakulam district with 83.8%, has the largest rural population, among others districts in the state. The overall population of the state comprises 17.1% of Scheduled Caste and 5.3% of Scheduled Tribe population.\nThere are male and female citizens\u2014a sex ratio of 996 females per 1000 males, higher than the national average of 926 per 1000. The literacy rate of the state stands at 67.41%. However, post bifurcation from Telangana, the state is expected to reach 91.1% by 2021. West Godavari district has the highest literacy rate of 74.6% and Vizianagaram district has the least with 58.9%.\nAndhra Pradesh ranks tenth of all Indian States in the Human Development Index scores with a score of 0.416. The National Council of Applied Economic Research district analysis in 2001 reveals that Krishna, West Godavari and Chittoor are the three districts in rural AP with the highest Human Development Index scores in ascending order.\nLanguages.\nTelugu is the official language of Andhra Pradesh, which is also the mother tongue of nearly 90% of the population. The Minister of Tourism and Culture has declared Telugu a Classical Language.\nUrdu is the largest minority language. Tamil, Kannada and Odia are also spoken mainly in the border-areas. Lambadi, Koya, Savara, Konda, Gadaba and a number of other languages are spoken by the Scheduled Tribes of the state.\nReligion.\nThe majority of the people in Andhra Pradesh are Hindus while Muslims constitute a sizeable minority. According to the 2011 census, the major religious groups in the state are Hindus (90.87%), Muslims (7.32%) and Christians (1.38%). Buddhists, Sikhs, Jains and the people who declined to state their religion make up the remaining portion of population.\nHinduism.\nVenkateswara Temple at Tirupati is the world's second-richest temple and is visited by millions of devotees throughout the year. Andhra Pradesh is home to Shankaracharya of Pushpagiri Peetham. Other Hindu saints include Sadasiva Brahmendra, Bhaktha Kannappa, Yogi Vemana, Sathya Sai Baba and Pothuluru Veerabrahmendra.\nMahayana Buddhism.\nBuddhism spread to Andhra Pradesh early in its history. The Krishna river valley was \"a site of extraordinary Buddhist activity for almost a thousand years.\" The ancient Buddhist sites in the lower Krishna valley, including Amaravati, Nagarjunakonda and Jaggayyapeta \"can be traced to at least the third century BCE, if not earlier.\"\nThe region played a central role in the development of Mahayana Buddhism, along with the Magadha-area in northeastern India. A. K. Warder holds that \"the Mah\u0101y\u0101na originated in the south of India and almost certainly in the Andhra country.\" According to Xing, \"Several scholars have suggested that the Prajnaparamita probably developed among the Mahasamghikas in Southern India probably in the Andhra country, on the Krishna River.\" The Praj\u00f1\u0101p\u0101ramit\u0101 Sutras belong to the earliest Mahayana Sutras.\nAdministrative divisions.\nRegions.\nAndhra Pradesh comprises three regions: Coastal Andhra, Uttarandhra and Rayalaseema.\nDistricts.\nIt has a total of 13 districts, six in Coastal Andhra region, three in Uttarandhra and four in the Rayalaseema region.\nCoastal Andhra Region :\nUttarandhra Region :\nRayalaseema Region :\nRevenue divisions.\nThese 13 districts are further divided into 50 revenue divisions. There are as many as 7 revenue divisions in East Godavari, and only 2 in Vizianagaram district.\nMandals.\nThe 50 revenue divisions are in turn divided into 671 mandals. Chittoor district has the most mandals with 66 and Vizianagaram has the least with 34.\nCities.\nThere are a total of 31 cities which include, 16 municipal corporations and 14 municipalities. There are two cities with more than one million inhabitants, namely Visakhapatnam and Vijayawada.\nGovernment and politics.\nWhen the state was first created, Tanguturi Prakasam Pantulu, became the Chief Minister. After the unification with Telangana, Neelam Sanjiva Reddy became the first Chief Minister. He later served as the President of India.\nThe Indian National Congress (INC), the Praja Socialist Party and the Krishi Lok Party were the major parties in the 1950s. Later the Communist Party of India (CPI) became the dominant opposition party. In the 1967 state assembly elections, all socialist parties were eliminated and the CPI lost opposition party status.\nThe INC ruled the state from 1956 to 1982. In 1983, the Telugu Desam Party (TDP) won the state elections and N. T. Rama Rao became the Chief Minister of the state for the first time. This broke the long-time single party monopoly enjoyed by the INC. The 1989 elections ended the rule of Rao, with the INC returning to power with Marri Chenna Reddy at the helm. He was replaced by Janardhan Reddy in 1990, who was replaced by Kotla Vijaya Bhaskara Reddy in 1992.\nIn 1994, Andhra Pradesh gave a mandate to the Telugu Desam Party again, and Rao became the Chief Minister again. Nara Chandrababu Naidu, Rao's son-in-law, came to power in 1995 with the backing of a majority of the MLAs. The Telugu Desam Party won both the assembly and Lok Sabha election in 1999 under the leadership of Chandrababu Naidu. Thus Naidu held the record for the longest-serving Chief Minister (1995 to 2004).\nIn 2004, Congress returned to power with a new chief ministerial face, YS Rajashekara Reddy, better known as YSR. He also won the 2009 elections, but shortly afterward was killed in a helicopter crash in September of that year. He was succeeded by two other Congressmen, namely Konijeti Rosaiah and Nallari Kiran Kumar Reddy, the last resigning over the impending division of Telangana.\nIn the last elections held in the unified state in 2014, the TDP got a mandate in their favour in the residuary (new) state. After Telangana became a separate state, Naidu, the chief of the TDP became the Chief Minister on 8 June 2014, for the new state of Andhra Pradesh.\nAs of 2014, the Legislative Assembly of Andhra Pradesh is the lower house of the state with 175 members and the Legislative Council is the upper house with 58 members. In the Parliament of India, Andhra Pradesh has 11 seats in the Rajya Sabha, and 25 seats in the Lok Sabha. There are a total of 175 Assembly constituencies in the state. East Godavari district has the highest number of constituencies with 19 and Vizianagaram district has the least with 9 assembly seats. Whereas, the legislative council of the state has 58 seats, which is one-third of total assembly seats.\nIn the 2019 elections, YSR's son Y. S. Jaganmohan Reddy of the YSR Congress Party (founded in 2011) became the Chief Minister with a resounding mandate by winning 151 out of 175 seats.\nEconomy.\nAndhra Pradesh was ranked eighth among other Indian states in terms of GSDP for the financial year 2014\u20132015. The GSDP at current prices was and at constant prices was . The domestic product of agriculture sector accounts for and industrial sector for . The service sector of the state accounts more percentage of the GSDP with a total of . In the 2010 list by \"Forbes\" magazine, several people from Andhra Pradesh were among the top 100 richest Indians.\nAgriculture.\nAndhra Pradesh's economy is mainly based on agriculture and livestock. Four important rivers of India, the Godavari, Krishna, Penna, and Tungabhadra flow through the state and provide irrigation. 60 percent of the population is engaged in agriculture and related activities. Rice is the major food crop and staple food of the state. It is an exporter of many agricultural products and is also known as \"Rice Bowl of India\". The state has three Agricultural Economic Zones in Chittoor district for mango pulp and vegetables, Krishna district for mangoes, Guntur district for chilies.\nBesides rice, farmers also grow jowar, bajra, maize, minor millet, coarse grain, many varieties of pulses, oil seeds, sugarcane, cotton, chili pepper, mango nuts and tobacco. Crops used for vegetable oil production such as sunflower and peanuts are popular. There are many multi-state irrigation projects under development, including Godavari River Basin Irrigation Projects and Nagarjuna Sagar Dam.\nLivestock and poultry is also another profitable business, which involves rearing cattle in enclosed areas for commercial purposes. The state is also a largest producer of eggs in the country and hence, it is nicknamed as \"Egg Bowl of Asia\".\nFisheries contribute 10% of total fish and over 70% of the shrimp production of India. The geographical location of the state allows marine fishing as well as inland fish production. The most exported marine exports include \"Vannamei shrimp\" and are expected to cross billion in 2013\u20132014.\nInfrastructure.\nAndhra Pradesh is investing in building infrastructure in the state such as highways and making every service of the government digital. National Highway 16 passes through Andhra Pradesh. The highways in the state are also being widened. APSFL is an initiative of the government of Andhra Pradesh to set up an optical fiber network throughout the thirteen districts of Andhra Pradesh. This network provides internet connectivity, telephony and IPTV with fiber to private and corporate users of Andhra Pradesh. The state also has seaports such as Visakhapatnam Port, Kakinada Port, Krishnapatnam Port for import and export and a shipyard for building ships at Visakhapatnam. Major airports in the state are Visakhapatnam, Rajahmundry, Vijayawada, with Visakhapatnam, Tirupati and Vijayawada being international airports.\nIndustrial sector.\nThe industrial sector of the state includes some of the key sectors like pharmaceutical, automobile, textiles etc. Sricity located in Chittoor district is an integrated business city which is home to firms including PepsiCo, Isuzu Motors, Cadbury India, Kellogg's, Colgate-Palmolive, Kobelco etc. The PepsiCo firm has its largest plant in India at Sri City. The state is also emerging as destination for the automobile industry which already hosts companies including Ashok Leyland in Krishna district, Hero Motors in Chittoor district, Kia Motors in Anantapur district.\nThe state is also emerging in information technology and biotechnology. The IT/ITES revenues of Visakhapatnam is at in 2012\u20132013. The development of IT in Tier-II and Tier-III cities like Vijayawada, Kakinada and Tirupati is also improving. In the fiscal year 2012\u20132013, Vijayawada's IT/ITeS revenues were . Tirupati with and Kakinada with stand next. For the benefit of state, that is, after separating Telangana from Andhra, people of Andhra protested for special status during January in 2017.\nResources.\nAndhra Pradesh is one of the storehouses of mineral resources in India. Andhra Pradesh with varied geological formations, contain rich and variety of industrial minerals and building stones.\nAndhra Pradesh is listed at the top in the deposit and production of mica in India. Minerals found in the state include limestone, reserves of oil and natural gas, manganese, asbestos, iron ore, ball clay, fire clay, gold diamonds, graphite, dolomite, quartz, tungsten, steatitic, feldspar, silica sand. It has about one-third of India's limestone reserves and is known for large exclusive deposits of barytes and galaxy granite in the international market.\nMining.\nMining is identified as one of the growth engines for the overall development of industry and infrastructure. The Tummalapalle Uranium mine in Andhra has confirmed of ore and there are indications that it could hold reserves totaling three times its current size. of metal grade Bauxite deposits in proximity to Visakhapatnam Port.\nReliance Industries struck nine trillion cubic feet of gas reserves in the KG basin, off the Andhra Pradesh coast near Kakinada. Discovery of a large quantity of natural gas in KG Basin is expected to provide rapid economic growth. During 2016, nearly of methane hydrate deposits were explored in KG basin whose extraction was adequate to impart energy security for many decades to India.\nPower plants.\nThe state is a pioneer nationwide in solar power generation. APGENCO is the power generating company owned by the state. The state has become power surplus with excess power generation being exported to other states. The state is abundantly endowed with solar power and high head PHES sites to convert the solar power available during the day time in to round the clock power supply. PHES projects also has synergy with the lift irrigation projects in storing water available during the monsoon season and supplying to the uplands throughout the year. Ultimate water and energy requirements of the state can be fully met by the combination of cheap solar power, PHES and irrigation projects economically harnessing renewable energy without much damage to the environment.\nThermal (natural gas and coal based) and renewable power plants totaling to 21,000\u00a0MW were installed in the state by the year 2015. Local power plants of 9,600\u00a0MW capacity only are supplying electricity in the state, which includes Simhadri Super Thermal Power Station (2000\u00a0MW) of NTPC, Vizag Thermal Power Station (1040\u00a0MW), Rayalaseema Thermal Power Station (1650\u00a0MW), Sri Damodaram Sanjeevaiah Thermal Power Station (1600\u00a0MW), and Narla Tata Rao Thermal Power Plant (1760\u00a0MW). Hydel power plants have a capacity of 1671\u00a0MW.\nCulture.\nAndhra Pradesh has rich culture and heritage.\nKuchipudi, the cultural dance recognized as the official dance form of the state of Andhra Pradesh, originated in the village of Kuchipudi in Krishna district. It entered the Guinness World Records for performing \"Mahabrinda Natyam\" with a total of 6,117 dancers in Vijayawada.\nAndhra Pradesh has thirteen geographical indications in categories of agricultural handicrafts, foodstuff and textiles as per \"Geographical Indications of Goods (Registration and Protection) Act, 1999\". It increased to fifteen with the addition of Banaganapalle Mangoes and Bandar laddu. The other GI tagged goods are, Bobbili Veena, Budithi Bell and Brass Craft, Dharmavaram Handloom Pattu Sarees and Paavadas, Guntur Sannam, Kondapalli Toys, Machilipatnam Kalamkari, Mangalagiri Sarees and Fabrics, Srikalahasti Kalamkari, Tirupati Laddu, Uppada Jamdani Sari and Venkatagiri Sari.\nArts, crafts and artifacts.\nMachilipatnam and Srikalahasti Kalamkari are the two unique textile art forms practised in India. There are also other notable handicrafts present in the state, like the soft limestone idol carvings of Durgi. Etikoppaka in Visakhapatnam district is notable for its lac industry, producing lacquered wooden.\nThe state has many museums, which features a varied collection of ancient sculptures, paintings, idols, weapons, cutlery, and inscriptions, and religious artifacts such as the Amaravati Archaeological Museum, Visakha Museum and Telugu Cultural Museum in Visakhapatnam displays the history of the pre-independence and the Victoria Jubilee Museum in Vijayawada with a large collection of artifacts.\nLiterature.\nNannayya, Tikkana and Yerrapragada form the trinity who translated the Sanskrit epic \"Mahabharata\" into Telugu language. Nannayya wrote the first treatise on Telugu grammar called \"Andhra Shabda Chintamani\" in Sanskrit, as there was no grammatical work in Telugu prior to that. Pothana is the poet who composed the classic \"Srimad Maha Bhagavatamu\", a Telugu translation of \"Sri Bhagavatam\". Vemana is notable for his philosophical poems. The Vijayanagara emperor Krishnadevaraya wrote Amuktamalyada. Telugu literature after Kandukuri Veeresalingam is termed as Adhunika Telugu Sahityam (Modern Telugu literature). He is known as \"Gadya Tikkana\" and was the author of Telugu social novel, \"Satyavati Charitam\". Jnanpith Award holders from the state include Viswanatha Satyanarayana. The Andhra Pradesh native and revolutionary poet Sri Sri brought new forms of expressionism into Telugu literature.\nMedia.\nThe print media in the state consists mainly of Telugu and English newspapers. \"Eenadu\", \"Sakshi\", \"Andhra Jyothi\", and Tel.J.D.Patrika Vaartha all these are Telugu newspapers. English newspapers include Deccan Chronicle and The Hans India.\nArt and cinema.\nMany composers of Carnatic music like Annamacharya, Kshetrayya, and Bhadrachala Ramadas were of Telugu descent. Modern Carnatic music composers and singers like Ghantasala, Sujatha Puligella and M. Balamuralikrishna are also of Telugu descent. The Telugu film industry hosts many music composers and playback singers such as S. P. Balasubrahmanyam, P. Susheela, S. Janaki and P. B. Sreenivas. Folk songs are very important and popular in the many rural areas of the state. Forms such as the \"Burra katha\" and \"Poli\" are still performed today. \"Harikathaa Kalakshepam (or Harikatha)\" involves the narration of a story, intermingled with various songs relating to the story. Harikatha was originated in Andhra. \"Burra katha\" is an oral storytelling technique with the topic be either a Hindu mythological story or a contemporary social issue. \"Rangasthalam\" is an Indian theatre in the Telugu language, based predominantly in Andhra Pradesh. Gurajada Apparao wrote the play \"Kanyasulkam\" in 1892, often considered the greatest play in the Telugu language. C. Pullaiah is cited as the father of Telugu theatre movement.\nThe Telugu film industry is largely based in Hyderabad and Visakhapatnam. The Telugu film culture (also known as \"Tollywood\") is the second-largest film industry in India next to the Bollywood film industry. Film producer D. Ramanaidu holds a Guinness Record for the most films produced by a person. In the years 2005, 2006 and 2008, the Telugu film industry produced the largest number of films in India, exceeding the number of films produced in Bollywood. The industry holds the Guinness World Record for the largest film production facility in the world.\nCuisine.\nTelugu people's traditional sweet Pootharekulu originated from Atreyapuram village of East Godavari district.\nTourism.\nThe state has several beaches in its coastal districts such as Rushikonda, Mypadu, Suryalanka etc.; caves such as, Borra Caves, Indian rock-cut architecture depicting Undavalli Caves and the country's second longest caves- the Belum Caves. The valleys and hills include, Araku Valley, Horsley Hills, Papi Hills etc. Arma Konda peak located in Visakhapatnam district is the highest peak in Eastern Ghats.\nThe state is home to various religious pilgrim destinations such as, Tirumala Temple, Simhachalam Temple, Annavaram temple, Srisailam temple, Kanaka Durga Temple, Amaravati, Srikalahasti, Shahi Jamia Masjid in Adoni, Gunadala Church in Vijayawada, Buddhist centres at Amaravati, and Nagarjuna Konda.\nTransport.\nThe state is well connected to other states through road and rail networks. It is also connected to other countries by means of airways and seaports as well. With a long seacoast along the Bay of Bengal, it also has many ports for sea trade. The state has one of the largest railway junctions at Vijayawada and one of the largest seaports at Visakhapatnam.\nRoads.\nThe state has a total road network of , of which of National highways, of state highways and of district roads. NH 16, with a highway network of around in the state, is a part of Golden Quadrilateral Project undertaken by National Highways Development Project. It also forms part of AH 45 which comes under the Asian Highway Network.\nThe state government owned Andhra Pradesh State Road Transport Corporation (APSRTC) is the major public bus transport, which runs thousands of buses connecting different parts of the state. Pandit Nehru Bus Station (PNBS) in Vijayawada is one of the largest bus terminals in Asia. From 30 January 2019, all the vehicles in the state are registered as AP\u201339, followed by an alphabet and four digits.\nRailways.\nAndhra Pradesh has a total broad-gauge railway route of and has no metre-gauge railway. The rail density of the state is 16.59 per , compared to an all India average of 20. The Howrah\u2013Chennai main line which runs through the state is proposed to be upgraded into a high-speed rail corridor through the Diamond Quadrilateral project of the Indian Railways.\nThe railway network spans two zones, further subdivided into divisions \u2013 Vijayawada, Guntur and Guntakal railway divisions of South Central Railway zone, and Waltair railway division of East Coast Railway zone. There is a demand for creating a unified zone for the state based out of Visakhapatnam.\nThere are three A1 and twenty three A-category railway stations in the state. has been declared the cleanest railway station in the country. The railway station of Shimiliguda was the first highest broad gauge railway station in the country.\nAs on date the Railways lines in Andhra Pradesh are under the following Railway zones/Divisions\nAirports.\nVisakhapatnam Airport, is the only airport in the state with operating international flights while Vijayawada Airport at Gannavaram has launched an international flight to Singapore, recently. The state has four other domestic airports, Rajahmundry Airport, Kadapa Airport, a privately owned, public use airport at Puttaparthi, and Tirupati Airport located in the city of Tirupati. There are also 16 small air strips located in the state.\nSea ports.\nAndhra Pradesh has one of the country's largest port at Visakhapatnam in terms of cargo handling. The other famous ports are Krishnapatnam Port (Nellore), Gangavaram Port and Kakinada Port. Gangavaram Port is a deep seaport which can accommodate ocean liners up to 200,000\u2013250,000 DWT. There are 14 notified non-major ports at Bheemunipatnam, S.Yanam, Machilipatnam, Nizampatnam, and Vadarevu.\nEducation and research.\nAndhra Pradesh has an overall literacy rate of 67.41% as per the 2011 Indian census. The primary and secondary school education is imparted by government, aided and private schools, managed and regulated by the School Education Department of the state. There are urban, rural and residential schools. As per the child info and school information report (2018\u201319), there were a total of students, enrolled in schools respectively. The Directorate of Government Examinations of the state administers and conduct the Secondary School Certificate (SSC) examination. More than students have appeared for the 2019 SSC exam and recorded an overall pass percentage of 94.88% with a 100% pass percentage in 5,464 schools. The mediums of instruction are primarily Telugu and English with a very few opting for Urdu, Hindi, Kannada, Odia and Tamil.\nHigher education in the state is administered by the Department of Higher Education. The central universities are All India Institute of Medical Sciences, IIM Visakhapatnam, IIT Tirupati, NIT Tadepalligudem, IIITDM Kurnool, Indian Institute of Petroleum and Energy, NIDV, Central University of Andhra Pradesh, IIIT Sri City, IISER Tirupati, Agriculture University, Guntur and IIFT Kakinada. The Government of Andhra Pradesh established Rajiv Gandhi University of Knowledge Technologies (RGUKT) in 2008 to cater to the education needs of the rural youth of Andhra Pradesh. As per the University Grants Commission, GITAM, KL University and Vignan University are the Deemed Universities in the state. There are 18 state universities in the districts providing higher education in horticulture, law, medical, technology, Vedic and veterinary. Andhra University is the oldest of the universities in the state, established in 1926.\nResearch.\nResearch institutes have been set up by the central state government. Naval Science and Technological Laboratory (NSTL), National Institute of Oceanography, Visakhapatnam (NIO), School of Planning and Architecture at Vijayawada is an autonomous research institute under Ministry of Human Resource Development of Government of India, National Atmospheric Research Laboratory carry out fundamental and applied research in atmospheric and space sciences, Indian Institute of Science Education and Research, Tirupati, Society for Applied Microwave Electronics Engineering and Research, Visakhapatnam Central Tobacco Research Institute, Rajahmundry under control of ICAR (Indian Council of Agriculture Research) conducts fundamental and applied research on tobacco for the benefit of the farming community, Indian Institute of Oil Palm Research (IIOPR) at Pedavegi near Eluru in West Godavari district serves as a centre for conducting and co-ordinating research on all aspects of oil palm conservation, improvement, production, protection, post-harvest technology and transfer of technology, CCRH Regional Research Institute at Gudivada, Clinical Research Institute at Tirupati and National Institute of Oceanography at Visakhapatnam are some of them.\nSpace research organisation.\nSatish Dhawan Space Centre, also known as Sriharikota Range (SHAR), at barrier island of Sriharikota in Nellore district is a satellite launching station operated by Indian Space Research Organisation. It is India's primary orbital launch site. India's lunar orbiter Chandrayaan-1 was launched from the centre at 6:22 AM IST on 22 October 2008.\nSports.\nThe Sports Authority of Andhra Pradesh is the governing body which looks after the infrastructure development in cricket, field hockey, association football, Skating, Olympic weightlifting, chess, water sports, tennis, badminton, table tennis, cycling, etc.\nCricket is one of the most popular sports in the state. The ACA-VDCA Stadium in Visakhapatnam is the home to Andhra Pradesh cricket team. The venue regularly hosts international as well as domestic matches. Notable cricketers from Andhra Pradesh include former Indian captain Mohammad Azharuddin, Maharajkumar of Vizianagram, M. V. Narasimha Rao, M. S. K. Prasad, VVS Laxman, Tirumalasetti Suman, Arshad Ayub, Ambati Rayudu, Venkatapathy Raju, Sravanthi Naidu, Yalaka Venugopal Rao and Hanuma Vihari.\nHumpy Koneru, from Gudivada in Krishna district, is an Indian chess Grandmaster.\nKarnam Malleswari, the first female Indian to win an Olympic medal, hails from Srikakulam district. She won the bronze medal on 19 September 2000, in the category with a lift of .\nKrishnam Raju Gadiraju of Bhimavaram, is a four-time world record holder. He is a speedsolver and Unicyclist.\nPullela Gopichand is a former Indian badminton player. He won the All England Open Badminton Championships in 2001, becoming the second Indian to win after Prakash Padukone.\nCherukuri Lenin (1985 or 198624 October 2010) was an Indian archer and coach who won a silver medal at the Asian Grand Prix in Malaysia and was a national archery coach."}
{"id": "2379", "revid": "153314", "url": "https://en.wikipedia.org/wiki?curid=2379", "title": "Asymmetrical relationship", "text": ""}
{"id": "2380", "revid": "13157623", "url": "https://en.wikipedia.org/wiki?curid=2380", "title": "Accelerated Graphics Port", "text": "Accelerated Graphics Port (AGP) is an expansion bus standard, designed for attaching a video card to a computer system to assist in the acceleration of 3D computer graphics. It was originally designed as a successor to PCI-type connections for video cards. Since 2004, AGP has been progressively phased out in favor of PCI Express (PCIe); by mid-2008, PCI Express cards dominated the market and only a few AGP models were available, with GPU manufacturers and add-in board partners eventually dropping support for the interface in favor of PCI Express.\nAdvantages over PCI.\nAs computers increasingly became graphically oriented, successive generations of graphics adapters began to push the limits of PCI, a bus with shared bandwidth. This led to the development of AGP, a \"bus\" dedicated to graphics adapters.\nAGP is heavily based on PCI, and in fact the AGP bus is a superset of the conventional PCI bus, and AGP cards must act as PCI cards.\nThe primary advantage of AGP over PCI is that it provides a dedicated pathway between the slot(s) and the processor rather than sharing the PCI bus. In addition to a lack of contention for the bus, the direct connection allows for higher clock speeds.\nThe second major change is that AGP uses split transactions, where the address and data phases of a PCI transaction are separated. The card may send many address phases, and the host processes them in order. This avoids long delays, with the bus idle, during read operations.\nThird, PCI bus handshaking is simplified. Unlike PCI bus transactions whose length is negotiated on a cycle-by-cycle basis using the FRAME# and STOP# signals, AGP transfers are always a multiple of 8 bytes long, and the total length is included in the request. Further, rather than using the IRDY# and TRDY# signals for each word, data is transferred in blocks of four clock cycles (32 words at AGP 8\u00d7 speed), and pauses are allowed only between blocks.\nFinally, AGP allows (optional in AGP 1.0 and 2.0, mandatory in AGP 3.0) \"sideband addressing\", meaning that the address and data buses are separated so the address phase does not use the main address/data (AD) lines at all. This is done by adding an extra 8-bit \"SideBand Address\" bus over which the graphics controller can issue new AGP requests while other AGP data is flowing over the main 32 address/data (AD) lines. This results in improved overall AGP data throughput.\nThis great improvement in memory read performance makes it practical for an AGP card to read textures directly from system RAM, while a PCI graphics card must copy it from system RAM to the card's video memory. System memory is made available using the graphics address remapping table (GART), which apportions main memory as needed for texture storage. The maximum amount of system memory available to AGP is defined as the \"AGP aperture\".\nHistory.\nThe AGP slot first appeared on x86-compatible system boards based on Socket 7 Intel P5 Pentium and Slot 1 P6 Pentium II processors. Intel introduced AGP support with the i440LX Slot 1 chipset on August 26, 1997, and a flood of products followed from all the major system board vendors.\nThe first Socket 7 chipsets to support AGP were the VIA Apollo VP3, SiS 5591/5592, and the ALI Aladdin V. Intel never released an AGP-equipped Socket 7 chipset. FIC demonstrated the first Socket 7 AGP system board in November 1997 as the \"FIC PA-2012\" based on the VIA Apollo VP3 chipset, followed very quickly by the \"EPoX P55-VP3\" also based on the VIA VP3 chipset which was first to market.\nEarly video chipsets featuring AGP support included the Rendition V\u00e9rit\u00e9 V2200, 3dfx Voodoo Banshee, Nvidia RIVA 128, 3Dlabs PERMEDIA 2, Intel i740, ATI Rage series, Matrox Millennium II, and S3 ViRGE GX/2. Some early AGP boards used graphics processors built around PCI and were simply bridged to AGP. This resulted in the cards benefiting little from the new bus, with the only improvement used being the 66\u00a0MHz bus clock, with its resulting doubled bandwidth over PCI, and bus exclusivity. Examples of such cards were the Voodoo Banshee, V\u00e9rit\u00e9 V2200, Millennium II, and S3 ViRGE GX/2. Intel's i740 was explicitly designed to exploit the new AGP feature set; in fact it was designed to texture only from AGP memory, making PCI versions of the board difficult to implement (local board RAM had to emulate AGP memory.)\nMicrosoft first introduced AGP support into \"Windows 95 OEM Service Release 2\" (OSR2 version 1111 or 950B) via the \"USB SUPPLEMENT to OSR2\" patch. After applying the patch the Windows 95 system became \"Windows 95 version 4.00.950 B\". The first Windows NT-based operating system to receive AGP support was Windows NT 4.0 with Service Pack 3, introduced in 1997. Linux support for AGP enhanced fast data transfers was first added in 1999 with the implementation of the AGPgart kernel module.\nVersions.\nIntel released \"AGP specification 1.0\" in 1997. It specified 3.3\u00a0V signals and 1\u00d7 and 2\u00d7 speeds. Specification 2.0 documented 1.5\u00a0V signaling, which could be used at 1\u00d7, 2\u00d7 and the additional 4\u00d7 speed and 3.0 added 0.8\u00a0V signaling, which could be operated at 4\u00d7 and 8\u00d7 speeds. (1\u00d7 and 2\u00d7 speeds are physically possible, but were not specified.)\nAvailable versions are listed in the adjacent table.\nAGP version 3.5 is only publicly mentioned by Microsoft under \"Universal Accelerated Graphics Port (UAGP)\", which specifies mandatory supports of extra registers once marked optional under AGP 3.0. Upgraded registers include PCISTS, CAPPTR, NCAPID, AGPSTAT, AGPCMD, NISTAT, NICMD. New required registers include APBASELO, APBASEHI, AGPCTRL, APSIZE, NEPG, GARTLO, GARTHI.\nThere are various physical interfaces (connectors); see the Compatibility section.\nOfficial extensions.\nAGP Pro.\nAn official extension for cards that required more electrical power, with a longer slot with additional pins for that purpose. AGP Pro cards were usually workstation-class cards used to accelerate professional computer-aided design applications employed in the fields of architecture, machining, engineering, simulations, and similar fields.\n64-bit AGP.\nA 64-bit channel was once proposed as an optional standard for AGP 3.0 in draft documents, but it was dropped in the final version of the standard.\nThe standard allows 64-bit transfer for AGP8\u00d7 reads, writes, and fast writes; 32-bit transfer for PCI operations.\nUnofficial variations.\nA number of non-standard variations of the AGP interface have been produced by manufacturers.\nCompatibility.\nAGP cards are backward and forward compatible within limits. 1.5 V-only keyed cards will not go into 3.3 V slots and vice versa, though \"Universal\" cards exist which will fit into either type of slot. There are also unkeyed \"Universal\" slots that will accept either type of card. When an AGP Universal card is plugged-into an AGP Universal slot, only the 1.5 V portion of the card is used. Some cards, like Nvidia's GeForce 6 series (except the 6200) or ATI's Radeon X800 series, only have keys for 1.5 V to prevent them from being installed in older mainboards without 1.5 V support. Some of the last modern cards with 3.3 V support were the Nvidia GeForce FX series (FX 5200, FX 5500, FX 5700, some FX 5800, FX 5900 and some FX 5950), certain Geforce 6 Series and 7 series (few cards were made with 3.3v support except for 6200 where 3.3v support was common) and the ATI Radeon 9500/9700/9800 (R300/R350) (but not 9600/9800(R360/RV360)). Some Geforce 6200/6600/6800 and Geforce 7300/7600/7800/7900/7950 cards will function with AGP 1.0 (3.3v) slots, but those are really uncommon compared to their AGP 1.5v only versions.\nAGP Pro cards will not fit into standard slots, but standard AGP cards will work in a Pro slot. Motherboards equipped with a Universal AGP Pro slot will accept a 1.5 V or 3.3 V card in either the AGP Pro or standard AGP configuration, a Universal AGP card, or a Universal AGP Pro card.\nSome cards incorrectly have dual notches, and some motherboards incorrectly have fully open slots, allowing a card to be plugged into a slot that does not support the correct signaling voltage, which may damage card or motherboard. Some incorrectly designed older 3.3 V cards have the 1.5 V key.\nThere are some proprietary systems incompatible with standard AGP; for example, Apple Power Macintosh computers with the Apple Display Connector (ADC) have an extra connector which delivers power to the attached display. Some cards designed to work with a specific CPU architecture (e.g., PC, Apple) may not work with others due to firmware issues.\nMark Allen of Playtools.com made the following comments regarding Practical AGP Compatibility for AGP 3.0 and AGP 2.0:\n\"...nobody makes AGP 3.0 cards, and nobody makes AGP 3.0 motherboards. At least not any manufacturers I can find. Every single video card I could find which claimed to be an AGP 3.0 card was actually a universal 1.5V AGP 3.0 card. And every motherboard which claimed to be an AGP 3.0 motherboard turned out to be a universal 1.5V AGP 3.0 motherboard. It makes sense, if you think about it, because if anyone actually shipped a consumer-oriented product which supported only 0.8 volts, they would end up with lots of confused customers and a support nightmare. In the consumer market, you'd have to be crazy to ship a 0.8 volt only product.\"\nPower consumption.\nActual power supplied by an AGP slot depends upon the card used. The maximum current drawn from the various rails is given in the specifications for the various versions. For example, if maximum current is drawn from all supplies and all voltages are at their specified upper limits, an AGP\u00a03.0 slot can supply up to 48.25\u00a0watts; this figure can be used to specify a power supply conservatively, but in practice a card is unlikely ever to draw more than 40\u00a0W from the slot, with many using less. AGP Pro provides additional power up to 110\u00a0W. Many AGP cards had additional power connectors to supply them with more power than the slot could provide.\nLater use.\nBy 2010, few new motherboards had AGP slots. No new motherboard chipsets were equipped with AGP support, but motherboards continued to be produced with older chipsets with support for AGP.\nGraphics processors of this period use PCI-Express, a general-purpose (not restricted to graphics) standard that supports higher data transfer rates and full-duplex. To create AGP-compatible graphics cards, those chips require an additional PCIe-to-AGP bridge-chip to convert PCIe signals to and from AGP signals. This incurs additional board costs due to the need for the additional bridge chip and for a separate AGP-designed circuit board.\nVarious manufacturers of graphics cards continued to produce AGP cards for the shrinking AGP user-base. The first bridged cards were the GeForce 6600 and ATI Radeon X800 XL boards, released during 2004\u20135. In 2009 AGP cards from Nvidia had a ceiling of the GeForce 7 Series. In 2011 DirectX 10-capable AGP cards from AMD vendors (Club 3D, HIS, Sapphire, Jaton, Visiontek, Diamond, etc.) included the Radeon HD 2400, 3450, 3650, 3850, 4350, 4650, and 4670. The HD 5000 AGP series mentioned in the AMD Catalyst software was never available. There were many problems with the AMD Catalyst 11.2 - 11.6 AGP hotfix drivers under Windows 7 with the HD 4000 series AGP video cards; use of 10.12 or 11.1 AGP hotfix drivers is the recommended workaround. Several of the vendors listed above make available past versions of the AGP drivers. \nIn 2016, Windows 10 version 1607 dropped support for AGP videocards making Windows 10 1511 the last Windows release to support AGP. AGP support removal in future Linux kernel and drivers was also considered as well.\nProtocol.\nAn AGP bus is a superset of a 66\u00a0MHz conventional PCI bus and, immediately after reset, follows the same protocol. The card must act as a PCI target, and optionally may act as a PCI master. (AGP 2.0 added a \"fast writes\" extension which allows PCI writes from the motherboard to the card to transfer data at higher speed.)\nAfter the card is initialized using PCI transactions, AGP transactions are permitted. For these, the card is always the AGP master and the motherboard is always the AGP target. The card queues multiple requests which correspond to the PCI address phase, and the motherboard schedules the corresponding data phases later. An important part of initialization is telling the card the maximum number of outstanding AGP requests which may be queued at a given time.\nAGP requests are similar to PCI memory read and write requests, but use a different encoding on command lines C/BE[3:0] and are always 8-byte aligned; their starting address and length are always multiples of 8 bytes (64 bits). The three low-order bits of the address are used instead to communicate the length of the request.\nWhenever the PCI GNT# signal is asserted, granting the bus to the card, three additional status bits ST[2:0] indicate the type of transfer to be performed next. If the bits are codice_1, a previously queued AGP transaction's data is to be transferred; if the three bits are codice_2, the card may begin a PCI transaction or (if sideband addressing is not in use) queue a request in-band using PIPE#.\nAGP command codes.\nLike PCI, each AGP transaction begins with an address phase, communicating an address and 4-bit command code. The possible commands are different from PCI, however:\nAGP 3.0 dropped high-priority requests and the long read commands, as they were little used. It also mandated side-band addressing, thus dropping the dual address cycle, leaving only four request types: low-priority read (0000), low-priority write (0100), flush (1010) and fence (1100).\nIn-band AGP requests using PIPE#.\nTo queue a request in-band, the card must request the bus using the standard PCI REQ# signal, and receive GNT# plus bus status ST[2:0] equal to codice_2. Then, instead of asserting FRAME# to begin a PCI transaction, the card asserts the PIPE# signal while driving the AGP command, address, and length on the C/BE[3:0], AD[31:3] and AD[2:0] lines, respectively. (If the address is 64 bits, a dual address cycle similar to PCI is used.) For every cycle that PIPE# is asserted, the card sends another request without waiting for acknowledgement from the motherboard, up to the configured maximum queue depth. The last cycle is marked by deasserting REQ#, and PIPE# is deasserted on the following idle cycle.\nSide-band AGP requests using SBA[7:0].\nIf side-band addressing is supported and configured, the PIPE# signal is not used. (And the signal is re-used for another purpose in the AGP 3.0 protocol, which requires side-band addressing.) Instead, requests are broken into 16-bit pieces which are sent as two bytes across the SBA bus. There is no need for the card to ask permission from the motherboard; a new request may be sent at any time as long as the number of outstanding requests is within the configured maximum queue depth. The possible values are:\nSideband address bytes are sent at the same rate as data transfers, up to 8\u00d7 the 66\u00a0MHz basic bus clock. Sideband addressing has the advantage that it mostly eliminates the need for turnaround cycles on the AD bus between transfers, in the usual case when read operations greatly outnumber writes.\nAGP responses.\nWhile asserting GNT#, the motherboard may instead indicate via the ST bits that a data phase for a queued request will be performed next. There are four queues: two priorities (low- and high-priority) for each of reads and writes, and each is processed in order. Obviously, the motherboard will attempt to complete high-priority requests first, but there is no limit on the number of low-priority responses which may be delivered while the high-priority request is processed.\nFor each cycle when the GNT# is asserted and the status bits have the value codice_13, a read response of the indicated priority is scheduled to be returned. At the next available opportunity (typically the next clock cycle), the motherboard will assert TRDY# (target ready) and begin transferring the response to the oldest request in the indicated read queue. (Other PCI bus signals like FRAME#, DEVSEL# and IRDY# remain deasserted.) Up to four clock cycles worth of data (16 bytes at AGP 1\u00d7 or 128 bytes at AGP 8\u00d7) are transferred without waiting for acknowledgement from the card. If the response is longer than that, both the card and motherboard must indicate their ability to continue on the third cycle by asserting IRDY# (initiator ready) and TRDY#, respectively. If either one does not, wait states will be inserted until two cycles after they both do. (The value of IRDY# and TRDY# at other times is irrelevant and they are usually deasserted.)\nThe C/BE# byte enable lines may be ignored during read responses, but are held asserted (all bytes valid) by the motherboard.\nThe card may also assert the RBF# (read buffer full) signal to indicate that it is temporarily unable to receive more low-priority read responses. The motherboard will refrain from scheduling any more low-priority read responses. The card must still be able to receive the end of the current response, and the first four-cycle block of the following one if scheduled, plus any high-priority responses it has requested.\nFor each cycle when GNT# is asserted and the status bits have the value codice_14, write data is scheduled to be sent across the bus. At the next available opportunity (typically the next clock cycle), the card will assert IRDY# (initiator ready) and begin transferring the data portion of the oldest request in the indicated write queue. If the data is longer than four clock cycles, the motherboard will indicate its ability to continue by asserting TRDY# on the third cycle. Unlike reads, there is no provision for the card to delay the write; if it didn't have the data ready to send, it shouldn't have queued the request.\nThe C/BE# lines \"are\" used with write data, and may be used by the card to select which bytes should be written to memory.\nThe multiplier in AGP 2\u00d7, 4\u00d7 and 8\u00d7 indicates the number of data transfers across the bus during each 66\u00a0MHz clock cycle. Such transfers use source synchronous clocking with a \"strobe\" signal (AD_STB[0], AD_STB[1], and SB_STB) generated by the data source. AGP 4\u00d7 adds complementary strobe signals.\nBecause AGP transactions may be as short as two transfers, at AGP 4\u00d7 and 8\u00d7 speeds it is possible for a request to complete in the middle of a clock cycle. In such a case, the cycle is padded with dummy data transfers (with the C/BE# byte enable lines held deasserted).\nConnector pinout.\nThe AGP connector contains almost all PCI signals, plus several additions. The connector has 66 contacts on each side, although 4 are removed for each keying notch. Pin\u00a01 is closest to the I/O bracket, and the B and A sides are as in the table, looking down at the motherboard connector.\nContacts are spaced at 1\u00a0mm intervals, however they are arranged in two staggered vertical rows so that there is 2\u00a0mm space between pins in each row. Odd-numbered A-side contacts, and even-numbered B-side contacts are in the lower row (1.0 to 3.5\u00a0mm from the card edge). The others are in the upper row (3.7 to 6.0\u00a0mm from the card edge).\nPCI signals omitted are:\nSignals added are:"}
{"id": "2381", "revid": "37247652", "url": "https://en.wikipedia.org/wiki?curid=2381", "title": "Andreas Aagesen", "text": "Andreas Aagesen (5 August 1826\u00a0\u2013 26 October 1879) was a Danish jurist.\nBiography.\nAagesen was educated for the law at Christianshavn and Copenhagen, and interrupted his studies in 1848 to take part in the First Schleswig War, in which he served as the leader of a reserve battalion.\nIn 1855 Aagesen became a professor of jurisprudence at the University of Copenhagen. In 1870 he was appointed a member of the commission for drawing up a maritime and commercial code, and the navigation law of 1882 is mainly his work. In 1879 he was elected a member of the Landsting (one of two chambers of the Danish Parliament, the Rigsdagen); but it is as a teacher at the university that he won his reputation. Aagesen was Carl Christian Hall's successor as lecturer on Roman law at the university, and in this department his research was epoch-making.\nBibliography.\nAmong his numerous juridical works may be mentioned:"}
{"id": "2382", "revid": "37857296", "url": "https://en.wikipedia.org/wiki?curid=2382", "title": "Aalen", "text": "Aalen () is a former Free Imperial City located in the eastern part of the German state of Baden-W\u00fcrttemberg, about east of Stuttgart and north of Ulm. It is the seat of the Ostalbkreis district and is its largest town. It is also the largest town in the Ostw\u00fcrttemberg region. Since 1956, Aalen has had the status of Gro\u00dfe Kreisstadt (major district town). It is noted for its many half-timbered houses constructed from the 16th century through the 18th century.\nWith an area of 146.63\u00a0km2, Aalen is ranked 7th in Baden-W\u00fcrttemberg and 2nd within the Government Region of Stuttgart, after Stuttgart. With a population of about 66,000, Aalen is the 15th most-populated settlement in Baden-W\u00fcrttemberg.\nGeography.\nSituation.\nAalen is situated on the upper reaches of the river Kocher, at the foot of the Swabian Jura which lies to the south and south-east, and close to the hilly landscapes of the Ellwangen Hills to the north and the \"Welland\" to the north-west.\nThe west of Aalen's territory is on the foreland of the eastern Swabian Jura, and the north and north-west is on the Swabian-Franconian Forest, both being part of the Swabian Keuper-Lias Plains. The south-west is part of the Albuch, the east is part of the H\u00e4rtsfeld, these two both being parts of the Swabian Jura.\nThe Kocher enters the town's territory from Oberkochen to the south, crosses the district of Unterkochen, then enters the town centre, where the \"Aal\" flows into it. The \"Aal\" is a small river located only within the town's territory. Next, the Kocher crosses the district of Wasseralfingen, then leaves the town for H\u00fcttlingen. Rivers originating near Aalen are the Rems (near Essingen, west of Aalen) and the Jagst (near Unterschneidheim, east of Aalen), both being tributaries of the Neckar, just like the Kocher.\nThe elevation in the centre of the market square is relative to Normalh\u00f6hennull. The territory's lowest point is at the Lein river near Rodamsd\u00f6rfle, the highest point is the Gr\u00fcnberg's peak near Unterkochen at .\nGeology.\nAalen's territory ranges over all lithostratigraphic groups of the South German Jurassic: Aalen's south and the \"Flexner\" massif are on top of the White Jurassic, the town centre is on the Brown Jurassic, and a part of Wasseralfingen is on the Black Jurassic. As a result, the town advertises itself as a \"Geologist's Mecca\".\nMost parts of the territory are on the \"Opalinuston-Formation\" (Opalinum Clay Formation) of the Aalenian subdivision of the Jurassic Period, which is named after Aalen. On the \"Sandberg\", the \"Schnaitberg\" and the \"Schradenberg\" hills, all in the west of Aalen, the \"Eisensandstein\" (Iron Sandstone) formation emerges to the surface. On the other hills of the city, sands \"(Goldsh\u00f6fer Sande)\", gravel and residual rubble prevail.\nThe historic centre of Aalen and the other areas in the Kocher valley are founded completely on holocenic floodplain loam \"(Auelehm)\" and riverbed gravel that have filled in the valley.\nMost parts of Dewangen and Fachsenfeld are founded on formations of \"Jurensismergel\" (Jurensis Marl), \"Posidonienschiefer\" (cf. Posidonia Shale), \"Amaltheenton\" (Amalthean Clay), \"Numismalismergel\" (Numismalis Marl) and \"Obtususton\" (Obtusus Clay, named after Asteroceras obtusum ammonites) moving from south to north, all belonging to the Jurassic and being rich in fossils. They are at last followed by the \"Trossingen Formation\" already belonging to the Late Triassic.\nUntil 1939 iron ore was mined on the \"Braunenberg\" hill. (see Tiefer Stollen section).\nExtent of the borough.\nThe maximum extent of the town's territory amounts to in a north\u2013south dimension and in an east\u2013west dimension. The area is , which includes 42.2% agriculturally used area and 37.7% of forest. 11.5% are built up or vacant, 6.4% is used by traffic infrastructure. Sporting and recreation grounds and parks comprise 1% , other areas 1.1% .\nAdjacent towns.\nThe following municipalities border on Aalen. They are listed clockwise, beginning south, with their respective linear distances to Aalen town centre given in brackets:\nOberkochen (), Essingen (), Heuchlingen (), Abtsgm\u00fcnd (), Neuler (), H\u00fcttlingen (), Rainau (), Westhausen (), Lauchheim (), Bopfingen () and Neresheim (), all in the Ostalbkreis district, furthermore Heidenheim an der Brenz () and K\u00f6nigsbronn (), both in Heidenheim district.\nBoroughs.\nAalen's territory consists of the town centre \"(Kernstadt)\" and the municipalities\nmerged from between 1938 (Unterrombach) and 1975 (Wasseralfingen, see mergings section).\nThe municipalities merged in the course of the latest municipal reform of the 1970s are also called \"Stadtbezirke\" (quarters or districts), and are \"Ortschaften\" (\"settlements\") in terms of Baden-W\u00fcrttemberg's \"Gemeindeordnung\" (municipal code), which means, each of them has its own council elected by its respective residents \"(Ortschaftsrat)\" and is presided by a spokesperson \"(Ortsvorsteher)\".\nThe town centre itself and the merged former municipalities consist of numerous villages \"(Teilorte)\", mostly separated by open ground from each other and having their own independent and long-standing history. Some however have been created as planned communities, which were given proper names, but no well-defined borders.\nList of villages:\nSpatial planning.\nAalen forms a \"Mittelzentrum\" (\"medium-level centre\") within the Ostw\u00fcrttemberg region. Its designated catchment area includes the following municipalities of the central and eastern Ostalbkreis district: Abtsgm\u00fcnd, Bopfingen, Essingen, H\u00fcttlingen, Kirchheim am Ries, Lauchheim, Neresheim, Oberkochen, Riesb\u00fcrg and Westhausen, and is interwoven with the catchment area of N\u00f6rdlingen, situated in Bavaria, east of Aalen.\nClimate.\nAs Aalen's territory sprawls on escarpments of the Swabian Jura, on the Albuch and the H\u00e4rtsfeld landscapes, and its elevation has a range of , the climate varies from district to district.\nThe weather station the following data originate from is located between the town centre and Wasseralfingen at about and has been in operation since 1991.\nThe sunshine duration is about 1800 hours per year, which averages 4.93 hours per day. So Aalen is above the German average of 1550 hours per year. However, with 167 days of precipitation, Aalen's region also ranks above the German average of 138. The annual rainfall is , which places Aalen in the middle within Baden-W\u00fcrttemberg.\nThe annual mean temperature is . Here Aalen ranks above the German average of and the Baden-W\u00fcrttemberg average of .\nHistory.\nCivic history.\nFirst settlements.\nNumerous remains of early civilization have been found in the area. Tools made of flint and traces of Mesolithic human settlement dated between the 8th and 5th millennium BC were found on several sites on the margins of the Kocher and Jagst valleys. On the \"Schlo\u00dfbaufeld\" plateau (appr. ), situated behind \"Kocherburg\" castle near Unterkochen, a hill-top settlement was found, with the core being dated to the Bronze Age. In the \"Appenwang\" forest near Wasseralfingen, in Goldsh\u00f6fe, and in Ebnat, tumuli of the Hallstatt culture were found. In Aalen and Wasseralfingen, gold and silver coins left by the Celts were found. The Celts were responsible for the fortifications in the Schlo\u00dfbaufeld settlement consisting of sectional embankments and a stone wall. Also, Near Heisenberg (Wasseralfingen), a Celtic nemeton has been identified; however it is no longer readily apparent.\nRoman era.\nAfter abandoning the Alb Limes (a \"limes\" generally following the ridgeline of the Swabian Jura) around 150 AD, Aalen's territory became part of the Roman Empire, in direct vicinity of the then newly erected Rhaetian Limes. The Romans erected a castrum to house the cavalry unit \"Ala II Flavia milliaria\"; its remains are known today as \"Kastell Aalen\" (\"Aalen Roman fort\"). The site is west of today's town centre at the bottom of the \"Schillerh\u00f6he\" hill. With about 1,000 horsemen and nearly as many grooms, it was the greatest fort of auxiliaries along the Rhaetian Limes. There were Civilian settlements adjacent along the south and the east. Around 260 AD, the Romans gave up the fort as they withdrew their presence in unoccupied Germania back to the Rhine and Danube rivers, and the Alamanni took over the region. Based on 3rd- and 4th-century coins found, the civilian settlement continued to exist for the time being. However, there is no evidence of continued civilization between the Roman era and the Middle Ages.\nFoundation.\nBased on discovery of alamannic graves, archaeologists have established the 7th century as the origination of Aalen. In the northern and western walls of St. John's church, which is located directly adjacent to the eastern gate of the Roman fort, Roman stones were incorporated. The building that exists today probably dates to the 9th century.\nThe first mention of Aalen was in 839, when emperor Louis the Pious reportedly permitted the Fulda monastery to exchange land with the Hammerstadt village, then known as \"Hamarstat\".\nAalen itself was first mentioned in an inventory list of Ellwangen Abbey, dated ca. 1136, as the village \"Alon\", along with a lower nobleman named Conrad of Aalen. This nobleman probably had his ancestral castle at a site south of today's town centre and was subject first to Ellwangen abbey, later to the House of Hohenstaufen, and eventually to the House of Oettingen. 1426 was the last time a member of that house was mentioned in connection with Aalen.\nDocuments, from the Middle Ages, indicate that the town of Aalen was founded by the Hohenstaufen some time between 1241 and 1246, but at a different location than the earlier village, which was supposedly destroyed in 1388 during the war between the Alliance of Swabian Cities and the Dukes of Bavaria.\nLater, it is documented that the counts of Oettingen ruled the town in 1340. They are reported to have pawned the town to Count Eberhard II and subsequently to the House of W\u00fcrttemberg in 1358 or 1359 in exchange for an amount of money.\nImperial City.\nDesignation as Imperial City.\nDuring the war against W\u00fcrttemberg, Emperor Charles IV took the town without a fight after a siege. On 3 December 1360, he declared Aalen an Imperial City, that is, a city or town responsible only to the emperor, a status that made it a quasi-sovereign city-state and that it kept until 1803. In 1377, Aalen joined the Alliance of Swabian Cities, and in 1385, the term \"civitas\" appears in the town's seal for the first time. In 1398, Aalen was granted the right to hold markets, and in 1401 Aalen obtained proper jurisdiction.\nThe oldest artistic representation of Aalen was made in 1528. It was made as the basis of a lawsuit between the town and the Counts of Oettingen at the Reichskammergericht in Speyer. It shows Aalen surrounded by walls, towers, and double moats. The layout of the moats, which had an embankment built between them, is recognizable by the present streets named \"N\u00f6rdlicher, \u00d6stlicher, S\u00fcdlicher\" and \"Westlicher Stadtgraben\" (Northern, Eastern, Southern and Western Moat respectively). The wall was about tall, 1518 single paces () long and enclosed an area of . During its early years, the town had two town gates: The \"Upper\" or \"Ellwangen Gate\" in the east, and St. Martin's gate in the south; however due to frequent floods, St. Martin's gate was bricked up in the 14th century and replaced by the \"Lower\" or \"Gm\u00fcnd Gate\" built in the west before 1400. Later, several minor side gates were added. The central street market took place on the \"Wettegasse\" (today called \"Marktplatz\", \"market square\") and the \"Reichsst\u00e4dter Stra\u00dfe\". So the market district stretched from one gate to the other, however in Aalen it was not straight, but with a 90-degree curve between southern (St. Martin's) gate and eastern (Ellwangen) gate.\nAround 1500, the civic graveyard was relocated from the town church to St. John's Church, and in 1514, the \"Vierundzwanziger\" (\"Group of 24\") was the first assembly constituted by the citizens.\nReformation.\nDelegated by W\u00fcrttemberg's Duke Louis III, on 28 June 1575, nearly 30 years after Martin Luther's death, Jakob Andreae, professor and chancellor of the University of T\u00fcbingen, arrived in Aalen. The sermon he gave the following day convinced the mayor, the council, and the citizens to adopt the Reformation in the town. Andreae stayed in Aalen for four weeks to help with the change. This brought along enormous changes, as the council forbade the Roman Catholic priests to celebrate masses and give sermons. However, after victories of the imperial armies at the beginning of the Thirty Years' War, the Prince-Provostry of Ellwangen, which still held the right of patronage in Aalen, were able to temporarily bring Catholicism back to Aalen; however after the military successes of the Protestant Union, Protestant church practices were instituted again.\nFire of 1634.\nOn the night of 5 September 1634, two ensigns of the army of Bernard of Saxe-Weimar who were fighting with the Swedes and retreating after the Battle of N\u00f6rdlingen set fire to two powder carriages, to prevent the war material to fall into Croatian hands and to prevent their advance. The result was a conflagration, that some say destroyed portions of the town. There are differing stories regarding this fire. According to 17th-century accounts, the church and all the buildings, except of the \"Schw\u00f6rturm\" tower, were casualties of the fire, and only nine families survived. 19th century research by Hermann Bauer, Lutheran pastor and local historian, discovered that the 17th-century account is exaggerated, but he does agree that the town church and buildings in a \"rather large\" semicircle around it were destroyed. The fire also destroyed the town archive housed in an addition to the church, with all of its documents. After the fire, soldiers of both armies went through the town looting. It took nearly 100 years for the town to reach its population of 2,000.\nFrench troops marched through Aalen in 1688 during the Nine Years' War; however, unlike other places, they left without leaving severe damages. The French came through again in 1702 during the War of the Spanish Succession and in 1741 during the War of the Austrian Succession, the latter also caused imperial troops to move through in 1743.\nThe town church's tower collapsed in 1765, presumably because proper building techniques were not utilized during the reconstruction after the fire of 1634. The collapsing tower struck two children of the tower watchman who died of their injuries, and destroyed the nave, leaving only the altar cross intact. The remaining walls had to be knocked down due to the damage. Reconstruction began the same year, creating the building that exists today.\nOn 22 November 1749, the so-called \"Aalen protocol\" regulating the cohabitation of Lutherans and Roman Catholics in the jointly ruled territory of Oberkochen was signed in Aalen by the Duchy of W\u00fcrttemberg and the Prince-Provostry of Ellwangen. Aalen had been chosen because of its neutral status as a Free Imperial City.\nNapoleonic era and end of the Imperial City of Aalen.\nDuring the War of the First Coalition (1796), Aalen was looted. The War of the Second Coalition concluded in 1801 with the signing of the Treaty of Lun\u00e9ville, which led to the German Mediatisation of 1803 that assigned most Imperial Cities to the neighbouring principalities. Aalen was assigned to the Electorate of W\u00fcrttemberg, which later became the Kingdom of W\u00fcrttemberg, and became seat of the District (\"Oberamt\") of Aalen. During the War of the Third Coalition, on 6 October 1805, Napoleon Bonaparte arrived in Aalen, with an army of 40,000. This event, along with Bavarian and Austrian troops moving in some days later, caused miseries that according to the town clerk \"no feather could describe\".\nIn 1811, the municipality of Unterrombach was formed out of some villages previously belonging to Aalen, some to the Barons of W\u00f6llwarth, and the eastern villages were assigned to the municipality of Unterkochen.\nIn the age of the Napoleonic wars, the town walls were no longer of use, and in the 18th century, with the maintenance of walls, gates and towers becoming more neglected Finally, due to the fact that the funds were lacking, starting in 1800, most towers were demolished, the other buildings followed soon.\nIndustrial revolution.\nBefore the industrial revolution, Aalen's economy was shaped by its rural setting. Many citizens were pursuing farming besides their craft, such as tanning. In the mid 19th century, there were twelve tanneries in Aalen, due to the proximity of Ulm, an important sales market. Other crafts that added to the economy were weaving mills, which produced linen and woolen goods, and baking of sweet pastry and gingerbread.\nIn Aalen, industrialisation was a slow process. The first major increase was in the 1840s, when three factories for nails and some other factories emerged. It was the link with the railway network, by the opening of the Rems Railway from Cannstatt to Wasseralfingen in 1861, that brought more industry to Aalen, along with the royal steel mill (later \"Schw\u00e4bische H\u00fcttenwerke\") in Wasseralfingen. The Rems Railway's extension to N\u00f6rdlingen in 1863, the opening of the Brenz Railway in 1864 and of the Upper Jagst Railway in 1866 turned Aalen into a railway hub. Furthermore, between 1901 and its shutdown in 1972, the H\u00e4rtsfeld Railway connected Aalen with Dillingen an der Donau via Neresheim. Part of becoming a rail hub entailed more jobs based on the rail industry. These included, a maintenance facility, a roundhouse, an administrative office, two track maintenance shops, and a freight station with an industrial branch line. This helped shape Aalen into what today's historians call a \"railwayman's town\". Starting in 1866, the utilities in town all began to be upgraded. Starting with the Aalen gasworks which were opened and gas lighting was introduced. Then in 1870, a modern water supply system was started and in 1912 the mains electricity. Finally, in 1935, the first electrically powered street lights were installed.\nTo fight housing shortage during and immediately after World War I, the town set up barracks settlement areas at the \"Schlauch\" and \"Alter Turnplatz\" grounds. In spite of the industry being crippled by the Great Depression of 1929, the public baths at the Hirschbach creek where modernized, extended and re-opened in 1931.\nNazi era.\nIn the federal election of 1932, the Nazi Party performed below average in Aalen with 25.8% of votes compared to 33.1% on the national level, thus finishing second to the Centre Party which had 26.6% (11.9% nationwide) of the votes, and ahead of the Social Democratic Party of Germany with 19.8% (20.4%). However, the March 1933 federal elections showed that the sentiment had changed as the Nazi Party received 34.1% (still below German average 43.9% nationwide), but by far the leading vote-getter in Aalen, followed by the Centre party at 26.6% (11.3% nationwide) and the Social Democrats 18.6% (18.3% nationwide).\nThe democratically elected mayor Friedrich Schwarz remained in office until the Nazis removed him from office, in 1934, and replaced him by chairman of the Nazi Party town council head and brewery owner Karl Barth. Karl Barth was a provisional mayor until the more permanent solution of Karl Sch\u00fcbel. In August 1934, the Nazi consumer fair Braune Messe (\"brown fair\") was held in Aalen.\nDuring Nazi rule in Germany, there were many military offices constructed in Aalen, starting with, in 1936, a military district riding and driving school. The Nazis also built an army replenishment office \"(Heeresverpflegungsamt)\", a branch arsenal office \"(Heeresnebenzeugamt)\" and a branch army ammunitions institute \"(Heeresnebenmunitionsanstalt)\".\nStarting in 1935, mergers of neighbouring towns began. In 1938, the Oberamt was transformed into the Landkreis of Aalen and the municipality of Unterrombach was disbanded. Its territory was mostly added to Aalen, with the exception of Hammerstadt, which was added to the municipality of Dewangen. Forst, Rauental and Vogelsang were added to Essingen (in 1952 the entire former municipality of Unterrombach was merged into Aalen, with the exception of Forst, which is part of Essingen until present).\nIn September 1944, the \"Wiesendorf\" concentration camp, a subcamp of Natzweiler-Struthof, was constructed nearby. It was designated for between 200 and 300 prisoners who were utilized for forced labor in industrial businesses nearby. Until the camp's dissolution in February 1945, 60 prisoners died. Between 1946 and 1957, the camp buildings were torn down; however, its foundations are still in place in house \"Moltkestra\u00dfe 44/46\". Also, there were several other labour camps which existed where prisoners of war along with women and men from occupied countries occupied by Germany were pooled. The prisoners at these other camps had to work for the arms industry in major businesses like \"Schw\u00e4bische H\u00fcttenwerke\" and the \"Alfing Ke\u00dfler\" machine factory.\nIn the civic hospital, the deaconesses on duty were gradually replaced by National Socialist People's Welfare nurses. Nazi eugenics led to compulsory sterilization of some 200 persons there.\nFortunately, Aalen avoided most of the combat activity during World War II. It was only during the last weeks of the war that Aalen became a target of air warfare, which led to the destruction and severe damage of parts of the town, the train station, and other railway installations. A series of air attacks lasting for more than three weeks reached its peak on 17 April 1945, when United States Army Air Forces planes bombed the branch arsenal office and the train station. During this raid, 59 people were killed, more than half of them buried by debris, and more than 500 lost their homes. Also, 33\u00a0residential buildings, 12\u00a0other buildings and 2\u00a0bridges were destroyed, and 163\u00a0buildings, including 2\u00a0churches, were damaged. Five days later, the Nazi rulers of Aalen were unseated by the US forces.\nPost-war era.\nAalen became part of the State of Baden-W\u00fcrttemberg, upon its creation in 1952. Then, with the Baden-W\u00fcrttemberg territorial reform of 1973, the District of Aalen was merged into the Ostalbkreis district. Subsequently, Aalen became seat of that district, and in 1975, the town's borough attained its present size (see below).\nThe population of Aalen exceeded the limit of 20,000, which was the requirement for to gain the status of Gro\u00dfe Kreisstadt (\"major district town\") in 1946. On 1 August 1947, Aalen was declared \"Unmittelbare Kreisstadt\" (\"immediate district town\"), and with the creation of the Gemeindeordnung (municipal code) of Baden-W\u00fcrttemberg on 1 April 1956, it was declared \"Gro\u00dfe Kreisstadt\".\nReligions.\nOn 31 December 2008, 51.1\u00a0percent of Aalen were members of the Catholic Church, 23.9\u00a0percent were members of the Evangelical-Lutheran Church. About 25\u00a0percent belong to other or no religious community or gave no information. The district of Waldhausen was the district with the highest percentage of Roman Catholic inhabitants at 75.6\u00a0percent, and the central district was the one with the highest percentage of Evangelical-Lutheran inhabitants at 25.6\u00a0percent, as well as those claiming no religious preference at 32.5\u00a0percent.\nProtestantism.\nAalen's population originally was subject to the jus patronatus of Ellwangen Abbey, and thus subject to the Roman Catholic Diocese of Augsburg.\nWith the assistance of the Duke of W\u00fcrttemberg, in 1575, the reformation was implemented in Aalen. Subsequently, Aalen has been a predominantly Protestant town for centuries, with the exception of the years from 1628 until 1632 (see reformation section). Being an Imperial City, Aalen could govern its clerical matters on its own, so Clerics, organists and choir masters were direct subjects to the council, which thus exerted bishop-like power. There was even a proper hymn book for Aalen. After the transition to W\u00fcrttemberg, in 1803, Aalen became seat of a deanery, with the dean church being the Town Church (with the building constructed from 1765 to 1767 and existing until present). Another popular church is St. John's Church, located on the cemetery and refurbished in 1561.\nAs Aalen's population grew in the 20th century, more parishes were founded: St. Mark's parish with its church building of 1967 and St. Martin's parish with its church of 1974. In the borough of Unterrombach, Aalen had implemented the reformation as well, but the community remained a chapel-of-ease of Aalen. A proper church, the Christ Church, was erected in 1912 and a proper parish was established in 1947. In Fachsenfeld, the ruling family of Woellwarth resp. of Leinroden implemented the reformation. A parish church was built in 1591, however with an influx of Catholics in the 18th century, a Catholic majority was established. The other districts of present-day Aalen remained mostly catholic after the reformation, however Wasseralfingen established a Lutheran parish in 1891 and a church, St. Magdalene's Church, in 1893. In Unterkochen, after World War II, a parish was established and a church was built in 1960. All four parishes belong to the deanery of Aalen within the Evangelical-Lutheran Church in W\u00fcrttemberg. Furthermore, in Aalen there are Old Pietistic communities.\nCatholicism.\nThe few Catholics of today's central district were covered by the parish of Unterkochen until the 19th century, a situation which continued for some years even after completion of St. Mary's Church in 1868, which was constructed by Georg Morlok. However, in 1872 Aalen got its proper parish again, and in 1913, a second Catholic church, Salvator's Church, was completed, and in 1969 the Holy Cross Church was also finished. In 1963, a second parish was set up, and in 1972 it got a new Church, the new St. Mary's Church, which has been erected in place of the old St. Mary's church, which had been torn down in 1968. Another church of the second parish was St. Augustine's Church, which was completed in 1970. Finally, in 1976 and 1988, St. Elizabeth's Church and St. Thomas' Church were completed. Furthermore, in 1963, the St. Michael pastoral care office was built.\nHofherrnweiler has its own Catholic church, St. Boniface's, since 1904. The villages of Dewangen, Ebnat, Hofen, Waldhausen and Wasseralfingen had remained Catholic after reformation, so old parishes and churches persist there. The \"Assumption of Mary\" Church in Dewangen has an early Gothic tower and a newly built nave (1875). Mary's Immaculate Conception Church in Ebnat was constructed in 1723; however the church was first mentioned in 1298.\nHofen's Saint George's Church is a fortified church, whose current nave was built between 1762 and 1775. Alongside the church, the Late Gothic St. Odile's Chapel is standing, whose entrance has the year 1462 engraved upon it. Foundations of prior buildings have been dated to the 11th and 13th century.\nSt. Mary's Church of Unterkochen was first mentioned in 1248, and has served the Catholics of Aalen for a long time. Waldhausen's parish church of St. Nicholas was built between 1699 and 1716. Wasseralfingen at first was a chapel of ease for Hofen, but has since had its own chapel, St. Stephen, built. It was presumably built in 1353 and remodeled in 1832. In 1834, a proper parish was established, which built a new St. Stephen's Church. This new building utilized the Romanesque Revival architecture style and was built between 1881 and 1883, and has since remained the parish's landmark. Also, Fachsenfeld received its own church, named Sacred Heart in 1895. All Catholic parishes within Aalen are today incorporated into four pastoral care units within the \"Ostalb\" Deanery of the Diocese of Rottenburg-Stuttgart; however these units also comprise some parishes outside of Aalen. Pastoral Care Unit two comprises the parishes of Essingen, Dewangen and Fachsenfeld, unit four comprises Hofen and Wasseralfingen, unit five comprises both parishes of Aalen's centre and Hofherrnweiler, unit five comprises Waldhausen, Ebnat, Oberkochen and Unterkochen.\nOther Christian communities.\nIn addition to the two major religions within Aalen, there are also free churches and other communities, including the United Methodist Church, the Baptists, the Seventh-day Adventist Church and the New Apostolic Church.\nOther religions.\nUntil the late 19th century, no Jews were documented within Aalen. In 1886 there were four Jews were living in Aalen, a number that rose to ten in 1900, fell to seven in 1905, and remained so until 1925. Upon the Nazis' rise to power in 1933, seven Jews, including two children, lived in Aalen. During the Kristallnacht in 1938, the vitrines of the three Jewish shops in the town were smashed and their proprietors imprisoned for several weeks. After their release, most Aalen Jews emigrated. The last Jews of Aalen, Fanny Kahn, was forcibly resettled to Oberdorf am Ipf, which had a large Jewish community. Today, a street of Aalen is named after her. The Jew Max Pfeffer returned from Brussels to Aalen in 1948 to continue his shop, but emigrated to Italy in 1967.\nIn Aalen, there is an Islamic Ditib community, which maintains the \"D.I.T.I.B. Mosque of Aalen (Central Mosque)\" located at Ulmer Stra\u00dfe. The mosque's construction started on 30 August 2008. The Islamist Mill\u00ee G\u00f6r\u00fc\u015f organisation maintains the Fatih Mosque, as well at Ulmer Stra\u00dfe.\nMergings.\nThe present-day make up of Aalen was created on 21 June 1975 by the unification of the cities of Aalen and Wasseralfingen, with the initial name of \"Aalen-Wasseralfingen\". This annexation made Aalen's territory one third larger than its prior size. On 1 July 1975, the name \"Aalen\" was revived. Prior to this merger, the town of Aalen had already annexed the following municipalities:\nPopulation\u2019s progression and structure.\nDuring the Middle Ages and the early modern period, Aalen was just a small town with a few hundred inhabitants. The population grew slowly due to numerous wars, famines and epidemics. It was the beginning of the Industrial Revolution in the 19th century where Aalen's growth accelerated. Whereas in 1803, only 1,932 people inhabited the town, in 1905 it had already increased to 10,442. The number continued to rise and reached 15,890 in 1939.\nThe influx of refugees and ethnic Germans from Germany's former eastern territories after World War II pushed the population to 31,814 in 1961. The merger with Wasseralfingen on 21 June 1975 added 14,597 persons and resulted in a total population of 65,165 people. On 30 June 2005, the population, which was officially determined by the Statistical Office of Baden-W\u00fcrttemberg, was 67,125.\nThe following overview shows how the population figures of the borough were ascertained. Until 1823, the figures are mostly estimates, thereafter census results or official updates by the state statistical office. Starting in 1871, the figures were determined by non-uniform method of tabulation using extrapolation.\nOn 31 December 2008, Aalen had precisely 66,058 inhabitants, of which 33,579 were female and 32,479 were male. The average age of Aalen's inhabitants rose from 40.5 years in 2000 to 42.4 in 2008. Within the borough, 6,312 foreigners resided, which is 9.56\u00a0percent. Of them, the largest percentage are from Turkey (38\u00a0percent of all foreigners), the second largest group are from Italy (13\u00a0percent), followed by Croatians (6\u00a0percent) and Serbs (5\u00a0percent).\nThe number of married residents fell from 32,948 in 1996 to 31,357 in 2007, while the number of divorced residents rose in the same period from 2,625 to 3,859. The number of single residents slightly increased between 1996 and 2004 from 25,902 to 26,268 and fell slightly until 2007 to 26,147. The number of widowed residents fell from 5,036 in 1996 to 4,783 in 2007.\nPolitics.\nAalen has arranged a municipal association with Essingen and H\u00fcttlingen.\nCouncil.\nSince the local election of 25 May 2014, the town council consists of 51\u00a0representatives having a term of five years. The seats are distributed as follows on parties and groups (changes refer to the second last election of 2004):\nMayors.\nSince 1374, the mayor and the council maintain the government of the town. In the 16th century, the town had two, sometimes three mayors, and in 1552, the council had 13 members. Later, the head of the administration was reorganized several times. In the W\u00fcrttemberg era, the mayor's title was initially called \"B\u00fcrgermeister\", then from 1819 it was Schulthei\u00df, and since 1947 it is \"Oberb\u00fcrgermeister\". The mayor is elected for a term of eight years, and he is chairman and a voting member of the council. He has one deputy with the official title of \"Erster B\u00fcrgermeister\" (\"first mayor\") and one with the official title of \"B\u00fcrgermeister\" (\"mayor\").\nHeads of town in Aalen since 1802\nCoat of arms and flag.\nAalen's coat of arms depicts a black eagle with a red tongue on golden background, having a red shield on its breast with a bent silver eel on it. Eagle and eel were first acknowledged as Aalen's heraldic animals in the seal of 1385, with the eagle representing the town's imperial immediacy. After the territorial reform, it was bestowed again by the Administrative District of Stuttgart on 16 November 1976.\nThe coat of arms' blazon reads: \u201cIn gold, the black imperial eagle, with a red breast shield applied to it, therein a bent silver eel\u201d \"(In Gold der schwarze Reichsadler, belegt mit einem roten Brustschild, darin ein gekr\u00fcmmter silberner Aal)\".\nAalen's flag is striped in red and white and contains the coat of arms.\nThe origin of the town's name is uncertain. Matth\u00e4us Merian (1593\u20131650) presumed the name to originate from its location at the Kocher river, where \"frequently eels are caught\", while \"Aal\" is German for \"eel\". Other explanations point to Aalen as the garrison of an ala during the Roman empire, respectively to an abridgement of the Roman name \"Aquileia\" as a potential name of the Roman fort, a name that nearby Heidenheim an der Brenz bore as well. Another interpretation points to a Celtic word aa meaning \"water\".\nGodparenthood.\nOn the occasion of the 1980 \"Reichsst\u00e4dter Tage\", Aalen took over godparenthood for the more than 3000 ethnic Germans displaced from the Wischau linguistic enclave. 972 of them settled in Aalen in 1946. The \"Wischau Linguistic Enclave Society\" \"(Gemeinschaft Wischauer Sprachinsel)\" regularly organises commemorative meetings in Aalen. Their traditional costumes are stored in the Old Town Hall.\nMunicipal finances.\nAccording to the 2007 municipal poll by the Baden-W\u00fcrttemberg chapter of the German Taxpayers Federation, municipal tax revenues totalling to 54,755 million Euros (2006) resp. 62,148 million Euros (2007) face the following debts:\nTwin towns \u2013 sister cities.\nAalen is twinned with:\nThe \"Twin Towns Society of Aalen\" \"(St\u00e4dtepartnerschaftsverein Aalen e.\u00a0V.)\" promotes friendly relations between Aalen and its twin towns, which comprises mutual exchanges of sports and cultural clubs, schools and other civic institutions. On the occasion of the Reichsst\u00e4dter Tage, from 11 until 13 September 2009 the first conference of twin towns was held.\nCulture and sights.\nTheatre.\nThe \"Theater der Stadt Aalen\" theatre was founded in 1991 and stages 400 to 500 performances a year.\nSchubart Literary Award.\nThe town endowed the \"Schubart Literary Award\" \"(Schubart-Literaturpreis)\" in 1955 in tribute to Christian Friedrich Daniel Schubart, who spent his childhood and youth in Aalen. It is one of the earliest literary awards in Baden-W\u00fcrttemberg and is awarded biennially to German-language writers whose work coincide with Schubart's \"liberal and enlightened reasoning\". It is compensated with 12,000\u00a0Euros.\nMusic.\nFounded in 1958, the \"Music School of the Town of Aalen\" today has about 1,500 students taught by 27 music instructors in 30 subjects. In 1977, a symphony orchestra was founded in Aalen, which today is called \"Aalener Sinfonieorchester\", and consists mostly of instructors and students of the music school. It performs three public concerts annually: The \u201cNew Year\u2019s Concert\u201d in January, the \u201cSymphony Concert\u201d in July and a \u201cChristmas Concert\u201d in December. Beyond that, music festivals regularly take place in Aalen, like the Aalen Jazzfest.\nThe Aalen volunteer fire department has had a marching band since 1952, whose roots date back to 1883. In 1959, the band received its first glockenspiel from TV host Peter Frankenfeld on the occasion of a TV appearance.\nA famous German rapper, designer and singer, that goes under the name of Cro, was born in Aalen and lived his early years here.\nMuseums and memorial sites.\nMuseums.\nIn the central district of Aalen, there are two museums: The \u201cAalen Limes Museum\" \"(Limesmuseum Aalen)\" is located at the place of the largest Roman cavalry fort north of the Alps until about 200 AD. It opened in 1964. The museum exhibits numerous objects from the Roman era. The ruins of the cavalry fort located beside the museum is open to museum visitors. Every other year, a Roman festival is held in the area of the museum (see below).\nIn the Geological-Paleontological Museum located in the historic town hall, there are more than 1500 fossils from the Swabian Jura, including ammonites, ichthyosaurs and corals, displayed.\nIn the Waldhausen district the \"Heimatst\u00fcble\" museum of local history has an exhibition on agriculture and rural living.\nIn the Wasseralfingen district, there are two more museums: The \"Museum Wasseralfingen\" comprises a local history exhibition and an art gallery including works of Hermann Plock, Helmut Schuster and Sieger K\u00f6der. Also, the stove plate collection of the \"Schw\u00e4bische H\u00fcttenwerke\" steel mill is exhibited, with artists, modellers and the production sequence of a cast plate from design to final product being presented.\nMemorial sites.\nThere is memorial stone at the \"Schillerlinde\" tree above Wasseralfingen's ore pit dedicated to four prisoners of the subcamp of Natzweiler-Struthof concentration camp killed there. Also in Wasseralfingen, in the cemetery a memorial with the Polish inscription \"To the victims of Hitler\" which commemorates the deceased forced labourers buried there.\nIn 1954, on the \"Schillerh\u00f6he\" hill the town erected a bell tower as a memorial to Aalen's victims of both world wars and to the displacement of ethnic Germans. The tower was planned by Emil Leo, the bell was endowed by Carl Schneider. The tower is open on request. Every evening at 18:45 (before 2003: at 19:45), the memorial's bell rings.\nBuildings.\nChurches.\nThe town centre is dominated by the Evangelical-Lutheran St. Nicholas' Church in the heart of the pedestrian area. The church, in its present shape being built between 1765 and 1767, is the only major Late Baroque building in Aalen and is the main church of the Evangelical-Lutheran parish of Aalen.\n\"St. John's Church\" is located inside of St. John's cemetery in the western centre. The building presumably is from the 9th century and thus is one of W\u00fcrttemberg's oldest existing churches. The interior features frescos from the early 13th century.\nFor other churches in Aalen, see the Religions section.\nHistoric Town Hall with \"Spy\".\nThe Historic Town Hall was originally built in the 14th century. After the fire of 1634, it was re-constructed in 1636. This building received a clock from Lauterburg, and the Imperial City of Nuremberg donated a Carillon. It features a figurine of the \"Spy of Aalen\" and historically displayed other figurines, however the latter ones were lost by a fire in 1884. Since then, the Spy resides inside the reconstructed tower and has become a symbol of the town. The building was used as the town hall until 1907. Since 1977, the Geological-Paleontological Museum resides in the Historic Town Hall.\nAccording to legend, the citizens of Aalen owe the \"Spy of Aalen\" \"(Spion von Aalen)\" their town having been spared from destruction by the emperor's army:\nThe Imperial City of Aalen once was were in quarrel with the emperor, and his army was shortly before the gates to take the town. The people of Aalen got scared and thus dispatched their \u201cmost cunning\u201d one out into the enemy\u2019s camp to spy out the strength of their troops. Without any digression, he went straight into the middle of the enemy camp, which inescapably led to him being seized and presented to the emperor. When the emperor asked him what he had lost here, he answered in Swabian German: \"Don't frighten, high lords, I just want to peek how many cannons and other war things you've got, since I am the spy of Aalen\". The emperor laughed upon such a blatancy and \"acted\" na\u00efvety, steered him all through the camp and then sent him back home. Soon the emperor withdrew with his army as he thought a town such \"wise guys\" reside in deserved being spared.\nOld Town Hall.\nThe earliest record of the Old Town Hall was in 1575. Its outside wall features the oldest known coat of arms, which is of 1664. Until 1851, the building also housed the \"Krone-Post\" hotel, which coincided with being a station of the Thurn und Taxis postal company. It has housed many notable persons. Thus the so-called \"Napoleon Window\" with its \"N\" painted on reminds of the stay of French emperor Napoleon Bonaparte in 1805. According to legend, he rammed his head so hard it bled on this window, when he was startled by the noise of his soldiers ridiculing the \"Spy of Aalen\". The building was used as Aalen's town hall from 1907 until 1975. Today it houses a cabaret caf\u00e9 and the stage of the Theatre of the Town of Aalen. The town has adopted the \"Wischau Linguistic Enclave Society\" due to their godparenthood and stores their traditional costumes in the building.\nB\u00fcrgerspital.\nThe \"B\u00fcrgerspital\" (\"Civic Asylum\") is a timber-frame house erected on \"Spritzenhausplatz\" (\"Fire Engine House Square\") in 1702. Until 1873, it was used as civic hospital, then, later as a retirement home. After a comprehensive renovation in 1980 it was turned into a senior citizen's community centre.\nLimes-Thermen.\nOn a slope of the \"Langert\" mountain, south of the town, the \"Limes-Thermen\" (\"Limes Thermae\") hot springs are located. They were built in ancient Roman style and opened in 1985. The health spa is supplied with water about .\nMarket square.\nThe market square is the historic hub of Aalen and runs along about from the town hall in the south to the Historic Town Hall and the Old Town Hall in the north, where it empties into \"Radgasse\" alley. Since 1809, it is site of the weekly market on Wednesday and Saturday. About in front of the \"Reichsst\u00e4dter Brunnen\" fountain at the town hall, the coats of arms of Aalen, its twinned cities and of the Wischau linguistic enclave are paved into the street as mosaic.\nMarket fountain.\nIn 1705, for the water supply of Aalen a well casing was erected at the northern point of the market square, in front of the Historic Town Hall. It was a present of duke Eberhard Louis. The fountain bore a statue of emperor Joseph\u00a0I., who was enthroned in 1705 and in 1707 renewed Aalen's Imperial City privileges. The fountain was supplied via a wooden pipe. Excessive water was dissipated through ditches branched from Kocher river. When in the early 1870s Aalen's water network was constructed, the fountain was replaced by a smaller fountain about distant. In 1975, the old market fountain was re-erected in baroque style. It bears a replica of the emperor's statue, with the original statue exhibited in the new town hall's lobby. The cast iron casing plates depict the 1718 coat of arms of the Duchy of W\u00fcrttemberg and the coats of arms of Aalen and of the merged municipalities.\nReichsst\u00e4dter Brunnen.\nThe \"Reichsst\u00e4dter Brunnen\" fountain (\"Imperial Civic Fountain\") is located in front of the town hall at the southern point of the market square. It was created by sculptor Fritz Nuss in 1977 to commemorate Aalen's time as an Imperial City (1360\u20131803). On its circumference is a frieze showing bronze figurines illustrating the town's history.\nRadgasse.\nThe \"Radgasse\" (\"Wheel Alley\") features Aalen's oldest fa\u00e7ade. Originally a small pond was on its side. The buildings were erected between 1659 and 1662 for peasants with citizenry privileges and renovated in the mid-1980s. The namesake for the alley was the \"Wheel\" tavern, which was to be found at the site of today's address \"Radgasse 15\".\nTiefer Stollen.\nThe former iron ore pit \"Wilhelm\" at Braunenberg hill was converted into the \"Tiefer Stollen\" tourist mine in order to remind of the old-day miners' efforts and to maintain it as a memorial of early industrialisation in the Aalen area. It has a mining museum open for visitors, and a mine railway takes visitors deep into the mountain. The Town of Aalen, a sponsorship association, and many citizens volunteered several thousand hours of labour to put the mine into its current state. As far as possible, things were left in the original state. In 1989, a sanitary gallery was established where respiratory diseases are treated within rest cures. Thus the Aalen village of R\u00f6thard, where the gallery is located, was awarded the title of \"Place with sanitary gallery service\" in 2004.\nObservatory.\nThe Aalen Observatory was built in 1969 as school observatory for the Schubart Gymnasium. In 2001, it was converted to a public observatory. Since then, it has been managed by the \"Astronomische Arbeitsgemeinschaft Aalen\" (\"Aalen Astronomical Society\"). It is located on Schillerh\u00f6he hill and features two refractive telescopes. They were manufactured by Carl Zeiss AG which has its headquarters in nearby Oberkochen and operates a manufacturing works in Aalen (see below). In the observatory, guided tours and lectures are held regularly.\nWindpark Waldhausen.\nThe \"Windpark Waldhausen\" wind farm began operations in early 2007. It consists of seven REpower MM92 wind turbines with a nameplate capacity of 2 MW each. The hub height of each wind turbine is , with a rotor diameter of .\nAalb\u00e4umle observation tower.\nThe tall \"Aalb\u00e4umle\" observation tower is built atop \"Langert\" mountain. This popular hiking destination was built in 1898 and was remodelled in 1992. It features a good view over Aalen and the Welland region, up to the Rosenstein mountain and Ellwangen. Beneath the tower, an adventure playground and a cabin is located. A flag on the tower signals whether the cabin's restaurant is open.\nNatural monuments.\nThe Baden-W\u00fcrttemberg State Institute for Environment, Measurements and Natural Conservation has laid out six protected landscapes in Aalen (the \"Swabian Jura escarpment between Lautern and Aalen with adjacent territories\", the \"Swabian Jura escarpment between Unterkochen and Baiershofen\", the \"Hilllands around Hofen\", the \"Kugeltal and Ebnater Tal valleys with parts of Heiligental valley and adjacent territories\", \"Laubachtal valley\" and \"Lower Lein Valley with side valleys\"), two sanctuary forests (\"Glash\u00fctte\" and \"Kocher Origin\"), 65 extensive natural monuments, 30 individual natural monuments and the following two protected areas:\nThe large \"Dellenh\u00e4ule\" protected area between Aalen's Waldhausen district and Neresheim's Elchingen district, created in 1969, is a sheep pasture with juniper and wood pasture of old willow oaks.\nThe large \"Goldsh\u00f6fer Sande\" protected area was established in 2000 and is situated between Aalen's Hofen district and H\u00fcttlingen. The sands on the hill originated from the Early Pleistocene are of geological importance, and the various grove structures offer habitat to severely endangered bird species.\nSports.\nThe football team, VfR Aalen, was founded in 1921 and played in the 2nd German League between 2012 and 2015, after which they were relegated to 3. Liga. Its playing venue is the Scholz-Arena situated in the west of the town, which bore the name \"St\u00e4dtisches Waldstadion Aalen\" (\"Civic Forest Stadium of Aalen\") until 2008. From 1939 until 1945, the VfR played in the Gauliga W\u00fcrttemberg, then one of several parallel top-ranking soccer leagues of Germany.\nThe KSV Aalen wrestles in the Wrestling Federal League. It was German champion in team wrestling in 2010. Its predecessor, the \"KSV Germania Aalen\" disbanded in 2005, was German champion eight times and runner-up five times since 1976. Another Aalen club, the TSV Dewangen, wrestled in the Federal League until 2009.\nTwo American sports, American Football and Baseball, are pursued by the \"MTV Aalen\". Volleyball has been gaining in popularity in Aalen for years. The first men's team of \"DJK Aalen\" accomplished qualification for regional league in the season of 2008/09.\nThe \"Ostalb\" ski lifts are located south of the town centre, at the northern slope of the Swabian Jura. The skiing area comprises two platter lifts that have a vertical rise of , with two runs with lengths of and a beginners' run.\nRegular events.\nReichsst\u00e4dter Tage.\nSince 1975, \"Reichsst\u00e4dter Tage\" (\"Imperial City days\") festival is held annually in the town centre on the second weekend in September. It is deemed the largest festival of the Ostw\u00fcrttemberg region, and is associated with a shopping Sunday in accordance with the Ladenschlussgesetz code. The festival is also attended by delegations from the twinned cities. On the town hall square, on Sunday an ecumenical service is held.\nRoman Festival.\nThe international Roman Festival \"(R\u00f6mertage)\" are held biannially on the site of the former Roman fort and the modern Limes museum. The festival's ninth event in 2008 was attended by around 11,000 people.\nAalen Jazz Festival.\nAnnually during the second week of November, the Aalen Jazz Festival brings known and unknown artists to Aalen. It has already featured musicians like Miles Davis, B. B. King, Ray Charles, David Murray, McCoy Tyner, Al Jarreau, Esbj\u00f6rn Svensson and Albert Mangelsdorff. The festival is complemented by individual concerts in spring and summer, and, including the individual concerts, comprises around 25 concerts with a total of about 13,000 visitors.\nEconomy and infrastructure.\nIn 2008 there were 30,008 employees liable to social insurance living in Aalen. 13,946 (46.5\u00a0percent) were employed in the manufacturing sector, 4,715 (15.7\u00a0percent) in commerce, catering, hotels and transport, and 11,306 (37.7\u00a0percent) in other services. Annually 16,000 employees commute to work, with about 9,000 living in the town and commuting out.\nAltogether in Aalen there are about 4,700 business enterprises, 1,100 of them being registered in the trade register. The others comprise 2,865 small enterprises and 701 craft enterprises.\nIn Aalen, metalworking is the predominant industry, along with machine-building. Other industries include optics, paper, information technology, chemicals, textiles, medical instruments, pharmaceuticals, and food.\nNotable enterprises include \"SHW Automotive\" (originating from the former \"Schw\u00e4bische H\u00fcttenwerke\" steel mills and a mill of 1671 in Wasseralfingen), the \"Alfing Kessler\" engineering works, the precision tools manufacturer \"MAPAL Dr.\u00a0Kress\", the snow chain manufacturer \"RUD\u00a0Ketten\u00a0Rieger\u00a0&amp;\u00a0Dietz\" and its subsidiary \"Erlau\", the \"Gesenkschmiede Schneider\" forging die smithery, the \"SDZ Druck und Medien\" media company, the \"Papierfabrik Palm\" paper mill, the alarm system manufacturer \"Telenot\", the laser show provider \"LOBO electronic\" and the textile finisher \"Lindenfarb\", which all have their seat in Aalen. A branch in Aalen is maintained by optical systems manufacturer Carl Zeiss headquartered in nearby Oberkochen.\nTransport.\nRail.\nAalen station is a regional railway hub on the Rems Railway from Stuttgart, the Brenz Railway from Ulm, the Upper Jagst Railway to Crailsheim and the Ries Railway to Donauw\u00f6rth. Until 1972, the H\u00e4rtsfeld Railway connected Aalen with Dillingen an der Donau via Neresheim. Other railway stations within the town limits are \"Hofen (b Aalen)\", \"Unterkochen\", \"Wasseralfingen\" and Goldsh\u00f6fe station. The \"Aalen-Erlau\" stop situated in the south is no longer operational.\nAalen station is served at two-hour intervals by trains of Intercity line 61 Karlsruhe\u2013Stuttgart\u2013Aalen\u2013Nuremberg. For regional rail travel, Aalen is served by various lines of the Interregio-Express, Regional-Express and Regionalbahn categories. Since the beginning of 2019, the British company Go-Ahead took over the regional railway business of DB Regio in the region surrounding Aalen. The town also operates the Aalen industrial railway \"(Industriebahn Aalen)\", which carries about 250 carloads per year.\nBus.\nAalen also is a regional hub in the bus network of OstalbMobil, the transport network of the district Aalen is in. The bus lines are operated and serviced by regional companies like OVA and RBS RegioBus Stuttgart.\nStreet.\nThe junctions of \"Aalen/Westhausen\" and \"Aalen/Oberkochen\" connect Aalen with the Autobahn A7 (W\u00fcrzburg\u2013F\u00fcssen). Federal roads (\"Bundesstra\u00dfen\") connecting with Aalen are B\u00a019 (W\u00fcrzburg\u2013Ulm), B\u00a029 (Waiblingen\u2013N\u00f6rdlingen) and B\u00a0290 (Tauberbischofsheim\u2013Westhausen). The Schw\u00e4bische Dichterstra\u00dfe (\"Swabian Poets' Route\") tourist route established in 1977/78 leads through Aalen.\nSeveral bus lines operate within the borough. The \"Omnibus-Verkehr Aalen\" company is one of the few in Germany that use double-decker buses, it has done so since 1966. A district-wide fare system, \"OstalbMobil\", has been in effect since 2007.\nAir transport.\nStuttgart Airport, offering international connections, is about away, the travel time by train is about 100\u00a0Minutes. At Aalen-Heidenheim Airport, located south-east of Aalen, small aircraft are permitted. Gliding airfields nearby are in Heubach and Bartholom\u00e4.\nBicycle.\nBicycle routes stretching through Aalen are the \"Deutscher Limes-Radweg\" (\"German Limes Bicycle Route\") and the \"Kocher-Jagst\" Bicycle Route.\nPublic facilities.\nAalen houses an Amtsgericht (local district court), chambers of the Stuttgart Labour Court, a notary's office, a tax office and an employment agency. It is the seat of the Ostalbkreis district office, of the Aalen Deanery of the Evangelical-Lutheran Church and of the \"Ostalb\" deanery of the Roman Catholic Diocese of Rottenburg-Stuttgart.\nThe Stuttgart administrative court, the Stuttgart Labour Court and the Ulm Social Welfare Court are in charge for Aalen.\nAalen had a civic hospital, which resided in the \"B\u00fcrgerspital\" building until 1873, then in a building at \"Alte Heidenheimer Stra\u00dfe\". In 1942, the hospital was taken over by the district. The district hospital at the present site of \"K\u00e4lblesrain\", known today as \"Ostalb-Klinikum\", was opened in 1955.\nMedia.\nThe first local newspaper, \"Der Bote von Aalen\" (\"The Herald of Aalen\"), has been published on Wednesdays and Saturdays since 1837.\nCurrently, local newspapers published in Aalen are the \"Schw\u00e4bische Post\", which obtains its supra-regional pages from the Ulm-based S\u00fcdwestpresse, and the \"Aalener Nachrichten\" (erstwhile \"Aalener Volkszeitung\"), a local edition of Schw\u00e4bische Zeitung in Leutkirch im Allg\u00e4u.\nTwo of Germany's biggest Lesezirkels (magazine rental services) are headquartered in Aalen: \"Brabandt LZ Plus Media\" and \"Lesezirkel Portal\".\nRegional event magazines are \"Xaver\", \"\u00e5la\", \"\u00e5lakultur\".\nThe commercial broadcasters \"Radio Ton\" and \"Radio 7\" have studios in Aalen.\nEducation.\nA Latin school was first recorded in Aalen in 1447; it was remodeled in 1616 and also later in various buildings that were all situated near the town church, and continued up through the 19th century. In the course of the reformation, a \"German school\" was established in tandem, being a predecessor of the latter Volksschule school type. In 1860, the \"Ritterschule\" was built as a \"Volksschule\" for girls; the building today houses the \"Pestalozzischule\". In 1866, a new building was erected for the Latin school and for the Realschule established in 1840. This building, later known as the \"Alte Gewerbeschule\", was torn down in 1975 to free up land for the new town hall. In 1912, the \"Parkschule\" building was opened. It was designed by Paul Bonatz and today houses the \"Schubart-Gymnasium\"\nThe biggest educational institution in the town is the \"Hochschule Aalen\", which was founded in 1962 and focuses on engineering and economics. It is attended by 5000 students on five campuses and employs 129 professors and 130 other lecturers.\nThe town provides three Gymnasiums, four Realschulen, two \"F\u00f6rderschulen\" (special schools), six combined Grundschulen and Hauptschulen and eight standalone Grundschulen. The Ostalbkreis district provides three vocational schools and three additional special schools. Finally, six non-state schools of various types exist.\nThe German Esperanto Library (German: \"Deutsche Esperanto-Bibliothek\", Esperanto: \"Germana Esperanto-Biblioteko\") has been located in the building of the town library since 1989.\nTV and radio transmission tower.\nThe S\u00fcdwestrundfunk broadcasting company operates the Aalen transmission tower on the \"Braunenberg\" hill. The tower was erected in 1956, it is tall and made of reinforced concrete.\nThings named after Aalen.\nThe following vehicles are named \"Aalen\":"}
{"id": "2383", "revid": "40943757", "url": "https://en.wikipedia.org/wiki?curid=2383", "title": "Alois Alzheimer", "text": "Alois Alzheimer (; ; 14 June 1864 \u2013 19 December 1915) was a German psychiatrist and neuropathologist and a colleague of Emil Kraepelin. Alzheimer is credited with identifying the first published case of \"presenile dementia\", which Kraepelin would later identify as Alzheimer's disease.\nEarly life and education.\nAlzheimer was born in Marktbreit, Bavaria, on 14 June 1864, the son of Anna Johanna Barbara Sabina and Eduard Rom\u00e1n Alzheimer. His father served in the office of notary public in the family's hometown.\nThe Alzheimers moved to Aschaffenburg when Alois was still young in order to give their children an opportunity to attend the Royal Humanistic Gymnasium. After graduating with Abitur in 1883, Alzheimer studied medicine at University of Berlin, University of T\u00fcbingen, and University of W\u00fcrzburg. In his final year at university, he was a member of a fencing fraternity, and even received a fine for disturbing the peace while out with his team. In 1887, Alois Alzheimer graduated from W\u00fcrzburg as Doctor of Medicine.\nCareer.\nThe following year, he spent five months assisting mentally ill women before he took an office in the city mental asylum in Frankfurt, the St\u00e4dtische Anstalt f\u00fcr Irre und Epileptische (Asylum for Lunatics and Epileptics). , a noted psychiatrist, was the dean of the asylum. Another neurologist, Franz Nissl, began to work in the same asylum with Alzheimer. Together, they conducted research on the pathology of the nervous system, specifically the normal and pathological anatomy of the cerebral cortex. Alzheimer was the co-founder and co-publisher of the journal \"Zeitschrift f\u00fcr die gesamte Neurologie und Psychiatrie\", though he never wrote a book that he could call his own.\nWhile at the Frankfurt asylum, Alzheimer also met Emil Kraepelin, one of the best-known German psychiatrists of the time. Kraepelin became a mentor to Alzheimer, and the two worked very closely for the next several years. When Kraepelin moved to Munich to work at the Royal Psychiatric Hospital in 1903, he invited Alzheimer to join him.\nAt the time, Kraepelin was doing clinical research on psychosis in senile patients; Alzheimer, on the other hand, was more interested in the lab work of senile illnesses. The two men would face many challenges involving the politics of the psychiatric community. For example, both formal and informal arrangements would be made among psychiatrists at asylums and universities to receive cadavers.\nIn 1904, Alzheimer completed his Habilitation at Ludwig Maximilian University of Munich, where he was appointed as a professor in 1908. Afterwards, he left Munich for the Silesian Friedrich Wilhelm University in Breslau in 1912, where he accepted a post as professor of psychiatry and director of the Neurologic and Psychiatric Institute. His health deteriorated shortly after his arrival so that he was hospitalized. Alzheimer died three years later.\nAuguste Deter.\nIn 1901, Alzheimer observed a patient at the Frankfurt asylum named Auguste Deter. The 51-year-old patient had strange behavioral symptoms, including a loss of short-term memory; she became his obsession over the coming years. Auguste Deter was a victim of the politics of the time in the psychiatric community; the Frankfurt asylum was too expensive for her husband. Herr Deter made several requests to have his wife moved to a less expensive facility, but Alzheimer intervened in these requests. Frau Deter, as she was known, remained at the Frankfurt asylum, where Alzheimer had made a deal to receive her records and brain upon her death.\nOn 8 April 1906, Frau Deter died, and Alzheimer had her medical records and brain brought to Munich where he was working in Kraepelin's laboratory. With two Italian physicians, he used the staining techniques of Bielschowsky to identify amyloid plaques and neurofibrillary tangles. These brain anomalies would become identifiers of what later became known as Alzheimer's disease.\nAnother hypothesis offered by Claire O'Brien was that Auguste Deter actually had a vascular dementing disease.\nFindings.\nAlzheimer discussed his findings on the brain pathology and symptoms of presenile dementia publicly on 3November 1906, at the T\u00fcbingen meeting of the Southwest German Psychiatrists. The attendees at this lecture seemed uninterested in what he had to say. The lecturer that followed Alzheimer was to speak on the topic of \"compulsive masturbation\", which the audience was so eagerly awaiting that they sent Alzheimer away without any questions or comments on his discovery of the pathology of a type of senile dementia.\nFollowing the lecture, Alzheimer published a short paper summarizing his lecture; in 1907 he wrote a larger paper detailing the disease and his findings. The disease would not become known as Alzheimer's disease until 1910, when Kraepelin named it so in the chapter on \"Presenile and Senile Dementia\" in the 8th edition of his \"Handbook of Psychiatry\". By 1911, his description of the disease was being used by European physicians to diagnose patients in the US.\nContemporaries.\nAmerican Solomon Carter Fuller gave a report similar to that of Alzheimer at a lecture five months before Alzheimer. Oskar Fischer was a fellow German psychiatrist, 12 years Alzheimer's junior, who reported 12 cases of senile dementia in 1907 around the time that Alzheimer published his short paper summarizing his lecture.\nAlzheimer and Fischer had different interpretations of the disease, but due to Alzheimer's short life, they never had the opportunity to meet and discuss their ideas.\nAmong the doctors trained by Alois Alzheimer and Emil Kraepelin at M\u00fcnchen in the beginning of the XXth century were the Spanish neuropathologists Nicol\u00e1s Ach\u00facarro and Gonzalo Rodr\u00edguez Lafora, two distinguished disciples of Santiago Ram\u00f3n y Cajal and members of the Spanish Neurological School. Alzheimer recommended the young and brilliant Nicol\u00e1s Ach\u00facarro to organize the neuropathological service at the Government Hospital for the Insane, at Washington D.C. (current, NIH), and after two years of work, he was substituted by Gonzalo Rodr\u00edguez Lafora.\nOther interests.\nAlzheimer was known for having a variety of medical interests including vascular diseases of the brain, early dementia, brain tumors, forensic psychiatry and epilepsy. Alzheimer was a leading specialist in histopathology in Europe. His colleagues knew him to be a dedicated professor and cigar smoker.\nPersonal life and death.\nIn 1894, Alzheimer married Cecilie Simonette Nathalie Geisenheimer, with whom he had three children. Geisenheimer died in 1901.\nIn August 1912, Alzheimer fell ill on the train on his way to the University of Breslau, where he had been appointed professor of psychiatry in July 1912. Most probably he had a streptococcal infection and subsequent rheumatic fever leading to valvular heart disease, heart failure and kidney failure. He had not recovered completely from this illness.\nHe died of heart failure on 19 December 1915 at age 51, in Breslau, Silesia (present-day Wroc\u0142aw, Poland). He was buried on 23 December 1915 next to his wife at the Frankfurt Main Cemetery."}
{"id": "2384", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=2384", "title": "Aedile", "text": "Aedile ( ; , from , \"temple edifice\") was an elected office of the Roman Republic. Based in Rome, the aediles were responsible for maintenance of public buildings () and regulation of public festivals. They also had powers to enforce public order and duties to ensure the city of Rome was well supplied and its civil infrastructure well maintained, akin to modern local government.\nThere were two pairs of aediles: the first were the \"plebeian aediles\" (Latin \"aediles plebis\") and possession of this office was limited to plebeians; the other two were \"curule aediles\" (Latin \"aediles curules\"), open to both plebeians and patricians, in alternating years. An \"aedilis curulis\" was classified as a \"magister curulis\".\nThe office of the aedilis was generally held by young men intending to follow the cursus honorum to high political office, traditionally after their quaestorship but before their praetorship. It was not a compulsory part of the cursus, and hence a former quaestor could be elected to the praetorship without having held the position of aedile. However, it was an advantageous position to hold because it demonstrated the aspiring politician's commitment to public service, as well as giving him the opportunity to hold public festivals and games, an excellent way to increase his name recognition and popularity.\nHistory of the office.\nPlebeian aediles.\nThe plebeian aediles were created in the same year as the Tribunes of the People (494 BC). Originally intended as assistants to the tribunes, they guarded the rights of the plebs with respect to their headquarters, the Temple of Ceres. Subsequently, they assumed responsibility for maintenance of the city's buildings as a whole. Their duties at first were simply ministerial. They were the assistants to the tribunes in whatever matters that the tribunes might entrust to them, although most matters with which they were entrusted were of minimal importance. Around 446 BC, they were given the authority to care for the decrees of the senate (). When a was passed, it would be transcribed into a document, and deposited in the public treasury, the \"Aerarium\". They were given this power because the consuls, who had held this power before, arbitrarily suppressed and altered the documents. They also maintained the acts of the Plebeian Council (popular assembly), the \"plebiscites\". Plebiscites, once passed, were also transcribed into a physical document for storage. While their powers grew over time, it is not always easy to distinguish the difference between their powers, and those of the censors. Occasionally, if a Censor was unable to carry out one of his tasks, an Aedile would perform the task instead.\nCurule aediles.\nAccording to Livy (vi. 42), after the passing of the Licinian rogations in 367 BC, an extra day was added to the Roman games; the plebeian aediles refused to bear the additional expense, whereupon the patricians offered to undertake it, on condition that they were admitted to the aedileship. The plebeians accepted the offer, and accordingly two \"curule\" aediles were appointed\u2014at first from the patricians alone, then from patricians and plebeians in turn, lastly, from either\u2014at the Tribal Assembly under the presidency of the consul. Curule Aediles, as formal magistrates, held certain honors that Plebeian Aediles (who were not technically magistrates), did not hold. Besides having the right to sit on a Curule Chair (\"sella curulis\") and to wear a toga praetexta, the Curule Aediles also held the power to issue edicts (\"jus edicendi\"). These edicts often pertained to matters such as the regulation of the public markets, or what we might call \"economic regulation\". Livy suggests, perhaps incorrectly, that both Curule as well as Plebeian Aediles were sacrosanct. Although the curule aediles always ranked higher than the plebeian, their functions gradually approximated and became practically identical. Within five days after the beginning of their terms, the four Aediles (two Plebeian, two Curule) were required to determine, by lot or by agreement among themselves, what parts of the city each should hold jurisdiction over.\nDifferences between the two.\nThere was a distinction between the two sets of Aediles when it came to public festivals. Some festivals were Plebeian in nature, and thus were under the superintendence of Plebeian Aediles. Other festivals were supervised exclusively by the Curule Aediles, and it was often with these festivals that the Aediles would spend lavishly. This was often done so as to secure the support of voters in future elections. Because Aediles were not reimbursed for any of their public expenditures, most individuals who sought the office were independently wealthy. Since this office was a stepping stone to higher office and the Senate, it helped to ensure that only wealthy individuals (mostly landowners) would win election to high office. These extravagant expenditures began shortly after the end of Second Punic War, and increased as the spoils returned from Rome's new eastern conquests. Even the decadence of the emperors rarely surpassed that of the Aediles under the Republic, as could have been seen during Julius Caesar's Aedileship.\nElection to the office.\nPlebeian aediles were elected by the Plebeian Council, usually while under the presidency of a Plebeian Tribune. Curule aediles were elected by the Tribal Assembly, usually while under the presidency of a consul. Since the plebeian aediles were elected by the plebeians, rather than by all of the People of Rome (plebeians as well as members of the Patrician aristocracy), they were not technically magistrates. Before the passage of the \"lex annalis\", individuals could run for the aedileship by the time they turned twenty-seven. After the passage of this law in 180 BC, a higher age was set, probably thirty-five. By the 1st century BC, aediles were elected in July, and took office on the first day in January.\nPowers of the office.\nCicero (Legg. iii. 3, 7) divides these functions under three heads:\n(1) Care of the city:\nthe repair and preservation of temples, sewers and aqueducts; street cleansing and paving; regulations regarding traffic, dangerous animals and dilapidated buildings; precautions against fire; superintendence of baths and taverns; enforcement of sumptuary laws; punishment of gamblers and usurers; the care of public morals generally, including the prevention of foreign superstitions and the registration of meretrices. They also punished those who had too large a share of the ager publicus, or kept too many cattle on the state pastures.\n(2) Care of provisions:\ninvestigation of the quality of the articles supplied and the correctness of weights and measures; the purchase of grain for disposal at a low price in case of necessity.\n(3) Care of the games: \nsuperintendence and organization of the public games, as well as of those given by themselves and private individuals (e.g. at funerals) at their own expense. \nAmbitious persons often spent enormous sums in this manner to win the popular favor with a view to official advancement.\nUnder the Empire.\nIn 44 BC Julius Caesar added two plebeian aediles, called \"Cereales\", whose special duty was the care of the cereal (grain) supply. Under Augustus the office lost much of its importance, its judicial functions and the care of the games being transferred to the praetor, while its city responsibilities were limited by the appointment of a praefectus urbi. Augustus took for himself its powers over various religious duties. By stripping it of its powers over temples, Augustus effectively destroyed the office, by taking from it its original function. After this point, few people were willing to hold such a powerless office, and Augustus was even known to compel individuals into holding the office. Augustus accomplished this by randomly selecting former tribunes and quaestors for the office. Future emperors would continue to dilute the power of the office by transferring its powers to newly created offices. However, the office did retain some powers over licentiousness and disorder, in particular over the baths and brothels, as well as the registration of prostitutes. In the 3rd century, it disappeared altogether.\nUnder the Empire, Roman colonies and cities often had officials with powers similar to those of the republican aediles, although their powers widely varied. It seems as though they were usually chosen annually. Today in Portugal the county mayor can still be referred to as \"edil\" (e.g. 'O edil de Coimbra', meaning 'the mayor of Coimbra'), a way of reference used also in Romania for any mayors (ex. 'Edil al Bucure\u0219tiului', meaning 'mayor of Bucharest'). In Spain (and Latin America) the members of municipal councils are called \"concejales\" or \"ediles\".\nShakespeare.\nIn his play \"Coriolanus\", Shakespeare references the aediles. However, they are minor characters, and their chief role is to serve as policemen."}
{"id": "2386", "revid": "37195927", "url": "https://en.wikipedia.org/wiki?curid=2386", "title": "American Airlines", "text": "American Airlines, Inc. (AA or AAL) is a major American airline headquartered in Fort Worth, Texas, within the Dallas\u2013Fort Worth metroplex. It is the world's largest airline when measured by fleet size, scheduled passengers carried, and revenue passenger mile. American, together with its regional partners, operates an extensive international and domestic network with almost 6,800 flights per day to nearly 350 destinations in more than 50 countries. American Airlines is a founding member of the Oneworld alliance, the third-largest airline alliance in the world. Regional service is operated by independent and subsidiary carriers under the brand name American Eagle.\nAmerican Airlines and American Eagle operate out of 10 hubs, with Dallas/Fort Worth (DFW) being its largest. The airline handles more than 200 million passengers annually with an average of more than 500,000 passengers daily. As of 2019, the company employs nearly 130,000 people.\nAmerican Airlines operates its primary and the largest maintenance and repair operations (MRO) base in Tulsa in addition to the maintenance locations at its hubs.\nHistory.\nAmerican Airlines was started in 1930 via a union of more than eighty small airlines. The two organizations from which American Airlines was originated were Robertson Aircraft Corporation and Colonial Air Transport. The former was first created in Missouri in 1921, with both being merged in 1929 into holding company The Aviation Corporation. This, in turn, was made in 1930 into an operating company and rebranded as American Airways. In 1934, when new laws and attrition of mail contracts forced many airlines to reorganize, the corporation redid its routes into a connected system and was renamed American Airlines. Between 1970 and 2000, the company grew into being an international carrier, purchasing Trans World Airlines in 2001.\nAmerican had a direct role in the development of the DC-3, which resulted from a marathon telephone call from American Airlines CEO C. R. Smith to Donald Douglas, when Smith persuaded a reluctant Douglas to design a sleeper aircraft based on the DC-2 to replace American's Curtiss Condor II biplanes. (The existing DC-2's cabin was wide, too narrow for side-by-side berths.) Douglas agreed to go ahead with development only after Smith informed him of American's intention to purchase 20 aircraft. The prototype DST (Douglas Sleeper Transport) first flew on December 17, 1935, (the 32nd anniversary of the Wright Brothers' flight at Kitty Hawk). Its cabin was wide, and a version with 21 seats instead of the 14\u201316 sleeping berths of the DST was given the designation DC-3. There was no prototype DC-3; the first DC-3 built followed seven DSTs off the production line and was delivered to American Airlines. American Airlines inaugurated passenger service on June 26, 1936, with simultaneous flights from Newark, New Jersey, and Chicago, Illinois.\nIn 2011, due to a downturn in the airline industry, American Airlines' parent company AMR Corporation filed for bankruptcy protection. In 2013, American Airlines merged with US Airways but kept the American Airlines name, as it was the better-recognized brand internationally; the combination of the two airlines resulted in the creation of the largest airline in the United States, and ultimately the world.\nDestinations and hubs.\nDestinations.\nAs of September 2020, American Airlines flies to 95 domestic destinations and 95 international destinations in 55 countries in five continents.\nHubs.\nAmerican currently operates ten hubs.\nAlliance and codeshare agreements.\nAmerican Airlines is a member of the Oneworld alliance and has codeshares with the following airlines:\nFleet.\nAs of February 2021, American Airlines operates the largest commercial fleet in the world, comprising 888 aircraft from both Boeing and Airbus, with an additional 7 planned or on order.\nOver 80% of American's aircraft are narrow-bodies, mainly Airbus A320 series and the Boeing 737-800. It is the largest A320 series aircraft operator in the world, as well as the largest operator of the A319 and A321 variants. It is the fourth-largest operator of 737 family aircraft and second-largest operator of the 737-800 variant.\nAmerican's wide-body aircraft are Boeing airliners. It is the third-largest operator of the Boeing 787 series and the sixth-largest operator of the Boeing 777 series.\nAmerican Airlines exclusively ordered Boeing aircraft throughout the 2000s. This strategy shifted on July 20, 2011, when American announced the largest combined aircraft order in history for 460 narrow-body jets including 260 aircraft from the Airbus A320 series. Additional Airbus aircraft joined the fleet in 2013 upon merger with US Airways, which operated Airbus aircraft almost exclusively.\nCabins.\nFlagship First is American's international First Class product. It is offered only on the airline's Boeing 777-300ERs. The seats are fully lie-flat and offer direct aisle access in a 1-2-1 reverse herringbone configuration. As with the airline's other premium cabins, Flagship First offers wider food and beverage options, larger seats, and lounge access at certain airports.\nFlagship Business is a premium cabin offered on all Boeing 777-200ERs, Boeing 777-300ERs, Boeing 787-8s, and Boeing 787-9s. All Flagship Business seats are fully lie-flat. \nAmerican has dedicated 17 Airbus A321s (A321T) in its fleet for the specific use of flying transcontinental routes between New York JFK and Los Angeles, New York JFK and San Francisco, and Boston and Los Angeles. These aircraft offer two premium cabins, Flagship First and Flagship Business, which are unique among domestic mainline aircraft in American's fleet. Both cabins feature lie-flat seats; Flagship First also includes direct aisle access from each seat.\nFirst Class is offered on all domestic mainline aircraft, as well as regional aircraft with more than 50 seats. Seats range from in width and have of pitch. Dining options include beverages, and alcohol on all flights, free snacks on flights over , and with meals offered on flights or longer.\nPremium Economy is American's economy plus product available on all widebody aircraft. The cabin debuted on the airline's Boeing 787-9s in late 2016 and is also available on Boeing 777-200s and -300s, and Boeing 787-8s. Premium Economy seats are wider than seats in Main Cabin (American's economy cabin) and provide more amenities: Premium Economy customers get two free checked bags, priority boarding, and enhanced food and drink service including free alcohol. This product made American Airlines the first U.S. carrier to offer a four-cabin aircraft.\nAmerican's economy plus product on narrowbody aircraft are Main Cabin Extra. It is available on most of the mainline fleet and American Eagle regional aircraft with more than 50 seats. Main Cabin Extra seats include greater pitch than is available in Main Cabin, along with free alcoholic beverages. American retained Main Cabin Extra when the new Premium Economy product entered service in late 2016.\nMain Cabin is American's economy product, and is found on all mainline and regional aircraft in its fleet. Seats range from in width and have of pitch.\nAmerican Airlines marketed increased legroom in economy class as \"More Room Throughout Coach\", also referred to as \"MRTC\", starting in February 2000. Two rows of economy class seats were removed on domestic narrowbody aircraft, resulting in more than half of all economy seats having a pitch of or more. Amid financial losses, this scheme was discontinued in 2004.\nOn some routes, American also offers Basic Economy, the airline's lowest main cabin fare. Basic Economy is located in the main cabin but comes with restrictions. These restrictions include waiting until check-in for a seat assignment, no upgrades or refunds, and boarding in the last group. Originally Basic Economy passengers could only carry a personal item, but American later revised their Basic Economy policies to allow for a carry-on bag.\nIn May 2017, American announced it would be adding more seats to some of its Boeing 737 MAX jetliners and reducing overall legroom in the basic economy class. The last three rows will lose , going from the current to . The remainder of the economy cabin will have of legroom.\nReward programs.\nAAdvantage.\nAAdvantage is the frequent flyer program for American Airlines. It was launched on May 1, 1981, and it remains the largest frequent flyer program with over 67 million members as of 2011. Miles accumulated in the program allow members to redeem tickets, upgrade service class, or obtain free or discounted car rentals, hotel stays merchandise, or other products and services through partners. The most active members, based on the amount and price of travel booked, are designated AAdvantage Gold, AAdvantage Platinum, AAdvantage Platinum Pro, and AAdvantage Executive Platinum elite members, with privileges such as separate check-in, priority upgrade, and standby processing, or free upgrades. They also receive similar privileges from AA's partner airlines, particularly those in oneworld.\nAAdvantage co-branded credit cards are also available and offer other benefits. The cards are issued by CitiCards, a subsidiary of Citigroup, and Barclaycard in the United States, by Butterfield Bank and Scotiabank in the Caribbean, and by Banco Santander in Brazil.\nAAdvantage allows one-way redemption, starting at 7,500 miles.\nAdmirals Club.\nThe Admirals Club was conceived by AA president C.R. Smith as a marketing promotion shortly after he was made an honorary Texas Ranger. Inspired by the Kentucky colonels and other honorary title designations, Smith decided to make particularly valued passengers \"admirals\" of the \"Flagship fleet\" (AA called its aircraft \"Flagships\" at the time). The list of Admirals included many celebrities, politicians, and other VIPs, as well as more \"ordinary\" customers who had been particularly loyal to the airline.\nThere was no physical Admirals Club until shortly after the opening of LaGuardia Airport. During the airport's construction, New York Mayor Fiorello LaGuardia had an upper-level lounge set aside for press conferences and business meetings. At one such press conference, he noted that the entire terminal was being offered for lease to airline tenants; after a reporter asked whether the lounge would be leased as well, LaGuardia replied that it would, and a vice president of AA immediately offered to lease the premises. The airline then procured a liquor license and began operating the lounge as the \"Admirals Club\" in 1939.\nThe second Admirals Club opened at Washington National Airport. Because it was illegal to sell alcohol in Virginia at the time, the club contained refrigerators for the use of its members, so they could store their liquor at the airport. For many years, membership in the Admirals Club (and most other airline lounges) was by the airline's invitation. After a passenger sued for discrimination, the club (and most other airline lounges) switched to a paid membership program.\nFlagship Lounge.\nThough affiliated with the Admirals Club and staffed by many of the same employees, the Flagship Lounge is a separate lounge specifically designed for customers flying in First Class and Business Class on international flights and transcontinental domestic flights, as well as AAdvantage Concierge Key, Executive Platinum, Platinum Pro, and Platinum, as well as Oneworld Emerald and Sapphire frequent flyers. As of May 2019, Flagship Lounges are located at five airports: New York\u2013JFK, Chicago-O'Hare, Miami International, Los Angeles, and Dallas/Fort Worth. Flagship Lounges are planned for London-Heathrow and Philadelphia.\nCorporate affairs.\nOwnership and structure.\nAmerican Airlines, Inc. is publicly traded through its parent company, American Airlines Group Inc., under NASDAQ: AAL , with a market capitalization of about $12 billion as of 2019, and is included in the S&amp;P 500 index.\nAmerican Eagle is a network of six regional carriers that operate under a codeshare and service agreement with American, operating flights to destinations in the United States, Canada, the Caribbean, and Mexico. Three of these carriers are independent and three are subsidiaries of American Airlines Group: Envoy Air Inc., Piedmont Airlines, Inc., and PSA Airlines Inc.\nHeadquarters.\nAmerican Airlines is headquartered in Fort Worth, Texas, adjacent to the Dallas/Fort Worth International Airport. The headquarters is located in two office buildings in the CentrePort office complex and these buildings together have about of space. over 4,300 employees work at this complex.\nBefore it was headquartered in Texas, American Airlines was headquartered at 633 Third Avenue in the Murray Hill area of Midtown Manhattan, New York City. In 1979, American moved its headquarters to a site at Dallas/Fort Worth International Airport, which affected up to 1,300 jobs. Mayor of New York City Ed Koch described the move as a \"betrayal\" of New York City. American moved to two leased office buildings in Grand Prairie, Texas. On January 17, 1983, the airline finished moving into a $150\u00a0million ($ when adjusted for inflation), facility in Fort Worth; $147\u00a0million (about $ when adjusted for inflation) in Dallas/Fort Worth International Airport bonds financed the headquarters. The airline began leasing the facility from the airport, which owns the facility. Following the merger of US Airways and American Airlines, US Airways consolidated the corporate headquarters of the new company in Fort Worth, leaving their current headquarters in Phoenix, AZ, which had also been the headquarters of the airline that brought US Airways out of bankruptcy, America West Airlines.\nAs of 2015, American Airlines is the corporation with the largest presence in Fort Worth.\nIn 2015, American announced that it would build a new headquarters in Fort Worth. Groundbreaking began in the spring of 2016 and occupancy completed in September 2019. The airline plans to house 5,000 new workers in the building.\nIt will be located on a property adjacent to the airline's flight academy and conference and training center, west of Texas State Highway 360, west from the current headquarters. The airline will lease a total of from Dallas-Fort Worth International Airport and this area will include the headquarters. Construction of the new headquarters began after the demolition of the Sabre facility, previously on the site.\nThe airline considered developing a new headquarters in Irving, Texas, on the old Texas Stadium site, before deciding to keep the headquarters in Fort Worth.\nCorporate identity.\nLogo.\nIn 1931, Goodrich Murphy, an American employee, designed the AA logo as an entry in a logo contest. The eagle in the logo was copied from a Scottish hotel brochure. The logo was redesigned by Massimo Vignelli in 1967. Thirty years later, in 1997, American Airlines was able to make its logo Internet-compatible by buying the domain AA.com. \"AA\" is also American's two-letter IATA airline designator.\nOn January 17, 2013, American launched a new rebranding and marketing campaign with FutureBrand dubbed, \"A New American\". This included a new logo, which includes elements of the 1967 logo.\nAmerican Airlines faced difficulty obtaining copyright registration for their 2013 logo. On June 3, 2016, American Airlines sought to register it with the United States Copyright Office, but in October of that year, the Copyright Office ruled that the logo was ineligible for copyright protection, as it did not pass the threshold of originality, and was thus in the public domain. American requested that the Copyright Office reconsider, but on January 8, 2018, the Copyright Office affirmed its initial determination. After American Airlines submitted additional materials, the Copyright Office reversed its decision on December 7, 2018, and ruled that the logo contained enough creativity to merit copyright protection.\nAircraft livery.\nAmerican's early liveries varied widely, but a common livery was adopted in the 1930s, featuring an eagle painted on the fuselage. The eagle became a symbol of the company and inspired the name of American Eagle Airlines. Propeller aircraft featured an international orange lightning bolt running down the length of the fuselage, which was replaced by a simpler orange stripe with the introduction of jets.\"\nIn the late 1960s, American commissioned designer Massimo Vignelli to develop a new livery. The original design called for a red, white, and blue stripe on the fuselage, and a simple \"AA\" logo, without an eagle, on the tail; instead, Vignelli created a highly stylized eagle, which remained the company's logo until January 16, 2013.\nOn January 17, 2013, American unveiled a new livery. Before then, American had been the only major U.S. airline to leave most of its aircraft surfaces unpainted. This was because C. R. Smith would not say he liked painted aircraft and refused to use any liveries that involved painting the entire plane. Robert \"Bob\" Crandall later justified the distinctive natural metal finish by noting that less paint reduced the aircraft's weight, thus saving on fuel costs.\nIn January 2013, American launched a new rebranding and marketing campaign dubbed, \"The New American\". In addition to a new logo, American Airlines introduced a new livery for its fleet. The airline calls the new livery and branding \"a clean and modern update\". The current design features an abstract American flag on the tail, along with a silver-painted fuselage, as a throw-back to the old livery. The new design was painted by Leading Edge Aviation Services in California. Doug Parker, the incoming CEO indicated that the new livery could be short-lived, stating that \"maybe we need to do something slightly different than that ... The only reason this is an issue now is that they just did it right in the middle, which kind of makes it confusing, so that gives us an opportunity, actually, to decide if we are going to do something different because we have so many airplanes to paint\". The current logo and livery have had mixed criticism, with \"Design Shack\" editor Joshua Johnson writing that they 'boldly and proudly communicate the concepts of American pride and freedom wrapped into a shape that instantly makes you think about an airplane', and \"AskThePilot.com\" author Patrick Smith describing the logo as 'a linoleum knife poking through a shower curtain'. Later in January 2013, Bloomberg asked the designer of the 1968 American Airlines logo (Massimo Vignelli) on his opinion over the rebranding.\nIn the end, American let their employees decide the new livery's fate. On an internal website for employees, American posted two options, one the new livery and one a modified version of the old livery. All of the American Airlines Group employees (including US Airways and other affiliates) were able to vote. American ultimately decided to keep the new look. Parker announced that American would keep a US Airways and America West heritage aircraft in the fleet, with plans to add a heritage TWA aircraft and a heritage American plane with the old livery. As of September 2019, American has heritage aircraft for Piedmont, PSA, America West, US Airways, Reno Air, TWA, and AirCal in their fleet. They also have two AA branded heritage 737-800 aircraft, an AstroJet N905NN, and the polished aluminum livery used from 1967 to 2013, N921NN.\nWorker relations.\nThe main representatives of key groups of employees are:\nConcerns and conflicts.\nEnvironmental violations.\nBetween October 1993 to July 1998, American Airlines was repeatedly cited for using high-sulfur fuel in motor vehicles at 10 major airports around the country, a violation of the Clean Air Act.\nLifetime AAirpass.\nSince 1981, as a means of creating revenue in a period of loss-making, American Airlines had offered a lifetime pass of unlimited travel, for the initial cost of $250,000. This entitled the pass holder to fly anywhere in the world. 28 were sold. However, after some time, the airline realised they were making losses on the tickets, with the ticketholders costing them up to $1 million each. Ticketholders were booking large amounts of flights, and some ticketholders flying interstate for lunch or flying to London multiple times a month. AA raised the cost of the lifetime pass to $3 million, and then finally stopped offering it in 2003. AA then used litigation to cancel two of the lifetime offers, saying the passes \"had been terminated due to fraudulent activity\".\nDiscrimination complaints.\nOn October 24, 2017, the NAACP issued a travel advisory for American Airlines urging African Americans to \"exercise caution\" when traveling with the airline. The NAACP issued the advisory after four incidents. In one incident, a black woman was moved from First Class to coach while her white traveling companion was allowed to remain in First Class. In another incident, a black man was forced to give up his seats after being confronted by two unruly white passengers. According to the NAACP, while they did receive complaints on other airlines, most of their complaints in the year before their advisory were on American Airlines. In July 2018, the NAACP lifted their travel advisory saying that American has made improvements to mitigate discrimination and unsafe treatment of African Americans.\nAccidents and incidents.\nAs of March 2019, the airline has had almost sixty aircraft hull losses, beginning with the crash of an American Airways Ford 5-AT-C Trimotor in August 1931. Of these most were propeller driven aircraft, including three Lockheed L-188 Electra turboprop aircraft (of which one, the crash in 1959 of Flight 320, resulted in fatalities). The two accidents with the highest fatalities in both the airline's and U.S. aviation history were Flight 191 in 1979 and Flight 587 in 2001.\nOut of the 17 hijackings of American Airlines flights, two aircraft were hijacked and destroyed in the September 11 attacks: Flight 11 crashed into the north facade of the North Tower of the World Trade Center, and Flight 77 crashed into the Pentagon; both were bound for LAX from Boston Logan International Airport and Washington Dulles International Airport respectively.\nOther accidents include the Flight 383 engine failure and fire in 2016. There were two training flight accidents in which the crew were killed and six that resulted in no fatalities. Another four jet aircraft have been written off due to incidents while they were parked between flights or while undergoing maintenance."}
{"id": "2388", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=2388", "title": "Antidepressant", "text": "Antidepressants are medications used to treat major depressive disorder, some anxiety disorders, some chronic pain conditions, and to help manage some addictions. Common side-effects of antidepressants include dry mouth, weight gain, dizziness, headaches, sexual dysfunction, and emotional blunting. There is a slight increased risk of suicidal thinking and behavior when taken by children, adolescents, and young adults. A discontinuation syndrome can occur after stopping any antidepressant which resembles recurrent depression.\nSome reviews of antidepressants for depression in adults find benefit while others do not. Evidence of benefit in children and adolescents is unclear. The twenty one most commonly prescribed antidepressant medications were found to be more effective than placebo for adults with major depressive disorder in a 2016 meta-study. There is debate in the medical community about how much of the observed effects of antidepressants can be attributed to the placebo effect, with some claiming that there is no effect above and beyond it. Most research on whether antidepressant drugs work is done on people with very severe symptoms, a population who exhibits much weaker placebo responses, so the results cannot be extrapolated to the general population.\nThere are effective treatments for depression which do not involve medications or may be used in conjunction with medications.\nMedical uses.\nAntidepressants are used to treat major depressive disorder and of other conditions, including some anxiety disorders, some chronic pain conditions, and to help manage some addictions. Antidepressants are often used in combinations with one another.\nThe proponents of the monoamine hypothesis of depression recommend choosing the antidepressant with the mechanism of action impacting the most prominent symptoms\u2014for example, they advocate that people with MDD who are also anxious or irritable should be treated with SSRIs or norepinephrine reuptake inhibitors, and the ones with the loss of energy and enjoyment of life\u2014with norepinephrine and dopamine enhancing drugs.\nMajor depressive disorder.\nThe UK National Institute for Health and Care Excellence (NICE) 2009 guidelines indicate that antidepressants should not be routinely used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommended that antidepressant treatment be considered for:\nThe guidelines further note that antidepressant treatment should be used in combination with psychosocial interventions in most cases, should be continued for at least six months to reduce the risk of relapse, and that SSRIs are typically better tolerated than other antidepressants.\nAmerican Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors that include severity of symptoms, co-existing disorders, prior treatment experience, and the person's preference. Options may include pharmacotherapy, psychotherapy, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. They recommended antidepressant medication as an initial treatment choice in people with mild, moderate, or severe major depression, that should be given to all people with severe depression unless ECT is planned.\nReviews of antidepressants generally find that they benefit adults with depression. On the other hand, some contend that most studies on antidepressant medication are confounded by several biases: the lack of an active placebo, which means that many people in the placebo arm of a double-blind study may figure out that they are not getting any true treatment, thus destroying double-blindness; a short follow up after termination of treatment; non-systematic recording of adverse effects; very strict exclusion criteria in samples of patients; studies being paid for by the industry; selective publication of results. That means that the small beneficial effects that are found may not be statistically significant.\nAnxiety disorders.\nGeneralized anxiety disorder.\nAntidepressants are recommended by the National Institute for Health and Care Excellence (NICE) for the treatment of generalized anxiety disorder (GAD) that has failed to respond to conservative measures such as education and self-help activities. GAD is a common disorder of which the central feature is excessive worry about a number of different events. Key symptoms include excessive anxiety about multiple events and issues, and difficulty controlling worrisome thoughts that persists for at least 6 months.\nAntidepressants provide a modest-to-moderate reduction in anxiety in GAD. The efficacy of different antidepressants is similar.\nSocial anxiety disorder.\nSome antidepressants are used as a treatment for social anxiety disorder, but their efficacy is not entirely convincing, as only a small proportion of antidepressants showed some efficacy for this condition. Paroxetine was the first drug to be FDA-approved for this disorder. Its efficacy is considered beneficial, although not everyone responds favorably to the drug. Sertraline and fluvoxamine extended release were later approved for it as well, while escitalopram is used off-label with acceptable efficacy. However, there isn't enough evidence to support citalopram for treating social phobia, and fluoxetine was no better than placebo in clinical trials. SSRIs are used as a first-line treatment for social anxiety, but they don't work for everyone. One alternative would be venlafaxine, which is a SNRI. It showed benefits for social phobia in five clinical trials against placebo, while the other SNRIs are not considered particularly useful for this disorder as many of them didn't undergo testing for it. As of now, it is unclear if duloxetine and desvenlafaxine can provide benefits for social anxiety sufferers. However, another class of antidepressants called MAOIs are considered effective for social anxiety, but they come with many unwanted side effects and are rarely used. Phenelzine was shown to be a good treatment option, but its use is limited by dietary restrictions. Moclobemide is a RIMA and showed mixed results but still got approval in some European countries for social anxiety disorder. TCA antidepressants, such as clomipramine and imipramine, are not considered effective for this anxiety disorder in particular. This leaves out SSRIs such as paroxetine, sertraline and fluvoxamine CR as acceptable and tolerated treatment options for this disorder.\nObsessive\u2013compulsive disorder.\nSSRIs are a second-line treatment of adult obsessive\u2013compulsive disorder (OCD) with mild functional impairment and as first-line treatment for those with moderate or severe impairment. In children, SSRIs are considered as a second-line therapy in those with moderate-to-severe impairment, with close monitoring for psychiatric adverse effects. SSRIs appear useful for OCD, at least in the short term. Efficacy has been demonstrated both in short-term treatment trials of 6 to 24 weeks and in discontinuation trials of 28 to 52 weeks duration. Clomipramine, a TCA drug, is considered effective and useful for OCD, however it is used as a second line treatment because it is less well tolerated than the SSRIs. Despite this, it has not shown superiority to fluvoxamine in trials. All SSRIs can be used effectively for OCD, and in some cases, SNRIs can also be tried even though none of them is approved specifically for OCD. However, even with all these treatment options, many people remain symptomatic after initiating the medication, and less than half of them do achieve remission.\nPost traumatic stress disorder.\nAntidepressants are one of the treatment options for PTSD, however their efficacy is not well established. Two antidepressants are FDA approved for it, paroxetine and sertraline, they belong to the serotonin reuptake inhibitors class. Paroxetine has slightly higher response and remission rates than sertraline for this condition, however both drugs are not considered very helpful for every person that takes them. Fluoxetine and venlafaxine are used off label, with fluoxetine producing unsatisfactory mixed results and venlafaxine, while having a response rates of 78%, which is significantly higher than what paroxetine and sertraline achieved, but it did not address all the symptoms of ptsd like the two drugs did, which is in part due to the fact the venlafaxine is an SNRI, this class of drugs inhibit the reuptake of norepinephrine too, this could cause some anxiety in some people. Fluvoxamine, escitalopram and citalopram were not well tested in this disorder. MAOIs, while some of them may be helpful, are not used much because of their unwanted side effects. This leaves paroxetine and sertraline as acceptable treatment options for some people, although more effective antidepressants are needed.\nPanic disorder.\nPanic disorder is relatively treated well with medications compared with other disorders, several classes of antidepressants have shown efficacy for this disorder, however SSRIs and SNRIs are used first-line. Paroxetine, sertraline, fluoxetine are FDA approved for panic disorder, although fluvoxamine, escitalopram and citalopram are considered effective for it. The SNRI venlafaxine is also approved for this condition. Unlike with social anxiety and PTSD, some TCAs antidepressants, like clomipramine and imipramine, have shown efficacy for panic disorder. Moreover, the MAOI phenelzine is considered useful too. Panic disorder has many drugs for its treatment, however, the starting dose must be lower than the one used for major depressive disorder because people, in the initiation of treatment, have reported an increase in anxiety as a result of starting the medication. In conclusion, while panic disorder's treatment options seem acceptable and useful for this condition, many people are still symptomatic after treatment with residual symptoms.\nEating disorders.\nAntidepressants are recommended as an alternative or additional first step to self-help programs in the treatment of bulimia nervosa. SSRIs (fluoxetine in particular) are preferred over other antidepressants due to their acceptability, tolerability, and superior reduction of symptoms in short-term trials. Long-term efficacy remains poorly characterized. Bupropion is not recommended for the treatment of eating disorders due to an increased risk of seizure.\nSimilar recommendations apply to binge eating disorder. SSRIs provide short-term reductions in binge eating behavior, but have not been associated with significant weight loss.\nClinical trials have generated mostly negative results for the use of SSRIs in the treatment of anorexia nervosa. Treatment guidelines from the National Institute of Health and Care Excellence recommend against the use of SSRIs in this disorder. Those from the American Psychiatric Association note that SSRIs confer no advantage regarding weight gain, but that they may be used for the treatment of co-existing depressive, anxiety, or obsessive\u2013compulsive disorders.\nPain.\nFibromyalgia.\nA 2012 meta-analysis concluded that antidepressants treatment favorably affects pain, health-related quality of life, depression, and sleep in fibromyalgia syndrome. Tricyclics appear to be the most effective class, with moderate effects on pain and sleep and small effects on fatigue and health-related quality of life. The fraction of people experiencing a 30% pain reduction on tricyclics was 48% versus 28% for placebo. For SSRIs and SNRIs the fraction of people experiencing a 30% pain reduction was 36% (20% in the placebo comparator arms) and 42% (32% in the corresponding placebo comparator arms). Discontinuation of treatment due to side effects was common. Antidepressants including amitriptyline, fluoxetine, duloxetine, milnacipran, moclobemide, and pirlindole are recommended by the European League Against Rheumatism (EULAR) for the treatment of fibromyalgia based on \"limited evidence\".\nNeuropathic pain.\nA 2014 meta-analysis from the Cochrane Collaboration found the antidepressant duloxetine to be effective for the treatment of pain resulting from diabetic neuropathy. The same group reviewed data for amitriptyline in the treatment of neuropathic pain and found limited useful randomized clinical trial data. They concluded that the long history of successful use in the community for the treatment of fibromyalgia and neuropathic pain justified its continued use. The group was concerned about the potential for overestimating the amount of pain relief provided by amitriptyline, and highlighted that only a small number of people will experience significant pain relief by taking this medication.\nOther.\nAntidepressants may be modestly helpful for treating people who both have depression and alcohol dependence, however the evidence supporting this association is of low quality. Buproprion is used to help people stop smoking. Antidepressants are also used to control some symptoms of narcolepsy. Antidepressants may be used to relieve pain in people with active rheumatoid arthritis however, further research is required. Antidepressants have been shown to be superior to placebo in treating depression in individuals with physical illness, although reporting bias may have exaggerated this finding.\nLimitations and strategies.\nBetween 30% and 50% of individuals treated with a given antidepressant do not show a response. Approximately one-third of people achieve a full remission, one-third experience a response and one-third are nonresponders. Partial remission is characterized by the presence of poorly defined residual symptoms. These symptoms typically include depressed mood, anxiety, sleep disturbance, fatigue and diminished interest or pleasure. It is currently unclear which factors predict partial remission. However, it is clear that residual symptoms are powerful predictors of relapse, with relapse rates 3\u20136\u00a0times higher in people with residual symptoms than in those who experience full remission. In addition, antidepressant drugs tend to lose efficacy over the course of treatment. According to data from the Centers for Disease Control and Prevention, less than one-third of Americans taking one antidepressant medication have seen a mental health professional in the previous year. A number of strategies are used in clinical practice to try to overcome these limits and variations. They include switching medication, augmentation, and combination.\nSwitching antidepressants.\nThe American Psychiatric Association 2000 Practice Guideline advises that where no response is achieved following six to eight weeks of treatment with an antidepressant, to switch to an antidepressant in the same class, then to a different class of antidepressant. A 2006 meta-analysis review found wide variation in the findings of prior studies; for people who had failed to respond to an SSRI antidepressant, between 12% and 86% showed a response to a new drug. However, the more antidepressants an individual had already tried, the less likely they were to benefit from a new antidepressant trial. However, a later meta-analysis found no difference between switching to a new drug and staying on the old medication; although 34% of treatment resistant people responded when switched to the new drug, 40% responded without being switched.\nAugmentation and combination.\nFor a partial response, the American Psychiatric Association guidelines suggest augmentation, or adding a drug from a different class. These include lithium and thyroid augmentation, dopamine agonists, sex steroids, NRIs, glucocorticoid-specific agents, or the newer anticonvulsants.\nA combination strategy involves adding another antidepressant, usually from a different class so as to have effect on other mechanisms. Although this may be used in clinical practice, there is little evidence for the relative efficacy or adverse effects of this strategy. Other tests conducted include the use of psychostimulants as an augmentation therapy. Several studies have shown the efficacy of combining modafinil for treatment-resistant people. It has been used to help combat SSRI-associated fatigue.\nLong-term use.\nThe effects of antidepressants typically do not continue once the course of medication ends. This results in a high rate of relapse. A 2003 meta-analysis found that 18% of people who had responded to an antidepressant relapsed while still taking it, compared to 41% whose antidepressant was switched for a placebo.\nA gradual loss of therapeutic benefit occurs in a minority of people during the course of treatment. A strategy involving the use of pharmacotherapy in the treatment of the acute episode, followed by psychotherapy in its residual phase, has been suggested by some studies.\nAdverse effects.\nAntidepressants can cause various adverse effects, depending on the individual and the drug in question.\nAlmost any medication involved with serotonin regulation has the potential to cause serotonin toxicity (also known as \"serotonin syndrome\") \u2014 an excess of serotonin that can induce mania, restlessness, agitation, emotional lability, insomnia and confusion as its primary symptoms. Although the condition is serious, it is not particularly common, generally only appearing at high doses or while on other medications. Assuming proper medical intervention has been taken (within about 24\u00a0hours) it is rarely fatal. Antidepressants appear to increase the risk of diabetes by about 1.3 fold.\nMAOIs tend to have pronounced (sometimes fatal) interactions with a wide variety of medications and over-the-counter drugs. If taken with foods that contain very high levels of tyramine (e.g., mature cheese, cured meats, or yeast extracts), they may cause a potentially lethal hypertensive crisis. At lower doses, the person may only experience a headache due to an increase in blood pressure.\nIn response to these adverse effects, a different type of MAOI has been developed: the reversible inhibitor of monoamine oxidase A (RIMA) class of drugs. Their primary advantage is that they do not require the person to follow a special diet, while being purportedly effective as SSRIs and tricyclics in treating depressive disorders.\nTricyclics and SSRI can cause the so-called drug-induced QT prolongation, especially in older adults; this condition can degenerate into a specific type of abnormal heart rhythm called torsades de points which can potentially lead to sudden cardiac arrest.\nPregnancy.\nSSRI use in pregnancy has been associated with a variety of risks with varying degrees of proof of causation. As depression is independently associated with negative pregnancy outcomes, determining the extent to which observed associations between antidepressant use and specific adverse outcomes reflects a causative relationship has been difficult in some cases. In other cases, the attribution of adverse outcomes to antidepressant exposure seems fairly clear.\nSSRI use in pregnancy is associated with an increased risk of spontaneous abortion of about 1.7-fold, and is associated with preterm birth and low birth weight.\nA systematic review of the risk of major birth defects in antidepressant-exposed pregnancies found a small increase (3% to 24%) in the risk of major malformations and a risk of cardiovascular birth defects that did not differ from non-exposed pregnancies. A study of fluoxetine-exposed pregnancies found a 12% increase in the risk of major malformations that just missed statistical significance. Other studies have found an increased risk of cardiovascular birth defects among depressed mothers not undergoing SSRI treatment, suggesting the possibility of ascertainment bias, e.g. that worried mothers may pursue more aggressive testing of their infants. Another study found no increase in cardiovascular birth defects and a 27% increased risk of major malformations in SSRI exposed pregnancies. The FDA advises for the risk of birth defects with the use of paroxetine and the MAOI should be avoided.\nA 2013 systematic review and meta-analysis found that antidepressant use during pregnancy was statistically significantly associated with some pregnancy outcomes, such as gestational age and preterm birth, but not with other outcomes. The same review cautioned that because differences between the exposed and unexposed groups were small, it was doubtful whether they were clinically significant.\nA neonate (infant less than 28\u00a0days old) may experience a withdrawal syndrome from abrupt discontinuation of the antidepressant at birth. Antidepressants have been shown to be present in varying amounts in breast milk, but their effects on infants are currently unknown.\nMoreover, SSRIs inhibit nitric oxide synthesis, which plays an important role in setting vascular tone. Several studies have pointed to an increased risk of prematurity associated with SSRI use, and this association may be due to an increase risk of pre-eclampsia of pregnancy.\nAntidepressant-induced mania.\nAnother possible problem with antidepressants is the chance of antidepressant-induced mania or hypomania in people with or without a diagnosis of bipolar disorder. Many cases of bipolar depression are very similar to those of unipolar depression. Therefore, the person can be misdiagnosed with unipolar depression and be given antidepressants. Studies have shown that antidepressant-induced mania can occur in 20\u201340% of people with bipolar disorder. For bipolar depression, antidepressants (most frequently SSRIs) can exacerbate or trigger symptoms of hypomania and mania.\nSuicide.\nStudies have shown that the use of antidepressants is correlated with an increased risk of suicidal behavior and thinking (suicidality) in those aged under 25. This problem has been serious enough to warrant government intervention by the US Food and Drug Administration (FDA) to warn of the increased risk of suicidality during antidepressant treatment. According to the FDA, the heightened risk of suicidality occurs within the first one to two months of treatment. The National Institute for Health and Care Excellence (NICE) places the excess risk in the \"early stages of treatment\". A meta-analysis suggests that the relationship between antidepressant use and suicidal behavior or thoughts is age-dependent. Compared with placebo, the use of antidepressants is associated with an increase in suicidal behavior or thoughts among those 25 or younger (OR=1.62). A review of RCTs and epidemiological studies by Healy and Whitaker found an increase of suicidal acts by a factor of 2.4..There is no effect or possibly a mild protective effect among those aged 25 to 64 (OR=0.79). Antidepressant treatment has a protective effect against suicidality among those aged 65 and over (OR=0.37).\nSexual.\nSexual side effects are also common with SSRIs, such as loss of sexual drive, failure to reach orgasm, and erectile dysfunction. Although usually reversible, these sexual side-effects can, in rare cases, continue after the drug has been completely withdrawn.\nIn a study of 1022 outpatients, overall sexual dysfunction with all antidepressants averaged 59.1% with SSRI values between 57% and 73%, mirtazapine 24%, nefazodone 8%, amineptine 7% and moclobemide 4%. Moclobemide, a selective reversible MAO-A inhibitor, does not cause sexual dysfunction, and can actually lead to an improvement in all aspects of sexual function.\nBiochemical mechanisms suggested as causative include increased serotonin, particularly affecting 5-HT2 and 5-HT3 receptors; decreased dopamine; decreased norepinephrine; blockade of cholinergic and \u03b11adrenergic receptors; inhibition of nitric oxide synthetase; and elevation of prolactin levels. Mirtazapine is reported to have fewer sexual side effects, most likely because it antagonizes 5-HT2 and 5-HT3 receptors and may, in some cases, reverse sexual dysfunction induced by SSRIs by the same mechanism.\nBupropion, a weak NDRI and nicotinic antagonist, may be useful in treating reduced libido as a result of SSRI treatment.\nChanges in weight.\nChanges in appetite or weight are common among antidepressants, but are largely drug-dependent and related to which neurotransmitters they affect. Mirtazapine and paroxetine, for example, may be associated with weight gain and/or increased appetite, while others (such as bupropion and venlafaxine) achieve the opposite effect.\nThe antihistaminic properties of certain TCA- and TeCA-class antidepressants have been shown to contribute to the common side effects of increased appetite and weight gain associated with these classes of medication.\nDiscontinuation syndrome.\nAntidepressant discontinuation syndrome, also called antidepressant withdrawal syndrome, is a condition that can occur following the interruption, reduction, or discontinuation of antidepressant medication. The symptoms may include flu-like symptoms, trouble sleeping, nausea, poor balance, sensory changes, and anxiety. The problem usually begins within three days and may last for several months. Rarely psychosis may occur.\nA discontinuation syndrome can occur after stopping any antidepressant including selective serotonin re-uptake inhibitors (SSRIs), serotonin\u2013norepinephrine reuptake inhibitors (SNRIs), and tricyclic antidepressants (TCAs). The risk is greater among those who have taken the medication for longer and when the medication in question has a short half-life. The underlying reason for its occurrence is unclear. The diagnosis is based on the symptoms.\nMethods of prevention include gradually decreasing the dose among those who wish to stop, though it is possible for symptoms to occur with tapering. Treatment may include restarting the medication and slowly decreasing the dose. People may also be switched to the long acting antidepressant fluoxetine which can then be gradually decreased.\nApproximately 20\u201350% of people who suddenly stop an antidepressant develop an antidepressant discontinuation syndrome. The condition is generally not serious. Though about half of people with symptoms describe them as severe. Some restart antidepressants due to the severity of the symptoms.\nEmotional blunting.\nSSRIs appear to cause emotional blunting, or numbness in some people who take them. This is a reduction in extremes of emotion, both positive and negative. While the person may feel less depressed, they may also feel less happiness or empathy. This may be cause for a dose reduction or medication change. The mechanism is unknown.\nPharmacology.\nThe earliest and probably most widely accepted scientific theory of antidepressant action is the monoamine hypothesis (which can be traced back to the 1950s), which states that depression is due to an imbalance (most often a deficiency) of the monoamine neurotransmitters (namely serotonin, norepinephrine and dopamine). It was originally proposed based on the observation that certain hydrazine anti-tuberculosis agents produce antidepressant effects, which was later linked to their inhibitory effects on monoamine oxidase, the enzyme that catalyses the breakdown of the monoamine neurotransmitters. All currently marketed antidepressants have the monoamine hypothesis as their theoretical basis, with the possible exception of agomelatine which acts on a dual melatonergic-serotonergic pathway. Despite the success of the monoamine hypothesis it has a number of limitations: for one, all monoaminergic antidepressants have a delayed onset of action of at least a week; and secondly, there are a sizeable portion (&gt;40%) of depressed patients that do not adequately respond to monoaminergic antidepressants. A number of alternative hypotheses have been proposed, including the glutamate, neurogenic, epigenetic, cortisol hypersecretion and inflammatory hypotheses.\nTypes.\nSelective serotonin reuptake inhibitors.\nSelective serotonin reuptake inhibitors (SSRIs) are believed to increase the extracellular level of the neurotransmitter serotonin by limiting its reabsorption into the presynaptic cell, increasing the level of serotonin in the synaptic cleft available to bind to the postsynaptic receptor. They have varying degrees of selectivity for the other monoamine transporters, with pure SSRIs having only weak affinity for the norepinephrine and dopamine transporters.\nSSRIs are the most widely prescribed antidepressants in many countries. The efficacy of SSRIs in mild or moderate cases of depression has been disputed.\nSerotonin\u2013norepinephrine reuptake inhibitors.\nSerotonin\u2013norepinephrine reuptake inhibitors (SNRIs) are potent inhibitors of the reuptake of serotonin and norepinephrine. These neurotransmitters are known to play an important role in mood. SNRIs can be contrasted with the more widely used selective serotonin reuptake inhibitors (SSRIs), which act mostly upon serotonin alone.\nThe human serotonin transporter (SERT) and norepinephrine transporter (NET) are membrane proteins that are responsible for the reuptake of serotonin and norepinephrine. Balanced dual inhibition of monoamine reuptake can possibly offer advantages over other antidepressants drugs by treating a wider range of symptoms.\nSNRIs are sometimes also used to treat anxiety disorders, obsessive\u2013compulsive disorder (OCD), attention deficit hyperactivity disorder (ADHD), chronic neuropathic pain, and fibromyalgia syndrome (FMS), and for the relief of menopausal symptoms.\nSerotonin modulators and stimulators.\nSerotonin modulator and stimulators (SMSs), sometimes referred to more simply as \"serotonin modulators\", are a type of drug with a multimodal action specific to the serotonin neurotransmitter system. To be precise, SMSs simultaneously modulate one or more serotonin receptors and inhibit the reuptake of serotonin. The term was coined in reference to the mechanism of action of the serotonergic antidepressant vortioxetine, which acts as a serotonin reuptake inhibitor (SRI), partial agonist of the 5-HT1A receptor, and antagonist of the 5-HT3 and 5-HT7 receptors. However, it can also technically be applied to vilazodone, which is an antidepressant as well and acts as an SRI and 5-HT1A receptor partial agonist.\nAn alternative term is serotonin partial agonist/reuptake inhibitor (SPARI), which can be applied only to vilazodone.\nSerotonin antagonists and reuptake inhibitors.\nSerotonin antagonist and reuptake inhibitors (SARIs) while mainly used as antidepressants, are also anxiolytics and hypnotics. They act by antagonizing serotonin receptors such as 5-HT2A and inhibiting the reuptake of serotonin, norepinephrine, and/or dopamine. Additionally, most also act as \u03b11-adrenergic receptor antagonists. The majority of the currently marketed SARIs belong to the phenylpiperazine class of compounds. They include trazodone and nefazodone.\nNorepinephrine reuptake inhibitors.\nNorepinephrine reuptake inhibitors (NRIs or NERIs) are a type of drug that acts as a reuptake inhibitor for the neurotransmitter norepinephrine (noradrenaline) by blocking the action of the norepinephrine transporter (NET). This in turn leads to increased extracellular concentrations of norepinephrine.\nNRIs are commonly used in the treatment of conditions like ADHD and narcolepsy due to their psychostimulant effects and in obesity due to their appetite suppressant effects. They are also frequently used as antidepressants for the treatment of major depressive disorder, anxiety and panic disorder. Additionally, many drugs of abuse such as cocaine and methylphenidate possess NRI activity, though it is important to mention that NRIs without combined dopamine reuptake inhibitor (DRI) properties are not significantly rewarding and hence are considered to have a negligible abuse potential. However, norepinephrine has been implicated as acting synergistically with dopamine when actions on the two neurotransmitters are combined (e.g., in the case of NDRIs) to produce rewarding effects in psychostimulant drugs of abuse.\nNorepinephrine-dopamine reuptake inhibitors.\nThe only drug used of this class for depression is bupropion.\nTricyclic antidepressants.\nThe majority of the tricyclic antidepressants (TCAs) act primarily as serotonin\u2013norepinephrine reuptake inhibitors (SNRIs) by blocking the serotonin transporter (SERT) and the norepinephrine transporter (NET), respectively, which results in an elevation of the synaptic concentrations of these neurotransmitters, and therefore an enhancement of neurotransmission. Notably, with the sole exception of amineptine, the TCAs have weak affinity for the dopamine transporter (DAT), and therefore have low efficacy as dopamine reuptake inhibitors (DRIs).\nAlthough TCAs are sometimes prescribed for depressive disorders, they have been largely replaced in clinical use in most parts of the world by newer antidepressants such as selective serotonin reuptake inhibitors (SSRIs), serotonin\u2013norepinephrine reuptake inhibitors (SNRIs) and norepinephrine reuptake inhibitors (NRIs). Adverse effects have been found to be of a similar level between TCAs and SSRIs.\nTetracyclic antidepressants.\nTetracyclic antidepressants (TeCAs) are a class of antidepressants that were first introduced in the 1970s. They are named after their chemical structure, which contains four rings of atoms, and are closely related to the tricyclic antidepressants (TCAs), which contain three rings of atoms.\nMonoamine oxidase inhibitors.\nMonoamine oxidase inhibitors (MAOIs) are chemicals which inhibit the activity of the monoamine oxidase enzyme family. They have a long history of use as medications prescribed for the treatment of depression. They are particularly effective in treating atypical depression. They are also used in the treatment of Parkinson's disease and several other disorders.\nBecause of potentially lethal dietary and drug interactions, monoamine oxidase inhibitors have historically been reserved as a last line of treatment, used only when other classes of antidepressant drugs (for example selective serotonin reuptake inhibitors and tricyclic antidepressants) have failed.\nMAOIs have been found to be effective in the treatment of panic disorder with agoraphobia, social phobia, atypical depression or mixed anxiety and depression, bulimia, and post-traumatic stress disorder, as well as borderline personality disorder. MAOIs appear to be particularly effective in the management of bipolar depression according to a retrospective-analysis. There are reports of MAOI efficacy in obsessive\u2013compulsive disorder (OCD), trichotillomania, dysmorphophobia, and avoidant personality disorder, but these reports are from uncontrolled case reports.\nMAOIs can also be used in the treatment of Parkinson's disease by targeting MAO-B in particular (therefore affecting dopaminergic neurons), as well as providing an alternative for migraine prophylaxis. Inhibition of both MAO-A and MAO-B is used in the treatment of clinical depression and anxiety disorders.\nNMDA receptor antagonists.\nNMDA receptor antagonists like ketamine and esketamine are rapid-acting antidepressants and seem to work via blockade of the ionotropic glutamate NMDA receptor.\nOthers.\nSee the list of antidepressants and management of depression for other drugs that are not specifically characterized.\nAdjuncts.\nAdjunct medications are an umbrella category of substances that increase the potency or \"enhance\" antidepressants. They work by affecting variables very close to the antidepressant, sometimes affecting a completely different mechanism of action. This may be attempted when depression treatments have not been successful in the past.\nCommon types of adjunct medication techniques generally fall into the following categories:\nIt is unknown if undergoing psychological therapy at the same time as taking anti-depressants enhances the anti-depressive effect of the medication.\nLess common adjuncts.\nLithium has been used to augment antidepressant therapy in those who have failed to respond to antidepressants alone. Furthermore, lithium dramatically decreases the suicide risk in recurrent depression. There is some evidence for the addition of a thyroid hormone, triiodothyronine, in patients with normal thyroid function.\nPsychopharmacologists have also tried adding a stimulant, in particular, d-amphetamine. However, the use of stimulants in cases of treatment-resistant depression is relatively controversial. A review article published in 2007 found psychostimulants may be effective in treatment-resistant depression with concomitant antidepressant therapy, but a more certain conclusion could not be drawn due to substantial deficiencies in the studies available for consideration, and the somewhat contradictory nature of their results.\nHistory.\nBefore the 1950s, opioids and amphetamines were commonly used as antidepressants. Their use was later restricted due to their addictive nature and side effects. Extracts from the herb St John's wort have been used as a \"nerve tonic\" to alleviate depression.\nIsoniazid, iproniazid, and imipramine.\nIn 1951, Irving Selikoff and , working out of Sea View Hospital on Staten Island, began clinical trials on two new anti-tuberculosis agents developed by Hoffman-LaRoche, isoniazid and iproniazid. Only patients with a poor prognosis were initially treated; nevertheless, their condition improved dramatically. Selikoff and Robitzek noted \"a subtle general stimulation ... the patients exhibited renewed vigor and indeed this occasionally served to introduce disciplinary problems.\" The promise of a cure for tuberculosis in the Sea View Hospital trials was excitedly discussed in the mainstream press.\nIn 1952, learning of the stimulating side effects of isoniazid, the Cincinnati psychiatrist Max Lurie tried it on his patients. In the following year, he and Harry Salzer reported that isoniazid improved depression in two-thirds of their patients and coined the term \"antidepressant\" to refer to its action. A similar incident took place in Paris, where Jean Delay, head of psychiatry at Sainte-Anne Hospital, heard of this effect from his pulmonology colleagues at Cochin Hospital. In 1952 (before Lurie and Salzer), Delay, with the resident , reported the positive effect of isoniazid on depressed patients. The mode of antidepressant action of isoniazid is still unclear. It is speculated that its effect is due to the inhibition of diamine oxidase, coupled with a weak inhibition of monoamine oxidase A.\nSelikoff and Robitzek also experimented with another anti-tuberculosis drug, iproniazid; it showed a greater psychostimulant effect, but more pronounced toxicity. Later, Jackson Smith, Gordon Kamman, George E. Crane, and Frank Ayd, described the psychiatric applications of iproniazid. Ernst Zeller found iproniazid to be a potent monoamine oxidase inhibitor. Nevertheless, iproniazid remained relatively obscure until Nathan S. Kline, the influential head of research at Rockland State Hospital, began to popularize it in the medical and popular press as a \"psychic energizer\". Roche put a significant marketing effort behind iproniazid. Its sales grew until it was recalled in 1961, due to reports of lethal hepatotoxicity.\nThe antidepressant effect of a tricyclic, a three ringed compound, was first discovered in 1957 by Roland Kuhn in a Swiss psychiatric hospital. Antihistamine derivatives were used to treat surgical shock and later as neuroleptics. Although in 1955 reserpine was shown to be more effective than placebo in alleviating anxious depression, neuroleptics were being developed as sedatives and antipsychotics.\nAttempting to improve the effectiveness of chlorpromazine, Kuhn in conjunction with the Geigy Pharmaceutical Company discovered the compound \"G 22355\", later renamed imipramine. Imipramine had a beneficial effect in patients with depression who showed mental and motor retardation. Kuhn described his new compound as a \"thymoleptic\" \"taking hold of the emotions,\" in contrast with neuroleptics, \"taking hold of the nerves\" in 1955\u201356. These gradually became established, resulting in the patent and manufacture in the US in 1951 by H\u00e4fliger and SchinderA.\nSecond generation antidepressants.\nAntidepressants became prescription drugs in the 1950s. It was estimated that no more than 50 to 100 individuals per million suffered from the kind of depression that these new drugs would treat, and pharmaceutical companies were not enthusiastic in marketing for this small market. Sales through the 1960s remained poor compared to the sales of tranquilizers, which were being marketed for different uses. Imipramine remained in common use and numerous successors were introduced. The use of monoamine oxidase inhibitors (MAOI) increased after the development and introduction of \"reversible\" forms affecting only the MAO-A subtype of inhibitors, making this drug safer to use.\nBy the 1960s, it was thought that the mode of action of tricyclics was to inhibit norepinephrine reuptake. However, norepinephrine reuptake became associated with stimulating effects. Later tricyclics were thought to affect serotonin as proposed in 1969 by Carlsson and Lindqvist as well as Lapin and Oxenkrug.\nResearchers began a process of rational drug design to isolate antihistamine-derived compounds that would selectively target these systems. The first such compound to be patented was zimelidine in 1971, while the first released clinically was indalpine. Fluoxetine was approved for commercial use by the US Food and Drug Administration (FDA) in 1988, becoming the first blockbuster SSRI. Fluoxetine was developed at Eli Lilly and Company in the early 1970s by Bryan Molloy, Klaus Schmiegel, David T. Wong and others. SSRIs became known as \"novel antidepressants\" along with other newer drugs such as SNRIs and NRIs with various selective effects.\nSt John's wort fell out of favor in most countries through the 19th and 20th centuries, except in Germany, where Hypericum extracts were eventually licensed, packaged and prescribed. Small-scale efficacy trials were carried out in the 1970s and 1980s, and attention grew in the 1990s following a meta-analysis. It remains an over-the-counter drug (OTC) supplement in most countries. Of concern are lead contaminant; on average, lead levels in women in the United States taking St. John's wort are elevated about 20%. Research continues to investigate its active component hyperforin, and to further understand its mode of action.\nRapid-acting antidepressants.\nEsketamine (brand name Spravato), the first rapid-acting antidepressant to be approved for clinical treatment of depression, was introduced for this indication in March 2019 in the United States.\nResearch.\nA 2016 randomized controlled trial evaluated the rapid antidepressant effects of the psychedelic ayahuasca in treatment-resistant depression with positive outcome. In 2018 the FDA granted Breakthrough Therapy Designation for psilocybin-assisted therapy for treatment-resistant depression and in 2019, the FDA granted Breakthrough Therapy Designation for psilocybin therapy treating major depressive disorder.\nSociety and culture.\nPrescription trends.\nIn the United States, antidepressants were the most commonly prescribed medication in 2013. Of the estimated 16 million \"long term\" (over 24 months) users, roughly 70 percent are female. As of 2017, about 16.5% of white people in the United States took antidepressants compared with 5.6% of black people in the United States.\nIn the UK, figures reported in 2010 indicated that the number of antidepressants prescribed by the National Health Service (NHS) almost doubled over a decade. Further analysis published in 2014 showed that number of antidepressants dispensed annually in the community went up by 25 million in the 14 years between 1998 and 2012, rising from 15 million to 40 million. Nearly 50% of this rise occurred in the four years after the 2008 banking crash, during which time the annual increase in prescriptions rose from 6.7% to 8.5%. These sources also suggest that aside from the recession, other factors that may influence changes in prescribing rates may include: improvements in diagnosis, a reduction of the stigma surrounding mental health, broader prescribing trends, GP characteristics, geographical location and housing status. Another factor that may contribute to increasing consumption of antidepressants is the fact that these medications now are used for other conditions including social anxiety and posttraumatic stress disorder.\nUnited States: The most commonly prescribed antidepressants in the US retail market in 2010 were:\nNetherlands: In the Netherlands, paroxetine is the most prescribed antidepressant, followed by amitriptyline, citalopram and venlafaxine.\nAdherence.\nAs of 2003, worldwide, 30 to 60% of people didn't follow their practitioner's instructions about taking their antidepressants, and as of 2013 in the US, it appeared that around 50% of people did not take their antidepressants as directed by their practitioner.\nWhen people fail to take their antidepressants, there is a greater risk that the drug won't help, that symptoms get worse, that they miss work or are less productive at work, and that the person may be hospitalized. This also increases costs for caring for them.\nSocial science perspective.\nSome academics have highlighted the need to examine the use of antidepressants and other medical treatments in cross-cultural terms, due to the fact that various cultures prescribe and observe different manifestations, symptoms, meanings and associations of depression and other medical conditions within their populations. These cross-cultural discrepancies, it has been argued, then have implications on the perceived efficacy and use of antidepressants and other strategies in the treatment of depression in these different cultures. In India, antidepressants are largely seen as tools to combat marginality, promising the individual the ability to reintegrate into society through their use\u2014a view and association not observed in the West.\nEnvironmental impacts.\nBecause most antidepressants function by inhibiting the reuptake of neurotransmitters serotonin, dopamine, and norepinepherine these drugs can interfere with natural neurotransmitter levels in other organisms impacted by indirect exposure. Antidepressants fluoxetine and sertraline have been detected in aquatic organisms residing in effluent dominated streams. The presence of antidepressants in surface waters and aquatic organisms has caused concern because ecotoxicological effects to aquatic organisms due to fluoxetine exposure have been demonstrated.\nCoral reef fish have been demonstrated to modulate aggressive behavior through serotonin. Artificially increasing serotonin levels in crustaceans can temporarily reverse social status and turn subordinates into aggressive and territorial dominant males.\nExposure to fluoxetine has been demonstrated to increase serotonergic activity in fish, subsequently reducing aggressive behavior. Perinatal exposure to fluoxetine at relevant environmental concentrations has been shown to lead to significant modifications of memory processing in 1-month-old cuttlefish. This impairment may disadvantage cuttlefish and decrease their survival. Somewhat less than 10% of orally administered fluoxetine is excreted from humans unchanged or as glucuronide."}
{"id": "2389", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=2389", "title": "Auger effect", "text": "The Auger effect is a physical phenomenon in which the filling of an inner-shell vacancy of an atom is accompanied by the emission of an electron from the same atom. When a core electron is removed, leaving a vacancy, an electron from a higher energy level may fall into the vacancy, resulting in a release of energy. Although most often this energy is released in the form of an emitted photon, the energy can also be transferred to another electron, which is ejected from the atom; this second ejected electron is called an Auger electron.\nEffect.\nThe effect was first discovered by Lise Meitner in 1922; Pierre Victor Auger independently discovered the effect shortly after and is credited with the discovery in most of the scientific community.\nUpon ejection, the kinetic energy of the Auger electron corresponds to the difference between the energy of the initial electronic transition into the vacancy and the ionization energy for the electron shell from which the Auger electron was ejected. These energy levels depend on the type of atom and the chemical environment in which the atom was located.\nAuger electron spectroscopy involves the emission of Auger electrons by bombarding a sample with either X-rays or energetic electrons and measures the intensity of Auger electrons that result as a function of the Auger electron energy. The resulting spectra can be used to determine the identity of the emitting atoms and some information about their environment.\nAuger recombination is a similar Auger effect which occurs in semiconductors. An electron and electron hole (electron-hole pair) can recombine giving up their energy to an electron in the conduction band, increasing its energy. The reverse effect is known as impact ionization.\nThe Auger effect can impact biological molecules such as DNA. Following the K-shell ionization of the component atoms of DNA, Auger electrons are ejected leading to damage of its sugar-phosphate backbone.\nDiscovery.\nThe Auger emission process was observed and published in 1922 by Lise Meitner, an Austrian-Swedish physicist, as a side effect in her competitive search for the nuclear beta electrons with the British physicist Charles Drummond Ellis.\nThe French physicist Pierre Victor Auger independently discovered it in 1923 upon analysis of a Wilson cloud chamber experiment and it became the central part of his PhD work. High-energy X-rays were applied to ionize gas particles and observe photoelectric electrons. The observation of electron tracks that were independent of the frequency of the incident photon suggested a mechanism for electron ionization that was caused from an internal conversion of energy from a radiationless transition. Further investigation, and theoretical work using elementary quantum mechanics and transition rate/transition probability calculations, showed that the effect was a radiationless effect more than an internal conversion effect."}
{"id": "2391", "revid": "1005449", "url": "https://en.wikipedia.org/wiki?curid=2391", "title": "Akio Morita", "text": "Akio Morita (January 26, 1921 \u2013 October 3, 1999) was a Japanese businessman and co-founder of Sony along with Masaru Ibuka.\nEarly life.\nAkio Morita was born in Nagoya, Aichi, Japan. Morita's family was involved in sake, miso and soy sauce production in the village of Kosugaya (currently a part of Tokoname City) on the western coast of Chita Peninsula in Aichi Prefecture since 1665. He was the oldest of four siblings and his father Kyuzaemon trained him as a child to take over the family business. Akio, however, found his true calling in mathematics and physics, and in 1944 he graduated from Osaka Imperial University with a degree in physics. He was later commissioned as a sub-lieutenant in the Imperial Japanese Navy, and served in World War II. During his service, Morita met his future business partner Masaru Ibuka in the Navy's Wartime Research Committee.\nSony.\nIn September 1945, Ibuka founded a radio repair shop in the bombed out Shirokiya Department Store in Nihonbashi, Tokyo. Morita saw a newspaper article about Ibuka's new venture and, after some correspondence, chose to join him in Tokyo. With funding from Morita's father, they co-founded \"Tokyo Tsushin Kogyo Kabushiki Kaisha\" (Tokyo Telecommunications Engineering Corporation, the forerunner of Sony Corporation) in 1946 with about 20 employees and initial capital of \u00a5190,000.\nIn 1949, the company developed magnetic recording tape and, in 1950, sold the first tape recorder in Japan. Ibuka was instrumental in securing the licensing of transistor technology from Bell Labs to Sony in the 1950s, thus making Sony one of the first companies to apply transistor technology to non-military uses. In 1957, the company produced a pocket-sized radio (the first to be fully transistorized), and in 1958, Morita and Ibuka decided to rename their company Sony Corporation (derived from \"sonus\"\u2014\u2013Latin for \"sound\"\u2014\u2013and \"Sonny-boys\" the most common American expression). Morita was an advocate for all the products made by Sony. However, since the radio was slightly too big to fit in a shirt pocket, Morita made his employees wear shirts with slightly larger pockets to give the radio a \"pocket sized\" appearance.\nMorita founded Sony Corporation of America (SONAM, currently abbreviated as SCA) in 1960. In the process, he was struck by the mobility of employees between American companies, which was unheard of in Japan at that time. When he returned to Japan, he encouraged experienced, middle-aged employees of other companies to reevaluate their careers and consider joining Sony. The company filled many positions in this manner, and inspired other Japanese companies to do the same. In 1961, Sony Corporation was the first Japanese company to be listed on the New York Stock Exchange, in the form of American depositary receipts (ADRs).\nIn March 1968, Morita set up a joint venture in Japan between Sony and CBS Records, with him as president, to manufacture \"software\" for Sony's hardware.\nMorita became president of Sony in 1971, taking over from Ibuka who had served from 1950 to 1971. In 1975, Sony released the first Betamax home videocassette recorder, a year before the VHS format came out.\nIbuka retired in 1976 and Morita was named chairman of the company. In 1979, the Walkman was introduced, making it one of the world's first portable music players and in 1982, Sony launched the world's first Compact Disc player, the Sony CDP-101, with a Compact Disc (CD) itself, a new data storage format Sony and Philips co-developed. In that year, a 3.5-inch floppy disk structure was introduced by Sony and it soon became the defacto standard. In 1984, Sony launched the Discman series which extended their Walkman brand to portable CD products.\nUnder the vision of Morita, the company aggressively expanded into new businesses. Part of its motivation for doing so was the pursuit of \"convergence\", linking film, music and digital electronics. Twenty years after setting up a joint venture with CBS Records in Japan, Sony bought CBS Records Group which consisted of Columbia Records, Epic Records and other CBS labels. In 1989, they also acquired Columbia Pictures Entertainment (Columbia Pictures, TriStar Pictures and others).\nNorio Ohga, who had joined the company in the 1950s after sending Morita a letter denouncing the poor quality of the company's tape recorders, succeeded Morita as chief executive officer in 1989.\nMorita suffered a cerebral hemorrhage in 1993 while playing tennis and on November 25, 1994, stepped down as Sony chairman to be succeeded by Ohga.\nOther affiliations.\nMorita was vice chairman of the Japan Business Federation (Japan Federation of Economic Organizations), and was a member of the Japan-U.S. Economic Relations Group, also known as the \"Wise Men's Group\". He helped General Motors with their acquisition of an interest in Isuzu Motors in 1972. He was also the third Japanese chairman of the Trilateral Commission. His amateur radio call sign is JP1DPJ.\nPublications.\nIn 1966, Morita wrote a book called \"Gakureki Muy\u014d Ron\" (\u5b66\u6b74\u7121\u7528\u8ad6, Never Mind School Records), where he stresses that school records are not important to success or one's business skills. In 1986, Morita wrote an autobiography titled \"Made in Japan\". He co-authored the 1991 book \"The Japan That Can Say No\" with politician Shintaro Ishihara, where they criticized American business practices and encouraged Japanese to take a more independent role in business and foreign affairs. (Actually, Morita had no intention to criticize American practices at that time.) The book was translated into English and caused controversy in the United States, and Morita later had his chapters removed from the English version and distanced himself from the book.\nAwards and Honours.\nIn 1972, Morita received the Golden Plate Award of the American Academy of Achievement. Morita was awarded the Albert Medal by the United Kingdom's Royal Society of Arts in 1982, the first Japanese to receive the honor. Two years later, he received the prestigious Legion of Honour, and in 1991, was awarded the First Class Order of the Sacred Treasure from the Emperor of Japan. In 1993, he was awarded an honorary British knighthood (KBE). Morita received the International Distinguished Entrepreneur Award from the University of Manitoba in 1987. In 1998, he was the only Asian person on \"Time magazine\"s list of the 20 most influential business people of the 20th Century as part of their . He was posthumously awarded the Grand Cordon of the Order of the Rising Sun in 1999.\nDeath.\nMorita, who loved to play golf and tennis and to watch movies when rainy, suffered a stroke in 1993, during a game of tennis. On November 25, 1994, he stepped down as Sony chairman. On October 3, 1999, Morita died of pneumonia at the age of 78.\nExternal links.\n "}
{"id": "2392", "revid": "26614034", "url": "https://en.wikipedia.org/wiki?curid=2392", "title": "Anode", "text": "An anode is an electrode through which the conventional current enters into a polarized electrical device. This contrasts with a cathode, an electrode through which conventional current leaves an electrical device. A common mnemonic is ACID, for \"anode current into device\". The direction of conventional current (the flow of positive charges) in a circuit is opposite to the direction of electron flow, so (negatively charged) electrons flow out the anode of a galvanic cell, into an outside or external circuit connected to the cell. In both a galvanic cell and an electrolytic cell, the anode is the electrode at which the oxidation reaction occurs.\nIn an electrolytic cell, the anode is the wire or plate having excess positive charge. Consequently, anions will tend to move towards the anode where they can undergo oxidation.\nHistorically, the anode has also been known as the zincode.\nCharge flow.\nThe terms anode and cathode are not defined by the voltage polarity of electrodes but the direction of current through the electrode. An anode is an electrode through which conventional current (positive charge) flows into the device from an external circuit, while a cathode is an electrode through which conventional current flows out of the device. If the current through the electrodes reverses direction, as occurs for example in a rechargeable battery when it is being charged, the naming of the electrodes as anode and cathode is reversed.\nConventional current depends not only on the direction the charge carriers move, but also the carriers' electric charge. The currents outside the device are usually carried by electrons in a metal conductor. Since electrons have a negative charge, the direction of electron flow is opposite to the direction of conventional current. Consequently, electrons leave the device through the anode and enter the device through the cathode.\nThe definition of anode and cathode is different for electrical devices such as diodes and vacuum tubes where the electrode naming is fixed and does not depend on the actual charge flow (current). These devices usually allow substantial current flow in one direction but negligible current in the other direction. Therefore, the electrodes are named based on the direction of this \"forward\" current. In a diode the anode is the terminal through which current enters and the cathode is the terminal through which current leaves, when the diode is forward biased. The names of the electrodes do not change in cases where reverse current flows through the device. Similarly, in a vacuum tube only one electrode can emit electrons into the evacuated tube due to being heated by a filament, so electrons can only enter the device from the external circuit through the heated electrode. Therefore, this electrode is permanently named the cathode, and the electrode through which the electrons exit the tube is named the anode.\nExamples.\nThe polarity of voltage on an anode with respect to an associated cathode varies depending on the device type and on its operating mode. In the following examples, the anode is negative in a device that provides power, and positive in a device that consumes power:\nIn a discharging battery or galvanic cell (diagram on left), the anode is the negative terminal because it is where conventional current flows into the cell. This inward current is carried externally by electrons moving outwards, negative charge flowing in one direction being electrically equivalent to positive charge flowing in the opposite direction.\nIn a recharging battery, or an electrolytic cell, the anode is the positive terminal, which receives current from an external generator. The current through a recharging battery is opposite to the direction of current during discharge; in other words, the electrode which was the cathode during battery discharge becomes the anode while the battery is recharging.\nThis ambiguity in the anode and cathode designation causes confusion in battery engineering, as is necessary to have the anode and cathode associated with unique physical components. The common convention is to name the electrode of a battery that releases electrons during discharge as the anode or the negative (-) electrode and the electrode that absorbs the electrons as the cathode or the positive (+). electrode.\nNaming the physical electrodes as positive (+) or negative (-) has the additional advantage as this terminology applies equally well to both charge/discharge conditions for rechargeable batteries as well as for electrochemistry and electronic devices.\nIn a diode, the anode is the positive terminal at the tail of the arrow symbol (flat side of the triangle), where current flows into the device. Note the electrode naming for diodes is always based on the direction of the forward current (that of the arrow, in which the current flows \"most easily\"), even for types such as Zener diodes or solar cells where the current of interest is the reverse current.\nIn vacuum tubes or gas-filled tubes, the anode is the terminal where current enters the tube.\nEtymology.\nThe word was coined in 1834 from the Greek \u1f04\u03bd\u03bf\u03b4\u03bf\u03c2 (\"anodos\"), 'ascent', by William Whewell, who had been consulted by Michael Faraday over some new names needed to complete a paper on the recently discovered process of electrolysis. In that paper Faraday explained that when an electrolytic cell is oriented so that electric current traverses the \"decomposing body\" (electrolyte) in a direction \"from East to West, or, which will strengthen this help to the memory, that in which the sun appears to move\", the anode is where the current enters the electrolyte, on the East side: \"\"ano\" upwards, \"odos\" a way; the way which the sun rises\".\nThe use of 'East' to mean the 'in' direction (actually 'in' \u2192 'East' \u2192 'sunrise' \u2192 'up') may appear contrived. Previously, as related in the first reference cited above, Faraday had used the more straightforward term \"eisode\" (the doorway where the current enters). His motivation for changing it to something meaning 'the East electrode' (other candidates had been \"eastode\", \"oriode\" and \"anatolode\") was to make it immune to a possible later change in the direction convention for current, whose exact nature was not known at the time. The reference he used to this effect was the Earth's magnetic field direction, which at that time was believed to be invariant. He fundamentally defined his arbitrary orientation for the cell as being that in which the internal current would run parallel to and in the same direction as a hypothetical magnetizing current loop around the local line of latitude which would induce a magnetic dipole field oriented like the Earth's. This made the internal current East to West as previously mentioned, but in the event of a later convention change it would have become West to East, so that the East electrode would not have been the 'way in' any more. Therefore, \"eisode\" would have become inappropriate, whereas \"anode\" meaning 'East electrode' would have remained correct with respect to the unchanged direction of the actual phenomenon underlying the current, then unknown but, he thought, unambiguously defined by the magnetic reference. In retrospect the name change was unfortunate, not only because the Greek roots alone do not reveal the anode's function any more, but more importantly because as we now know, the Earth's magnetic field direction on which the \"anode\" term is based is subject to reversals whereas the current direction convention on which the \"eisode\" term was based has no reason to change in the future.\nSince the later discovery of the electron, an easier to remember and more durably correct technically although historically false, etymology has been suggested: anode, from the Greek \"anodos\", 'way up', 'the way (up) out of the cell (or other device) for electrons'.\nElectrolytic anode.\nIn electrochemistry, the \"anode\" is where oxidation occurs and is the positive polarity contact in an electrolytic cell. At the anode, anions (negative ions) are forced by the electrical potential to react chemically and give off electrons (oxidation) which then flow up and into the driving circuit. Mnemonics: LEO Red Cat (Loss of Electrons is Oxidation, Reduction occurs at the Cathode), or AnOx Red Cat (Anode Oxidation, Reduction Cathode), or OIL RIG (Oxidation is Loss, Reduction is Gain of electrons), or Roman Catholic and Orthodox (Reduction \u2013 Cathode, anode \u2013 Oxidation), or LEO the lion says GER (Losing electrons is Oxidation, Gaining electrons is Reduction).\nThis process is widely used in metals refining. For example, in copper refining, copper anodes, an intermediate product from the furnaces, are electrolysed in an appropriate solution (such as sulfuric acid) to yield high purity (99.99%) cathodes. Copper cathodes produced using this method are also described as electrolytic copper.\nHistorically, when non-reactive anodes were desired for electrolysis, graphite (called plumbago in Faraday's time) or platinum were chosen. They were found to be some of the least reactive materials for anodes. Platinum erodes very slowly compared to other materials, and graphite crumbles and can produce carbon dioxide in aqueous solutions but otherwise does not participate in the reaction.\nBattery or galvanic cell anode.\nIn a battery or galvanic cell, the anode is the negative electrode from which electrons flow out towards the external part of the circuit. Internally the positively charged cations are flowing away from the anode (even though it is negative and therefore would be expected to attract them, this is due to electrode potential relative to the electrolyte solution being different for the anode and cathode metal/electrolyte systems); but, external to the cell in the circuit, electrons are being pushed out through the negative contact and thus through the circuit by the voltage potential as would be expected. Note: in a galvanic cell, contrary to what occurs in an electrolytic cell, no anions flow to the anode, the internal current being entirely accounted for by the cations flowing away from it (cf drawing).\nBattery manufacturers may regard the negative electrode as the anode, particularly in their technical literature. Though technically incorrect, it does resolve the problem of which electrode is the anode in a secondary (or rechargeable) cell. Using the traditional definition, the anode switches ends between charge and discharge cycles.\nVacuum tube anode.\nIn electronic vacuum devices such as a cathode ray tube, the anode is the positively charged electron collector. In a tube, the anode is a charged positive plate that collects the electrons emitted by the cathode through electric attraction. It also accelerates the flow of these electrons.\nDiode anode.\nIn a semiconductor diode, the anode is the P-doped layer which initially supplies holes to the junction. In the junction region, the holes supplied by the anode combine with electrons supplied from the N-doped region, creating a depleted zone. As the P-doped layer supplies holes to the depleted region, negative dopant ions are left behind in the P-doped layer ('P' for positive charge-carrier ions). This creates a base negative charge on the anode. When a positive voltage is applied to anode of the diode from the circuit, more holes are able to be transferred to the depleted region, and this causes the diode to become conductive, allowing current to flow through the circuit. The terms anode and cathode should not be applied to a Zener diode, since it allows flow in either direction, depending on the polarity of the applied potential (i.e. voltage).\nSacrificial anode.\nIn cathodic protection, a metal anode that is more reactive to the corrosive environment than the metal system to be protected is electrically linked to the protected system. As a result, the metal anode partially corrodes or dissolves instead of the metal system. As an example, an iron or steel ship's hull may be protected by a zinc sacrificial anode, which will dissolve into the seawater and prevent the hull from being corroded. Sacrificial anodes are particularly needed for systems where a static charge is generated by the action of flowing liquids, such as pipelines and watercraft. Sacrificial anodes are also generally used in tank-type water heaters.\nIn 1824 to reduce the impact of this destructive electrolytic action on ships hulls, their fastenings and underwater equipment, the scientist-engineer Humphry Davy developed the first and still most widely used marine electrolysis protection system. Davy installed sacrificial anodes made from a more electrically reactive (less noble) metal attached to the vessel hull and electrically connected to form a cathodic protection circuit.\nA less obvious example of this type of protection is the process of galvanising iron. This process coats iron structures (such as fencing) with a coating of zinc metal. As long as the zinc remains intact, the iron is protected from the effects of corrosion. Inevitably, the zinc coating becomes breached, either by cracking or physical damage. Once this occurs, corrosive elements act as an electrolyte and the zinc/iron combination as electrodes. The resultant current ensures that the zinc coating is sacrificed but that the base iron does not corrode. Such a coating can protect an iron structure for a few decades, but once the protecting coating is consumed, the iron rapidly corrodes.\nIf, conversely, tin is used to coat steel, when a breach of the coating occurs it actually accelerates oxidation of the iron.\nImpressed current anode.\nAnother cathodic protection is used on the impressed current anode. It is made from titanium and covered with mixed metal oxide. Unlike the sacrificial anode rod, the impressed current anode does not sacrifice its structure. This technology uses an external current provided by a DC source to create the cathodic protection. Impressed current anodes are used in larger structures like pipelines, boats, and water heaters.\nRelated antonym.\nThe opposite of an anode is a cathode. When the current through the device is reversed, the electrodes switch functions, so anode becomes cathode, while cathode becomes anode, as long as the reversed current is applied, with the exception of diodes where electrode naming is always based on the forward current direction."}
{"id": "2393", "revid": "1022122966", "url": "https://en.wikipedia.org/wiki?curid=2393", "title": "Analog television", "text": "Analog television is the original television technology that uses analog signals to transmit video and audio. In an analog television broadcast, the brightness, colors and sound are represented by amplitude, phase and frequency of an analog signal.\nAnalog signals vary over a continuous range of possible values which means that electronic noise and interference may be introduced. Thus with analog, a moderately weak signal becomes snowy and subject to interference. In contrast, picture quality from a digital television (DTV) signal remains good until the signal level drops below a threshold where reception is no longer possible or becomes intermittent.\nAnalog television may be wireless (terrestrial television and satellite television) or can be distributed over a cable network as cable television.\nAll broadcast television systems used analog signals before the arrival of DTV. Motivated by the lower bandwidth requirements of compressed digital signals, since the 2010s a digital television transition is proceeding in most countries of the world, with different deadlines for the cessation of analog broadcasts.\nDevelopment.\nThe earliest systems of analog television were mechanical television systems that used spinning disks with patterns of holes punched into the disc to scan an image. A similar disk reconstructed the image at the receiver. Synchronization of the receiver disc rotation was handled through sync pulses broadcast with the image information. Camera systems used similar spinning discs and required intensely bright illumination of the subject for the light detector to work. The reproduced images from these mechanical systems were dim, very low resolution and flickered severely. \nAnalog television did not really begin as an industry until the development of the cathode-ray tube (CRT), which uses a focused electron beam to trace lines across a phosphor coated surface. The electron beam could be swept across the screen much faster than any mechanical disc system, allowing for more closely spaced scan lines and much higher image resolution. Also, far less maintenance was required of an all-electronic system compared to a mechanical spinning disc system. All-electronic systems became popular with households after World War II.\nStandards.\nBroadcasters of analog television encode their signal using different systems. The official systems of transmission are named: A, B, C, D, E, F, G, H, I, K, K1, L, M and N. These systems determine the number of scan lines, frame rate, channel width, video bandwidth, video-audio separation, and so on. The colors in those systems are encoded with one of three color coding schemes: NTSC, PAL, or SECAM, and then use RF modulation to modulate this signal onto a very high frequency (VHF) or ultra high frequency (UHF) carrier wave. Each frame of a television image is composed of scan lines drawn on the screen. The lines are of varying brightness; the whole set of lines is drawn quickly enough that the human eye perceives it as one image. The process repeats and next sequential frame is displayed, allowing the depiction of motion. The analog television signal contains timing and synchronization information so that the receiver can reconstruct a two-dimensional moving image from a one-dimensional time-varying signal.\nThe first commercial television systems were black-and-white; the beginning of color television was in the 1950s.\nA practical television system needs to take luminance, chrominance (in a color system), synchronization (horizontal and vertical), and audio signals, and broadcast them over a radio transmission. The transmission system must include a means of television channel selection.\nAnalog broadcast television systems come in a variety of frame rates and resolutions. Further differences exist in the frequency and modulation of the audio carrier. The monochrome combinations still existing in the 1950s were standardized by the International Telecommunication Union (ITU) as capital letters A through N. When color television was introduced, the chrominance information was added to the monochrome signals in a way that black and white televisions ignore. In this way backward compatibility was achieved.\nThere are three standards for the way the additional color information can be encoded and transmitted. The first was the American NTSC system. The European and Australian PAL and the French and former Soviet Union SECAM standards were developed later and attempt to cure certain defects of the NTSC system. PAL's color encoding is similar to the NTSC systems. SECAM, though, uses a different modulation approach than PAL or NTSC.\nIn principle, all three color encoding systems can be used with any scan line/frame rate combination. Therefore, in order to describe a given signal completely, it's necessary to quote the color system and the broadcast standard as a capital letter. For example, the United States, Canada, Mexico and South Korea use NTSC-M, Japan uses NTSC-J, the UK uses PAL-I, France uses SECAM-L, much of Western Europe and Australia use PAL-B/G, most of Eastern Europe uses SECAM-D/K or PAL-D/K and so on.\nHowever, not all of these possible combinations actually exist. NTSC is currently only used with system M, even though there were experiments with NTSC-A (405 line) in the UK and NTSC-N (625 line) in part of South America. PAL is used with a variety of 625-line standards (B, G, D, K, I, N) but also with the North American 525-line standard, accordingly named PAL-M. Likewise, SECAM is used with a variety of 625-line standards.\nFor this reason, many people refer to any 625/25 type signal as \"PAL\" and to any 525/30 signal as \"NTSC\", even when referring to digital signals; for example, on DVD-Video, which does not contain any analog color encoding, and thus no PAL or NTSC signals at all.\nAlthough a number of different broadcast television systems were in use worldwide, the same principles of operation apply.\nDisplaying an image.\nA cathode-ray tube (CRT) television displays an image by scanning a beam of electrons across the screen in a pattern of horizontal lines known as a raster. At the end of each line the beam returns to the start of the next line; the end of the last line is a link that returns to the top of the screen. As it passes each point the intensity of the beam is varied, varying the luminance of that point. A color television system is identical except that an additional signal known as chrominance controls the color of the spot.\nRaster scanning is shown in a slightly simplified form below.\nWhen analog television was developed, no affordable technology for storing any video signals existed; the luminance signal has to be generated and transmitted at the same time at which it is displayed on the CRT. It is therefore essential to keep the raster scanning in the camera (or other device for producing the signal) in exact synchronization with the scanning in the television.\nThe physics of the CRT require that a finite time interval be allowed for the spot to move back to the start of the next line (\"horizontal retrace\") or the start of the screen (\"vertical retrace\"). The timing of the luminance signal must allow for this.\nThe human eye has a characteristic called Phi phenomenon. Quickly displaying successive scan images will allow the apparent illusion of smooth motion. Flickering of the image can be partially solved using a long persistence phosphor coating on the CRT, so that successive images fade slowly. However, slow phosphor has the negative side-effect of causing image smearing and blurring when there is a large amount of rapid on-screen motion occurring.\nThe maximum frame rate depends on the bandwidth of the electronics and the transmission system, and the number of horizontal scan lines in the image. A frame rate of 25 or 30 hertz is a satisfactory compromise, while the process of interlacing two video fields of the picture per frame is used to build the image. This process doubles the apparent number of video frames per second and further reduces flicker and other defects in transmission.\nOther types of display screens.\nPlasma screens and LCD screens have been used in analog television sets. These types of display screens use lower voltages than older CRT displays. Many dual system television receivers, equipped to receive both analog transmissions and digital transmissions have analog tuner receiving capability and must use a television antenna.\nReceiving signals.\nThe television system for each country will specify a number of television channels within the UHF or VHF frequency ranges. A channel actually consists of two signals: the picture information is transmitted using amplitude modulation on one frequency, and the sound is transmitted with frequency modulation at a frequency at a fixed offset (typically 4.5 to 6\u00a0MHz) from the picture signal.\nThe channel frequencies chosen represent a compromise between allowing enough bandwidth for video (and hence satisfactory picture resolution), and allowing enough channels to be packed into the available frequency band. In practice a technique called vestigial sideband is used to reduce the channel spacing, which would be nearly twice the video bandwidth if pure AM was used.\nSignal reception is invariably done via a superheterodyne receiver: the first stage is a \"tuner\" which selects a television channel and frequency-shifts it to a fixed intermediate frequency (IF). The signal amplifier performs amplification to the IF stages from the microvolt range to fractions of a volt.\nExtracting the sound.\nAt this point the IF signal consists of a video carrier signal at one frequency and the sound carrier at a fixed offset. A demodulator recovers the video signal. Also at the output of the same demodulator is a new frequency modulated sound carrier at the offset frequency. In some sets made before 1948, this was filtered out, and the sound IF of about 22\u00a0MHz was sent to an FM demodulator to recover the basic sound signal. In newer sets, this new carrier at the offset frequency was allowed to remain as \"intercarrier sound\", and it was sent to an FM demodulator to recover the basic sound signal. One particular advantage of intercarrier sound is that when the front panel fine tuning knob is adjusted, the sound carrier frequency does not change with the tuning, but stays at the above-mentioned offset frequency. Consequently, it is easier to tune the picture without losing the sound.\nSo the FM sound carrier is then demodulated, amplified, and used to drive a loudspeaker. Until the advent of the NICAM and MTS systems, television sound transmissions were invariably monophonic.\nStructure of a video signal.\nThe video carrier is demodulated to give a composite video signal; this contains luminance, chrominance and synchronization signals; this is identical to the video signal format used by analog video devices such as VCRs or CCTV cameras. Note that the RF signal modulation is inverted compared to the conventional AM: the minimum video signal level corresponds to maximum carrier amplitude, and vice versa. To ensure good linearity (fidelity), consistent with affordable manufacturing costs of transmitters and receivers, the video carrier is never shut off altogether. When intercarrier sound was invented later in 1948, not completely shutting off the carrier had the side effect of allowing intercarrier sound to be economically implemented.\nEach line of the displayed image is transmitted using a signal as shown above. The same basic format (with minor differences mainly related to timing and the encoding of color) is used for PAL, NTSC, and SECAM television systems. A monochrome signal is identical to a color one, with the exception that the elements shown in color in the diagram (the color burst, and the chrominance signal) are not present.\nThe \"front porch\" is a brief (about 1.5 microsecond) period inserted between the end of each transmitted line of picture and the leading edge of the next line sync pulse. Its purpose was to allow voltage levels to stabilise in older televisions, preventing interference between picture lines. The \"front porch\" is the first component of the horizontal blanking interval which also contains the horizontal sync pulse and the \"back porch\".\nThe \"back porch\" is the portion of each scan line between the end (rising edge) of the horizontal sync pulse and the start of active video. It is used to restore the black level (300 mV) reference in analog video. In signal processing terms, it compensates for the fall time and settling time following the sync pulse.\nIn color television systems such as PAL and NTSC, this period also includes the colorburst signal. In the SECAM system, it contains the reference subcarrier for each consecutive color difference signal in order to set the zero-color reference.\nIn some professional systems, particularly satellite links between locations, the audio is embedded within the back porch of the video signal, to save the cost of renting a second channel.\nMonochrome video signal extraction.\nThe luminance component of a composite video signal varies between 0\u00a0 V and approximately 0.7\u00a0 V above the \"black\" level. In the NTSC system, there is a \"blanking\" signal level used during the front porch and back porch, and a \"black\" signal level 75\u00a0 mV above it; in PAL and SECAM these are identical.\nIn a monochrome receiver the luminance signal is amplified to drive the control grid in the electron gun of the CRT. This changes the intensity of the electron beam and therefore the brightness of the spot being scanned. Brightness and contrast controls determine the DC shift and amplification, respectively.\nColor video signal extraction.\nA color signal conveys picture information for each of the red, green, and blue components of an image (see the article on color space for more information). However, these are not simply transmitted as three separate signals, because: such a signal would not be compatible with monochrome receivers (an important consideration when color broadcasting was first introduced). It would also occupy three times the bandwidth of existing television, requiring a decrease in the number of television channels available. Furthermore, typical problems with the signal transmission (such as differing received signal levels between different colors) would produce unpleasant side effects.\nInstead, the RGB signals are converted into YUV form, where the Y signal represents the lightness and darkness (luminance) of the colors in the image. Because the rendering of colors in this way is the goal of both black and white (monochrome) film and black and white (monochrome) television systems, the Y signal is ideal for transmission as the luminance signal. This ensures a monochrome receiver will display a correct picture in black and white, where a given color is reproduced by a shade of gray that correctly reflects how light or dark the original color is.\nThe U and V signals are \"color difference\" signals. The U signal is the difference between the B signal and the Y signal, also known as B minus Y (B-Y), and the V signal is the difference between the R signal and the Y signal, also known as R minus Y (R-Y). The U signal then represents how \"purplish-blue\" or its complementary color \"yellowish-green\" the color is, and the V signal how \"purplish-red\" or it's complementary \"greenish-cyan\" it is. The advantage of this scheme is that the U and V signals are zero when the picture has no color content. Since the human eye is more sensitive to detail in luminance than in color, the U and V signals can be transmitted in a relatively lossy (specifically: bandwidth-limited) way with acceptable results.\nIn the receiver, a single demodulator can extract an additive combination of U plus V. An example is the X demodulator used in the X/Z demodulation system. In that same system, a second demodulator, the Z demodulator, also extracts an additive combination of U plus V, but in a different ratio. The X and Z color difference signals are further matrixed into three color difference signals, (R-Y), (B-Y), and (G-Y). The combinations of usually two, but sometimes three demodulators were:\nIn the end, further matrixing of the above color-difference signals c through f yielded the three color-difference signals, (R-Y), (B-Y), and (G-Y).\nThe R, G, B signals in the receiver needed for the display device (CRT, Plasma display, or LCD display) are electronically derived by matrixing as follows: R is the additive combination of (R-Y) with Y, G is the additive combination of (G-Y) with Y, and B is the additive combination of (B-Y) with Y. All of this is accomplished electronically. It can be seen that in the combining process, the low-resolution portion of the Y signals cancel out, leaving R, G, and B signals able to render a low-resolution image in full color. However, the higher resolution portions of the Y signals do not cancel out, and so are equally present in R, G, and B, producing the higher definition (higher resolution) image detail in monochrome, although it appears to the human eye as a full-color and full resolution picture.\nIn the NTSC and PAL color systems, U and V are transmitted by using quadrature amplitude modulation of a subcarrier. This kind of modulation applies two independent signals to one subcarrier, with the idea that both signals will be recovered independently at the receiving end. Before transmission, the subcarrier itself is removed from the active (visible) portion of the video, and moved, in the form of a burst, to the horizontal blanking portion, which is not directly visible on the screen. (More about the burst below.)\nFor NTSC, the subcarrier is a 3.58\u00a0 MHz sine wave. For the PAL system it is a 4.43\u00a0 MHz sine wave. After the above-mentioned quadrature amplitude modulation of the subcarrier, subcarrier sidebands are produced, and the subcarrier itself is filtered out of the visible portion of the video, since it is the subcarrier sidebands that carry all of the U and V information, and the subcarrier itself carries no information.\nThe resulting subcarrier sidebands are also known as \"chroma\" or \"chrominance\". Physically, this chrominance signal is a 3.58\u00a0 MHz (NTSC) or 4.43\u00a0 MHz (PAL) sine wave which, in response to changing U and V values, changes phase as compared to the subcarrier, and also changes amplitude.\nAs it turns out, the chroma amplitude (when considered together with the Y signal) represents the approximate saturation of a color, and the chroma phase against the subcarrier as reference approximately represents the hue of the color. For particular test colors found in the test color bar pattern, exact amplitudes and phases are sometimes defined for test and troubleshooting purposes only.\nAlthough in response to changing U and V values, the chroma sinewave changes phase with respect to the subcarrier, it's not correct to say that the subcarrier is simply \"phase modulated\". That is because a single sine wave U test signal with QAM produces only one pair of sidebands, whereas real phase modulation under the same test conditions would produce multiple sets of sidebands occupying a more frequency spectrum.\nIn NTSC, the chrominance sine wave has the same average frequency as the subcarrier frequency. But a spectrum analyzer instrument shows that, for transmitted chrominance, the frequency component at the subcarrier frequency is actually zero energy, verifying that the subcarrier was indeed removed before transmission.\nThese sideband frequencies are within the luminance signal band, which is why they are called \"subcarrier\" sidebands instead of simply \"carrier\" sidebands. Their exact frequencies were chosen such that (for NTSC), they are midway between two harmonics of the frame repetition rate, thus ensuring that the majority of the power of the luminance signal does not overlap with the power of the chrominance signal.\nIn the British PAL (D) system, the actual chrominance center frequency, with equal lower and upper sidebands, is 4.43361875\u00a0 MHz, a direct multiple of the scan rate frequency. This frequency was chosen to minimize the chrominance beat interference pattern that would be visible in areas of high color saturation in the transmitted picture.\nAt certain times, the chrominance signal represents only the U signal, and 70 nanoseconds (NTSC) later, the chrominance signal represents only the V signal. (This is the nature of the quadrature amplitude modulation process that created the chrominance signal.) About 70 nanoseconds later still, -U, and another 70 nanoseconds, -V.\nSo to extract U, a synchronous demodulator is utilized, which uses the subcarrier to briefly gate (sample) the chroma every 280 nanoseconds, so that the output is only a train of discrete pulses, each having an amplitude that is the same as the original U signal at the corresponding time. In effect, these pulses are discrete-time analog samples of the U signal. The pulses are then low-pass filtered so that the original analog continuous-time U signal is recovered. For V, a 90-degree shifted subcarrier briefly gates the chroma signal every 280 nanoseconds, and the rest of the process is identical to that used for the U signal.\nGating at any other time than those times mentioned above will yield an additive mixture of any two of U, V, -U, or -V. One of these \"off-axis\" (that is, of the U and V axis) gating methods is called I/Q demodulation. Another much more popular \"off-axis\" scheme was the X/Z demodulation system. Further matrixing recovered the original U and V signals. This scheme was actually the most popular demodulator scheme throughout the 60s.\nThe above process uses the subcarrier. But as previously mentioned, it was deleted before transmission, and only the chroma is transmitted. Therefore, the receiver must reconstitute the subcarrier. For this purpose, a short burst of the subcarrier, known as the color burst, is transmitted during the back porch (re-trace blanking period) of each scan line. A subcarrier oscillator in the receiver locks onto this signal (see phase-locked loop) to achieve a phase reference, resulting in the oscillator producing the reconstituted subcarrier.\nNTSC uses this process unmodified. Unfortunately, this often results in poor color reproduction due to phase errors in the received signal, caused sometimes by multipath, but mostly by poor implementation at the studio end. With the advent of solid-state receivers, cable TV, and digital studio equipment for conversion to an over-the-air analog signal, these NTSC problems have been largely fixed, leaving operator error at the studio end as the sole color rendition weakness of the NTSC system. In any case, the PAL D (delay) system mostly corrects these kinds of errors by reversing the phase of the signal on each successive line, and averaging the results over pairs of lines. This process is achieved by the use of a 1H (where H = horizontal scan frequency) duration delay line. (A typical circuit used with this device converts the low-frequency color signal to ultrasound and back again). Phase shift errors between successive lines are therefore canceled out and the wanted signal amplitude is increased when the two in-phase (coincident) signals are re-combined.\nNTSC is more spectrum efficient than PAL, giving more picture detail for a given bandwidth. This is because sophisticated comb filters in receivers are more effective with NTSC's 4 field color phase cadence compared to PAL's 8 field cadence. However, in the end, the larger channel width of most PAL systems in Europe still give their PAL systems the edge in transmitting more picture detail.\nIn the SECAM television system, U and V are transmitted on \"alternate\" lines, using simple frequency modulation of two different color subcarriers.\nIn some analog color CRT displays, starting in 1956, the brightness control signal (luminance) is fed to the cathode connections of the electron guns, and the color difference signals (chrominance signals) are fed to the control grids connections. This simple CRT matrix mixing technique was replaced in later solid state designs of signal processing with the original matrixing method used in the 1954 and 1955 color TV receivers.\nSynchronization.\nSynchronizing pulses added to the video signal at the end of every scan line and video frame ensure that the sweep oscillators in the receiver remain locked in step with the transmitted signal so that the image can be reconstructed on the receiver screen.\nA \"sync separator\" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync.\nHorizontal synchronization.\nThe horizontal synchronization pulse (\"horizontal sync\", or \"HSync\"), separates the scan lines. The horizontal sync signal is a single short pulse which indicates the start of every line. The rest of the scan line follows, with the signal ranging from 0.3\u00a0V (black) to 1\u00a0V (white), until the next horizontal or vertical synchronization pulse.\nThe format of the horizontal sync pulse varies. In the 525-line NTSC system it is a 4.85\u00a0\u03bcs-long pulse at 0\u00a0V. In the 625-line PAL system the pulse is 4.7\u00a0\u03bcs synchronization pulse at 0\u00a0V . This is lower than the amplitude of any video signal (\"blacker than black\") so it can be detected by the level-sensitive \"sync stripper\" circuit of the receiver.\nVertical synchronization.\nVertical synchronization (also called vertical sync or VSync) separates the video fields. In PAL and NTSC, the vertical sync pulse occurs within the vertical blanking interval. The vertical sync pulses are made by prolonging the length of HSYNC pulses through almost the entire length of the scan line.\nThe \"vertical sync\" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or midway through).\nThe format of such a signal in 525-line NTSC is:\nEach pre- or post- equalizing pulse consists in half a scan line of black signal: 2\u00a0\u03bcs at 0\u00a0V, followed by 30\u00a0\u03bcs at 0.3\u00a0V.\nEach long sync pulse consists of an equalizing pulse with timings inverted: 30\u00a0\u03bcs at 0\u00a0 V, followed by 2\u00a0\u03bcs at 0.3\u00a0 V.\nIn video production and computer graphics, changes to the image are often kept in step with the vertical synchronization pulse to avoid visible discontinuity of the image. Since the frame buffer of a computer graphics display imitates the dynamics of a cathode-ray display, if it is updated with a new image while the image is being transmitted to the display, the display shows a mishmash of both frames, producing a page tearing artifact partway down the image.\nVertical synchronization eliminates this by timing frame buffer fills to coincide with the vertical blanking interval, thus ensuring that only whole frames are seen on-screen. Software such as video games and computer-aided design (CAD) packages often allow vertical synchronization as an option, because it delays the image update until the vertical blanking interval. This produces a small penalty in latency because the program has to wait until the video controller has finished transmitting the image to the display before continuing. Triple buffering reduces this latency significantly.\nTwo-timing intervals are defined\u00a0\u2013 the \"front porch\" between the end of the displayed video and the start of the sync pulse, and the \"back porch\" after the sync pulse and before the displayed video. These and the sync pulse itself are called the \"horizontal blanking\" (or \"retrace\") \"interval\" and represent the time that the electron beam in the CRT is returning to the start of the next display line.\nHorizontal and vertical hold.\nAnalog television receivers and composite monitors often provide manual controls to adjust horizontal and vertical timing.\nThe sweep (or deflection) oscillators were designed to run without a signal from the television station (or VCR, computer, or other composite video source). This provides a blank canvas, similar to today's \"CHECK SIGNAL CABLE\" messages on monitors: it allows the television receiver to display a raster to confirm the basic operation of the set's most fundamental circuits, and to allow an image to be presented during antenna placement. With sufficient signal strength, the receiver's sync separator circuit would split timebase pulses from the incoming video and use them to reset the horizontal and vertical oscillators at the appropriate time to synchronize with the signal from the station.\nThe free-running oscillation of the horizontal circuit is especially critical, as the horizontal deflection circuits typically power the flyback transformer (which provides acceleration potential for the CRT) as well as the filaments for the high voltage rectifier tube and sometimes the filament(s) of the CRT itself. Without the operation of the horizontal oscillator and output stages, for virtually every analog television receiver since the 1940s, there will be absolutely no illumination of the CRT's face.\nThe lack of precision timing components in early television receivers meant that the timebase circuits occasionally needed manual adjustment.\nIf their free-run frequencies were too far from the actual line and field rates, the circuits would not be able to follow the incoming sync signals.\nLoss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.\nThe adjustment took the form of \"horizontal hold\" and \"vertical hold\" controls, usually on the front panel along with other common controls. These adjusted the free-run frequencies of the corresponding timebase oscillators.\nProperly working, adjusting a horizontal or vertical hold should cause the picture to almost \"snap\" into place on the screen; this is called \"sync lock\". A slowly rolling vertical picture demonstrates that the vertical oscillator is nearly synchronized with the television station but is not locking to it, often due to a weak signal or a failure in the sync separator stage not resetting the oscillator. Sometimes, the black interval bar will almost stop at the right place, again indicating a fault in sync separation is not properly resetting the vertical oscillator.\nHorizontal sync errors cause the image to be torn diagonally and repeated across the screen as if it were wrapped around a screw or a barber's pole; the greater the error, the more \"copies\" of the image will be seen at once wrapped around the barber pole. Given the importance of the horizontal sync circuit as a power supply to many subcircuits in the receiver, they may begin to malfunction as well; and horizontal output components that were designed to work together in a resonant circuit may become damaged.\nIn the earliest electronic television receivers (1930s-1950s), the time base for the sweep oscillators was generally derived from RC circuits based on carbon resistors and paper capacitors. After turning on the receiver, the vacuum tubes in the set would warm up and the oscillators would begin to run, allowing a watchable picture. Resistors were generally simple pieces of carbon inside a Bakelite enclosure, and the capacitors were usually alternating layers of paper and aluminum foil inside cardboard tubes sealed with bee's wax. Moisture ingress (from ambient air humidity) as well as thermal instability of these components affected their electrical values. As the heat from the tubes and the electrical currents passing through the RC circuits warmed them up, the electrical properties of the RC timebase would shift, causing the oscillators to drift in frequency to a point that they could no longer be synchronized with the received pulses coming from the TV station via the sync separator circuit, causing tearing (horizontal) or rolling (vertical).\nHermetically-sealed passive components and cooler-running semiconductors as active components gradually improved reliability to the point where the horizontal hold was moved to the rear of the set first, and the vertical hold control (due to the longer period in the RC constant) persisted as a front panel control well into the 1970s as the consistency of larger-value capacitors increased.\nBy the early 1980s the efficacy of the synchronization circuits, plus the inherent stability of the sets' oscillators, had been improved to the point where these controls were no longer necessary. Integrated Circuits which eliminated the horizontal hold control were starting to appear as early as 1969.\nThe final generations of analog television receivers (most TV sets with internal on-screen displays to adjust brightness, color, tint, contrast) used \"TV-set-on-a-chip\" designs where the receiver's timebases were divided down from crystal oscillators, usually based on the 3.58\u00a0 MHz NTSC colorburst reference. PAL and SECAM receivers were similar though operating at different frequencies. With these sets, adjustment of the free-running frequency of either sweep oscillator was either physically impossible (being derived inside the integrated circuit) or possibly through a hidden service mode typically offering only NTSC/PAL frequency switching, accessible through the On-Screen Display's menu system.\nHorizontal and Vertical Hold controls were rarely used in CRT-based computer monitors, as the quality and consistency of components were quite high by the advent of the computer age, but might be found on some composite monitors used with the 1970s-1980s home or personal computers.\nThere is no equivalent in modern television systems.\nOther technical information.\nComponents of a television system.\nA typical analog monochrome television receiver is based around the block diagram shown below:\nThe tuner is the object which \"plucks\" the television signals out of the air, with the aid of an antenna. There are two types of tuners in analog television, VHF and UHF tuners. The VHF tuner selects the VHF television frequency. This consists of a 4\u00a0 MHz video bandwidth and a 2\u00a0 MHz audio bandwidth. It then amplifies the signal and converts it to a 45.75\u00a0 MHz Intermediate Frequency (IF) amplitude-modulated picture and a 41.25\u00a0 MHz IF frequency-modulated audio carrier.\nThe IF amplifiers are centered at 44\u00a0 MHz for optimal frequency transference of the audio and frequency carriers. What centers this frequency is the IF transformer. They are designed for a certain amount of bandwidth to encompass the audio and video. It depends on the number of stages (the amplifier between the transformers). Most of the early television sets (1939\u201345) used 4 stages with specially designed video amplifier tubes (the type 1852/6AC7). In 1946 the RCA presented a new innovation in television; the RCA 630TS. Instead of using the 1852 octal tube, it uses the 6AG5 7-pin miniature tube. It still had 4 stages, but it was 1/2 the size. Soon all of the manufactures followed RCA and designed better IF stages. They developed higher amplification tubes, and lower stage counts with more amplification. When the tube era came to an end in the mid-70s, they had shrunk the IF stages down to 1-2 (depending on the set) and with the same amplification as the 4 stage, 1852 tube sets. Like radio, television has Automatic Gain Control (AGC). This controls the gain of the IF amplifier stages and the tuner. More of this will be discussed below.\nThe video amp and output amplifier consist of a low linear pentode or a high powered transistor. The video amp and output stage separate the 45.75\u00a0 MHz from the 41.25\u00a0 MHz. It simply uses a diode to detect the video signal. But the frequency-modulated audio is still in the video. Since the diode only detects AM signals, the FM audio signal is still in the video in the form of a 4.5\u00a0 MHz signal. There are two ways to attach this problem, and both of them work. We can detect the signal before it enters into the video amplifier, or do it after the audio amplifier. Many television sets (1946 to late 1960s) used the after video amplification method, but of course, there is the occasional exception. Many of the later set late (1960s-now) use the before-the-video amplifier way. In some of the early television sets (1939\u201345) used its own separate tuner, so there was no need for a detection stage next to the amplifier. After the video detector, the video is amplified and sent to the sync separator and then to the picture tube.\nAt this point, we will now look at the audio section. The means of detection of the audio signal is by a 4.5\u00a0 MHz traps coil/transformer. After that, it then goes to a 4.5\u00a0 MHz amplifier. This amplifier prepares the signal for the 4.5Mhz detector. It then goes through a 4.5\u00a0 MHz IF transformer to the detector. In television, there are 2 ways of detecting FM signals. One way is by the ratio detector. This is simple but very hard to align. The next is a relatively simple detector. This is the quadrature detector. It was invented in 1954. The first tube designed for this purpose was the 6BN6 type. It is easy to align and simple in circuitry. It was such a good design that it is still being used today in the Integrated circuit form. After the detector, it goes to the audio amplifier.\nThe next part is the sync separator/clipper. This also does more than what is in its name. It also forms the AGC voltage, as previously stated. This sync separator turns the video into a signal that the horizontal and vertical oscillators can use to keep in sync with the video.\nThe horizontal and vertical oscillators form the raster on the CRT. They are kept in sync by the sync separator. There are many ways to create these oscillators. The first one is the earliest of its kind is the thyratron oscillator. Although it is known to drift, it makes a perfect sawtooth wave. This sawtooth wave is so good that no linearity control is needed. This oscillator was for the electrostatic deflection CRTs. It found some purpose for the electromagnetically deflected CRTs. The next oscillator is the blocking oscillator. It uses a transformer to create a sawtooth wave. This was only used for a brief time period and never was very popular after the beginning. The next oscillator is the multivibrator. This oscillator was probably the most successful. It needed more adjustment than the other oscillators, but it is very simple and effective. This oscillator was so popular that it was used from the early 1950s until today.\nThe oscillator amplifier is sorted into two categories. The vertical amplifier directly drives the yoke. There is not much to this. It is similar to an audio amplifier. The horizontal oscillator is a different situation. The oscillator must supply the high voltage and the yoke power. This requires a high power flyback transformer, and a high powered tube or transistor. This is a problematic section for CRT televisions because it has to handle high power.\nSync separator.\nImage synchronization is achieved by transmitting negative-going pulses; in a composite video signal of 1-volt amplitude, these are approximately 0.3\u00a0 V below the \"black level\". The \"horizontal sync\" signal is a single short pulse which indicates the start of every line. Two-timing intervals are defined\u00a0\u2013 the \"front porch\" between the end of the displayed video and the start of the sync pulse, and the \"back porch\" after the sync pulse and before the displayed video. These and the sync pulse itself are called the \"horizontal blanking\" (or \"retrace\") \"interval\" and represent the time that the electron beam in the CRT is returning to the start of the next display line.\nThe \"vertical sync\" signal is a series of much longer pulses, indicating the start of a new field. The sync pulses occupy the whole of line interval of a number of lines at the beginning and end of a scan; no picture information is transmitted during vertical retrace. The pulse sequence is designed to allow horizontal sync to continue during vertical retrace; it also indicates whether each field represents even or odd lines in interlaced systems (depending on whether it begins at the start of a horizontal line, or midway through).\nIn the television receiver, a \"sync separator\" circuit detects the sync voltage levels and sorts the pulses into horizontal and vertical sync.\nLoss of horizontal synchronization usually resulted in an unwatchable picture; loss of vertical synchronization would produce an image rolling up or down the screen.\nCounting sync pulses, a video line selector picks a selected line from a TV signal, used for teletext, on-screen displays, station identification logos as well as in the industry when cameras were used as a sensor.\nTimebase circuits.\nIn an analog receiver with a CRT display sync pulses are fed to horizontal and vertical \"timebase\" circuits (commonly called \"sweep circuits\" in the United States), each consisting of an oscillator and an amplifier. These generate modified sawtooth and parabola current waveforms to scan the electron beam in a linear way. The waveform shapes are necessary to make up for the distance variations from the electron beam source and the screen surface. The oscillators are designed to free-run at frequencies very close to the field and line rates, but the sync pulses cause them to reset at the beginning of each scan line or field, resulting in the necessary synchronization of the beam sweep with the originating signal. The output waveforms from the timebase amplifiers are fed to the horizontal and vertical \"deflection coils\" wrapped around the CRT tube. These coils produce magnetic fields proportional to the changing current, and these deflect the electron beam across the screen.\nIn the 1950s, the power for these circuits was derived directly from the mains supply.\nA simple circuit consisted of a series voltage dropper resistance and a rectifier valve (tube) or semiconductor diode. This avoided the cost of a large high voltage mains supply (50 or 60\u00a0Hz) transformer. This type of circuit was used for the thermionic valve (vacuum tube) technology. It was inefficient and produced a lot of heat which led to premature failures in the circuitry. Although failure was common, it was easily repairable.\nIn the 1960s, semiconductor technology was introduced into timebase circuits. During the late 1960s in the UK, synchronous (with the scan line rate) power generation was introduced into solid state receiver designs. These had very complex circuits in which faults were difficult to trace, but had very efficient use of power.\nIn the early 1970s AC mains (50 or 60\u00a0Hz), and line timebase (15,625\u00a0Hz), thyristor based switching circuits were introduced. In the UK use of the simple (50\u00a0 Hz) types of power, circuits were discontinued. The reason for design changes arose from the electricity supply contamination problems arising from EMI, and supply loading issues due to energy being taken from only the positive half cycle of the mains supply waveform.\nCRT flyback power supply.\nMost of the receiver's circuitry (at least in transistor- or IC-based designs) operates from a comparatively low-voltage DC power supply. However, the anode connection for a cathode-ray tube requires a very high voltage (typically 10\u201330\u00a0kV) for correct operation.\nThis voltage is not directly produced by the main power supply circuitry; instead, the receiver makes use of the circuitry used for horizontal scanning. Direct current (DC), is switched through the line output transformer, and alternating current (AC) is induced into the scan coils. At the end of each horizontal scan line the magnetic field, which has built up in both transformer and scan coils by the current, is a source of latent electromagnetic energy. This stored collapsing magnetic field energy can be captured. The reverse flow, short duration, (about 10% of the line scan time) current from both the line output transformer and the horizontal scan coil is discharged again into the primary winding of the flyback transformer by the use of a rectifier which blocks this negative reverse emf. A small value capacitor is connected across the scan switching device. This tunes the circuit inductances to resonate at a much higher frequency. This slows down (lengthens) the flyback time from the extremely rapid decay rate that would result if they were electrically isolated during this short period. One of the secondary windings on the flyback transformer then feeds this brief high voltage pulse to a Cockcroft\u2013Walton generator design voltage multiplier. This produces the required EHT supply. A flyback converter is a power supply circuit operating on similar principles.\nA typical modern design incorporates the flyback transformer and rectifier circuitry into a single unit with a captive output lead, (known as a diode split line output transformer or an Integrated High Voltage Transformer (IHVT)), so that all high-voltage parts are enclosed. Earlier designs used a separate line output transformer and a well-insulated high voltage multiplier unit. The high frequency (15\u00a0kHz or so) of the horizontal scanning allows reasonably small components to be used.\nTransition to digital.\nIn many countries, over-the-air broadcast television of analog audio and analog video signals has been discontinued, to allow the re-use of the television broadcast radio spectrum for other services such as datacasting and subchannels.\nThe first country to make a wholesale switch to digital over-the-air (terrestrial television) broadcasting was Luxembourg in 2006, followed later in 2006 by the Netherlands; in 2007 by Finland, Andorra, Sweden and Switzerland; in 2008 by Belgium (Flanders) and Germany; in 2009 by the United States (high power stations), southern Canada, the Isle of Man, Norway, and Denmark. In 2010, Belgium (Wallonia), Spain, Wales, Latvia, Estonia, the Channel Islands, San Marino, Croatia, and Slovenia; in 2011 Israel, Austria, Monaco, Cyprus, Japan (excluding Miyagi, Iwate, and Fukushima prefectures), Malta and France; in 2012 the Czech Republic, Arab World, Taiwan, Portugal, Japan (including Miyagi, Iwate, and Fukushima prefectures), Serbia, Italy, Canada, Mauritius, the United Kingdom, the Republic of Ireland, Lithuania, Slovakia, Gibraltar, and South Korea; in 2013, the Republic of Macedonia, Poland, Bulgaria, Hungary, Australia, and New Zealand, completed the transition. The United Kingdom made the transition to digital television between 2008 and 2012, with the exception of Barrow-in-Furness, which made the switch over in 2007. The first digital TV-only area in the United Kingdom was Ferryside in Carmarthenshire.\nThe Digital television transition in the United States for high-powered transmission was completed on 12 June 2009, the date that the Federal Communications Commission (FCC) set. Almost two million households could no longer watch television because they had not prepared for the transition. The switchover had been delayed by the DTV Delay Act. While the majority of the viewers of over-the-air broadcast television in the U.S. watch full-power stations (which number about 1800), there are three other categories of television stations in the U.S.: low-power broadcasting stations, class A stations, and television translator stations. They were given later deadlines. In broadcasting, whatever happens in the United States also influences southern Canada and northern Mexico because those areas are covered by television stations in the U.S.\nIn Japan, the switch to digital began in northeastern Ishikawa Prefecture on 24 July 2010 and ended in 43 of the country's 47 prefectures (including the rest of Ishikawa) on 24 July 2011, but in Fukushima, Iwate, and Miyagi prefectures, the conversion was delayed to 31 March 2012, due to complications from the 2011 T\u014dhoku earthquake and tsunami and its related nuclear accidents.\nIn Canada, most of the larger cities turned off analog broadcasts on 31 August 2011.\nChina is scheduled to end analog broadcasting between 2015 and 2018.\nBrazil switched to digital television on 2 December 2007 in its major cities. It is now estimated that Brazil will end analog broadcasting in 2023.\nIn Malaysia, the Malaysian Communications &amp; Multimedia Commission (MCMC) advertised for tender bids to be submitted in the third quarter of 2009 for the 470 through 742\u00a0 MHz UHF allocation, to enable Malaysia's broadcast system to move into DTV. The new broadcast band allocation would result in Malaysia's having to build an infrastructure for all broadcasters, using a single digital terrestrial transmission/television broadcast (DTTB) channel. Large portions of Malaysia are covered by television broadcasts from Singapore, Thailand, Brunei, and Indonesia (from Borneo and Batam). Starting from 1 November 2019, all regions in Malaysia were no longer using the analog system after the states of Sabah and Sarawak finally turned it off on 31 October 2019.\nIn Singapore, digital television under DVB-T2 began on 16 December 2013. The switchover was delayed many times until analog TV was switched off at midnight on 2 January 2019.\nIn the Philippines, the National Telecommunications Commission required all broadcasting companies to end analog broadcasting on 31 December 2015 at 11:59\u00a0p.m. Due to delay of the release of the implementing rules and regulations for digital television broadcast, the target date was moved to 2020. Full digital broadcast is expected in 2021 and all of the analog TV services should be shut down by the end of 2023.\nIn the Russian Federation, the Russian Television and Radio Broadcasting Network (RTRS) disabled analog broadcasting of federal channels in five stages, shutting down broadcasting in multiple federal subjects at each stage. The first region to have analog broadcasting disabled was Tver Oblast on 3 December 2018, and the switchover was completed on 14 October 2019. During the transition, DVB-T2 receivers and monetary compensations for purchasing of terrestrial or satellite digital TV reception equipment were provided to disabled people, World War II veterans, certain categories of retirees and households with income per member below living wage."}
{"id": "2395", "revid": "25131418", "url": "https://en.wikipedia.org/wiki?curid=2395", "title": "April 11", "text": ""}
{"id": "2396", "revid": "35064546", "url": "https://en.wikipedia.org/wiki?curid=2396", "title": "Adhesive", "text": "Adhesive, also known as glue, cement, mucilage, or paste, is any non-metallic substance applied to one or both surfaces of two separate items that binds them together and resists their separation.\nThe use of adhesives offers certain advantages over other binding techniques such as sewing, mechanical fastenings, or welding. These include the ability to bind different materials together, the more efficient distribution of stress across a joint, the cost-effectiveness of an easily mechanized process, and greater flexibility in design. Disadvantages of adhesive use include decreased stability at high temperatures, relative weakness in bonding large objects with a small bonding surface area, and greater difficulty in separating objects during testing. Adhesives are typically organized by the method of adhesion followed by \"reactive\" or \"non-reactive\", a term which refers to whether the adhesive chemically reacts in order to harden. Alternatively, they can be organized either by their starting physical phase or whether their raw stock is of natural or synthetic origin.\nAdhesives may be found naturally or produced synthetically. The earliest human use of adhesive-like substances was approximately 200,000 years ago, when Neanderthals produced tar from the dry distillation of birch bark for use in binding stone tools to wooden handles. The first references to adhesives in literature appeared in approximately 2000 BC. The Greeks and Romans made great contributions to the development of adhesives. In Europe, glue was not widely used until the period AD 1500\u20131700. From then until the 1900s increases in adhesive use and discovery were relatively gradual. Only since the last century has the development of synthetic adhesives accelerated rapidly, and innovation in the field continues to the present.\nHistory.\nThe earliest known use of adhesives was discovered in central Italy when two stone flakes partially covered with birch-bark tar and a third uncovered stone from the Middle Pleistocene era (circa 200,000 years ago) were found. This is thought to be the oldest discovered human use of tar-hafted stones.\nThe birch-bark-tar adhesive is a simple, one-component adhesive. A study from 2019 showed that birch tar production can be a very simple process - merely involving the burning of birch bark near smooth vertical surfaces in open air conditions. Although sticky enough, plant-based adhesives are brittle and vulnerable to environmental conditions. The first use of compound adhesives was discovered in Sibudu, South Africa. Here, 70,000-year-old stone segments that were once inserted in axe hafts were discovered covered with an adhesive composed of plant gum and red ochre (natural iron oxide) as adding ochre to plant gum produces a stronger product and protects the gum from disintegrating under wet conditions. The ability to produce stronger adhesives allowed middle Stone Age humans to attach stone segments to sticks in greater variations, which led to the development of new tools.\nMore recent examples of adhesive use by prehistoric humans have been found at the burial sites of ancient tribes. Archaeologists studying the sites found that approximately 6,000 years ago the tribesmen had buried their dead together with food found in broken clay pots repaired with tree resins. Another investigation by archaeologists uncovered the use of bituminous cements to fasten ivory eyeballs to statues in Babylonian temples dating to approximately 4000 BC.\nIn 2000, a paper revealed the discovery of a 5,200-year-old man nicknamed the \"Tyrolean Iceman\" or \"\u00d6tzi\", who was preserved in a glacier near the Austria-Italy border. Several of his belongings were found with him including two arrows with flint arrowheads and a copper hatchet, each with evidence of organic glue used to connect the stone or metal parts to the wooden shafts. The glue was analyzed as pitch, which requires the heating of tar during its production. The retrieval of this tar requires a transformation of birch bark by means of heat, in a process known as pyrolysis.\nThe first references to adhesives in literature appeared in approximately 2000 BC. Further historical records of adhesive use are found from the period spanning 1500\u20131000 BC. Artifacts from this period include paintings depicting wood gluing operations and a casket made of wood and glue in King Tutankhamun's tomb. Other ancient Egyptian artifacts employ animal glue for bonding or lamination. Such lamination of wood for bows and furniture is thought to have extended their life and was accomplished using casein (milk protein)-based glues. The ancient Egyptians also developed starch-based pastes for the bonding of papyrus to clothing and a plaster of Paris-like material made of calcined gypsum.\nFrom AD 1 to 500 the Greeks and Romans made great contributions to the development of adhesives. Wood veneering and marquetry were developed, the production of animal and fish glues refined, and other materials utilized. Egg-based pastes were used to bond gold leaves incorporated various natural ingredients such as blood, bone, hide, milk, cheese, vegetables, and grains. The Greeks began the use of slaked lime as mortar while the Romans furthered mortar development by mixing lime with volcanic ash and sand. This material, known as pozzolanic cement, was used in the construction of the Roman Colosseum and Pantheon. The Romans were also the first people known to have used tar and beeswax as caulk and sealant between the wooden planks of their boats and ships.\nIn Central Asia, the rise of the Mongols in approximately AD 1000 can be partially attributed to the good range and power of the bows of Genghis Khan's hordes. These bows were made of a bamboo core, with horn on the belly (facing towards the archer) and sinew on the back, bound together with animal glue.\nIn Europe, glue fell into disuse until the period AD 1500\u20131700. At this time, world-renowned cabinet and furniture makers such as Thomas Chippendale and Duncan Phyfe began to use adhesives to hold their products together. In 1690, the first commercial glue plant was established in The Netherlands. This plant produced glues from animal hides. In 1750, the first British glue patent was issued for fish glue. The following decades of the next century witnessed the manufacture of casein glues in German and Swiss factories. In 1876, the first US patent (number 183,024) was issued to the Ross brothers for the production of casein glue.\nThe first US postage stamps used starch-based adhesives when issued in 1847. The first US patent (number 61,991) on dextrin (a starch derivative) adhesive was issued in 1867.\nNatural rubber was first used as material for adhesives starting in 1830, which marked the starting point of the modern adhesive. In 1862, a British patent (number 3288) was issued for the plating of metal with brass by electrodeposition to obtain a stronger bond to rubber. The development of the automobile and the need for rubber shock mounts required stronger and more durable bonds of rubber and metal. This spurred the development of cyclized rubber treated in strong acids. By 1927, this process was used to produce solvent-based thermoplastic rubber cements for metal to rubber bonding.\nNatural rubber-based sticky adhesives were first used on a backing by Henry Day (US Patent 3,965) in 1845. Later these kinds of adhesives were used in cloth backed surgical and electric tapes. By 1925, the pressure-sensitive tape industry was born.\nToday, sticky notes, Scotch tape, and other tapes are examples of PSA (pressure-sensitive adhesives).\nA key step in the development of synthetic plastics was the introduction of a thermoset plastic known as Bakelite phenolic in 1910. Within two years, phenolic resin was applied to plywood as a coating varnish. In the early 1930s, phenolics gained importance as adhesive resins.\nThe 1920s, 1930s, and 1940s witnessed great advances in the development and production of new plastics and resins due to the First and Second World Wars. These advances greatly improved the development of adhesives by allowing the use of newly developed materials that exhibited a variety of properties. With changing needs and ever evolving technology, the development of new synthetic adhesives continues to the present. However, due to their low cost, natural adhesives are still more commonly used.\nEconomic importance.\nIn the course of time and during their development, adhesives have gained a stable position in an increasing number of production processes. There is hardly any product in our surroundings that does not contain at least one adhesive\u2014be it the label on a beverage bottle, protective coatings on automobiles, or profiles on window frames. Market researchers forecasted a turnover of almost US$50 billion for the global adhesives market in 2019. In particular, the economic development of emerging countries such as China, India, Russia, and Brazil will cause a rising demand for adhesives in the future.\nTypes.\nAdhesives are typically organized by the method of adhesion. These are then organized into reactive and non-reactive adhesives, which refers to whether the adhesive chemically reacts in order to harden. Alternatively they can be organized by whether the raw stock is of natural, or synthetic origin, or by their starting physical phase.\nBy reactiveness.\nNon-reactive.\nDrying.\nThere are two types of adhesives that harden by drying: \"solvent-based adhesives\" and \"polymer dispersion adhesives\", also known as \"emulsion adhesives\".\nSolvent-based adhesives are a mixture of ingredients (typically polymers) dissolved in a solvent. White glue, contact adhesives and rubber cements are members of the \"drying adhesive\" family. As the solvent evaporates, the adhesive hardens. Depending on the chemical composition of the adhesive, they will adhere to different materials to greater or lesser degrees.\nPolymer dispersion adhesives are milky-white dispersions often based on polyvinyl acetate (PVAc). They are used extensively in the woodworking and packaging industries. They are also used with fabrics and fabric-based components, and in engineered products such as loudspeaker cones.\nPressure-sensitive.\n\"Pressure-sensitive adhesives\" (PSA) form a bond by the application of light pressure to marry the adhesive with the adherend. They are designed to have a balance between flow and resistance to flow. The bond forms because the adhesive is soft enough to flow (i.e., \"wet\") to the adherend. The bond has strength because the adhesive is hard enough to resist flow when stress is applied to the bond. Once the adhesive and the adherend are in close proximity, molecular interactions, such as van der Waals forces, become involved in the bond, contributing significantly to its ultimate strength.\nPSAs are designed for either permanent or removable applications. Examples of permanent applications include safety labels for power equipment, foil tape for HVAC duct work, automotive interior trim assembly, and sound/vibration damping films. Some high performance permanent PSAs exhibit high adhesion values and can support kilograms of weight per square centimeter of contact area, even at elevated temperatures. Permanent PSAs may initially be removable (for example to recover mislabeled goods) and build adhesion to a permanent bond after several hours or days.\nRemovable adhesives are designed to form a temporary bond, and ideally can be removed after months or years without leaving residue on the adherend. Removable adhesives are used in applications such as surface protection films, masking tapes, bookmark and note papers, barcode labels, price marking labels, promotional graphics materials, and for skin contact (wound care dressings, EKG electrodes, athletic tape, analgesic and transdermal drug patches, etc.). Some removable adhesives are designed to repeatedly stick and unstick. They have low adhesion, and generally cannot support much weight. Pressure-sensitive adhesive is used in Post-it notes.\nPressure-sensitive adhesives are manufactured with either a liquid carrier or in 100% solid form. Articles are made from liquid PSAs by coating the adhesive and drying off the solvent or water carrier. They may be further heated to initiate a cross-linking reaction and increase molecular weight. 100% solid PSAs may be low viscosity polymers that are coated and then reacted with radiation to increase molecular weight and form the adhesive, or they may be high viscosity materials that are heated to reduce viscosity enough to allow coating, and then cooled to their final form. Major raw material for PSA's are acrylate-based polymers.\nContact.\n\"Contact adhesives\" are used in strong bonds with high shear-resistance like laminates, such as bonding Formica to a wooden counter, and in footwear, as in attaching outsoles to uppers. Natural rubber and polychloroprene (Neoprene) are commonly used contact adhesives. Both of these elastomers undergo strain crystallization.\nContact adhesives must be applied to both surfaces and allowed some time to dry before the two surfaces are pushed together. Some contact adhesives require as long as 24 hours to dry before the surfaces are to be held together. Once the surfaces are pushed together, the bond forms very quickly. It is usually not necessary to apply pressure for a long time, so there is less need for clamps.\nHot.\n\"Hot adhesives\", also known as \"hot melt adhesives\", are thermoplastics applied in molten form (in the 65\u2013180\u00a0\u00b0C range) which solidify on cooling to form strong bonds between a wide range of materials. Ethylene-vinyl acetate-based hot-melts are particularly popular for crafts because of their ease of use and the wide range of common materials they can join. A glue gun (shown at right) is one method of applying hot adhesives. The glue gun melts the solid adhesive, then allows the liquid to pass through its barrel onto the material, where it solidifies.\nThermoplastic glue may have been invented around 1940 by Procter &amp; Gamble as a solution to the problem that water-based adhesives, commonly used in packaging at that time, failed in humid climates, causing packages to open.\nAnaerobic.\nAnaerobic adhesives cure when in contact with metal, in the absence of oxygen. They work well in a close-fitting space, as when used as a Thread-locking fluid.\nMulti-part.\n\"Multi-component adhesives\" harden by mixing two or more components which chemically react. This reaction causes polymers to cross-link into acrylates, urethanes, and epoxies .\nThere are several commercial combinations of multi-component adhesives in use in industry. Some of these combinations are:\nThe individual components of a multi-component adhesive are not adhesive by nature. The individual components react with each other after being mixed and show full adhesion only on curing. The multi-component resins can be either solvent-based or solvent-less. The solvents present in the adhesives are a medium for the polyester or the polyurethane resin. The solvent is dried during the curing process.\nPre-mixed and frozen adhesives.\n\"Pre-mixed and frozen adhesives\" (PMFs) are adhesives that are mixed, deaerated, packaged, and frozen. As it is necessary for PMFs to remain frozen before use, once they are frozen at \u221280\u00a0\u00b0C they are shipped with dry ice and are required to be stored at or below \u221240\u00a0\u00b0C. PMF adhesives eliminate mixing mistakes by the end user and reduce exposure of curing agents that can contain irritants or toxins. PMFs were introduced commercially in the 1960s and are commonly used in aerospace and defense.\nOne-part.\n\"One-part adhesives\" harden via a chemical reaction with an external energy source, such as radiation, heat, and moisture.\n\"Ultraviolet\" (UV) \"light curing adhesives\", also known as \"light curing materials\" (LCM), have become popular within the manufacturing sector due to their rapid curing time and strong bond strength. Light curing adhesives can cure in as little as one second and many formulations can bond dissimilar substrates (materials) and withstand harsh temperatures. These qualities make UV curing adhesives essential to the manufacturing of items in many industrial markets such as electronics, telecommunications, medical, aerospace, glass, and optical. Unlike traditional adhesives, UV light curing adhesives not only bond materials together but they can also be used to seal and coat products. They are generally acrylic-based.\n\"Heat curing adhesives\" consist of a pre-made mixture of two or more components. When heat is applied the components react and cross-link. This type of adhesive includes thermoset epoxies, urethanes, and polyimides.\n\"Moisture curing adhesives\" cure when they react with moisture present on the substrate surface or in the air. This type of adhesive includes cyanoacrylates and urethanes.\nBy origin.\nNatural.\nNatural adhesives are made from organic sources such as vegetable starch (dextrin), natural resins, or animals (e.g. the milk protein casein and hide-based animal glues). These are often referred to as bioadhesives.\nOne example is a simple paste made by cooking flour in water. Starch-based adhesives are used in corrugated board and paper sack production, paper tube winding, and wallpaper adhesives. Casein glue is mainly used to adhere glass bottle labels. Animal glues have traditionally been used in bookbinding, wood joining, and many other areas but now are largely replaced by synthetic glues except in specialist applications like the production and repair of stringed instruments. Albumen made from the protein component of blood has been used in the plywood industry. Masonite, a wood hardboard, was originally bonded using natural wood lignin, an organic polymer, though most modern particle boards such as MDF use synthetic thermosetting resins.\nSynthetic.\nSynthetic adhesives are based on elastomers, thermoplastics, emulsions, and thermosets. Examples of thermosetting adhesives are: epoxy, polyurethane, cyanoacrylate and acrylic polymers. The first commercially produced synthetic adhesive was Karlsons Klister in the 1920s.\nApplication.\nApplicators of different adhesives are designed according to the adhesive being used and the size of the area to which the adhesive will be applied. The adhesive is applied to either one or both of the materials being bonded. The pieces are aligned and pressure is added to aid in adhesion and rid the bond of air bubbles.\nCommon ways of applying an adhesive include brushes, rollers, using films or pellets, spray guns and applicator guns (\"e.g.\", caulk gun). All of these can be used manually or automated as part of a machine.\nMechanisms of adhesion.\nFor an adhesive to be effective it must have three main properties. It must be able to wet the substrate. It must increase in strength after application, and finally it must be able to transmit load between the two surfaces/substrates being adhered.\nAdhesion, the attachment between adhesive and substrate may occur either by mechanical means, in which the adhesive works its way into small pores of the substrate, or by one of several chemical mechanisms. The strength of adhesion depends on many factors, including the means by which it occurs.\nIn some cases, an actual chemical bond occurs between adhesive and substrate. In others, electrostatic forces, as in static electricity, hold the substances together. A third mechanism involves the van der Waals forces that develop between molecules. A fourth means involves the moisture-aided diffusion of the glue into the substrate, followed by hardening.\nMethods to improve adhesion.\nThe quality of adhesive bonding depends strongly on the ability of the adhesive to efficiently cover (wet) the substrate area. This happens when the surface energy of the substrate is greater than the surface energy of the adhesive. However, high strength adhesives have high surface energy. Thus, their application is problematic for low energy materials such as polymers. To solve this problem, surface treatment can be used to increase the surface energy as a preparation step before adhesive bonding. Importantly, surface preparation provides a reproducible surface allowing consistent bonding results. The commonly used surface activation techniques include plasma activation, flame treatment and wet chemistry priming.\nFailure.\nThere are several factors that could contribute to the failure of two adhered surfaces. Sunlight and heat may weaken the adhesive. Solvents can deteriorate or dissolve adhesive. Physical stresses may also cause the separation of surfaces. When subjected to loading, debonding may occur at different locations in the adhesive joint. The major fracture types are the following:\nCohesive fracture.\n\"Cohesive fracture\" is obtained if a crack propagates in the bulk polymer which constitutes the adhesive. In this case the surfaces of both adherends after debonding will be covered by fractured adhesive. The crack may propagate in the center of the layer or near an interface. For this last case, the cohesive fracture can be said to be \"cohesive near the interface\".\nAdhesive fracture.\n\"Adhesive fracture\" (sometimes referred to as \"interfacial fracture\") is when debonding occurs between the adhesive and the adherend. In most cases, the occurrence of adhesive fracture for a given adhesive goes along with smaller fracture toughness.\nOther types of fracture.\nOther types of fracture include:\nDesign of adhesive joints.\nAs a general design rule, the material properties of the object need to be greater than the forces anticipated during its use. (i.e. geometry, loads, etc.). The engineering work will consist of having a good model to evaluate the function. For most adhesive joints, this can be achieved using fracture mechanics. Concepts such as the stress concentration factor and the strain energy release rate can be used to predict failure. In such models, the behavior of the adhesive layer itself is neglected and only the adherents are considered.\nFailure will also very much depend on the opening \"mode\" of the joint.\nAs the loads are usually fixed, an acceptable design will result from combination of a material selection procedure and geometry modifications, if possible. In adhesively bonded structures, the global geometry and loads are fixed by structural considerations and the design procedure focuses on the material properties of the adhesive and on local changes on the geometry.\nIncreasing the joint resistance is usually obtained by designing its geometry so that:\nShelf life.\nSome glues and adhesives have a limited shelf life. Exposure to heat, oxygen, water vapor, freezing, etc. can degrade the adhesive over time, preventing it from functioning properly."}
{"id": "2397", "revid": "13018051", "url": "https://en.wikipedia.org/wiki?curid=2397", "title": "Anthony Hopkins", "text": "Sir Philip Anthony Hopkins (born 31 December 1937) is a Welsh actor, director and film producer. He has received many awards, including two Academy Awards, four BAFTAs, two Emmys, the Cecil B. DeMille Award and a British Academy Television Award. In 1993, he was knighted by Queen Elizabeth II for services to the arts. Hopkins received a star on the Hollywood Walk of Fame in 2003 and the BAFTA Fellowship for lifetime achievement from the British Academy of Film and Television Arts in 2008.\nAfter graduating from the Royal Welsh College of Music &amp; Drama in 1957, Hopkins trained at the Royal Academy of Dramatic Art in London, and was then spotted by Laurence Olivier who invited him to join the Royal National Theatre in 1965. Productions at the National included \"King Lear\", his favourite Shakespeare play. His last stage play was a West End production of \"M. Butterfly\" in 1989. \nIn 1968, Hopkins achieved recognition in film, playing Richard the Lionheart in \"The Lion in Winter\". In the mid-1970s, Richard Attenborough, who directed five Hopkins films, called him \"the greatest actor of his generation.\" In 1991, he portrayed Hannibal Lecter in the psychological horror film \"The Silence of the Lambs\", winning the Academy Award for Best Actor. He reprised the role in its sequel \"Hannibal\" and the prequel \"Red Dragon\". Other notable films include \"The Elephant Man\" (1980), \"84 Charing Cross Road\" (1987), \"Howards End\" (1992), \"Bram Stoker's Dracula\" (1992), \"Shadowlands\" (1993), \"Legends of the Fall\" (1994), \"Meet Joe Black\" (1998), \"The Mask of Zorro\" (1998), \"Thor\" (2011), ' (2013), ' (2017), and \"\" (2017). He received four more Academy Award nominations for \"The Remains of the Day\" (1993), \"Nixon\" (1995), \"Amistad\" (1997) and \"The Two Popes\" (2019) before winning a fourth BAFTA Award and a second Academy Award for Best Actor for his portrayal of an elderly man diagnosed with dementia in \"The Father\" (2020), becoming the oldest Best Actor Oscar winner to date.\nSince making his television debut with the BBC in 1967, Hopkins has continued to appear on television. In 1973 he received a British Academy Television Award for Best Actor for his performance in \"War and Peace\". In 2015, he starred in the BBC film \"The Dresser\" alongside Ian McKellen. In 2018, he starred in \"King Lear\" opposite Emma Thompson. In 2016 and 2018, he starred in the HBO television series \"Westworld\", for which he received a Primetime Emmy Award nomination.\nEarly life.\nPhilip Anthony Hopkins was born in the Margam suburb of Port Talbot on 31 December 1937, the son of Annie Muriel (n\u00e9e Yeates) and baker Richard Arthur Hopkins. He stated his father's working-class values have always underscored his life, \"Whenever I get a feeling that I may be special or different, I think of my father and I remember his hands \u2013 his hardened, broken hands.\" His school days were unproductive; he would rather immerse himself in art, such as painting and drawing, or playing the piano, than attend to his studies. In 1949, to instill discipline, his parents insisted he attend Jones' West Monmouth Boys' School in Pontypool. He remained there for five terms and was then educated at Cowbridge Grammar School in the Vale of Glamorgan. In a 2002 interview he stated, \"I was a poor learner, which left me open to ridicule and gave me an inferiority complex. I grew up absolutely convinced I was stupid.\"\nHopkins was inspired by fellow Welsh actor Richard Burton, whom he met at the age of 15. He later called Burton \"very gracious, very nice\" but elaborated, \"I don't know where everyone gets the idea we were good friends. I suppose it's because we are both Welsh and grew up near the same town. For the record, I didn't really know him at all.\" He enrolled at the Royal Welsh College of Music &amp; Drama in Cardiff, from which he graduated in 1957. He next met Burton in 1975 as Burton prepared to take over Hopkins' role as the psychiatrist in Peter Shaffer\u2019s \"Equus\", with Hopkins stating, \"He was a phenomenal actor. So was Peter O'Toole \u2013 they were wonderful, larger-than-life characters.\" After two years of his national service between 1958 and 1960, which he served in the British Army, Hopkins moved to London to study at the Royal Academy of Dramatic Art.\nActing career.\n1960s: Early work.\nHopkins made his first professional stage appearance in the Palace Theatre, Swansea, in 1960 with Swansea Little Theatre's production of \"Have a Cigarette\". In 1965, after several years in repertory, he was spotted by Laurence Olivier, who invited him to join the Royal National Theatre in London. Hopkins became Olivier's understudy, and filled in when Olivier was struck with appendicitis during a 1967 production of August Strindberg's \"The Dance of Death\". Olivier later noted in his memoir, \"Confessions of an Actor\", that\nHopkins was nervous prior to going on stage, but since that night he has relaxed, quoting his mentor: \"He [Olivier] said: 'Remember: nerves is [sic] vanity \u2013 you're wondering what people think of you; to hell with them, just jump off the edge'. It was great advice.\" Despite his success at the National, Hopkins tired of repeating the same roles nightly and yearned to be in films. He made his small-screen debut in a 1967 BBC broadcast of \"A Flea in Her Ear\". His first starring role in a film came in 1964 in \"Changes\", a short directed by Drewe Henley, written and produced by James Scott and co-starring Jacqueline Pearce. \nIn 1968, Hopkins got his break in \"The Lion in Winter\" playing Richard the Lionheart, a performance which saw him nominated for the BAFTA Award for Best Actor in a Supporting Role. Although he continued in theatre (most notably at the National Theatre as Lambert Le Roux in \"Pravda\" by David Hare and Howard Brenton and as Antony in \"Antony and Cleopatra\" opposite Judi Dench as well as in the Broadway production of Peter Shaffer's \"Equus\") he gradually moved away from it to become more established as a television and film actor.\n1970s.\nHopkins portrayed Charles Dickens in the BBC television film \"The Great Inimitable Mr. Dickens\" in 1970, and Pierre Bezukhov in the BBC's mini series \"War and Peace\" (1972), receiving the British Academy Television Award for Best Actor for his performance in the latter. In film he appeared in Frank Pierson's neo-noir action thriller \"The Looking Glass War\" (1970), and \u00c9tienne P\u00e9rier's \"When Eight Bells Toll\" (1971). He then starred in a film adaptation of the Henrik Ibsen play \"A Doll's House\" (1973) alongside Claire Bloom, Ralph Richardson, Denholm Elliott, and Edith Evans. He then appeared in the American comedy \"The Girl from Petrovka\" (1974) with Goldie Hawn and Hal Holbrook. That same year he starred in the Richard Lester suspense film \"Juggernaut\" opposite Richard Harris and Omar Sharif. In 1978 he starred in the sequel to \"National Velvet\" (1944), entitled \"International Velvet\" with Tatum O'Neal, Christopher Plummer, which was directed by Bryan Forbes.\nMaking a name for himself as a screen actor, Hopkins collaborated with director Richard Attenborough in \"Young Winston\" (1972), \"A Bridge Too Far\" (1977), and \"Magic\" (1978). In 1972 he starred as British politician David Lloyd George in \"Young Winston\", and in 1977 he played British Army officer John Frost in the World War II-set film \"A Bridge Too Far\". Both of these films were directed by Richard Attenborough, who described Hopkins as \"unquestionably the greatest actor of his generation\". \"A Bridge Too Far\" featured an ensemble cast of actors including Laurence Olivier, Michael Caine, Gene Hackman, Sean Connery, Liv Ullman, Elliott Gould, and Robert Redford. In 1978 he starred in Attenborough's next project, a psychological horror film \"Magic\" about a demonic ventriloquist's puppet which received critical acclaim with Gene Siskel adding it as one of the best films of the year.\n1980s.\nIn 1980, he starred in David Lynch's \"The Elephant Man\" as the English doctor Sir Frederick Treves, who attends to Joseph Merrick (portrayed by John Hurt), a severely deformed man in 19th century London. The film received critical praise and attention from critics and received eight Academy Award nominations including for Best Picture. That year he also starred opposite Shirley MacLaine in \"A Change of Seasons\" and famously didn't get along with Hopkins adding \"she was the most obnoxious actress I have ever worked with.\" The film was an immense box office and critical failure.\nIn 1983, Hopkins also became a company member of The Mirror Theater Ltd's Repertory Company. He remained an enthusiastic member of the company and the Mirror's Producing Artistic Director Sabra Jones visited him in London in 1986 to discuss moving \"Pravda\" to New York from the National Theatre. In 1984, he starred opposite Mel Gibson in \"The Bounty\" as William Bligh, captain of the Royal Navy ship , in a more accurate retelling of the mutiny on the \"Bounty\". In 1985 Hopkins starred opposite Colin Firth in the Arthur Schnitzler play \"The Lonely Road\" at The Old Vic. In 1986 he starred in David Hare\u2019s production of \"King Lear\", Hopkins' favourite Shakespeare play, at the National Theatre. In 1989, Hopkins made his last stage performance in a West End production of \"M. Butterfly\".\n1990s.\nHopkins won acclaim among critics and audiences as the cannibalistic serial killer Hannibal Lecter in \"The Silence of the Lambs\", for which he won the Academy Award for Best Actor in 1991, with Jodie Foster as Clarice Starling, who also won for Best Actress. The film won Best Picture, Best Director and Academy Award for Best Adapted Screenplay, and Hopkins also picked up his first BAFTA for Best Actor. Hopkins reprised his role as Lecter twice; in Ridley Scott's \"Hannibal\" (2001), and \"Red Dragon\" (2002).\nHis original portrayal of the character in \"The Silence of the Lambs\" has been labelled by the AFI as the number-one film villain. Director Jonathan Demme wanted a British actor for the role, with Jodie Foster stating, \"Lecter is a manipulator and has a way of using language to keep people at bay. You wanted to see that Shakespearean monster.\" At the time he was offered the role, Hopkins was making a return to the London stage, performing in \"M. Butterfly\". He had come back to Britain after living for a number of years in Hollywood, having all but given up on a career there, saying, \"Well that part of my life's over; it's a chapter closed. I suppose I'll just have to settle for being a respectable actor poncing around the West End and doing respectable BBC work for the rest of my life.\" Hopkins played the iconic villain in adaptations of the first three of the Lecter novels by Thomas Harris. The author was reportedly pleased with Hopkins' portrayal of his antagonist. However, Hopkins stated that \"Red Dragon\" would feature his final performance as the character, and that he would not reprise even a narrative role in the latest addition to the series, \"Hannibal Rising\". Hopkins played Professor Van Helsing in Francis Ford Coppola's \"Bram Stoker's Dracula\" (1992). \nIn 1992, Hopkins starred in Merchant-Ivory's period film based on the E. M. Forster novel \"Howards End\". Hopkins acted alongside Emma Thompson and Helena Bonham Carter where he played the cold businessman Henry Wilcox. The film received enormous critical acclaim, with critic Leonard Maltin calling it \"extraordinarily good on every level.\" The following year, Hopkins reunited with Merchant-Ivory and Emma Thompson in \"The Remains of the Day\" (1993), a film set in 1950s post-war Britain based on the novel by Kazuo Ishiguro. The film was ranked by the British Film Institute as one of the 64th greatest British film of the 20th century. Starring as the butler Stevens, Hopkins named it among his favourite films. He was nominated for an Academy Award for Best Actor for his performance, and received the BAFTA Award for Best Actor.\nHopkins portrayed Oxford academic C. S. Lewis in the 1993 British biographical film \"Shadowlands\", for which he was nominated for a BAFTA Award for Best Actor. During the 1990s, Hopkins had the chance to work with Bart the Bear in two films: \"Legends of the Fall\" (1994) and \"The Edge\" (1997). According to trainer, Lynn Seus, \"Tony Hopkins was absolutely brilliant with Bart...He acknowledged and respected him like a fellow actor. He would spend hours just looking at Bart and admiring him. He did so many of his own scenes with Bart.\"\nHopkins was Britain's highest paid performer in 1998, starring in \"The Mask of Zorro\" and \"Meet Joe Black\", and also agreed to reprise his role as Dr Hannibal Lecter for a fee of \u00a315\u00a0million.\n2000s.\nIn 2000, Hopkins narrated Ron Howard's live action remake of \"How the Grinch Stole Christmas\". He then reprised the role of Hannibal Lecter in the long awaited return from \"The Silence of the Lambs\" (1991) in its sequel simply entitled \"Hannibal\" (2001). Director Ridley Scott and actress Julianne Moore replaced Jonathan Demme and Jodie Foster who declined to participate in the sequel. Hopkins agreed to do the role approving of the script. In the book, Lecter uses bandages to disguise himself as a plastic surgery patient. This was left out of the film because Scott and Hopkins agreed to leave the face alone. Hopkins said: \"It's as if he's making a statement\u2014'catch me if you can'. With his big hat, he's so obvious that nobody thinks he's Hannibal Lecter. I've always thought he's a very elegant man, a Renaissance man.\" \nIn the film, Lecter is first seen in Florence \"as the classical Lecter, lecturing and being smooth\", according to Hopkins. When the film moves to the U.S., Hopkins changed his appearance by building up muscle and cropping his hair short \"to make him like a mercenary, that he would be so fit and so strong that he could just snap somebody in two if they got ... in his way\". The film broke international box office records receiving $351 million dollars. but received mixed reviews from critics. Hopkins starred in the third film in the series \"Red Dragon\" (2002) alongside Ralph Fiennes, Edward Norton, Harvey Keitel, Emily Watson, and Philip Seymour Hoffman. The film received favourable reviews and was a box office hit. \nIn 2003, Hopkins received a star on the Hollywood Walk of Fame. Hopkins stated that his role as Burt Munro, whom he portrayed in his 2005 film \"The World's Fastest Indian\", was his favourite. He also asserted that Munro was the easiest role that he had played because both men have a similar outlook on life. In 2006, Hopkins was the recipient of the Golden Globe Cecil B. DeMille Award for lifetime achievement. In 2008, he received the BAFTA Academy Fellowship Award, the highest award the British Film Academy can bestow. In a 2003 poll conducted by Channel 4 Hopkins was ranked seventh on their list of the 100 Greatest Movie Stars.\n2010s.\nOn 24 February 2010, it was announced that Hopkins had been cast in \"The Rite\", which was released on 28 January 2011. He played a priest who is \"an expert in exorcisms and whose methods are not necessarily traditional\". Hopkins, an agnostic who is quoted as saying \"I don't know what I believe, myself personally\", reportedly wrote a line\u2014\"Some days I don't know if I believe in God or Santa Claus or Tinkerbell\"\u2014into his character to identify with it. In 2011, Hopkins has said, \"what I enjoy is uncertainty. \u2026 I don't know. You don't know.\" On 21 September 2011, Peter R. de Vries cast Hopkins in the role of the Heineken owner Freddy Heineken, in the film about his kidnapping. \"Kidnapping Freddy Heineken\", was released in 2015.\nHopkins portrayed Odin, the Allfather or \"king\" of Asgard, in the 2011 film adaptation of Marvel Comics' \"Thor\" and would go on to reprise his role as Odin in ' in 2013, and again in 2017's '. Hopkins portrayed Alfred Hitchcock in Sacha Gervasi's biopic \"Hitchcock\" alongside Helen Mirren who played Hitchcock's wife, Alma Reville. The film focuses on the film of \"Psycho\" and that which followed. In 2014, he portrayed Methuselah in Darren Aronofsky's \"Noah\". Hopkins played Autobot ally Sir Edmund Burton in \"\", which was released in June 2017. \nIn October 2015, Hopkins appeared as Sir in a BBC Two production of Ronald Harwood's \"The Dresser\", alongside Ian McKellen, Edward Fox and Emily Watson. \"The Dresser\" is set in a London theatre during the Blitz, where an aging actor-manager, Sir, prepares for his starring role in \"King Lear\" with the help of his devoted dresser, Norman. Hopkins described his role as Sir as \"the highlight of my life. It was a chance to work with the actors I had run away from. To play another actor is fun because you know the ins and outs of their thinking \u2013 especially with someone like Sir, who is a diabolically insecure, egotistical man.\" He spoke again on the impact the role had on him in 2018, \"When I was at the Royal National Theatre all those years ago, I knew I had something in me, but I didn\u2019t have the discipline. I had a Welsh temperament and didn\u2019t have that 'fitting in' mechanism. I would fight, I would rebel. I thought, 'Well, I don\u2019t belong here.' And for almost 50 years afterwards, I felt that edge of, 'I don\u2019t belong anywhere, I\u2019m a loner.' But in \"The Dresser\", when Ian [McKellen] responded, it was wonderful. We got on so well and I suddenly felt at home, as though that lack of belonging was all in my imagination, all in my vanity\". \nBeginning in October 2016, Hopkins starred as Robert Ford in the HBO sci-fi series \"Westworld\" where he received a Primetime Emmy Award nomination for his performance. Hopkins starred as Lear in the 2018 television film \"King Lear\" acting alongside Emma Thompson, Florence Pugh, and Jim Broadbent which was broadcast on BBC Two on 28 May 2018. Hopkins received a Screen Actors Guild Award nomination for his performance. \nIn 2019, Hopkins portrayed Pope Benedict XVI opposite Jonathan Pryce as Pope Francis in Fernando Meirelles's \"The Two Popes\". He stated, \"The great treasure was working with \u2013 apart from [director] Meirelles \u2013 Pryce. We\u2019re both from Wales. He\u2019s from the north, and I\u2019m from the south\". The film is set in the Vatican City in the aftermath of the Vatican leaks scandal and follows Pope Benedict XVI as he attempts to convince Cardinal Jorge Mario Bergoglio to reconsider his decision to resign as an archbishop as he confides his own intentions to abdicate the papacy. In August 2019, the film premiered at the Telluride Film Festival to critical acclaim. The film started streaming on December 20, 2019, by Netflix. The performances of Pryce and Hopkins, as well as McCarten's screenplay, received high praise from critics, and all three men received nominations for their work at the Academy Awards, Golden Globes and British Academy Film Awards.\n2020s.\nIn 2020, Hopkins played a man struggling with his memory in \"The Father\". The film premiered at the Sundance Film Festival where it received critical acclaim, with many critics praising Hopkins' performance and calling him a standout and Oscar frontrunner. The film also stars Olivia Colman as his daughter. It is based on a Tony Award nominated play \"Le P\u00e8re\" by Florian Zeller, who also directed the film. \"The Father\" was released on 18 December 2020 by Sony Pictures Classics. In a Q&amp;A at the Telluride Film Festival Hopkins praised both Colman and Zeller saying comparing the working experience saying it \"might've been the highlight of my life\". Hopkins mentioned how lucky he's been over the past five years working with Ian McKellen in \"The Dresser\", Emma Thompson in \"King Lear\", and Jonathan Pryce in \"The Two Popes\". Hopkins won the BAFTA Award for Best Actor in a Leading Role for his performance in \"The Father\", making it his fourth BAFTA and his third for Best Actor. He also won a second Academy Award for Best Actor for his role, becoming the oldest person to win an acting Oscar. Hopkins did not attend the Oscars ceremony, but accepted the award in a video posted on social media, from Wales, the following day, saying: \"Here I am in my homeland in Wales. And at 83 years of age, I did not expect to get this award. I really didn't and am very grateful to the Academy and thank you.\" He also paid tribute to fellow nominee Chadwick Boseman, who had died the previous year.\nComposer.\nSingle.\nIn a 2012 interview, Hopkins stated, \"I've been composing music all my life and if I'd been clever enough at school I would like to have gone to music college. As it was I had to settle for being an actor.\" In 1986, he released a single called \"Distant Star\", which peaked at No. 75 in the UK Singles Chart. In 2007, he announced he would retire temporarily from the screen to tour around the world. Hopkins has also written music for the concert hall, in collaboration with Stephen Barton as orchestrator. These compositions include \"The Masque of Time\", given its world premiere with the Dallas Symphony Orchestra in October 2008, and \"Schizoid Salsa\".\nAlbums.\nOn 31 October 2011, Andr\u00e9 Rieu released an album including a waltz which Hopkins had composed in 1964, at the age of 26. Hopkins had never heard his composition, \"And the Waltz Goes On\", before it was premiered by Rieu's orchestra in Vienna; Rieu's album was given the same name as Hopkins' piece.\nIn January 2012, Hopkins released an album of classical music, entitled \"Composer\", performed by the City of Birmingham Symphony Orchestra, and released on CD via the UK radio station Classic FM. The album consists of nine of his original works and film scores, with one of the pieces titled \"Margam\" in tribute to his home town near Port Talbot in Wales.\nDirector.\nIn 1990, Hopkins directed a film about his Welsh compatriot, poet Dylan Thomas, titled \"Dylan Thomas: Return Journey\", which was his directing debut for the screen. In the same year, as part of the restoration process for the Stanley Kubrick film \"Spartacus\", Hopkins was approached to re-record lines from a scene that was being added back to the film; this scene featured Laurence Olivier and Tony Curtis, with Hopkins recommended by Olivier's widow, Joan Plowright to perform her late husband's part thanks to his talent for mimicry.\nIn 1995, he directed \"August\", an adaptation of Chekhov's \"Uncle Vanya\" set in Wales. His first screenplay, an experimental drama called \"Slipstream\", which he also directed and scored, premiered at the Sundance Film Festival in 2007. In 1997, Hopkins narrated the BBC natural documentary series, \"Killing for a Living\", which showed predatory behaviour in nature. He narrated episode 1 through 3 before being replaced by John Shrapnel.\nActing style.\nHopkins is renowned for his preparation for roles. He indicated in interviews that once he has committed to a project, he will go over his lines as many times as is needed (sometimes upwards of 200) until the lines sound natural to him, so that he can \"do it without thinking\". This leads to an almost casual style of delivery that belies the amount of groundwork done beforehand. While it can allow for some careful improvisation, it has also brought him into conflict with the occasional director who departs from the script, or demands what the actor views as an excessive number of takes. Hopkins has stated that after he is finished with a scene, he simply discards the lines, not remembering them later on. This is unlike others who usually remember their lines from a film, even years later.\nRichard Attenborough, who directed Hopkins on five occasions, found himself going to great lengths during the filming of \"Shadowlands\" (1993) to accommodate the differing approaches of his two stars (Hopkins and Debra Winger), who shared many scenes. Whereas Hopkins preferred the spontaneity of a fresh take and liked to keep rehearsals to a minimum, Winger rehearsed continuously. To allow for this, Attenborough stood in for Hopkins during Winger's rehearsals, only bringing him in for the last one before a take. The director praised Hopkins for \"this extraordinary ability to make you believe when you hear him that it is the very first time he has ever said that line. It's an incredible gift.\"\nRenowned for his ability to remember lines, Hopkins keeps his memory supple by learning things by heart such as poetry and Shakespeare. In Steven Spielberg's \"Amistad\" (1997), Hopkins astounded the crew with his memorisation of a seven-page courtroom speech, delivering it in one go. An overawed Spielberg couldn't bring himself to call Hopkins \"Tony\", and insisted on addressing him as Sir Anthony throughout the shoot.\nIn a 2016 interview with the \"Radio Times\", Hopkins spoke of his ability to frighten people since he was a boy growing up in Port Talbot, Wales. \"I don't know why but I've always known what scares people. When I was a kid I'd tell the girls around the street the story about Dracula and I'd go 'th-th-th' (the sucking noise which he reproduced in \"The Silence of the Lambs\"). As a result, they'd run away screaming.\" He recalled going through the script of \"Silence of the Lambs\" for the first time with fellow cast members. \"I didn't know what they were going to make of it but I'd prepared it\u2014my first line to Jodie Foster was: 'Good morning. You're one of Jack Crawford's aren't you?' Everyone froze. There was a silence. Then one of the producers said, 'Holy crap, don't change a thing'.\" On Hopkins' approach to playing villains, Miranda Sawyer in \"The Guardian\" writes, \"When he portrays deliberately scary people, he plays them quietly, emphasising their sinister control.\"\nHopkins is a well-known mimic, adept at turning his native Welsh accent into whatever is required by a character. In the 1991 restoration of \"Spartacus\", he recreated the voice of his late mentor Laurence Olivier in a scene for which the soundtrack had been lost. His interview on the 1998 relaunch edition of the British TV talk show \"Parkinson\" featured an impersonation of comedian Tommy Cooper. Hopkins has said acting \"like a submarine\" has helped him to deliver credible performances in his thrillers. He said, \"It's very difficult for an actor to avoid, you want to show a bit. But I think the less one shows the better.\"\nAwards and honours.\nHopkins was appointed a CBE in 1987 and was knighted by Queen Elizabeth II for \"services to the arts\" at Buckingham Palace in 1993. In 1988, he was awarded an honorary D.Litt. degree and in 1992 received an honorary fellowship from the University of Wales, Lampeter. He was made a freeman of his home town, Port Talbot, in 1996.\nHopkins has also been honored with various life time achievement awards for his work in film and television. In 2006, Gwyneth Paltrow presented him with the Golden Globe Cecil B. DeMille award In 2008, Richard Attenborough presented Hopkins with the BAFTA Fellowship for lifetime achievement from the British Academy of Film and Television Arts. Hopkins has also received a star on the Hollywood Walk of Fame in 2003. In 2021, Hopkins won the Oscar for the Best Actor for \"The Father\". He became the oldest nominee and winner of the award.\nPersonal life.\nHopkins resides in Malibu, California. He had moved to the United States once before, during the late 1970s, to pursue his film career, but returned to London in the late 1980s. However, he decided to return to the US following his 1990s success. Retaining his British citizenship, he became a naturalised American citizen on 12 April 2000, with Hopkins stating: \"I have dual citizenship; it just so happens I live in America\".\nHopkins has been married three times. He was married to Petronella Barker from 1966 to 1972, Jennifer Lynton from 1973 to 2002, and Stella Arroyave since 2003. On Christmas Eve 2012, he celebrated his 10th wedding anniversary by having a blessing at a private service at St Davids Cathedral in St Davids. He has a daughter, actress and singer Abigail Hopkins (born 20 August 1968), from his first marriage. The two are estranged; when asked if he had any grandchildren, he said, \"I don't have any idea. People break up. Families split and, you know, 'Get on with your life.' People make choices. I don't care one way or the other.\"\nHopkins is a recovering alcoholic; he has stayed sober since he stopped drinking just after Christmas 1975. He said, \"I made that quantum leap when I asked for help. I just found something and a woman talked to me and she said, just trust in God. And I said, well, why not?\" When asked, \"Did you literally pray?\" Hopkins responded: \"No, I didn't. I think because I asked for help, which is a form of prayer.\" In January 2020, when asked if he was still agnostic, he responded, \"Agnosticism is a bit strange. An agnostic doubts and atheism denies. I'm not a holy Joe; I'm just an old sinner like everyone else. I do believe more than ever now that there is a vast area of our own lives that we know nothing about. As I get older, I can cry at the drop of a hat because the wonderful, terrible passion of life is so short. I have to believe there's something bigger than me. I'm just a microbe. That, for me, is the biggest feeling of relief \u2013 acknowledging that I am really nothing. I'm compelled to say, whoever's running the show, thank you very much.\"\nHopkins quit smoking using the Allen Carr method. In 2008, he embarked on a weight loss programme, and by 2010, he had lost 80 pounds. In January 2017, in an interview with \"The Desert Sun\", Hopkins reported that he had been diagnosed with Asperger syndrome, but that he was \"high end\". Hopkins has a pet cat named Niblo, which he adopted in Budapest.\nHopkins is a fan of the BBC sitcom \"Only Fools and Horses\", and once remarked in an interview how he would love to appear in the series. Writer John Sullivan saw the interview, and with Hopkins in mind created the character Danny Driscoll, a local villain. However, filming of the new series coincided with the filming of \"The Silence of the Lambs\", making Hopkins unavailable. The role instead went to Roy Marsden.\nPhilanthropy.\nHopkins has offered his support to various charities and appeals, notably becoming President of the National Trust's Snowdonia Appeal, raising funds for the preservation of Snowdonia National Park in north Wales. In 1998 he donated \u00a31\u00a0million towards the \u00a33\u00a0million needed to aid the Trust's efforts in purchasing parts of Snowdon. Prior to the campaign, Hopkins authored \"Anthony Hopkins' Snowdonia\", which was published in 1995. Due to his contributions to Snowdonia, in addition to his film career, in 2004 Hopkins was named among the 100 Welsh Heroes in a Welsh poll.\nHopkins has been a patron of the YMCA centre in his home town of Port Talbot, South Wales for more than 20 years, having first joined the YMCA in the 1950s. He supports other various philanthropic groups. He was a Guest of Honour at a Gala Fundraiser for Women in Recovery, Inc., a Venice, California-based non-profit organisation offering rehabilitation assistance to women in recovery from substance abuse. He is also a volunteer teacher at the Ruskin School of Acting in Santa Monica, California. Hopkins served as the Honorary Patron of The New Heritage Theatre Company in Boise, Idaho from 1997 to 2007, participating in fundraising and marketing efforts for the repertory theatre.\nHopkins contributed toward the refurbishment of a \u00a32.3\u00a0million wing at his alma mater, the Royal Welsh College of Music &amp; Drama in Cardiff, named the Anthony Hopkins Centre. It opened in 1999.\nHopkins is a prominent member of environmental protection group Greenpeace and as of early 2008 featured in a television advertisement campaign, voicing concerns about Japan's continuing annual whale hunt. He has also been a patron of RAPt (Rehabilitation for Addicted Prisoners Trust) since its early days and in 1992 helped open their first intensive drug and alcohol rehabilitation unit at Downview (HM Prison), a women's prison in Surrey, England.\nHopkins is an admirer of the late Welsh comedian Tommy Cooper. On 23 February 2008, as patron of the Tommy Cooper Society, he unveiled a commemorative statue in the entertainer's home town of Caerphilly. For the ceremony, he donned Cooper's trademark fez and performed a comic routine."}
{"id": "2398", "revid": "1018130895", "url": "https://en.wikipedia.org/wiki?curid=2398", "title": "Ardal O'Hanlon", "text": "Ardal O'Hanlon (; born 8 October 1965) is an Irish comedian and actor. He played Father Dougal McGuire in \"Father Ted\" (1995-1998), George Sunday/Thermoman in \"My Hero\" (2000-2006), and DI Jack Mooney in \"Death in Paradise\" (2017-2020).\nEarly life.\nO'Hanlon was born on 8 October 1965 in Carrickmacross, County Monaghan, the son of Fianna F\u00e1il TD and doctor Rory O'Hanlon and Teresa (n\u00e9e Ward). He is the third of six children, and has three brothers and two sisters. The episode of \"Who Do You Think You Are?\" which aired on 6 October 2008 revealed that O'Hanlon's paternal grandfather, Michael O'Hanlon, was a medical student at University College Dublin who had joined the Irish Republican Army (IRA) during the Irish War of Independence and was a member of Michael Collins's Squad, which assassinated British secret service agents on the morning of Bloody Sunday. Details of his grandfather's activities survive in UCD Archives, as well as Blackrock College. It also transpired that, on his mother's side, he is a close relative of Peter Fenelon Collier.\nO'Hanlon was schooled in Blackrock College in Dublin and graduated, in 1987, from the National Institute for Higher Education, Dublin (now Dublin City University) with a degree in Communications Studies.\nCareer.\nTogether with Kevin Gildea and Barry Murphy, O'Hanlon founded the International Comedy Cellar, upstairs in the International Bar on Dublin's South Wicklow Street. Dublin had no comedy scene at the time. As a stand up, O'Hanlon won the Hackney Empire New Act of the Year competition in 1994. For a time he was the presenter of \"The Stand Up Show\".\nHe was spotted by Graham Linehan, who was to cast him as Father Dougal McGuire in \"Father Ted\" (1995\u201398). In 1995 he received the Top TV Comedy Newcomer at the British Comedy Awards for this role. In 1995, he appeared (as Father Dougal) in a Channel 4 ident (\"Hello, you're watching... television\"), and during Comic Relief on BBC1. This was followed by the award-winning short comedy film \"Flying Saucer Rock'n'Roll\". In a 2019 interview, O'Hanlon admitted that he had attempted to distance himself from \"Father Ted\" once the show had finished.\nO'Hanlon moved into straight acting alongside Emma Fielding and Beth Goddard in the ITV comedy-drama \"Big Bad World\", which aired for two series in summer 1999 and winter 2001. He also played a minor role in \"The Butcher Boy\" as Joe's (Francie's best friend) father, and appeared in an episode of the original \"Whose Line is it Anyway?\".\nIn 2000, O'Hanlon starred in the comedy series \"My Hero\", in which he played a very naive superhero from the planet Ultron. His character juggled world-saving heroics with life in suburbia. He stayed in the role until the first episode of series 6 in July 2006, when he was replaced by James Dreyfus during the same episode.\nO'Hanlon also provided the voice of the lead character in the three Christmas television cartoon specials of \"Robbie the Reindeer\". He appeared in the 2005 BBC One sitcom \"Blessed\", written by Ben Elton; at the 2005 British Comedy Awards, it was publicly slated by Jonathan Ross, albeit in jest. Towards the end of 2005, he played an eccentric Scottish character, Coconut Tam, in the family based film, \"The Adventures of Greyfriars Bobby\". He has also appeared on radio, including an appearance on \"Quote... Unquote\" on BBC Radio 4 on 18 July 2011. Appropriately, one of his questions concerned a quotation from \"Father Ted\". In 2015 he appeared as incompetent angel Smallbone in the sitcom \"The Best Laid Plans\", on the same channel.\nIn 2006, O'Hanlon wrote and presented an RT\u00c9 television series called \"Leagues Apart\", which saw him investigate the biggest and most passionate football rivalries in a number of European countries. Included were Roma vs Lazio in Italy, Barcelona vs Real Madrid in Spain, and Galatasaray vs Fenerbahce in Turkey. He followed this with another RT\u00c9 show, \"So You Want To Be Taoiseach?\" in 2007. It was a political series in which O'Hanlon gave tongue-in-cheek advice on how to go about becoming Taoiseach of Ireland.\nHe appeared in the \"Doctor Who\" episode \"Gridlock\", broadcast on 14 April 2007, in which he played a cat-like creature named Thomas Kincade Brannigan. O'Hanlon appears in Series 3 of the TV show \"Skins\", playing Naomi Campbell (Lily Loveless)'s Politics teacher named Kieran, who attempted to kiss her. He then went on to form a relationship with Naomi's mother (Olivia Colman). O'Hanlon plays the lead role in Irish comedy television programme \"Val Falvey, TD\" on RT\u00c9 One. He has recently performed in the Edinburgh Fringe.\nIn February 2011, O'Hanlon returned to the Gate Theatre, Dublin starring in the Irish premiere of Christopher Hampton's translation of Yasmina Reza's \"God of Carnage\", alongside Maura Tierney. Later that year, he appeared in the comedy panel show \"Argumental\".\nO'Hanlon has written a novel, \"The Talk of the Town\" (known in the United States as \"Knick Knack Paddy Whack\"), which was published in 1998. The novel is about a teenage boy, Patrick Scully, and his friends.\nIn February 2015 he officially launched the 2015 Sky Cat Laughs Comedy Festival, which took place in Kilkenny from 28 May\u20131 June. In 2015 he played the role of Peter the Milkman in the Sky One sitcom \"After Hours\".\nOn 2 February 2017, it was announced he would play the lead role in the BBC crime drama \"Death in Paradise\" taking the role of DI Jack Mooney following Kris Marshall's departure the same day. He announced his intention to leave the series in early 2020 and was replaced by Ralf Little.\nStand-up.\nO'Hanlon has been doing stand-up comedy for many years, appearing on many shows including Live at the Apollo, Michael McIntyre's Comedy Roadshow and Dave's One Night Stand. In 1994 he won the Hackney Empire New Act of the Year.\nPersonal life.\nO'Hanlon is married to Melanie O'Hanlon, whom he met as a teenager; they have three children: Emily, Rebecca and Red. He is a supporter of Leeds United."}
{"id": "2400", "revid": "1024143998", "url": "https://en.wikipedia.org/wiki?curid=2400", "title": "Advanced Micro Devices", "text": "Advanced Micro Devices, Inc. (AMD) is an American multinational semiconductor company based in Santa Clara, California, that develops computer processors and related technologies for business and consumer markets. While it initially manufactured its own processors, the company later outsourced its manufacturing, a practice known as going fabless, after GlobalFoundries was spun off in 2009. AMD's main products include microprocessors, motherboard chipsets, embedded processors and graphics processors for servers, workstations, personal computers and embedded system applications.\nHistory.\nFirst twelve years.\nAdvanced Micro Devices was formally incorporated by Jerry Sanders, along with seven of his colleagues from Fairchild Semiconductor, on May 1, 1969. Sanders, an electrical engineer who was the director of marketing at Fairchild, had, like many Fairchild executives, grown frustrated with the increasing lack of support, opportunity, and flexibility within the company. He later decided to leave to start his own semiconductor company. Robert Noyce, who had developed the first silicon integrated circuit at Fairchild in 1959, had left Fairchild together with Gordon Moore and founded the semiconductor company Intel in July 1968.\nIn September 1969, AMD moved from its temporary location in Santa Clara to Sunnyvale, California. To immediately secure a customer base, AMD initially became a second source supplier of microchips designed by Fairchild and National Semiconductor. AMD first focused on producing logic chips. The company guaranteed quality control to United States Military Standard, an advantage in the early computer industry since unreliability in microchips was a distinct problem that customers \u2013 including computer manufacturers, the telecommunications industry, and instrument manufacturers \u2013 wanted to avoid.\nIn November 1969, the company manufactured its first product: the Am9300, a 4-bit MSI shift register, which began selling in 1970. Also in 1970, AMD produced its first proprietary product, the Am2501 logic counter, which was highly successful. Its best-selling product in 1971 was the Am2505, the fastest multiplier available.\nIn 1971, AMD entered the RAM chip market, beginning with the Am3101, a 64-bit bipolar RAM. That year AMD also greatly increased the sales volume of its linear integrated circuits, and by year-end the company's total annual sales reached US$4.6 million.\nAMD went public in September 1972. The company was a second source for Intel MOS/LSI circuits by 1973, with products such as Am14/1506 and Am14/1507, dual 100-bit dynamic shift registers. By 1975, AMD was producing 212 products \u2013 of which 49 were proprietary, including the Am9102 (a static N-channel 1024-bit RAM) and three low-power Schottky MSI circuits: Am25LS07, Am25LS08, and Am25LS09.\nIntel had created the first microprocessor, its 4-bit 4004, in 1971. By 1975, AMD entered the microprocessor market with the Am9080, a reverse-engineered clone of the Intel 8080, and the Am2900 bit-slice microprocessor family. When Intel began installing microcode in its microprocessors in 1976, it entered into a cross-licensing agreement with AMD, which was granted a copyright license to the microcode in its microprocessors and peripherals, effective October 1976.\nIn 1977, AMD entered into a joint venture with Siemens, a German engineering conglomerate wishing to enhance its technology expertise and enter the American market. Siemens purchased 20% of AMD's stock, giving the company an infusion of cash to increase its product lines. The two companies also jointly established Advanced Micro Computers (AMC), located in Silicon Valley and in Germany, allowing AMD to enter the microcomputer development and manufacturing field, in particular based on AMD's second-source Zilog Z8000 microprocessors. When the two companies' vision for Advanced Micro Computers diverged, AMD bought out Siemens' stake in the American division in 1979. AMD closed Advanced Micro Computers in late 1981 after switching focus to manufacturing second-source Intel x86 microprocessors.\nTotal sales in fiscal year 1978 topped $100 million, and in 1979, AMD debuted on the New York Stock Exchange. In 1979, production also began on AMD's new semiconductor fabrication plant in Austin, Texas; the company already had overseas assembly facilities in Penang and Manila, and began construction on a fabrication plant in San Antonio in 1981. In 1980, AMD began supplying semiconductor products for telecommunications, an industry undergoing rapid expansion and innovation.\nTechnology exchange agreement with Intel.\nIntel had introduced the first x86 microprocessors in 1978. In 1981, IBM created its PC, and wanted Intel's x86 processors, but only under the condition that Intel also provide a second-source manufacturer for its patented x86 microprocessors. Intel and AMD entered into a 10-year technology exchange agreement, first signed in October 1981 and formally executed in February 1982. The terms of the agreement were that each company could acquire the right to become a second-source manufacturer of semiconductor products developed by the other; that is, each party could \"earn\" the right to manufacture and sell a product developed by the other, if agreed to, by exchanging the manufacturing rights to a product of equivalent technical complexity. The technical information and licenses needed to make and sell a part would be exchanged for a royalty to the developing company. The 1982 agreement also extended the 1976 AMD\u2013Intel cross-licensing agreement through 1995. The agreement included the right to invoke arbitration of disagreements, and after five years the right of either party to end the agreement with one year's notice. The main result of the 1982 agreement was that AMD became a second-source manufacturer of Intel's x86 microprocessors and related chips, and Intel provided AMD with database tapes for its 8086, 80186, and 80286 chips. However, in the event of a bankruptcy or takeover of AMD, the cross-licensing agreement would be effectively cancelled.\nBeginning in 1982, AMD began volume-producing second-source Intel-licensed 8086, 8088, 80186, and 80188 processors, and by 1984, its own Am286 clone of Intel's 80286 processor, for the rapidly growing market of IBM PCs and IBM clones. It also continued its successful concentration on proprietary bipolar chips. In 1983, it introduced INT.STD.1000, the highest manufacturing quality standard in the industry.\nThe company continued to spend greatly on research and development, and in addition to other breakthrough products, created the world's first 512K EPROM in 1984. That year, AMD was listed in the book \"The 100 Best Companies to Work for in America\", and later made the \"Fortune\" 500 list for the first time in 1985.\nBy mid-1985, the microchip market experienced a severe downturn, mainly due to long-term aggressive trade practices (dumping) from Japan, but also due to a crowded and non-innovative chip market in the United States. AMD rode out the mid-1980s crisis by aggressively innovating and modernizing, devising the Liberty Chip program of designing and manufacturing one new chip or chipset per week for 52 weeks in fiscal year 1986, and by heavily lobbying the U.S. government until sanctions and restrictions were put in place to prevent predatory Japanese pricing. During this time, AMD withdrew from the DRAM market, and made some headway into the CMOS market, which it had lagged in entering, having focused instead on bipolar chips.\nAMD had some success in the mid-1980s with the AMD7910 and AMD7911 \"World Chip\" FSK modem, one of the first multi-standard devices that covered both Bell and CCITT tones at up to 1200 baud half duplex or 300/300 full duplex. Beginning in 1986, AMD embraced the perceived shift toward RISC with their own AMD Am29000 (29k) processor; the 29k survived as an embedded processor. The company also increased its EPROM memory market share in the late 1980s. Throughout the 1980s, AMD was a second-source supplier of Intel x86 processors. In 1991, it introduced its own 386-compatible Am386, an AMD-designed chip. Creating its own chips, AMD began to compete directly with Intel.\nAMD had a large, successful flash memory business, even during the dotcom bust. In 2003, to divest some manufacturing and aid its overall cash flow, which was under duress from aggressive microprocessor competition from Intel, AMD spun off its flash memory business and manufacturing into Spansion, a joint venture with Fujitsu, which had been co-manufacturing flash memory with AMD since 1993. In December 2005, AMD divested itself of Spansion in order to focus on the microprocessor market, and Spansion went public in an IPO.\nAcquisition of ATI, spin-off of GlobalFoundries, and acquisition of Xilinx.\nOn July 24, 2006, AMD announced its acquisition of the graphics processor company ATI Technologies. AMD paid $4.3\u00a0billion and 58\u00a0million shares of its stock, for a total of approximately $5.4\u00a0billion. The transaction was completed on October 25, 2006. On August 30, 2010, AMD announced that it would retire the ATI brand name for its graphics chipsets in favor of the AMD brand name.\nIn October 2008, AMD announced plans to spin off manufacturing operations in the form of GlobalFoundries Inc., a multibillion-dollar joint venture with Advanced Technology Investment Co., an investment company formed by the government of Abu Dhabi. The partnership and spin-off gave AMD an infusion of cash and allowed it to focus solely on chip design. To assure the Abu Dhabi investors of the new venture's success, AMD's CEO Hector Ruiz stepped down in July 2008, while remaining executive chairman, in preparation for becoming chairman of GlobalFoundries in March 2009. President and COO Dirk Meyer became AMD's CEO. Recessionary losses necessitated AMD cutting 1,100 jobs in 2009.\nIn August 2011, AMD announced that former Lenovo executive Rory Read would be joining the company as CEO, replacing Meyer. In November 2011, AMD announced plans to lay off more than 10% (1,400) of its employees from across all divisions worldwide. In October 2012, it announced plans to lay off an additional 15% of its workforce to reduce costs in the face of declining sales revenue.\nAMD acquired the low-power server manufacturer SeaMicro in early 2012, with an eye to bringing out an ARM architecture server chip.\nOn October 8, 2014, AMD announced that Rory Read had stepped down after three years as president and chief executive officer. He was succeeded by Lisa Su, a key lieutenant who had been serving as chief operating officer since June.\nOn October 16, 2014, AMD announced a new restructuring plan along with its Q3 results. Effective July 1, 2014, AMD reorganized into two business groups: Computing and Graphics, which primarily includes desktop and notebook processors and chipsets, discrete GPUs, and professional graphics; and Enterprise, Embedded, and Semi-Custom, which primarily includes server and embedded processors, dense servers, semi-custom SoC products (including solutions for gaming consoles), engineering services, and royalties. As part of this restructuring, AMD announced that 7% of its global workforce would be laid off by the end of 2014.\nAfter the GlobalFoundries spin-off and subsequent layoffs, AMD was left with significant vacant space at 1 AMD Place, its aging Sunnyvale headquarters office complex. In August 2016, AMD's 47 years in Sunnyvale came to a close when it signed a lease with the Irvine Company for a new 220,000 sq. ft. headquarters building in Santa Clara. AMD's new location at Santa Clara Square faces the headquarters of archrival Intel across the Bayshore Freeway and San Tomas Aquino Creek. Around the same time, AMD also agreed to sell 1 AMD Place to the Irvine Company. In April 2019, the Irvine Company secured approval from the Sunnyvale City Council of its plans to demolish 1 AMD Place and redevelop the entire 32-acre site into townhomes and apartments.\nIn October 2020, AMD announced that it was acquiring Xilinx in an all-stock transaction valued at $35 billion. The deal is expected to be completed by the end of 2021.\nProducts.\nCPUs and APUs.\nIBM PC and the x86 architecture.\nIn February 1982, AMD signed a contract with Intel, becoming a licensed second-source manufacturer of 8086 and 8088 processors. IBM wanted to use the Intel 8088 in its IBM PC, but its policy at the time was to require at least two sources for its chips. AMD later produced the Am286 under the same arrangement. In 1984, Intel internally decided to no longer cooperate with AMD in supplying product information in order to shore up its advantage in the marketplace, and delayed and eventually refused to convey the technical details of the Intel 80386. In 1987, AMD invoked arbitration over the issue, and Intel reacted by canceling the 1982 technological-exchange agreement altogether. After three years of testimony, AMD eventually won in arbitration in 1992, but Intel disputed this decision. Another long legal dispute followed, ending in 1994 when the Supreme Court of California sided with the arbitrator and AMD.\nIn 1990, Intel countersued AMD, renegotiating AMD's right to use derivatives of Intel's microcode for its cloned processors. In the face of uncertainty during the legal dispute, AMD was forced to develop clean room designed versions of Intel code for its x386 and x486 processors, the former long after Intel had released its own x386 in 1985. In March 1991, AMD released the Am386, its clone of the Intel 386 processor. By October of the same year it had sold one million units.\nIn 1993, AMD introduced the first of the Am486 family of processors, which proved popular with a large number of original equipment manufacturers, including Compaq, which signed an exclusive agreement using the Am486. The Am5x86, another Am486-based processor, was released in November 1995, and continued AMD's success as a fast, cost-effective processor.\nFinally, in an agreement effective 1996, AMD received the rights to the microcode in Intel's x386 and x486 processor families, but not the rights to the microcode in the following generations of processors.\nK5, K6, Athlon, Duron, and Sempron.\nAMD's first in-house x86 processor was the K5, launched in 1996. The \"K\" in its name was a reference to Kryptonite, the only substance which known to harm comic book character Superman. This itself was a reference to Intel's hegemony over the market, i.e., an anthropomorphization of them as Superman. The number \"5\" was a reference to the fifth generation of x86 processors; rival Intel had previously introduced its line of fifth-generation x86 processors as Pentium because the U.S. Trademark and Patent Office had ruled that mere numbers could not be trademarked.\nIn 1996, AMD purchased NexGen, specifically for the rights to their Nx series of x86-compatible processors. AMD gave the NexGen design team their own building, left them alone, and gave them time and money to rework the Nx686. The result was the K6 processor, introduced in 1997. Although it was based on Socket 7, variants such as K6-3/450 were faster than Intel's Pentium II (sixth-generation processor).\nThe K7 was AMD's seventh-generation x86 processor, making its debut under the brand name Athlon on June 23, 1999. Unlike previous AMD processors, it could not be used on the same motherboards as Intel's, due to licensing issues surrounding Intel's Slot 1 connector, and instead used a Slot A connector, referenced to the Alpha processor bus. The Duron was a lower-cost and limited version of the Athlon (64KB instead of 256KB L2 cache) in a 462-pin socketed PGA (socket A) or soldered directly onto the motherboard. Sempron was released as a lower-cost Athlon XP, replacing Duron in the socket A PGA era. It has since been migrated upward to all new sockets, up to AM3.\nOn October 9, 2001, the Athlon XP was released. On February 10, 2003, the Athlon XP with 512KB L2 Cache was released.\nAthlon 64, Opteron and Phenom.\nThe K8 was a major revision of the K7 architecture, with the most notable features being the addition of a 64-bit extension to the x86 instruction set (called x86-64, AMD64, or x64), the incorporation of an on-chip memory controller, and the implementation of an extremely high performance point-to-point interconnect called HyperTransport, as part of the Direct Connect Architecture. The technology was initially launched as the Opteron server-oriented processor on April 22, 2003. Shortly thereafter, it was incorporated into a product for desktop PCs, branded Athlon 64.\nOn April 21, 2005, AMD released the first dual core Opteron, an x86-based server CPU. A month later, it released the Athlon 64 X2, the first desktop-based dual core processor family. In May 2007, AMD abandoned the string \"64\" in its dual-core desktop product branding, becoming Athlon X2, downplaying the significance of 64-bit computing in its processors. Further updates involved improvements to the microarchitecture, and a shift of the target market from mainstream desktop systems to value dual-core desktop systems. In 2008, AMD started to release dual-core Sempron processors exclusively in China, branded as the Sempron 2000 series, with lower HyperTransport speed and smaller L2 cache. AMD completed its dual-core product portfolio for each market segment.\nIn September 2007, AMD released the first server Opteron K10 processors, followed in November by the Phenom processor for desktop. K10 processors came in dual-core, triple-core, and quad-core versions, with all cores on a single die. AMD released a new platform codenamed \"Spider\", which utilized the new Phenom processor, as well as an R770 GPU and a 790 GX/FX chipset from the AMD 700 chipset series. However, AMD built the Spider at 65nm, which was uncompetitive with Intel's smaller and more power-efficient 45nm.\nIn January 2009, AMD released a new processor line dubbed Phenom II, a refresh of the original Phenom built using the 45\u00a0nm process. AMD's new platform, codenamed \"Dragon\", utilized the new Phenom II processor, and an ATI R770 GPU from the R700 GPU family, as well as a 790 GX/FX chipset from the AMD 700 chipset series. The Phenom II came in dual-core, triple-core and quad-core variants, all using the same die, with cores disabled for the triple-core and dual-core versions. The Phenom II resolved issues that the original Phenom had, including a low clock speed, a small L3 cache, and a Cool'n'Quiet bug that decreased performance. The Phenom II cost less but was not performance-competitive with Intel's mid-to-high-range Core 2 Quads. The Phenom II also enhanced its predecessor's memory controller, allowing it to use DDR3 in a new native socket AM3, while maintaining backward compatibility with AM2+, the socket used for the Phenom, and allowing the use of the DDR2 memory that was used with the platform.\nIn April 2010, AMD released a new Phenom II Hexa-core (6-core) processor codenamed \"Thuban\". This was a totally new die based on the hexa-core \"Istanbul\" Opteron processor. It included AMD's \"turbo core\" technology, which allows the processor to automatically switch from 6 cores to 3 faster cores when more pure speed is needed.\nThe Magny Cours and Lisbon server parts were released in 2010. The Magny Cours part came in 8 to 12\u00a0cores and the Lisbon part in 4 and 6\u00a0core parts. Magny Cours is focused on performance while the Lisbon part is focused on high performance per watt. Magny Cours is an MCM (multi-chip module) with two hexa-core \"Istanbul\" Opteron parts. This will use a new G34 socket for dual and quad-socket processors and thus will be marketed as Opteron 61xx series processors. Lisbon uses C32 socket certified for dual-socket use or single socket use only and thus will be marketed as Opteron 41xx processors. Both will be built on a 45 nm SOI process.\nFusion becomes the AMD APU.\nFollowing AMD's 2006 acquisition of Canadian graphics company ATI Technologies, an initiative codenamed \"Fusion\" was announced to integrate a CPU and GPU together on some of AMD's microprocessors, including a built in PCI Express link to accommodate separate PCI Express peripherals, eliminating the northbridge chip from the motherboard. The initiative intended to move some of the processing originally done on the CPU (e.g. floating-point unit operations) to the GPU, which is better optimized for some calculations. The Fusion was later renamed the AMD APU (Accelerated Processing Unit).\nLlano was AMD's first APU built for laptops. Llano was the second APU released, targeted at the mainstream market. It incorporated a CPU and GPU on the same die, as well as northbridge functions, and used \"Socket FM1\" with DDR3 memory. The CPU part of the processor was based on the Phenom II \"Deneb\" processor. AMD suffered an unexpected decrease in revenue based on production problems for the Llano.\nNew microarchitectures.\nHigh-power, high-performance Bulldozer cores.\nBulldozer was AMD's microarchitecture codename for server and desktop AMD FX processors, first released on October 12, 2011. This family 15h microarchitecture is the successor to the family 10h (K10) microarchitecture design. Bulldozer was a clean-sheet design, not a development of earlier processors. The core was specifically aimed at 10\u2013125\u00a0W TDP computing products. AMD claimed dramatic performance-per-watt efficiency improvements in high-performance computing (HPC) applications with Bulldozer cores. While hopes were high that Bulldozer would bring AMD to be performance-competitive with Intel once more, most benchmarks were disappointing. In some cases the new Bulldozer products were slower than the K10 models they were built to replace.\nThe Piledriver microarchitecture was the 2012 successor to Bulldozer, increasing clock speeds and performance relative to its predecessor. Piledriver would be released in AMD FX, APU, and Opteron product lines. Piledriver was subsequently followed by the Steamroller microarchitecture in 2013. Used exclusively in AMD's APUs, Steamroller focused on greater parallelism.\nIn 2015, the Excavator microarchitecture replaced Piledriver. Expected to be the last microarchitecture of the Bulldozer series, Excavator focused on improved power efficiency.\nLow-power Cat cores.\nThe Bobcat microarchitecture was revealed during a speech from AMD executive vice-president Henri Richard in Computex 2007 and was put into production during the first quarter of 2011. Based on the difficulty competing in the x86 market with a single core optimized for the 10\u2013100\u00a0W range, AMD had developed a simpler core with a target range of 1\u201310\u00a0watts. In addition, it was believed that the core could migrate into the hand-held space if the power consumption can be reduced to less than 1\u00a0W.\nJaguar is a microarchitecture codename for Bobcat's successor, released in 2013, that is used in various APUs from AMD aimed at the low-power/low-cost market. Jaguar and its derivates would go on to be used in the custom APUs of the PlayStation 4, Xbox One, PlayStation 4 Pro, Xbox One S, and Xbox One X. Jaguar would be later followed by the Puma microarchitecture in 2014.\nARM architecture-based designs.\nIn 2012, AMD announced it was working on an ARM architecture products, both as a semi-custom product and server product. The initial server product was announced as the Opteron A1100 in 2014, and 8-core Cortex-A57 based ARMv8-A SoC, and was expected to be followed by an APU incorporating a Graphic Core Next GPU. However, the Opteron A1100 was not released until 2016, with the delay attributed to adding software support. The A1100 was also criticized for not having support from major vendors upon its release.\nIn 2014, AMD also announced the K12 custom core for release in 2016. While being ARMv8-A instruction set architecture compliant, the K12 is expected to be entirely custom designed targeting server, embedded, and semi-custom markets. While ARM architecture development continued, products based on K12 were subsequently delayed with no release planned, in preference to the development of AMD's x86 based Zen microarchitecture.\nZen based CPUs and APUs.\nZen is a new architecture for x86-64 based Ryzen series CPUs and APUs, introduced in 2017 by AMD and built from the ground up by a team led by Jim Keller, beginning with his arrival in 2012, and taping out before his departure in September 2015. One of AMD's primary goals with Zen was an IPC increase of at least 40%, however in February 2017 AMD announced that they had actually achieved a 52% increase. Processors made on the Zen architecture are built on the 14\u00a0nm FinFET node and have a renewed focus on single-core performance and HSA compatibility. Previous processors from AMD were either built in the 32\u00a0nm process (\"Bulldozer\" and \"Piledriver\" CPUs) or the 28\u00a0nm process (\"Steamroller\" and \"Excavator\" APUs). Because of this, Zen is much more energy efficient. The Zen architecture is the first to encompass CPUs and APUs from AMD built for a single socket (Socket AM4). Also new for this architecture is the implementation of simultaneous multithreading (SMT) technology, something Intel has had for years on some of their processors with their proprietary Hyper-Threading implementation of SMT. This is a departure from the \"Clustered MultiThreading\" design introduced with the Bulldozer architecture. Zen also has support for DDR4 memory. AMD released the Zen-based high-end Ryzen 7 \"Summit Ridge\" series CPUs on March 2, 2017, mid-range Ryzen 5 series CPUs on April 11, 2017, and entry level Ryzen 3 series CPUs on July 27, 2017. AMD later released the Epyc line of Zen derived server processors for 1P and 2P systems. In October 2017, AMD released Zen based APUs as Ryzen Mobile, incorporating Vega graphics cores. In January 2018 AMD has announced their new lineup plans, with Ryzen 2. AMD launched CPUs with the 12nm Zen+ microarchitecture in April 2018, following up with the 7nm Zen 2 microarchitecture in June 2019, including an update to the Epyc line with new processors using the Zen 2 microarchitecture in August 2019, and Zen 3 slated for release in Q3 2020. As of 2019, AMD's Ryzen processors were reported to outsell Intel's consumer desktop processors. At CES 2020 AMD announced their Ryzen Mobile 4000, as the first 7\u00a0nm x86 mobile processor, the first 7\u00a0nm 8-core (also 16-thread) high performance mobile processor, and the first 8-core (also 16-thread) processor for ultrathin laptops. This generation is still based on the Zen 2 architecture. In October 2020 AMD announced their Zen 3 CPU. On PassMark's Single thread performance test the Ryzen 5 5600x bested all other CPUs besides the Ryzen 9 5950X.\nBoth the PlayStation 5 and the Xbox Series X and Series S use chips based on the Zen 2 microarchitecture, with proprietary tweaks and different configurations in each system's implementation than AMD sells in its own commercially available APUs.\nGraphics products and GPUs.\nRadeon within AMD.\nIn 2008, the ATI division of AMD released the TeraScale microarchitecture implementing a unified shader model. This design replaced the previous fixed-function hardware of previous graphics cards with multipurpose, programmable shaders. Initially released as part of the GPU for the Xbox 360, this technology would go on to be used in Radeon branded HD 2000 parts. Three generations of TeraScale would be designed and used in parts from 2008 to 2014.\nCombined GPU and CPU divisions.\nIn a 2009 restructuring, AMD merged the CPU and GPU divisions to support the company's APUs, which fused both graphics and general purpose processing. In 2011, AMD released the successor to TeraScale, Graphics Core Next (GCN). This new microarchitecture emphasized GPGPU compute capability in addition to graphics processing, with a particular aim of supporting heterogeneous computing on AMD's APUs. GCN's reduced instruction set ISA allowed for significantly increased compute capability over TeraScale's very long instruction word ISA. Since GCN's introduction with the HD 7970, five generations of the GCN architecture have been produced from 2008 through at least 2017.\nRadeon Technologies Group.\nIn September 2015, AMD separated the graphics technology division of the company into an independent internal unit called the Radeon Technologies Group (RTG) headed by Raja Koduri. This gave the graphics division of AMD autonomy in product design and marketing. The RTG then went on to create and release the Polaris and Vega microarchitectures released in 2016 and 2017, respectively. In particular the Vega, or 5th generation GCN, microarchitecture includes a number of major revisions to improve performance and compute capabilities.\nIn November 2017, Raja Koduri left RTG and CEO and President Lisa Su took his position. In January 2018, it was reported that two industry veterans joined RTG, namely Mike Rayfield as senior vice president and general manager of RTG, and David Wang as senior vice president of engineering for RTG. In January 2020, AMD announced that its second generation RDNA graphics architecture was in development, with the aim of competing with the Nvidia RTX graphics products for performance leadership. In October 2020, AMD announced their new RX 6000 series series GPUs, their first high end product based on RDNA2 and capable of handling ray-tracing natively, aiming to challenge Nvidia's RTX 3000 GPUs.\nSemi-custom and game console products.\nIn 2012, AMD's then CEO Rory Read began a program to offer semi-custom designs. Rather than AMD simply designing and offering a single product, potential customers could work with AMD to design a custom chip based on AMD's intellectual property. Customers pay a non-recurring engineering fee for design and development, and a purchase price for the resulting semi-custom products. In particular, AMD noted their unique position of offering both x86 and graphics intellectual property. These semi-custom designs would have design wins as the APUs in the PlayStation 4 and Xbox One and the subsequent PlayStation 4 Pro, Xbox One S, Xbox One X, Xbox Series and PlayStation 5. Financially, these semi-custom products would represent a majority of the company's revenue in 2016. In November 2017, AMD and Intel announced that Intel would market a product combining in a single package an Intel Core CPU, a semi-custom AMD Radeon GPU, and HBM2 memory.\nOther hardware.\nAMD motherboard chipsets.\nBefore the launch of Athlon 64 processors in 2003, AMD designed chipsets for their processors spanning the K6 and K7 processor generations. The chipsets include the AMD-640, AMD-751, and the AMD-761 chipsets. The situation changed in 2003 with the release of Athlon 64 processors, and AMD chose not to further design its own chipsets for its desktop processors while opening the desktop platform to allow other firms to design chipsets. This was the \"Open Platform Management Architecture\" with ATI, VIA and SiS developing their own chipset for Athlon 64 processors and later Athlon 64 X2 and Athlon 64 FX processors, including the Quad FX platform chipset from Nvidia.\nThe initiative went further with the release of Opteron server processors as AMD stopped the design of server chipsets in 2004 after releasing the AMD-8111 chipset, and again opened the server platform for firms to develop chipsets for Opteron processors. As of today , Nvidia and Broadcom are the sole designing firms of server chipsets for Opteron processors.\nAs the company completed the acquisition of ATI Technologies in 2006, the firm gained the ATI design team for chipsets which previously designed the Radeon Xpress 200 and the Radeon Xpress 3200 chipsets. AMD then renamed the chipsets for AMD processors under AMD branding (for instance, the CrossFire Xpress 3200 chipset was renamed as AMD 580X CrossFire chipset). In February 2007, AMD announced the first AMD-branded chipset since 2004 with the release of the AMD 690G chipset (previously under the development codename \"RS690\"), targeted at mainstream IGP computing. It was the industry's first to implement a HDMI 1.2 port on motherboards, shipping for more than a million units. While ATI had aimed at releasing an Intel IGP chipset, the plan was scrapped and the inventories of Radeon Xpress 1250 (codenamed \"RS600\", sold under ATI brand) was sold to two OEMs, Abit and ASRock. Although AMD stated the firm would still produce Intel chipsets, Intel had not granted the license of FSB to ATI.\nOn November 15, 2007, AMD announced a new chipset series portfolio, the AMD 7-Series chipsets, covering from the enthusiast multi-graphics segment to the value IGP segment, to replace the AMD 480/570/580 chipsets and AMD 690 series chipsets, marking AMD's first enthusiast multi-graphics chipset. Discrete graphics chipsets were launched on November 15, 2007, as part of the codenamed \"Spider\" desktop platform, and IGP chipsets were launched at a later time in spring 2008 as part of the codenamed \"Cartwheel\" platform.\nAMD returned to the server chipsets market with the AMD 800S series server chipsets. It includes support for up to six SATA 6.0 Gbit/s ports, the C6 power state, which is featured in Fusion processors and AHCI 1.2 with SATA FIS\u2013based switching support. This is a chipset family supporting Phenom processors and Quad FX enthusiast platform (890FX), IGP (890GX).\nWith the advent of AMD's APUs in 2011, traditional northbridge features such as the connection to graphics and the PCI Express controller were incorporated into the APU die. Accordingly, APUs were connected to a single chip chipset, renamed the Fusion Controller Hub (FCH), which primarily provided southbridge functionality.\nAMD released new chipsets in 2017 to support the release of their new Ryzen products. As the Zen microarchitecture already includes much of the northbridge connectivity, the AM4 based chipsets primarily varied in the number of additional PCI Express lanes, USB connections, and SATA connections available. These AM4 chipsets were designed in conjunction with ASMedia.\nEmbedded products.\nEmbedded CPUs.\nIn February 2002, AMD acquired Alchemy Semiconductor for its Alchemy line of MIPS processors for the hand-held and portable media player markets. On June 13, 2006, AMD officially announced that the line was to be transferred to Raza Microelectronics, Inc., a designer of MIPS processors for embedded applications.\nIn August 2003, AMD also purchased the Geode business which was originally the Cyrix MediaGX from National Semiconductor to augment its existing line of embedded x86 processor products. During the second quarter of 2004, it launched new low-power Geode NX processors based on the K7 Thoroughbred architecture with speeds of fanless processors and , and processor with fan, of TDP 25\u00a0W. This technology is used in a variety of embedded systems (Casino slot machines and customer kiosks for instance), several UMPC designs in Asia markets, as well as the OLPC XO-1 computer, an inexpensive laptop computer intended to be distributed to children in developing countries around the world. The Geode LX processor was announced in 2005 and is said will continue to be available through 2015.\nAMD has also introduced 64-bit processors into its embedded product line starting with the AMD Opteron processor. Leveraging the high throughput enabled through HyperTransport and the Direct Connect Architecture these server-class processors have been targeted at high-end telecom and storage applications. In 2007, AMD added the AMD Athlon, AMD Turion, and Mobile AMD Sempron processors to its embedded product line. Leveraging the same 64-bit instruction set and Direct Connect Architecture as the AMD Opteron but at lower power levels, these processors were well suited to a variety of traditional embedded applications. Throughout 2007 and into 2008, AMD has continued to add both single-core Mobile AMD Sempron and AMD Athlon processors and dual-core AMD Athlon X2 and AMD Turion processors to its embedded product line and now offers embedded 64-bit solutions starting with 8W TDP Mobile AMD Sempron and AMD Athlon processors for fan-less designs up to multi-processor systems leveraging multi-core AMD Opteron processors all supporting longer than standard availability.\nThe ATI acquisition in 2006 included the Imageon and Xilleon product lines. In late 2008, the entire handheld division was sold off to Qualcomm, who have since produced the Adreno series. Also in 2008, the Xilleon division was sold to Broadcom.\nIn April 2007, AMD announced the release of the M690T integrated graphics chipset for embedded designs. This enabled AMD to offer complete processor and chipset solutions targeted at embedded applications requiring high-performance 3D and video such as emerging digital signage, kiosk, and Point of Sale applications. The M690T was followed by the M690E specifically for embedded applications which removed the TV output, which required Macrovision licensing for OEMs, and enabled native support for dual TMDS outputs, enabling dual independent DVI interfaces.\nIn January 2011, AMD announced the AMD Embedded G-Series Accelerated Processing Unit. This was the first APU for embedded applications. These were followed by updates in 2013 and 2016.\nIn May 2012, AMD Announced the AMD Embedded R-Series Accelerated Processing Unit. This family of products incorporates the Bulldozer CPU architecture, and Discrete-class Radeon HD 7000G Series graphics. This was followed by a system on a chip (SoC) version in 2015 which offered a faster CPU and faster graphics, with support for DDR4 SDRAM memory.\nEmbedded graphics.\nAMD builds graphic processors for use in embedded systems. They can be found in anything from casinos to healthcare, with a large portion of products being used in industrial machines. These products include a complete graphics processing device in a compact multi-chip module including RAM and the GPU. ATI began offering embedded GPUs with the E2400 in 2008. Since that time AMD has released regular updates to their embedded GPU lineup in 2009, 2011, 2015, and 2016; reflecting improvements in their GPU technology.\nCurrent product lines.\nCPU and APU products.\nAMD's portfolio of CPUs and APUs \nGraphics products.\nAMD's portfolio of dedicated graphics processors \nRadeon-branded products.\nRAM.\nIn 2011, AMD began selling Radeon branded DDR3 SDRAM to support the higher bandwidth needs of AMD's APUs. While the RAM is sold by AMD, it was manufactured by Patriot Memory and VisionTek. This was later followed by higher speeds of gaming oriented DDR3 memory in 2013. Radeon branded DDR4 SDRAM memory was released in 2015, despite no AMD CPUs or APUs supporting DDR4 at the time. AMD noted in 2017 that these products are \"mostly distributed in Eastern Europe\" and that it continues to be active in the business.\nSolid-state drives.\nAMD announced in 2014 it would sell Radeon branded solid-state drives manufactured by OCZ with capacities up to 480 GB and using the SATA interface. This was followed in 2016 by updated drives of up to 960 GB, with M.2/NVMe drives expected later.\nTechnologies.\nCPU technologies.\n technologies found in AMD CPU/APU products include:\nGraphics technologies.\n technologies found in AMD GPU products include:\nProduction and fabrication.\nPreviously, AMD produced its chips at company-owned semiconductor foundries. AMD pursued a strategy of collaboration with other semiconductor manufacturers IBM and Motorola to co-develop production technologies. AMD's founder Jerry Sanders termed this the \"Virtual Gorilla\" strategy to compete with Intel's significantly greater investments in fabrication.\nIn 2008, AMD spun off its chip foundries into an independent company named GlobalFoundries. This break-up of the company was attributed to the increasing costs of each process node. The Emirate of Abu Dhabi purchased the newly created company through its subsidiary Advanced Technology Investment Company (ATIC), purchasing the final stake from AMD in 2009.\nWith the spin-off of its foundries, AMD became a fabless semiconductor manufacturer, designing products to be produced at for-hire foundries. Part of the GlobalFoundries spin-off included an agreement with AMD to produce some number of products at GlobalFoundries. Both prior to the spin-off and after AMD has pursued production with other foundries including TSMC and Samsung. It has been argued that this would reduce risk for AMD by decreasing dependence on any one foundry which has caused issues in the past.\nIn 2018, AMD started shifting the production of their CPUs and GPUs to TSMC, following GlobalFoundries' announcement that they were halting development of their 7 nm process. AMD revised their wafer purchase requirement with GlobalFoundries in 2019, allowing AMD to freely choose foundries for 7\u00a0nm nodes and below, while maintaining purchase agreements for 12\u00a0nm and above through 2021.\nCorporate affairs.\nPartnerships.\nAMD utilizes strategic industry partnerships to further its business interests as well as to rival Intel's dominance and resources:\nLitigation with Intel.\nAMD has a long history of litigation with former (and current) partner and x86 creator Intel."}
{"id": "2402", "revid": "735741", "url": "https://en.wikipedia.org/wiki?curid=2402", "title": "Albrecht D\u00fcrer", "text": "Albrecht D\u00fcrer (; ; 21 May 1471 \u2013 6 April 1528), sometimes spelled in English as Durer or Duerer (without an umlaut), was a German painter, printmaker, and theorist of the German Renaissance. Born in Nuremberg, D\u00fcrer established his reputation and influence across Europe in his twenties due to his high-quality woodcut prints. He was in contact with the major Italian artists of his time, including Raphael, Giovanni Bellini and Leonardo da Vinci, and from 1512 was patronized by Emperor Maximilian I. \nD\u00fcrer's vast body of work includes engravings, his preferred technique in his later prints, altarpieces, portraits and self-portraits, watercolours and books. The woodcuts series are more Gothic than the rest of his work. His well-known engravings include the three \"Meisterstiche\" (master prints) \"Knight, Death and the Devil\" (1513), \"Saint Jerome in his Study\" (1514) and \"Melencolia I\" (1514). His watercolours mark him as one of the first European landscape artists, while his woodcuts revolutionized the potential of that medium.\nD\u00fcrer's introduction of classical motifs into Northern art, through his knowledge of Italian artists and German humanists, has secured his reputation as one of the most important figures of the Northern Renaissance. This is reinforced by his theoretical treatises, which involve principles of mathematics, perspective, and ideal proportions.\nBiography.\nEarly life (1471\u20131490).\nD\u00fcrer was born on 21 May 1471, the third child and second son of Albrecht D\u00fcrer the Elder and Barbara Holper, who married in 1467 and had eighteen children together. Albrecht D\u00fcrer the Elder (originally Albrecht Ajt\u00f3si), was a successful goldsmith who by 1455 had moved to Nuremberg from Ajt\u00f3s, near Gyula in Hungary. He married Holper, his master's daughter, when he himself qualified as a master. One of Albrecht's brothers, Hans D\u00fcrer, was also a painter and trained under him. Another of Albrecht's brothers, Endres D\u00fcrer, took over their father's business and was a master goldsmith. The German name \"D\u00fcrer\" is a translation from the Hungarian, \"Ajt\u00f3si\". Initially, it was \"T\u00fcrer\", meaning doormaker, which is \"ajt\u00f3s\" in Hungarian (from \"ajt\u00f3\", meaning door). A door is featured in the coat-of-arms the family acquired. Albrecht D\u00fcrer the Younger later changed \"T\u00fcrer\", his father's diction of the family's surname, to \"D\u00fcrer\", to adapt to the local Nuremberg dialect.\nD\u00fcrer's godfather Anton Koberger left goldsmithing to become a printer and publisher in the year of D\u00fcrer's birth. He became the most successful publisher in Germany, eventually owning twenty-four printing-presses and a number of offices in Germany and abroad. Koberger's most famous publication was the \"Nuremberg Chronicle\", published in 1493 in German and Latin editions. It contained an unprecedented 1,809 woodcut illustrations (albeit with many repeated uses of the same block) by the Wolgemut workshop. D\u00fcrer may have worked on some of these, as the work on the project began while he was with Wolgemut.\nBecause D\u00fcrer left autobiographical writings and was widely known by his mid-twenties, his life is well documented in several sources. After a few years of school, D\u00fcrer learned the basics of goldsmithing and drawing from his father. Though his father wanted him to continue his training as a goldsmith, he showed such a precocious talent in drawing that he started as an apprentice to Michael Wolgemut at the age of fifteen in 1486. A self-portrait, a drawing in silverpoint, is dated 1484 (Albertina, Vienna) \"when I was a child\", as his later inscription says. Wolgemut was the leading artist in Nuremberg at the time, with a large workshop producing a variety of works of art, in particular woodcuts for books. Nuremberg was then an important and prosperous city, a centre for publishing and many luxury trades. It had strong links with Italy, especially Venice, a relatively short distance across the Alps.\n\"Wanderjahre\" and marriage (1490\u20131494).\nAfter completing his apprenticeship, D\u00fcrer followed the common German custom of taking \"Wanderjahre\"\u2014in effect gap years\u2014in which the apprentice learned skills from artists in other areas; D\u00fcrer was to spend about four years away. He left in 1490, possibly to work under Martin Schongauer, the leading engraver of Northern Europe, but who died shortly before D\u00fcrer's arrival at Colmar in 1492. It is unclear where D\u00fcrer travelled in the intervening period, though it is likely that he went to Frankfurt and the Netherlands. In Colmar, D\u00fcrer was welcomed by Schongauer's brothers, the goldsmiths Caspar and Paul and the painter Ludwig. In 1493 D\u00fcrer went to Strasbourg, where he would have experienced the sculpture of Nikolaus Gerhaert. D\u00fcrer's first painted self-portrait (now in the Louvre) was painted at this time, probably to be sent back to his fianc\u00e9e in Nuremberg.\nIn early 1492 D\u00fcrer travelled to Basel to stay with another brother of Martin Schongauer, the goldsmith Georg. Very soon after his return to Nuremberg, on 7 July 1494, at the age of 23, D\u00fcrer was married to Agnes Frey following an arrangement made during his absence. Agnes was the daughter of a prominent brass worker (and amateur harpist) in the city. However, no children resulted from the marriage, and with Albrecht the D\u00fcrer name died out. The marriage between Agnes and Albrecht was not a generally happy one, as indicated by the letters of D\u00fcrer in which he quipped to Willibald Pirckheimer in an extremely rough tone about his wife. He called her an \"old crow\" and made other vulgar remarks. Pirckheimer also made no secret of his antipathy towards Agnes, describing her as a miserly shrew with a bitter tongue, who helped cause D\u00fcrer's death at a young age. One author speculates that Albrecht was bisexual, if not homosexual, due to several of his works containing themes of homosexual desire, as well as the intimate nature of his correspondence with certain very close male friends.\nFirst journey to Italy (1494\u20131495).\nWithin three months of his marriage, D\u00fcrer left for Italy, alone, perhaps stimulated by an outbreak of plague in Nuremberg. He made watercolour sketches as he traveled over the Alps. Some have survived and others may be deduced from accurate landscapes of real places in his later work, for example his engraving \"Nemesis\".\nIn Italy, he went to Venice to study its more advanced artistic world. Through Wolgemut's tutelage, D\u00fcrer had learned how to make prints in drypoint and design woodcuts in the German style, based on the works of Schongauer and the Housebook Master. He also would have had access to some Italian works in Germany, but the two visits he made to Italy had an enormous influence on him. He wrote that Giovanni Bellini was the oldest and still the best of the artists in Venice. His drawings and engravings show the influence of others, notably Antonio Pollaiuolo, with his interest in the proportions of the body; Lorenzo di Credi; and Andrea Mantegna, whose work he produced copies of while training. D\u00fcrer probably also visited Padua and Mantua on this trip.\nReturn to Nuremberg (1495\u20131505).\nOn his return to Nuremberg in 1495, D\u00fcrer opened his own workshop (being married was a requirement for this). Over the next five years, his style increasingly integrated Italian influences into underlying Northern forms. Arguably his best works in the first years of the workshop were his woodcut prints, mostly religious, but including secular scenes such as \"The Men's Bath House\" (ca. 1496). These were larger and more finely cut than the great majority of German woodcuts hitherto, and far more complex and balanced in composition.\nIt is now thought unlikely that D\u00fcrer cut any of the woodblocks himself; this task would have been performed by a specialist craftsman. However, his training in Wolgemut's studio, which made many carved and painted altarpieces and both designed and cut woodblocks for woodcut, evidently gave him great understanding of what the technique could be made to produce, and how to work with block cutters. D\u00fcrer either drew his design directly onto the woodblock itself, or glued a paper drawing to the block. Either way, his drawings were destroyed during the cutting of the block.\nHis series of sixteen designs for the \"Apocalypse\" is dated 1498, as is his engraving of\" St. Michael Fighting the Dragon\". He made the first seven scenes of the \"Great Passion\" in the same year, and a little later, a series of eleven on the Holy Family and saints. The \"Seven Sorrows Polyptych\", commissioned by Frederick III of Saxony in 1496, was executed by D\u00fcrer and his assistants c.\u00a01500. In 1502, D\u00fcrer's father died. Around 1503\u20131505 D\u00fcrer produced the first 17 of a set illustrating the \"Life of the Virgin\", which he did not finish for some years. Neither these nor the \"Great Passion\" were published as sets until several years later, but prints were sold individually in considerable numbers.\nDuring the same period D\u00fcrer trained himself in the difficult art of using the burin to make engravings. It is possible he had begun learning this skill during his early training with his father, as it was also an essential skill of the goldsmith. In 1496 he executed the \"Prodigal Son\", which the Italian Renaissance art historian Giorgio Vasari singled out for praise some decades later, noting its Germanic quality. He was soon producing some spectacular and original images, notably \"Nemesis\" (1502), \"The Sea Monster\" (1498), and \"Saint Eustace\" (c. 1501), with a highly detailed landscape background and animals. His landscapes of this period, such as \"Pond in the Woods\" and \"Willow Mill\", are quite different from his earlier watercolours. There is a much greater emphasis on capturing atmosphere, rather than depicting topography. He made a number of Madonnas, single religious figures, and small scenes with comic peasant figures. Prints are highly portable and these works made D\u00fcrer famous throughout the main artistic centres of Europe within a very few years.\nThe Venetian artist Jacopo de' Barbari, whom D\u00fcrer had met in Venice, visited Nuremberg in 1500, and D\u00fcrer said that he learned much about the new developments in perspective, anatomy, and proportion from him. De' Barbari was unwilling to explain everything he knew, so D\u00fcrer began his own studies, which would become a lifelong preoccupation. A series of extant drawings show D\u00fcrer's experiments in human proportion, leading to the famous engraving of \"Adam and Eve\" (1504), which shows his subtlety while using the burin in the texturing of flesh surfaces. This is the only existing engraving signed with his full name.\nD\u00fcrer created large numbers of preparatory drawings, especially for his paintings and engravings, and many survive, most famously the \"Betende H\u00e4nde\" (\"Praying Hands\") from circa 1508, a study for an apostle in the Heller altarpiece. He continued to make images in watercolour and bodycolour (usually combined), including a number of still lifes of meadow sections or animals, including his \"Young Hare\" (1502) and the \"Great Piece of Turf\" (1503).\nSecond journey to Italy (1505\u20131507).\nIn Italy, he returned to painting, at first producing a series of works executed in tempera on linen. These include portraits and altarpieces, notably, the Paumgartner altarpiece and the \"Adoration of the Magi\". In early 1506, he returned to Venice and stayed there until the spring of 1507. By this time D\u00fcrer's engravings had attained great popularity and were being copied. In Venice he was given a valuable commission from the emigrant German community for the church of San Bartolomeo. This was the altar-piece known as the \"Adoration of the Virgin\" or the \"Feast of Rose Garlands\". It includes portraits of members of Venice's German community, but shows a strong Italian influence. It was later acquired by the Emperor Rudolf II and taken to Prague.\nNuremberg and the masterworks (1507\u20131520).\nDespite the regard in which he was held by the Venetians, D\u00fcrer returned to Nuremberg by mid-1507, remaining in Germany until 1520. His reputation had spread throughout Europe and he was on friendly terms and in communication with most of the major artists including Raphael. \nBetween 1507 and 1511 D\u00fcrer worked on some of his most celebrated paintings: \"Adam and Eve\" (1507), \"Martyrdom of the Ten Thousand\" (1508, for Frederick of Saxony), \"Virgin with the Iris\" (1508), the altarpiece \"Assumption of the Virgin\" (1509, for Jacob Heller of Frankfurt), and \"Adoration of the Trinity\" (1511, for Matthaeus Landauer). During this period he also completed two woodcut series, the \"Great Passion\" and the \"Life of the Virgin\", both published in 1511 together with a second edition of the \"Apocalypse\" series. The post-Venetian woodcuts show D\u00fcrer's development of chiaroscuro modelling effects, creating a mid-tone throughout the print to which the highlights and shadows can be contrasted.\nOther works from this period include the thirty-seven \"Little Passion\" woodcuts, first published in 1511, and a set of fifteen small engravings on the same theme in 1512. Complaining that painting did not make enough money to justify the time spent when compared to his prints, he produced no paintings from 1513 to 1516. In 1513 and 1514 D\u00fcrer created his three most famous engravings: \"Knight, Death and the Devil\" (1513, probably based on Erasmus's \"Handbook of a Christian Knight\"), \"St. Jerome in His Study\", and the much-debated \"Melencolia\u00a0I\" (both 1514, the year D\u00fcrer's mother died). Further outstanding pen and ink drawings of D\u00fcrer's period of art work of 1513 were drafts for his friend Pirckheimer. These drafts were later used to design Lusterweibchen chandeliers, combining an antler with a wooden sculpture.\nIn 1515, he created his \"woodcut of a Rhinoceros\" which had arrived in Lisbon from a written description and sketch by another artist, without ever seeing the animal himself. An image of the Indian rhinoceros, the image has such force that it remains one of his best-known and was still used in some German school science text-books as late as last century. In the years leading to 1520 he produced a wide range of works, including the woodblocks for the first western printed star charts in 1515 and portraits in tempera on linen in 1516. His only experiments with etching came in this period, producing five 1515\u20131516 and a sixth 1518; a technique he may have abandoned as unsuited to his aesthetic of methodical, classical form.\nPatronage of Maximilian I.\nFrom 1512, Maximilian I became D\u00fcrer's major patron. H commissiond \"The Triumphal Arch\", a vast work printed from 192 separate blocks, the symbolism of which is partly informed by Pirckheimer's translation of Horapollo's \"Hieroglyphica\". The design program and explanations were devised by Johannes Stabius, the architectural design by the master builder and court-painter J\u00f6rg K\u00f6lderer and the woodcutting itself by Hieronymous Andreae, with D\u00fcrer as designer-in-chief. \"The Arch\" was followed by \"The Triumphal Procession\", the program of which was worked out in 1512 by and includes woodcuts by Albrecht Altdorfer and Hans Springinklee, as well as D\u00fcrer.\nD\u00fcrer worked with pen on the marginal images for an edition of the Emperor's printed Prayer-Book; these were quite unknown until facsimiles were published in 1808 as part of the first book published in lithography. D\u00fcrer's work on the book was halted for an unknown reason, and the decoration was continued by artists including Lucas Cranach the Elder and Hans Baldung. D\u00fcrer also made several portraits of the Emperor, including one shortly before Maximilian's death in 1519.\nJourney to the Netherlands (1520\u20131521).\nMaximilian's death came at a time when D\u00fcrer was concerned he was losing \"my sight and freedom of hand\" (perhaps caused by arthritis) and increasingly affected by the writings of Martin Luther. In July 1520 D\u00fcrer made his fourth and last major journey, to renew the Imperial pension Maximilian had given him and to secure the patronage of the new emperor, Charles V, who was to be crowned at Aachen. D\u00fcrer journeyed with his wife and her maid via the Rhine to Cologne and then to Antwerp, where he was well received and produced numerous drawings in silverpoint, chalk and charcoal. In addition to attending the coronation, he visited Cologne (where he admired the painting of Stefan Lochner), Nijmegen, 's-Hertogenbosch, Bruges (where he saw Michelangelo's \"Madonna of Bruges\"), Ghent (where he admired van Eyck's \"Ghent altarpiece\"), and Zeeland.\nD\u00fcrer took a large stock of prints with him and wrote in his diary to whom he gave, exchanged or sold them, and for how much. This provides rare information of the monetary value placed on prints at this time. Unlike paintings, their sale was very rarely documented. While providing valuable documentary evidence, D\u00fcrer's Netherlandish diary also reveals that the trip was not a profitable one. For example, D\u00fcrer offered his last portrait of Maximilian to his daughter, Margaret of Austria, but eventually traded the picture for some white cloth after Margaret disliked the portrait and declined to accept it. During this trip he also met Bernard van Orley, Jan Provoost, Gerard Horenbout, Jean Mone, Joachim Patinir and Tommaso Vincidor, though he did not, it seems, meet Quentin Matsys.\nHaving secured his pension, D\u00fcrer returned home in July 1521, having caught an undetermined illness, which afflicted him for the rest of his life, and greatly reduced his rate of work.\nFinal years, Nuremberg (1521\u20131528).\nOn his return to Nuremberg, D\u00fcrer worked on a number of grand projects with religious themes, including a crucifixion scene and a Sacra conversazione, though neither was completed. This may have been due in part to his declining health, but perhaps also because of the time he gave to the preparation of his theoretical works on geometry and perspective, the proportions of men and horses, and fortification.\nHowever, one consequence of this shift in emphasis was that during the last years of his life, D\u00fcrer produced comparatively little as an artist. In painting, there was only a portrait of , a , , and two panels showing St. John with St. Peter in and St. Paul with St. Mark in the . This last great work, \"the Four Apostles\", was given by D\u00fcrer to the City of Nuremberg\u2014although he was given 100 guilders in return.\nAs for engravings, D\u00fcrer's work was restricted to portraits and illustrations for his treatise. The portraits include Cardinal-Elector Albert of Mainz; Frederick the Wise, elector of Saxony; the humanist scholar Willibald Pirckheimer; Philipp Melanchthon, and Erasmus of Rotterdam. For those of the Cardinal, Melanchthon, and D\u00fcrer's final major work, a drawn portrait of the Nuremberg patrician Ulrich Starck, D\u00fcrer depicted the sitters in profile.\nDespite complaining of his lack of a formal classical education, D\u00fcrer was greatly interested in intellectual matters and learned much from his boyhood friend Willibald Pirckheimer, whom he no doubt consulted on the content of many of his images. He also derived great satisfaction from his friendships and correspondence with Erasmus and other scholars. D\u00fcrer succeeded in producing two books during his lifetime. \"The Four Books on Measurement\" were published at Nuremberg in 1525 and was the first book for adults on mathematics in German, as well as being cited later by Galileo and Kepler. The other, a work on city fortifications, was published in 1527. \"The Four Books on Human Proportion\" were published posthumously, shortly after his death in 1528.\nD\u00fcrer died in Nuremberg at the age of 56, leaving an estate valued at 6,874 florins \u2013 a considerable sum. He is buried in the \"Johannisfriedhof\" cemetery. His large house (purchased in 1509 from the heirs of the astronomer Bernhard Walther), where his workshop was located and where his widow lived until her death in 1539, remains a prominent Nuremberg landmark.\nD\u00fcrer and the Reformation.\nD\u00fcrer's writings suggest that he may have been sympathetic to Luther's ideas, though it is unclear if he ever left the Catholic Church. D\u00fcrer wrote of his desire to draw Luther in his diary in 1520: \"And God help me that I may go to Dr. Martin Luther; thus I intend to make a portrait of him with great care and engrave him on a copper plate to create a lasting memorial of the Christian man who helped me overcome so many difficulties.\" In a letter to Nicholas Kratzer in 1524, D\u00fcrer wrote, \"because of our Christian faith we have to stand in scorn and danger, for we are reviled and called heretics\". Most tellingly, Pirckheimer wrote in a letter to Johann Tscherte in 1530: \"I confess that in the beginning I believed in Luther, like our Albert of blessed memory ... but as anyone can see, the situation has become worse.\" D\u00fcrer may even have contributed to the Nuremberg City Council's mandating Lutheran sermons and services in March 1525. Notably, D\u00fcrer had contacts with various reformers, such as Zwingli, Andreas Karlstadt, Melanchthon, Erasmus and Cornelius Grapheus from whom D\u00fcrer received Luther's \"Babylonian Captivity\" in 1520. Yet Erasmus and C. Grapheus are better said to be Catholic change agents. Also, from 1525, \"the year that saw the peak and collapse of the Peasants' War, the artist can be seen to distance himself somewhat from the [Lutheran] movement...\"\nD\u00fcrer's later works have also been claimed to show Protestant sympathies. His 1523 \"The Last Supper\" woodcut has often been understood to have an evangelical theme, focusing as it does on Christ espousing the Gospel, as well the inclusion of the Eucharistic cup, an expression of Protestant utraquism, although this interpretation has been questioned. The delaying of the engraving of St Philip, completed in 1523 but not distributed until 1526, may have been due to D\u00fcrer's uneasiness with images of saints; even if D\u00fcrer was not an iconoclast, in his last years he evaluated and questioned the role of art in religion.\nLegacy and influence.\nD\u00fcrer exerted a huge influence on the artists of succeeding generations, especially in printmaking, the medium through which his contemporaries mostly experienced his art, as his paintings were predominantly in private collections located in only a few cities. His success in spreading his reputation across Europe through prints was undoubtedly an inspiration for major artists such as Raphael, Titian, and Parmigianino, all of whom collaborated with printmakers to promote and distribute their work.\nHis engravings seem to have had an intimidating effect upon his German successors; the \"Little Masters\" who attempted few large engravings but continued D\u00fcrer's themes in small, rather cramped compositions. Lucas van Leyden was the only Northern European engraver to successfully continue to produce large engravings in the first third of the 16th century. The generation of Italian engravers who trained in the shadow of D\u00fcrer all either directly copied parts of his landscape backgrounds (Giulio Campagnola, Giovanni Battista Palumba, Benedetto Montagna and Cristofano Robetta), or whole prints (Marcantonio Raimondi and Agostino Veneziano). However, D\u00fcrer's influence became less dominant after 1515, when Marcantonio perfected his new engraving style, which in turn travelled over the Alps to also dominate Northern engraving.\nIn painting, D\u00fcrer had relatively little influence in Italy, where probably only his altarpiece in Venice was seen, and his German successors were less effective in blending German and Italian styles. His intense and self-dramatizing self-portraits have continued to have a strong influence up to the present, especially on painters in the 19th and 20th century who desired a more dramatic portrait style. D\u00fcrer has never fallen from critical favour, and there have been significant revivals of interest in his works in Germany in the \"D\u00fcrer Renaissance\" of about 1570 to 1630, in the early nineteenth century, and in German nationalism from 1870 to 1945.\nTheoretical works.\nIn all his theoretical works, in order to communicate his theories in the German language rather than in Latin, D\u00fcrer used graphic expressions based on a vernacular, craftsmen's language. For example, \"Schneckenlinie\" (\"snail-line\") was his term for a spiral form. Thus, D\u00fcrer contributed to the expansion in German prose which Luther had begun with his translation of the Bible.\n\"Four Books on Measurement\".\nD\u00fcrer's work on geometry is called the \"Four Books on Measurement\" (\"Underweysung der Messung mit dem Zirckel und Richtscheyt\" or \"Instructions for Measuring with Compass and Ruler\"). The first book focuses on linear geometry. D\u00fcrer's geometric constructions include helices, conchoids and epicycloids. He also draws on Apollonius, and Johannes Werner's 'Libellus super viginti duobus elementis conicis' of 1522.\nThe second book moves onto two-dimensional geometry, i.e. the construction of regular polygons. Here D\u00fcrer favours the methods of Ptolemy over Euclid. The third book applies these principles of geometry to architecture, engineering and typography.\nIn architecture D\u00fcrer cites Vitruvius but elaborates his own classical designs and columns. In typography, D\u00fcrer depicts the geometric construction of the Latin alphabet, relying on Italian precedent. However, his \nconstruction of the Gothic alphabet is based upon an entirely different modular system. The fourth book completes the progression of the first and second by moving to three-dimensional forms and the construction of polyhedra. Here D\u00fcrer discusses the five Platonic solids, as well as seven Archimedean semi-regular solids, as well as several of his own invention.\nIn all these, D\u00fcrer shows the objects as nets. Finally, D\u00fcrer discusses the Delian Problem and moves on to the 'construzione legittima', a method of depicting a cube in two dimensions through linear perspective. He is thought to be the first to describe a visualization technique used in modern computers, ray tracing. It was in Bologna that D\u00fcrer was taught (possibly by Luca Pacioli or Bramante) the principles of linear perspective, and evidently became familiar with the 'costruzione legittima' in a written description of these principles found only, at this time, in the unpublished treatise of Piero della Francesca. He was also familiar with the 'abbreviated construction' as described by Alberti and the geometrical construction of shadows, a technique of Leonardo da Vinci. Although D\u00fcrer made no innovations in these areas, he is notable as the first Northern European to treat matters of visual representation in a scientific way, and with understanding of Euclidean principles. In addition to these geometrical constructions, D\u00fcrer discusses in this last book of \"Underweysung der Messung\" an assortment of mechanisms for drawing in perspective from models and provides woodcut illustrations of these methods that are often reproduced in discussions of perspective.\n\"Four Books on Human Proportion\".\nD\u00fcrer's work on human proportions is called the \"Four Books on Human Proportion\" (\"Vier B\u00fccher von Menschlicher Proportion\") of 1528. The first book was mainly composed by 1512/13 and completed by 1523, showing five differently constructed types of both male and female figures, all parts of the body expressed in fractions of the total height. D\u00fcrer based these constructions on both Vitruvius and empirical observations of \"two to three hundred living persons\", in his own words. The second book includes eight further types, broken down not into fractions but an Albertian system, which D\u00fcrer probably learned from Francesco di Giorgio's 'De harmonica mundi totius' of 1525. In the third book, D\u00fcrer gives principles by which the proportions of the figures can be modified, including the mathematical simulation of convex and concave mirrors; here D\u00fcrer also deals with human physiognomy. The fourth book is devoted to the theory of movement.\nAppended to the last book, however, is a self-contained essay on aesthetics, which D\u00fcrer worked on between 1512 and 1528, and it is here that we learn of his theories concerning 'ideal beauty'. D\u00fcrer rejected Alberti's concept of an objective beauty, proposing a relativist notion of beauty based on variety. Nonetheless, D\u00fcrer still believed that truth was hidden within nature, and that there were rules which ordered beauty, even though he found it difficult to define the criteria for such a code. In 1512/13 his three criteria were function ('Nutz'), na\u00efve approval ('Wohlgefallen') and the happy medium ('Mittelmass'). However, unlike Alberti and Leonardo, D\u00fcrer was most troubled by understanding not just the abstract notions of beauty but also as to how an artist can create beautiful images. Between 1512 and the final draft in 1528, D\u00fcrer's belief developed from an understanding of human creativity as spontaneous or inspired to a concept of 'selective inward synthesis'. In other words, that an artist builds on a wealth of visual experiences in order to imagine beautiful things. D\u00fcrer's belief in the abilities of a single artist over inspiration prompted him to assert that \"one man may sketch something with his pen on half a sheet of paper in one day, or may cut it into a tiny piece of wood with his little iron, and it turns out to be better and more artistic than another's work at which its author labours with the utmost diligence for a whole year\".\n\"Book on Fortification\".\nIn 1527, D\u00fcrer also published \"Various Lessons on the Fortification of Cities, Castles, and Localities\" (\"Etliche Underricht zu Befestigung der Stett, Schloss und Flecken\"). It was printed in Nuremberg, probably by Hieronymus Andreae and reprinted in 1603 by Johan Janssenn in Arnhem. In 1535 it was also translated into Latin as \"On Cities, Forts, and Castles, Designed and Strengthened by Several Manners: Presented for the Most Necessary Accommodation of War\" (\"De vrbibus, arcibus, castellisque condendis, ac muniendis rationes aliquot : praesenti bellorum necessitati accommodatissimae\"), published by Christian Wechel (Wecheli/Wechelus) in Paris. \nThe work is less proscriptively theoretical than his other works, and was soon overshadowed by the Italian theory of polygonal fortification (the \"trace italienne\" \u2013 see Bastion fort), though his designs seem to have had some influence in the eastern German lands and up into the Baltic States.\nList of works.\nFor lists of Albrecht D\u00fcrer's works, see:"}
{"id": "2403", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=2403", "title": "Australian rules football", "text": "Australian rules football, also called Australian football, or simply called \"Aussie rules\", \"football\" or \"footy\", is a contact sport played between two teams of 18 players on an oval field, often a modified cricket ground. Points are scored by kicking the oval ball between the middle goal posts (worth six points) or between a goal and behind post (worth one point).\nDuring general play, players may position themselves anywhere on the field and use any part of their bodies to move the ball. The primary methods are kicking, handballing and running with the ball. There are rules on how the ball can be handled, for example, players running with the ball must intermittently bounce or touch it on the ground. Throwing the ball is not allowed and players must not get caught holding the ball. A distinctive feature of the game is the mark, where players anywhere on the field who catch the ball from a kick (with specific conditions) are awarded possession. Possession of the ball is in dispute at all times except when a free kick or mark is paid. Players can tackle using their hands or use their whole body to obstruct opponents. Dangerous physical contact (such as pushing an opponent in the back), interference when marking and deliberately slowing the play are discouraged with free kicks, distance penalties or suspension for a certain number of matches, depending on the severity of the infringement. The game features frequent physical contests, spectacular marking, fast movement of both players and the ball and high scoring.\nThe sport's origins can be traced to football matches played in Melbourne, Victoria, in 1858, inspired by English public school football games. Seeking to develop a game more suited to adults and Australian conditions, the Melbourne Football Club published the first laws of Australian football in May 1859, making it the oldest of the world's major football codes.\nAustralian football has the highest spectator attendance and television viewership of all sports in Australia, while the Australian Football League (AFL), the sport's only fully professional competition, is the nation's wealthiest sporting body. The AFL Grand Final, held annually at the Melbourne Cricket Ground, is the highest attended club championship event in the world. The sport is also played at amateur level in many countries and in several variations. Its rules are governed by the AFL Commission with the advice of the AFL's Laws of the Game Committee.\nName.\nAustralian rules football is known by several nicknames, including Aussie rules, football and footy. In some regions, the Australian Football League markets the game as AFL after itself.\nHistory.\nOrigins.\nThere is evidence of football being played sporadically in the Australian colonies in the first half of the 19th century. Compared to cricket and horse racing, football was considered a mere \"amusement\" at the time, and while little is known about these early one-off games, it is clear they share no causal link with Australian football. In Melbourne, Victoria, in 1858, in a move that would help to shape Australian football in its formative years, private schools (then termed \"public schools\" in accordance with English scholastic nomenclature) began organising football games inspired by precedents at English public schools. The earliest such match, held in St Kilda on 15 June, was between Melbourne Grammar and St Kilda Grammar.\nOn 10 July 1858, the Melbourne-based \"Bell's Life in Victoria and Sporting Chronicle\" published a letter by Tom Wills, captain of the Victoria cricket team, calling for the formation of a \"foot-ball club\" with a \"code of laws\" to keep cricketers fit during winter. Born in Australia, Wills played a nascent form of rugby football whilst a pupil at Rugby School in England, and returned to his homeland a star athlete and cricketer. His letter is regarded by many historians as giving impetus for the development of a new code of football today known as Australian football. Two weeks later, Wills' friend, cricketer Jerry Bryant, posted an advertisement for a scratch match at the Richmond Paddock adjoining the Melbourne Cricket Ground (MCG). This was the first of several \"kickabouts\" held that year involving members of the Melbourne Cricket Club, including Wills, Bryant, W. J. Hammersley and J. B. Thompson. Trees were used as goalposts and play typically lasted an entire afternoon. Without an agreed upon code of laws, some players were guided by rules they had learned in the British Isles, \"others by no rules at all\".\nAnother significant milestone in 1858 was a match played under experimental rules between Melbourne Grammar and Scotch College, held at the Richmond Paddock. This 40-a-side contest, umpired by Wills and Scotch College teacher John Macadam, began on 7 August and continued over two subsequent Saturdays, ending in a draw with each side kicking one goal. It is commemorated with a statue outside the MCG, and the two schools have competed annually ever since in the Cordner-Eggleston Cup, the world's oldest continuous football competition.\nSince the early 20th century, it has been suggested that Australian football was derived from the Irish sport of Gaelic football, which was not codified until 1885. There is no archival evidence in favour of a Gaelic influence, and the style of play shared between the two modern codes appeared in Australia long before the Irish game evolved in a similar direction. Another theory, first proposed in 1983, posits that Wills, having grown up amongst Aboriginal people in Victoria, may have seen or played the Aboriginal ball game of Marn Grook, and incorporated some of its features into early Australian football. The evidence that he knew of the game is only circumstantial, and according to biographer Greg de Moore's research, Wills was \"almost solely influenced by his experience at Rugby School\".\nFirst rules.\nA loosely organised Melbourne side, captained by Wills, played against other football enthusiasts in the winter and spring of 1858. The following year, on 14 May, the Melbourne Football Club was officially established, making it one of the world's oldest football clubs. Three days later, Wills, Hammersley, Thompson and teacher Thomas H. Smith met near the MCG at the Parade Hotel, owned by Bryant, and drafted ten rules: \"The Rules of the Melbourne Football Club\". These are the laws from which Australian football evolved. The club stated that they aimed to create a simple code suited to the hard playing surfaces around Melbourne, and to eliminate the roughest aspects of English school games\u2014such as \"hacking\" (shin-kicking) in Rugby School football\u2014to lessen the chance of injuries to working men. In another significant departure from English public school football, the Melbourne rules omitted any offside law. \"The new code was as much a reaction against the school games as influenced by them\", writes Mark Pennings.\nThe rules were distributed throughout the colony; Thompson in particular did much to promote the new code in his capacity as a journalist. Australian football's date of codification predates that of any other major football code, including soccer (codified in 1863) and rugby union (codified in 1871).\nEarly competition in Victoria.\nFollowing Melbourne's lead, Geelong and Melbourne University also formed football clubs in 1859. While many early Victorian teams participated in one-off matches, most had not yet formed clubs for regular competition. A South Yarra side devised its own rules. To ensure the supremacy of the Melbourne rules, the first-club level competition in Australia, the Caledonian Society's Challenge Cup (1861\u201364), stipulated that only the Melbourne rules were to be used. This law was reinforced by the Athletic Sports Committee (ASC), which ran a variation of the Challenge Cup in 1865\u201366. With input from other clubs, the rules underwent several minor revisions, establishing a uniform code known as \"Victorian rules\". In 1866, the \"first distinctively Victorian rule\", the running bounce, was formalised at a meeting of club delegates chaired by H. C. A. Harrison, an influential pioneer who took up football in 1859 at the invitation of Wills, his cousin.\nThe game around this time was defensive and low-scoring, played low to the ground in congested rugby-style scrimmages. The typical match was a 20-per-side affair, played with a ball that was roughly spherical, and lasted until a team scored two goals. The shape of the playing field was not standardised; matches often took place in rough, tree-spotted public parks, most notably the Richmond Paddock (Yarra Park), known colloquially as the Melbourne Football Ground. Wills argued that the turf of cricket fields would benefit from being trampled upon by footballers in winter, and, as early as 1859, football was allowed on the MCG. However, cricket authorities frequently prohibited football on their grounds until the 1870s, when they saw an opportunity to capitalise on the sport's growing popularity. Football gradually adapted to an oval-shaped field, and most grounds in Victoria expanded to accommodate the dual purpose\u2014a situation that continues to this day.\nSpread to other colonies.\nFootball became organised in South Australia in 1860 with the formation of the Adelaide Football Club, the oldest football club in Australia outside Victoria. It devised its own rules, and, along with other Adelaide-based clubs, played a variety of codes until 1876, when they agreed to uniformly adopt most of the Victorian rules, with South Australian football pioneer Charles Kingston noting their similarity to \"the old Adelaide rules\". Likewise, Tasmanian clubs quarrelled over different rules until they adopted a slightly modified version of the Victorian game in 1879. The South Australian Football Association (SAFA), the sport's first governing body, formed on 30 April 1877, firmly establishing Victorian rules as the preferred code in that colony. The Victorian Football Association (VFA) formed the following month.\nAs clubs began touring the colonies in the late 1870s, the sport spread to New South Wales, and in 1879, the first intercolonial match took place in Melbourne between Victoria and South Australia. In order to standardise the sport across Australia, delegates representing the football associations of South Australia, Tasmania, Victoria and Queensland met in 1883 and updated the code. New rules such as holding the ball led to a \"golden era\" of fast, long-kicking and high-marking football in the 1880s, a time which also saw the rise of professionalism, particularly in Victoria and Western Australia (where the code took hold during the colony's gold rushes), and players such as George Coulthard achieve superstardom. Now known as Australasian rules or Australian rules, it became the first football code to develop mass spectator appeal, attracting world record attendances for sports viewing and gaining a reputation as \"the people's game\".\nThe sport reached Queensland as early as 1866, and experienced a period of dominance there, but, like in New Zealand and areas of New South Wales north of the Riverina, it struggled to thrive, largely due to the spread of rugby football with British migration, regional rivalries and the lack of strong local governing bodies. In the case of Sydney, denial of access to grounds, the influence of university headmasters from Britain who favoured rugby, and the loss of players to other codes inhibited the game's growth.\nEmergence of the VFL.\nIn 1896, delegates from six of the wealthiest VFA clubs\u2014Carlton, Essendon, Fitzroy, Geelong, Melbourne and South Melbourne\u2014met to discuss the formation of a breakaway professional competition. Later joined by Collingwood and St Kilda, the clubs formed the Victorian Football League (VFL), which held its inaugural season in 1897. The VFL's popularity grew rapidly as it made several innovations, such as instituting a finals system, reducing teams from 20 to 18 players, and introducing the behind as a score. Richmond and University joined the VFL in 1908, and by 1925, with the addition of Hawthorn, Footscray and North Melbourne, it had become the preeminent league in the country and would take a leading role in many aspects of the sport.\nEffects of the World Wars.\nBoth World War I and World War II had a devastating effect on Australian football and on Australian sport in general. While scratch matches were played by Australian \"diggers\" in remote locations around the world, the game lost many of its great players to wartime service. Some clubs and competitions never fully recovered. Between 1914 and 1915, a proposed hybrid code of Australian football and rugby league, the predominant code of football in New South Wales and Queensland, was trialed without success. The advent of World War I started a recession of the game in New Zealand, affecting the game's popularity for three-quarters of a century. In Queensland, the state league went into recess for the duration of the war. VFL club University left the league and went into recess due to severe casualties. The WAFL lost two clubs and the SANFL was suspended for one year in 1916 due to heavy club losses. The Anzac Day match, the annual game between Essendon and Collingwood on Anzac Day, is one example of how the war continues to be remembered in the football community.\nInterstate football and the ANFC.\nThe role of the Australian National Football Council (ANFC) was primarily to govern the game at a national level and to facilitate interstate representative and club competition. The ANFC ran the Championship of Australia, the first national club competition, which commenced in 1888 and saw clubs from different states compete on an even playing field. Although clubs from other states were at times invited, the final was almost always between the premiers from the two strongest state competitions of the time\u2014South Australia and Victoria\u2014and the majority of matches were played in Adelaide at the request of the SAFA/SANFL. The last match was played in 1976, with North Adelaide being the last non-Victorian winner in 1972. Between 1976 and 1987, the ANFC, and later the Australian Football Championships (AFC) ran a night series, which invited clubs and representative sides from around the country to participate in a knock-out tournament parallel to the premiership seasons, which Victorian sides still dominated.\nWith the lack of international competition, state representative matches were regarded with great importance. The Australian Football Council co-ordinated regular interstate carnivals, including the Australasian Football Jubilee, held in Melbourne in 1908 to celebrate the game's semicentenary. Due in part to the VFL poaching talent from other states, Victoria dominated interstate matches for three-quarters of a century. State of Origin rules, introduced in 1977, stipulated that rather than representing the state of their adopted club, players would return to play for the state they were first recruited in. This instantly broke Victoria's stranglehold over state titles and Western Australia and South Australia began to win more of their games against Victoria. Both New South Wales and Tasmania scored surprise victories at home against Victoria in 1990.\nTowards a national competition.\nThe term \"Barassi Line\", named after VFL star Ron Barassi, was coined by scholar Ian Turner in 1978 to describe the \"fictitious geographical barrier\" separating large parts of New South Wales and Queensland which predominately followed the two rugby codes from the rest of the country, where Australian football reigned. It became a reference point for the expansion of Australian football and for establishing a national league.\nThe way the game was played had changed dramatically due to innovative coaching tactics, with the phasing out of many of the game's kicking styles and the increasing use of handball; while presentation was influenced by television.\nIn 1982, in a move that heralded big changes within the sport, one of the original VFL clubs, South Melbourne, relocated to Sydney and became known as the Sydney Swans. In the late 1980s, due to the poor financial standing of many of the Victorian clubs, and a similar situation existing in Western Australia in the sport, the VFL pursued a more national competition. Two more non-Victorian clubs, West Coast and Brisbane, joined the league in 1987. In their early years, the Sydney and Brisbane clubs struggled both on and off-field because the substantial TV revenues they generated by playing on a Sunday went to the VFL. To protect these revenues the VFL granted significant draft concessions and financial aid to keep the expansion clubs competitive. Each club was required to pay a licence fee which allowed the Victorian-based clubs to survive.\nThe VFL changed its name to the Australian Football League (AFL) for the 1990 season, and over the next decade, three non-Victorian clubs gained entry: Adelaide (1991), Fremantle (1995) and the SANFL's Port Adelaide (1997), the only pre-existing club outside Victoria to join the league. In 2011 and 2012 respectively, two new non-Victorian clubs were added to the competition: Gold Coast and Greater Western Sydney. The AFL, currently with 18 member clubs, is the sport's elite competition and most powerful body. Following the emergence of the AFL, state leagues were quickly relegated to a second-tier status. The VFA merged with the former VFL reserves competition in 1998, adopting the VFL name. State of Origin also declined in importance, especially after an increasing number of player withdrawals. The AFL turned its focus to the annual International Rules Series against Ireland in 1998 before abolishing State of Origin the following year. State and territorial leagues still contest interstate matches, as do AFL Women players.\nAlthough a Tasmanian AFL bid is ongoing, the AFL's focus has been on expanding into markets outside Australian football's traditional heartlands. The AFL regularly schedules pre-season exhibition matches in all Australian states and territories as part of the Regional Challenge. The AFL signalled further attempts at expansion in the 2010s by hosting home-and-away matches in New Zealand, followed by China.\nLaws of the game.\nField.\nAustralian rules football playing fields have no fixed dimensions but at senior level are typically between long and wide wing-to-wing. The field, like the ball, is oval-shaped, and in Australia, cricket grounds are often used. No more than 18 players of each team (or, in AFL Women's, 16 players) are permitted to be on the field at any time.\nUp to four interchange (reserve) players may be swapped for those on the field at any time during the game. In Australian rules terminology, these players wait for substitution \"on the bench\"\u2014an area with a row of seats on the sideline. Players must interchange through a designated interchange \"gate\" with strict penalties for having too many players from one team on the field. In addition, some leagues have each team designate one player as a substitute who can be used to make a single permanent exchange of players during a game.\nThere is no offside rule nor are there set positions in the rules; unlike many other forms of football, players from both teams may disperse across the whole field before the start of play. However, a typical on-field structure consists of six forwards, six defenders or \"backmen\" and six midfielders, usually two wingmen, one centre and three followers, including a ruckman, ruck-rover and rover. Only four players from each team are allowed within the centre square () at every centre bounce, which occurs at the commencement of each quarter, and to restart the game after a goal is scored. There are also other rules pertaining to allowed player positions during set plays (that is, after a mark or free kick) and during kick-ins following the scoring of a behind.\nMatch duration.\nA game consists of four quarters and a timekeeper officiates their duration. At the professional level, each quarter consists of 20 minutes of play, with the clock being stopped for instances such as scores, the ball going out of bounds or at the umpire's discretion, e.g. for serious injury. Lower grades of competition might employ shorter quarters of play. The umpire signals \"time-off\" to stop the clock for various reasons, such as the player in possession being tackled into stagnant play. Time resumes when the umpire signals \"time-on\" or when the ball is brought into play. Stoppages cause quarters to extend approximately 5\u201310 minutes beyond the 20 minutes of play. 6 minutes of rest is allowed before the second and fourth quarters, and 20 minutes of rest is allowed at \"half-time\".\nThe official game clock is available only to the timekeeper(s), and is not displayed to the players, umpires or spectators. The only public knowledge of game time is when the timekeeper sounds a siren at the start and end of each quarter. Coaching staff may monitor the game time themselves and convey information to players via on-field trainers or substitute players. Broadcasters usually display an approximation of the official game time for television audiences, although some will now show the exact time remaining in a quarter.\nGeneral play.\nGames are officiated by umpires. Before the game, the winner of a coin toss determines which directions the teams will play to begin. Australian football begins after the first siren, when the umpire bounces the ball on the ground (or throws it into the air if the condition of the ground is poor), and the two ruckmen (typically the tallest players from each team) battle for the ball in the air on its way back down. This is known as the \"ball-up\". Certain disputes during play may also be settled with a \"ball-up\" from the point of contention. If the ball is kicked or hit from a ball-up or boundary throw-in over the boundary line or into a behind post without the ball bouncing, a free kick is paid for out of bounds on the full. A free kick is also paid if the ball is deemed by the umpire to have been deliberately carried or directed out of bounds. If the ball travels out of bounds in any other circumstances (for example, contested play results in the ball being knocked out of bounds) a boundary umpire will stand with his back to the infield and return the ball into play with a \"throw-in\", a high backwards toss back into the field of play.\nThe ball can be propelled in any direction by way of a foot, clenched fist (called a handball or \"handpass\") or open-hand tap but it cannot be thrown under any circumstances. Once a player takes possession of the ball he must dispose of it by either kicking or handballing it. Any other method of disposal is illegal and will result in a free kick to the opposing team. This is usually called \"incorrect disposal\", \"dropping the ball\" or \"throwing\". If the ball is not in the possession of one player it can be moved on with any part of the body.\nA player may run with the ball, but it must be bounced or touched on the ground at least once every . Opposition players may bump or tackle the player to obtain the ball and, when tackled, the player must dispose of the ball cleanly or risk being penalised for holding the ball unless the umpire rules no prior opportunity for disposal. The ball carrier may only be tackled between the shoulders and knees. If the opposition player forcefully contacts a player in the back while performing a tackle, the opposition player will be penalised for a push in the back. If the opposition tackles the player with possession below the knees (a \"low tackle\" or a \"trip\") or above the shoulders (a \"high tackle\"), the team with possession of the football gets a free kick.\nIf a player takes possession of the ball that has travelled more than from another player's kick, by way of a catch, it is claimed as a \"mark\" (meaning that the game stops while he prepares to kick from the point at which he marked). Alternatively, he may choose to \"play on\" forfeiting the set shot in the hope of pressing an advantage for his team (rather than allowing the opposition to reposition while he prepares for the free kick). Once a player has chosen to play on, normal play resumes and the player who took the mark is again able to be tackled.\nThere are different styles of kicking depending on how the ball is held in the hand. The most common style of kicking seen in today's game, principally because of its superior accuracy, is the drop punt, where the ball is dropped from the hands down, almost to the ground, to be kicked so that the ball rotates in a reverse end over end motion as it travels through the air. Other commonly used kicks are the torpedo punt (also known as the spiral, barrel, or screw punt), where the ball is held flatter at an angle across the body, which makes the ball spin around its long axis in the air, resulting in extra distance (similar to the traditional motion of an American football punt), and the checkside punt or \"banana\", kicked across the ball with the outside of the foot used to curve the ball (towards the right if kicked off the right foot) towards targets that are on an angle. There is also the \"snap\", which is almost the same as a checkside punt except that it is kicked off the inside of the foot and curves in the opposite direction. It is also possible to kick the ball so that it bounces along the ground. This is known as a \"grubber\". Grubbers can bounce in a straight line, or curve to the left or right.\nApart from free kicks, marks or when the ball is in the possession of an umpire for a \"ball up\" or \"throw in\", the ball is always in dispute and any player from either side can take possession of the ball.\nScoring.\nA \"goal\", worth 6 points, is scored when the football is propelled through the goal posts at any height (including above the height of the posts) by way of a kick from the attacking team. It may fly through \"on the full\" (without touching the ground) or bounce through, but must not have been touched, on the way, by any player from either team or a goalpost. A goal cannot be scored from the foot of an opposition (defending) player.\nA \"behind\", worth 1 point, is scored when the ball passes between a goal post and a behind post at any height, or if the ball hits a goal post, or if any player sends the ball between the goal posts by touching it with any part of the body other than a foot. A behind is also awarded to the attacking team if the ball touches any part of an opposition player, including a foot, before passing between the goal posts. When an opposition player deliberately scores a behind for the attacking team (generally as a last resort to ensure that a goal is not scored) this is termed a rushed behind. As of the 2009 AFL season, a free kick is awarded against any player who deliberately rushes a behind.\nThe goal umpire signals a goal with two hands pointed forward at elbow height, or a behind with one hand. Both goal umpires then wave flags above their heads to communicate this information to the scorers.\nThe team that has scored the most points at the end of play wins the game. If the scores are level on points at the end of play, then the game is a draw; extra time applies only during finals matches in some competitions.\nAs an example of a score report, consider a match between and with the former as the home team. Essendon's score of 11 goals and 14 behinds equates to 80 points. Melbourne's score of 10 goals and 7 behinds equates to a 67-point tally. Essendon wins the match by a margin of 13 points. Such a result would be written as:\nAnd spoken as:\nAdditionally, it can be said that:\nThe home team is typically listed first and the visiting side is listed second. The scoreline is written with respect to the home side.\nFor example, won in successive weeks, once as the home side and once as the visiting side. These would be written out thus:\nA draw would be written as:\nStructure and competitions.\nThe football season proper is from March to August (early autumn to late winter in Australia) with finals being held in September and October. In the tropics, the game is sometimes played in the wet season (October to March).\nThe AFL is recognised by the Australian Sports Commission as being the National Sporting Organisation for Australian Football. There are also seven state/territory-based organisations in Australia, all of which are affiliated with the AFL. These state leagues hold annual semi-professional club competitions, with some also overseeing more than one league. Local semi-professional or amateur organisations and competitions are often affiliated to their state organisations.\nThe AFL is the \"de facto\" world governing body for Australian football. There are also a number of affiliated organisations governing amateur clubs and competitions around the world.\nFor almost all Australian football club competitions the aim is to win the Premiership. The premiership is typically decided by a finals series. The teams that occupy the highest positions on the ladder after the home-and-away season play off in a \"semi-knockout\" finals series, culminating in a single Grand Final match to determine the premiers. Between four and eight teams contest a finals series, typically using the AFL final eight system or a variation of the McIntyre System. The team which finishes first on the ladder after the home-and-away season is referred to as a \"minor premier\", but this usually holds little stand-alone significance, other than receiving a better draw in the finals.\nMany metropolitan leagues have several tiered divisions, with promotion of the lower division premiers and relegation of the upper division's last placed team at the end of each year. At present, none of the top level national or state level leagues in Australia utilise this structure.\nWomen and Australian football.\nThe high level of interest shown by women in Australian football is considered unique among the world's football codes. It was the case in the 19th century, as it is in modern times, that women made up approximately half of total attendances at Australian football matches\u2014a far greater proportion than, for example, the estimated 10 per cent of women that comprise British soccer crowds. This has been attributed in part to the egalitarian character of Australian football's early years in public parks where women could mingle freely and support the game in various ways.\nIn terms of participation, there are occasional 19th-century references to women playing the sport, but it was not until the 1910s that the first organised women's teams and competitions appeared. Women's state leagues emerged in the 1980s, and in 2013, the AFL announced plans to establish a nationally televised women's competition. Amidst a surge in viewing interest and participation in women's football, the AFL pushed the founding date of the competition, named AFL Women's, to 2017. Eight AFL clubs won licences to field sides in its inaugural season.\nVariations and related sports.\nMany related games have emerged from Australian football, mainly with variations of contact to encourage greater participation. These include Auskick (played by children aged between 5 and 12), kick-to-kick (and its variants end-to-end footy and marks up), rec footy, 9-a-side footy, masters Australian football, handball and longest-kick competitions. Players outside of Australia sometimes engage in related games adapted to available fields, like metro footy (played on gridiron fields) and Samoa rules (played on rugby fields). One such prominent example in use since 2018 is AFLX, a shortened variation of the game with seven players a side, played on a soccer-sized pitch.\nInternational rules football.\nThe similarities between Australian football and the Irish sport of Gaelic football have allowed for the creation of a hybrid code known as international rules football. The first international rules matches were contested in Ireland during the 1967 Australian Football World Tour. Since then, various sets of compromise rules have been trialed, and in 1984 the International Rules Series commenced with national representative sides selected by Australia's state leagues (later by the AFL) and the Gaelic Athletic Association (GAA). The competition became an annual event in 1998, but was postponed indefinitely in 2007 when the GAA pulled out due to Australia's severe and aggressive style of play. It resumed in Australia in 2008 under new rules to protect the player with the ball.\nGlobal reach.\nAustralian rules football was played outside Australasia as early as 1888 when Australians studying at Edinburgh University and London University formed teams and competed in London. Today, the sport is played at an amateur level in various countries throughout the world. Twenty countries participated in the Euro Cup and 23 countries have participated in the International Cup with both competitions prohibiting Australian players. Over 20 countries have either affiliation or working agreements with the AFL. There have been many VFL/AFL players who were born outside Australia, an increasing number of which have been recruited through initiatives and, more recently, international scholarship programs.\nMany of the overseas-born AFL players have been Irish, as interest in recruiting talented Gaelic football players dates back to the start of the Irish experiment in the 1960s. Irishmen in the AFL have since become not just starters for their clubs but also Brownlow Medalists (Jim Stynes) and premiership players (Tadhg Kennelly). The AFL also selects a team to represent Australia against an Irish team chosen by the Gaelic Athletic Association in the International Rules Series, utilising rules from both codes with the two countries taking turns hosting the series. Both countries' and codes' respective most prestigious venues \u2013 the MCG and Croke Park in Dublin \u2013 have hosted series Tests. The series has its roots in 1967, when Harry Beitzel organized an Australian team to travel to Ireland and play Mayo and All-Ireland senior champions Meath. Known as the Galahs, it included Bob Skilton, Royce Hart, Alex Jesaulenko and Ron Barassi as captain-coach.\nIn the late 19th and early 20th centuries, the game spread with the Australian diaspora to areas such as New Zealand and South Africa; however this growth went into rapid decline following World War I. After World War II, the sport experienced a small amount of growth in the Pacific region, particularly in Nauru (where Australian football is the national sport) as well as Papua New Guinea and New Zealand.\nMost of the current amateur clubs and leagues in existence have developed since the 1980s, when leagues began to be established in North America, Europe and Asia. The sport developed a cult following in the United States when matches were broadcast on the fledgling ESPN network in the 1980s. As the size of the Australian diaspora has increased, so has the number of clubs outside Australia. This expansion has been further aided by multiculturalism and assisted by exhibition matches as well as exposure generated through players who have converted to and from other football codes. In Papua New Guinea, New Zealand, South Africa, Canada, and the United States there are many thousands of players.\nA fan of the sport since attending school in Geelong, Prince Charles is the Patron of AFL Europe. In 2013, participation across AFL Europe's 21 member nations was more than 5,000 players, the majority of which are European nationals rather than Australian expats. The sport also has a growing presence in India.\nThe AFL became the de facto governing body when it pushed for the closure of the International Australian Football Council in 2002. The Australian Football International Cup, held triennially in Melbourne since 2002, is the highest level of international competition.\nAlthough Australian rules football has not yet been a full sport at the Olympic Games or Commonwealth Games, when Melbourne hosted the 1956 Summer Olympics, which included the MCG being the main stadium, Australian rules football was chosen as the native sport to be demonstrated as per International Olympic Committee rules. On 7 December, the sport was demonstrated as an exhibition match at the MCG between a team of VFL and VFA amateurs and a team of VAFA amateurs (professionals were excluded due to the Olympics' strict amateurism policy at the time). The Duke of Edinburgh was among the spectators for the match, which the VAFA won by 12.9 (81) to 8.7 (55).\nCultural impact and popularity.\nAustralian football is a sport rich in tradition and Australian cultural references, especially surrounding the rituals of gameday for players, officials and supporters.\nAustralian football has attracted more overall interest among Australians than any other football code, and, when compared with all sports throughout the nation, has consistently ranked first in the winter reports, and third behind cricket and swimming in summer. Over 875,000 fans were paying members of AFL clubs in 2016, which is equal to one in every 28 Australians. The 2016 AFL Grand Final was the year's most-watched television broadcast in Australia, with an in-home audience of up to 6.5\u00a0million watching the match.\nIn 2006, 615,549 registered participants played Australian football in Australia. Participation increased 7.84% between 2005 and 2006. The Australian Sports Commission statistics showed a 64% increase in the total number of participants over the 10-year period between 2001 and 2010. In 2008 there were 35,000 people in 32 countries playing in structured competitions of Australian football outside of Australia.\nIn the arts and popular culture.\nAustralian football has been an inspiration for writers and poets including Manning Clarke, Bruce Dawe and Philip Hodgins. Paintings by Arthur Streeton (\"The National Game\", 1889) and Sidney Nolan (\"Footballer\", 1946) helped to establish Australian football as a serious subject for artists. Many Aboriginal artists have explored the game, often fusing it with the mythology of their region. Statues of Australian football identities can be found throughout the country. In cartooning, WEG's VFL/AFL premiership posters\u2014inaugurated in 1954\u2014have achieved iconic status among Australian football fans. Dance sequences based on Australian football feature heavily in Robert Helpmann's 1964 ballet \"The Display\", his first and most famous work for the Australian Ballet. The game has also inspired well-known plays such as \"And the Big Men Fly\" (1963) by Alan Hopgood and David Williamson's \"The Club\" (1977), which was adapted into a 1980 film, directed by Bruce Beresford. Mike Brady's 1979 hit \"Up There Cazaly\" is considered an Australian football anthem, and references to the sport can be found in works by popular musicians, from singer-songwriter Paul Kelly to the alternative rock band TISM. Many Australian football video games have been released, most notably the AFL series.\nAustralian Football Hall of Fame.\nFor the centenary of the VFL/AFL in 1996, the Australian Football Hall of Fame was established. That year, 136 significant figures across the various competitions were inducted into the Hall of Fame. An additional 115 inductees have been added since the creation of the Hall of Fame, resulting in a total number of 251 inductees.\nIn addition to the Hall of Fame, select members are chosen to receive the elite \"Legend\" status. Due to restrictions limiting the number of Legend status players to 10% of the total number of Hall of Fame inductees, there are currently 25 players with the status in the Hall of Fame."}
{"id": "2404", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=2404", "title": "Aon Insurance", "text": ""}
{"id": "2405", "revid": "40803894", "url": "https://en.wikipedia.org/wiki?curid=2405", "title": "Aon (company)", "text": "Aon plc () is a multinational British professional services firm that sells a range of financial risk-mitigation products, including insurance, pension administration, and health-insurance plans. Aon has approximately 50,000 employees in 120 countries.\nAon was created in 1982 when the Ryan Insurance Group merged with the Combined Insurance Company of America. In 1987, that company was renamed Aon from \"aon\", a Gaelic word meaning \"one\". The company is headquartered in the UK and incorporated in Ireland.\nHistory.\nW. Clement Stone's mother bought a small Detroit insurance agency, and in 1918 brought her son into the business. Mr. Stone sold low-cost, low-benefit accident insurance, underwriting and issuing policies on-site. The next year he founded his own agency, the Combined Registry Co.\nAs the Great Depression began, Stone reduced his workforce and improved training. Forced by his son's respiratory illness to winter in the South, Stone moved to Arkansas and Texas. In 1939 he bought American Casualty Insurance Co. of Dallas, Texas. It was consolidated with other purchases as the Combined Insurance Co. of America in 1947. The company continued through the 1950s and 1960s, continuing to sell health and accident policies. In the 1970s, Combined expanded overseas despite being hit hard by the recession.\nIn 1982, after 10 years of stagnation under Clement Stone Jr., the elder Stone, then 79, resumed control until the completion of a merger with Ryan Insurance Co. allowed him to transfer control to Patrick Ryan. Ryan, the son of a Ford dealer in Wisconsin, had started his company as an auto credit insurer in 1964. In 1976, the company bought the insurance brokerage units of the Esmark conglomerate. Ryan focused on insurance brokering and added more upscale insurance products. He also trimmed staff and took other cost-cutting measures, and in 1987 he changed Combined's name to Aon. In 1992, he bought Dutch insurance broker Hudig-Langeveldt. In 1995, the company sold its remaining direct life insurance holdings to General Electric to focus on consulting. The following year, it began offering hostile takeover insurance policies to small and mid-sized companies.\nAon built a global presence through purchases. In 1997, it bought The Minet Group, as well as insurance brokerage Alexander &amp; Alexander Services, Inc. in a deal that made Aon (temporarily) the largest insurance broker worldwide. The firm made no US buys in 1998, but doubled its employee base with purchases including Spain's largest retail insurance broker, Gil y Carvajal, and the formation of Aon Korea, the first non-Korean firm of its kind to be licensed there.\nResponding to industry demands, Aon announced its new fee disclosure policy in 1999, and the company reorganised to focus on buying personal line insurance firms and to integrate its acquisitions. That year it bought Nikols Sedgwick Group, an Italian insurance firm, and formed RiskAttack (with Zurich US), a risk analysis and financial management concern aimed at technology companies. The cost of integrating its numerous purchases, however, hammered profits in 1999.\nDespite its troubles, in 2000 Aon bought Reliance Group's accident and health insurance business, as well as Actuarial Sciences Associates, a compensation and employee benefits consulting company. Later in that year, however, the company decided to cut 6% of its workforce as part of a restructuring effort. In 2003, the company saw revenues increase primarily because of rate hikes in the insurance industry. Also that year, Endurance Specialty, a Bermuda-based underwriting operation that Aon helped to establish in November 2001 along with other investors, went public. The next year Aon sold most of its holdings in Endurance.\nIn late 2007, Aon announced the divestiture of its underwriting business. With this move, the firm sold off its two major underwriting subsidiaries: Combined Insurance Company of America (acquired by ACE Limited for $2.4 billion) and Sterling Life Insurance Company (purchased by Munich Re Group for $352 million). The low margin and capital-intensive nature of the underwriting industry was the primary reason for the firm's decision to divest. Upon completion of the move, Aon turned its attention to expanding its broking and consulting capabilities.\nThis growth strategy manifested in November 2008 when Aon announced it had acquired reinsurance intermediary and capital advisor Benfield Group Limited for $1.75 billion. The acquisition amplified the firm's broking capabilities, positioning Aon one of the largest players in the reinsurance brokerage industry.\nIn 2010, Aon made its most significant acquisition to date with the purchase of Hewitt Associates for $4.9 billion. Aside from drastically boosting Aon's human resources consulting capacity and entering the firm into the business process outsourcing industry, the move added 23,000 colleagues and more than $3 billion in revenue.\nIn January 2012, Aon announced that its headquarters would be moved from Chicago to London.\nOn 10 February 2017, Aon announced that it was selling its employee benefits outsourcing business to private equity firm The Blackstone Group for US$4.8 billion (\u00a33.8 billion)\nIn February 2020, Aon named Eric Andersen as president of Aon after co-president Michael O'Connor departed the company to pursue new opportunities. He will be reporting to Greg Case, the firm's CEO.\nIn June 2020, Aon announced it was planning to repay the Temporary 20% pay cut from 70% of employees that was published in a statement in April 2020 regarding the COVID-19 Pandemic. On 30 June 2020, Aon announced it would repay staff in full, plus 5% of the withheld amount.\nIn June 2020: Willis Towers Watson has called its shareholders to two meetings to discuss its acquisition with Aon for 26 August 2020. It was revealed that the US Department of Justice has requested more information on the deal under antitrust rules.\nSeptember 11 attacks.\nAon's New York offices were on the 92nd and 98th\u2013105th floors of the South Tower of the World Trade Center at the time of the September 11 attacks. When the North Tower was struck by American Airlines Flight 11 at 8:46\u00a0a.m., employees began evacuating from the upper floors of the South Tower. The evacuation of Aon's offices was carried out quickly, as 924 of the estimated 1,100 Aon employees present at the time managed to evacuate the building before United Airlines Flight 175 struck it twenty stories below them at 9:03\u00a0a.m.\nMany, however, did not manage to exit the building in time. As a result, 176 employees of Aon were killed when the tower collapsed at 9:59\u00a0a.m.\nSpitzer investigation.\nIn 2004\u20132005, Aon, along with other brokers including Marsh &amp; McLennan and Willis, fell under regulatory investigation under New York Attorney General Eliot Spitzer and other state attorneys general. At issue was the practice of insurance companies' payments to brokers (known as contingent commissions). The payments were thought to bring a conflict of interest, swaying broker decisions on behalf of carriers, rather than customers. In the spring of 2005, without acknowledging any wrongdoing, Aon agreed to a $190 million settlement, payable over 30 months.\nUK regulatory breach.\nIn January 2009, Aon was fined \u00a35.69 million in the UK by the Financial Services Authority, who stated that the fine related to the company's inadequate bribery and corruption controls, claiming that between 14 January 2005 and 30 September 2007 Aon had failed to properly assess the risks involved in its dealings with overseas firms and individuals. The Authority did not find that any money had actually made its way to illegal organisations. Aon qualified for a 30% discount on the fine as a result of its cooperation with the investigation. Aon said its conduct was not deliberate, adding it had since \"significantly strengthened and enhanced its controls around the usage of third parties\".\nUS Foreign Corrupt Practices Act violations.\nIn December 2011, Aon Corporation paid a $16.26 million penalty to the U.S. Securities and Exchange Commission (SEC) and the U.S. Department of Justice (DOJ) for violations of the US Foreign Corrupt Practices Act (FCPA).\nAccording to the SEC, Aon's subsidiaries made improper payments of over $3.6 million to government officials and third-party facilitators in Costa Rica, Egypt, Vietnam, Indonesia, the United Arab Emirates, Myanmar and Bangladesh, between 1983 and 2007, to obtain and retain insurance contracts.\nMajor acquisitions.\nOn 5 January 2007, Aon announced that its Aon Affinity group had acquired the WedSafe Wedding Insurance program.\nOn 22 August 2008, Aon announced that it had acquired London-based Benfield Group. The acquiring price was US$1.75 billion or \u00a3935 million, with US$170 million of debt.\nOn 5 March 2010, Hewitt Associates announced that it acquired Senior Educators Ltd. The acquisition offers companies a new way to address retiree medical insurance commitments.\nOn 12 July 2010, Aon announced that it had agreed to buy Lincolnshire, Illinois-based Hewitt Associates for $4.9 billion in cash and stock.\nOn 7 April 2011, Aon announced that it had acquired Johannesburg, South Africa-based Glenrand MIB. Financial terms were not disclosed.\nOn 19 July 2011, Aon announced that it bought Westfield Financial Corp., the owner of insurance-industry consulting firm Ward Financial Group, from Ohio Farmers Insurance Co. Financial terms were not disclosed.\nOn 22 October 2012, Aon announced that it agreed to buy OmniPoint, Inc, a Workday consulting firm. Financial terms were not disclosed.\nOn 16 June 2014, Aon announced that it agreed to buy National Flood Services, Inc., a large processor of flood insurance, from Stoneriver Group, L.P.\nOn 31 October 2016, Aon's Aon Risk Solutions completed acquisition of Stroz Friedberg LLC, a specialised risk management firm focusing on cybersecurity.\nOn 14 November 2016, Aon acquired CoCubes an online Indian Assessment firm, facilitating hiring of entry-level engineering graduates.\nOn 10 February 2017, Aon plc agreed to sell its human resources outsourcing platform for US$4.8 billion (\u00a33.8 billion) to Blackstone Group L.P. (BX.N), creating a new company called Alight Solutions.\nIn September 2017, Aon announced its intent to purchase real estate investment management firm The Townsend Group from Colony NorthStar for $475 million, expanding Aon's property investment management portfolio.\nOn 9 March 2020, Aon announced its merger with Willis Towers Watson for nearly $30 billion in an all-stock deal that creates the world's largest insurance broker. As of 21 May 2020, Willis board was under probe over merger agreement with Aon.\nOperations.\nManchester United.\nOn 3 June 2009, it was reported that Aon had signed a four-year shirt sponsorship deal with English football giant Manchester United. On 1 June 2010, Aon replaced American insurance company AIG as the principal sponsor of the club. The Aon logo was prominently displayed on the front of the club's shirts until the 2014/2015 season when Chevrolet replaced them. The deal was said to be worth \u00a380 million over four years, replacing United's deal with AIG as the most lucrative shirt deal in history at the time.\nIn April 2013, Aon signed a new eight-year deal with Manchester United to rename their training ground as the Aon Training Complex and sponsor the club's training kits, reportedly worth \u00a3180 million to the club."}
{"id": "2406", "revid": "39460120", "url": "https://en.wikipedia.org/wiki?curid=2406", "title": "Alban Berg", "text": "Alban Maria Johannes Berg (; ; 9 February 1885 \u2013 24 December 1935) was an Austrian composer of the Second Viennese School. His compositional style combined Romantic lyricism with the twelve-tone technique. Although he left a relatively small oeuvre, he is remembered as one of the most important composers of the 20th century for his expressive style encompassing \"entire worlds of emotion and structure\".\nBerg was born and lived in Vienna. He began to compose only at the age of fifteen. He studied counterpoint, music theory and harmony with Arnold Schoenberg between 1904 and 1911, and adopted his principles of \"developing variation\" and the twelve-tone technique. Berg's major works include the operas \"Wozzeck\" (1924) and \"Lulu\" (1935, finished posthumously), the chamber pieces \"Lyric Suite\" and Chamber Concerto, as well as a Violin Concerto. He also composed a number of songs (\"lieder\"). He is said to have brought more \"human values\" to the twelve-tone system, his works seen as more \"emotional\" than Schoenberg's. His music had a surface glamour that won him admirers when Schoenberg himself had few.\nBerg died from sepsis in 1935.\nBiography.\nEarly life.\nBerg was born in Vienna, the third of four children of Johanna and Konrad Berg. His father ran a successful export business, and the family owned several estates in Vienna and the countryside. The family's financial situation turned to the worse after the death of Konrad Berg in 1900, and it particularly affected young Berg, who had to repeat both his sixth and seventh grade to pass the exams. Berg was more interested in literature than music as a child and did not begin to compose until he was fifteen, when he started to teach himself music. With Marie Scheuchl, a maid in the family estate of Berghof in Carinthia and fifteen years his senior, he fathered a daughter, Albine, born 4 December 1902.\nBerg had little formal music education before he became a student of Arnold Schoenberg in October 1904. With Schoenberg, he studied counterpoint, music theory, and harmony. By 1906 he was studying music full-time; by 1907 he began composition lessons. His student compositions included five drafts for piano sonatas. He also wrote songs, including his \"Seven Early Songs\" (\"Sieben fr\u00fche Lieder\"), three of which were Berg's first publicly performed work in a concert that featured the music of Schoenberg's pupils in Vienna that year.\nThe early sonata sketches eventually culminated in Berg's Piano Sonata, Op. 1 (1907\u20131908); it is one of the most formidable \"first\" works ever written. Berg studied with Schoenberg for six years until 1911. Among Schoenberg's teaching was the idea that the unity of a musical composition depends upon all its aspects being derived from a single basic idea; this idea was later known as \"developing variation\". Berg passed this on to his students, one of whom, Theodor W. Adorno, stated: \"The main principle he conveyed was that of variation: everything was supposed to develop out of something else and yet be intrinsically different\". The Piano Sonata is an example\u2014the whole composition is derived from the work's opening quartal gesture and its opening phrase.\nInnovation.\nBerg was a part of Vienna's cultural elite during the heady \"fin de si\u00e8cle\" period. His circle included the musicians Alexander von Zemlinsky and Franz Schreker, the painter Gustav Klimt, the writer and satirist Karl Kraus, the architect Adolf Loos, and the poet Peter Altenberg.\nIn 1906 Berg met the singer (1885\u20131976), daughter of a wealthy family (rumoured to be in fact the illegitimate daughter of Emperor Franz Joseph I from his liaison with Anna Nahowski). Despite the outward hostility of her family, the couple married on 3 May 1911.\nIn 1913 two of Berg's \"Altenberg Lieder\" (1912) were premi\u00e8red in Vienna, conducted by Schoenberg in the infamous \"Skandalkonzert\". Settings of aphoristic poetic utterances, the songs are accompanied by a very large orchestra. The performance caused a riot, and had to be halted. Berg effectively withdrew the work, and it was not performed in full until 1952. The full score remained unpublished until 1966.\nFrom 1915 to 1918 Berg served in the Austro-Hungarian Army. During a period of leave in 1917 he accelerated work on his first opera, \"Wozzeck\". After the end of World War I, he settled again in Vienna, where he taught private pupils. He also helped Schoenberg run his Society for Private Musical Performances, which sought to create the ideal environment for the exploration and appreciation of unfamiliar new music by means of open rehearsals, repeat performances, and the exclusion of professional critics.\nBerg had a particular interest in the number 23, using it to structure several works. Various suggestions have been made as to the reason for this interest: that he took it from the biorhythms theory of Wilhelm Fliess, in which a 23-day cycle is considered significant, or because he first suffered an asthma attack on the 23rd of the month.\nSuccess of \"Wozzeck\" and inception of \"Lulu\" (1924\u201329).\nIn 1924 three excerpts from \"Wozzeck\" were performed, which brought Berg his first public success. The opera, which Berg completed in 1922, was first performed on 14 December 1925, when Erich Kleiber conducted the first performance in Berlin. Today, \"Wozzeck\" is seen as one of the century's most important works. Berg made a start on his second opera, the three-act \"Lulu\", in 1928 but interrupted the work in 1929 for the concert aria \"Der Wein\" which he completed that summer. \"Der Wein\" presaged \"Lulu\" in a number of ways, including vocal style, orchestration, design and text.\nOther well-known Berg compositions include the \"Lyric Suite\" (1926), which was later shown to employ elaborate cyphers to document a secret love affair; the post-Mahlerian Three Pieces for Orchestra (completed in 1915 but not performed until after \"Wozzeck\"); and the Chamber Concerto (\"Kammerkonzert\", 1923\u201325) for violin, piano, and 13 wind instruments: this latter is written so conscientiously that Pierre Boulez has called it \"Berg's strictest composition\" and it, too, is permeated by cyphers and posthumously disclosed hidden programs.\nFinal years (1930\u201335).\nLife for the musical world was becoming increasingly difficult in the 1930s both in Vienna and Germany due to the rising tide of antisemitism and the Nazi cultural ideology that denounced modernity. Even to have an association with someone who was Jewish could lead to denunciation, and Berg's \"crime\" was to have studied with the Jewish composer Arnold Schoenberg. Berg found that opportunities for his work to be performed in Germany were becoming rare, and eventually his music was proscribed and placed on the list of degenerate music.\nIn 1932 Berg and his wife acquired an isolated lodge, the \"Waldhaus\" on the southern shore of the W\u00f6rthersee, near Schiefling am See in Carinthia, where he was able to work in seclusion, mainly on \"Lulu\" and the Violin Concerto. At the end of 1934, Berg became involved in the political intrigues around finding a replacement for Clemens Krauss as director of the Vienna State Opera.\nAs more of the performances of his work in Germany were cancelled by the Nazis, who had come to power in early 1933, he needed to ensure the new director would be an advocate for modernist music. Originally, the premiere of \"Lulu\" had been planned for the Berlin State Opera, where Erich Kleiber continued to champion his music and had conducted the premiere of \"Wozzeck\" in 1925, but now this was looking increasingly uncertain, and \"Lulu\" was rejected by the Berlin authorities in the spring of 1934. Kleiber's production of the \"Lulu\" symphonic suite on 30 November 1934 in Berlin was also the occasion of his resignation in protest at the extent of conflation of culture with politics. Even in Vienna, the opportunities for the Vienna School of musicians was dwindling.\nBerg had interrupted the orchestration of \"Lulu\" because of an unexpected (and financially much-needed) commission from the Russian-American violinist Louis Krasner for a Violin Concerto (1935). This profoundly elegiac work, composed at unaccustomed speed and posthumously premiered, has become Berg's best-known and most-beloved composition. Like much of his mature work, it employs an idiosyncratic adaptation of Schoenberg's \"dodecaphonic\" or twelve-tone technique, that enables the composer to produce passages openly evoking tonality, including quotations from historical tonal music, such as a Bach chorale and a Carinthian folk song. The Violin Concerto was dedicated \"to the memory of an Angel\", Manon Gropius, the deceased daughter of architect Walter Gropius and Alma Mahler.\nDeath.\nBerg died aged 50 in Vienna, on Christmas Eve 1935, from blood poisoning apparently caused by a furuncle on his back, induced by an insect sting that occurred in November. He was buried at the Hietzing Cemetery in Vienna.\nBefore he died, Berg had completed the orchestration of only the first two of the three acts of \"Lulu\". The completed acts were successfully premi\u00e8red in Z\u00fcrich in 1937. For personal reasons Helene Berg subsequently imposed a ban on any attempt to \"complete\" the final act, which Berg had in fact completed in short score. An orchestration was therefore commissioned in secret from Friedrich Cerha and premi\u00e8red in Paris (under Pierre Boulez) only in 1979, soon after Helene Berg's own death. \nLegacy.\nBerg is remembered as one of the most important composers of the 20th century and the most widely performed opera composer among the Second Viennese School. He is said to have brought more \"human values\" to the twelve-tone system, his works seen as more \"emotional\" than Schoenberg's. Critically, he is seen as having preserved the Viennese tradition in his music.\nBerg scholar Douglas Jarman writes in the \"New Grove Dictionary of Music and Musicians\" that \"[as] the 20th century closed, the 'backward-looking' Berg suddenly came as [George] Perle remarked, to look like its most forward-looking composer.\"\nAlban Berg Quartett was a string quartet named after him, active during 1971\u20132008.\nThe asteroid 4528 Berg is named after him (1983).\nMajor compositions.\nPiano\nChamber\nOrchestral\nVocal\nOperas"}
{"id": "2408", "revid": "7266189", "url": "https://en.wikipedia.org/wiki?curid=2408", "title": "Analytical chemistry", "text": "Analytical chemistry studies and uses instruments and methods used to separate, identify, and quantify matter. In practice, separation, identification or quantification may constitute the entire analysis or be combined with another method. Separation isolates analytes. Qualitative analysis identifies analytes, while quantitative analysis determines the numerical amount or concentration.\nAnalytical chemistry consists of classical, wet chemical methods and modern, instrumental methods. Classical qualitative methods use separations such as precipitation, extraction, and distillation. Identification may be based on differences in color, odor, melting point, boiling point, solubility, radioactivity or reactivity. Classical quantitative analysis uses mass or volume changes to quantify amount. Instrumental methods may be used to separate samples using chromatography, electrophoresis or field flow fractionation. Then qualitative and quantitative analysis can be performed, often with the same instrument and may use light interaction, heat interaction, electric fields or magnetic fields. Often the same instrument can separate, identify and quantify an analyte.\nAnalytical chemistry is also focused on improvements in experimental design, chemometrics, and the creation of new measurement tools. Analytical chemistry has broad applications to medicine, science and engineering.\nHistory.\nAnalytical chemistry has been important since the early days of chemistry, providing methods for determining which elements and chemicals are present in the object in question. During this period significant contributions to analytical chemistry include the development of systematic elemental analysis by Justus von Liebig and systematized organic analysis based on the specific reactions of functional groups.\nThe first instrumental analysis was flame emissive spectrometry developed by Robert Bunsen and Gustav Kirchhoff who discovered rubidium (Rb) and caesium (Cs) in 1860.\nMost of the major developments in analytical chemistry take place after 1900. During this period instrumental analysis becomes progressively dominant in the field. In particular many of the basic spectroscopic and spectrometric techniques were discovered in the early 20th century and refined in the late 20th century.\nThe separation sciences follow a similar time line of development and also become increasingly transformed into high performance instruments. In the 1970s many of these techniques began to be used together as hybrid techniques to achieve a complete characterization of samples.\nStarting in approximately the 1970s into the present day analytical chemistry has progressively become more inclusive of biological questions (bioanalytical chemistry), whereas it had previously been largely focused on inorganic or small organic molecules. Lasers have been increasingly used in chemistry as probes and even to initiate and influence a wide variety of reactions. The late 20th century also saw an expansion of the application of analytical chemistry from somewhat academic chemical questions to forensic, environmental, industrial and medical questions, such as in histology.\nModern analytical chemistry is dominated by instrumental analysis. Many analytical chemists focus on a single type of instrument. Academics tend to either focus on new applications and discoveries or on new methods of analysis. The discovery of a chemical present in blood that increases the risk of cancer would be a discovery that an analytical chemist might be involved in. An effort to develop a new method might involve the use of a tunable laser to increase the specificity and sensitivity of a spectrometric method. Many methods, once developed, are kept purposely static so that data can be compared over long periods of time. This is particularly true in industrial quality assurance (QA), forensic and environmental applications. Analytical chemistry plays an increasingly important role in the pharmaceutical industry where, aside from QA, it is used in discovery of new drug candidates and in clinical applications where understanding the interactions between the drug and the patient are critical.\nClassical methods.\nAlthough modern analytical chemistry is dominated by sophisticated instrumentation, the roots of analytical chemistry and some of the principles used in modern instruments are from traditional techniques, many of which are still used today. These techniques also tend to form the backbone of most undergraduate analytical chemistry educational labs.\nQualitative analysis.\nA qualitative analysis determines the presence or absence of a particular compound, but not the mass or concentration. By definition, qualitative analyses do not measure quantity.\nChemical tests.\nThere are numerous qualitative chemical tests, for example, the acid test for gold and the Kastle-Meyer test for the presence of blood.\nFlame test.\nInorganic qualitative analysis generally refers to a systematic scheme to confirm the presence of certain aqueous ions or elements by performing a series of reactions that eliminate ranges of possibilities and then confirms suspected ions with a confirming test. Sometimes small carbon containing ions are included in such schemes. With modern instrumentation these tests are rarely used but can be useful for educational purposes and in field work or other situations where access to state-of-the-art instruments are not available or expedient.\nQuantitative analysis.\nQuantitative analysis is the measurement of the quantities of particular chemical constituents present in a substance.\nGravimetric analysis.\nGravimetric analysis involves determining the amount of material present by weighing the sample before and/or after some transformation. A common example used in undergraduate education is the determination of the amount of water in a hydrate by heating the sample to remove the water such that the difference in weight is due to the loss of water.\nVolumetric analysis.\nTitration involves the addition of a reactant to a solution being analyzed until some equivalence point is reached. Often the amount of material in the solution being analyzed may be determined. Most familiar to those who have taken chemistry during secondary education is the acid-base titration involving a color changing indicator. There are many other types of titrations, for example potentiometric titrations.\nThese titrations may use different types of indicators to reach some equivalence point.\nInstrumental methods.\nSpectroscopy.\nSpectroscopy measures the interaction of the molecules with electromagnetic radiation. Spectroscopy consists of many different applications such as atomic absorption spectroscopy, atomic emission spectroscopy, ultraviolet-visible spectroscopy, x-ray spectroscopy, fluorescence spectroscopy, infrared spectroscopy, Raman spectroscopy, dual polarization interferometry, nuclear magnetic resonance spectroscopy, photoemission spectroscopy, M\u00f6ssbauer spectroscopy and so on.\nMass spectrometry.\nMass spectrometry measures mass-to-charge ratio of molecules using electric and magnetic fields. There are several ionization methods: electron ionization, chemical ionization, electrospray ionization, fast atom bombardment, matrix assisted laser desorption/ionization, and others. Also, mass spectrometry is categorized by approaches of mass analyzers: magnetic-sector, quadrupole mass analyzer, quadrupole ion trap, time-of-flight, Fourier transform ion cyclotron resonance, and so on.\nElectrochemical analysis.\nElectroanalytical methods measure the potential (volts) and/or current (amps) in an electrochemical cell containing the analyte. These methods can be categorized according to which aspects of the cell are controlled and which are measured. The four main categories are potentiometry (the difference in electrode potentials is measured), coulometry (the transferred charge is measured over time), amperometry (the cell's current is measured over time), and voltammetry (the cell's current is measured while actively altering the cell's potential).\nThermal analysis.\nCalorimetry and thermogravimetric analysis measure the interaction of a material and heat.\nSeparation.\nSeparation processes are used to decrease the complexity of material mixtures. Chromatography, electrophoresis and field flow fractionation are representative of this field.\nHybrid techniques.\nCombinations of the above techniques produce a \"hybrid\" or \"hyphenated\" technique. Several examples are in popular use today and new hybrid techniques are under development. For example, gas chromatography-mass spectrometry, gas chromatography-infrared spectroscopy, liquid chromatography-mass spectrometry, liquid chromatography-NMR spectroscopy. liquid chromagraphy-infrared spectroscopy and capillary electrophoresis-mass spectrometry.\nHyphenated separation techniques refers to a combination of two (or more) techniques to detect and separate chemicals from solutions. Most often the other technique is some form of chromatography. Hyphenated techniques are widely used in chemistry and biochemistry. A slash is sometimes used instead of hyphen, especially if the name of one of the methods contains a hyphen itself.\nMicroscopy.\nThe visualization of single molecules, single cells, biological tissues and nanomaterials is an important and attractive approach in analytical science. Also, hybridization with other traditional analytical tools is revolutionizing analytical science. Microscopy can be categorized into three different fields: optical microscopy, electron microscopy, and scanning probe microscopy. Recently, this field is rapidly progressing because of the rapid development of the computer and camera industries.\nLab-on-a-chip.\nDevices that integrate (multiple) laboratory functions on a single chip of only millimeters to a few square centimeters in size and that are capable of handling extremely small fluid volumes down to less than picoliters.\nErrors.\nError can be defined as numerical difference between observed value and true value. The experimental error can be divided into two types, systematic error and random error. Systematic error results from a flaw in equipment or the design of an experiment while random error results from uncontrolled or uncontrollable variables in the experiment.\nIn error the true value and observed value in chemical analysis can be related with each other by the equation\nwhere \nError of a measurement is an inverse measure of accurate measurement i.e. smaller the error greater the accuracy of the measurement.\nErrors can be expressed relatively. Given the relative error(formula_5):\nThe percent error can also be calculated:\nIf we want to use these values in a function, we may also want to calculate the error of the function. Let formula_8 be a function with formula_9 variables. Therefore, the propagation of uncertainty must be calculated in order to know the error in formula_8:\nStandards.\nStandard curve.\nA general method for analysis of concentration involves the creation of a calibration curve. This allows for determination of the amount of a chemical in a material by comparing the results of unknown sample to those of a series of known standards. If the concentration of element or compound in a sample is too high for the detection range of the technique, it can simply be diluted in a pure solvent. If the amount in the sample is below an instrument's range of measurement, the method of addition can be used. In this method a known quantity of the element or compound under study is added, and the difference between the concentration added, and the concentration observed is the amount actually in the sample.\nInternal standards.\nSometimes an internal standard is added at a known concentration directly to an analytical sample to aid in quantitation. The amount of analyte present is then determined relative to the internal standard as a calibrant. An ideal internal standard is isotopically-enriched analyte which gives rise to the method of isotope dilution.\nStandard addition.\nThe method of standard addition is used in instrumental analysis to determine concentration of a substance (analyte) in an unknown sample by comparison to a set of samples of known concentration, similar to using a calibration curve. Standard addition can be applied to most analytical techniques and is used instead of a calibration curve to solve the matrix effect problem.\nSignals and noise.\nOne of the most important components of analytical chemistry is maximizing the desired signal while minimizing the associated noise. The analytical figure of merit is known as the signal-to-noise ratio (S/N or SNR).\nNoise can arise from environmental factors as well as from fundamental physical processes.\nThermal noise.\nThermal noise results from the motion of charge carriers (usually electrons) in an electrical circuit generated by their thermal motion. Thermal noise is white noise meaning that the power spectral density is constant throughout the frequency spectrum.\nThe root mean square value of the thermal noise in a resistor is given by\nwhere \"k\"B is Boltzmann's constant, \"T\" is the temperature, \"R\" is the resistance, and formula_13 is the bandwidth of the frequency formula_14.\nShot noise.\nShot noise is a type of electronic noise that occurs when the finite number of particles (such as electrons in an electronic circuit or photons in an optical device) is small enough to give rise to statistical fluctuations in a signal.\nShot noise is a Poisson process and the charge carriers that make up the current follow a Poisson distribution. The root mean square current fluctuation is given by\nwhere \"e\" is the elementary charge and \"I\" is the average current. Shot noise is white noise.\nFlicker noise.\nFlicker noise is electronic noise with a 1/\"\u0192\" frequency spectrum; as \"f\" increases, the noise decreases. Flicker noise arises from a variety of sources, such as impurities in a conductive channel, generation and recombination noise in a transistor due to base current, and so on. This noise can be avoided by modulation of the signal at a higher frequency, for example through the use of a lock-in amplifier.\nEnvironmental noise.\nEnvironmental noise arises from the surroundings of the analytical instrument. Sources of electromagnetic noise are power lines, radio and television stations, wireless devices, compact fluorescent lamps and electric motors. Many of these noise sources are narrow bandwidth and therefore can be avoided. Temperature and vibration isolation may be required for some instruments.\nNoise reduction.\nNoise reduction can be accomplished either in computer hardware or software. Examples of hardware noise reduction are the use of shielded cable, analog filtering, and signal modulation. Examples of software noise reduction are digital filtering, ensemble average, boxcar average, and correlation methods.\nApplications.\nAnalytical chemistry has applications including in forensic science, bioanalysis, clinical analysis, environmental analysis, and materials analysis. Analytical chemistry research is largely driven by performance (sensitivity, detection limit, selectivity, robustness, dynamic range, linear range, accuracy, precision, and speed), and cost (purchase, operation, training, time, and space). Among the main branches of contemporary analytical atomic spectrometry, the most widespread and universal are optical and mass spectrometry. In the direct elemental analysis of solid samples, the new leaders are laser-induced breakdown and laser ablation mass spectrometry, and the related techniques with transfer of the laser ablation products into inductively coupled plasma. Advances in design of diode lasers and optical parametric oscillators promote developments in fluorescence and ionization spectrometry and also in absorption techniques where uses of optical cavities for increased effective absorption pathlength are expected to expand. The use of plasma- and laser-based methods is increasing. An interest towards absolute (standardless) analysis has revived, particularly in emission spectrometry.\nGreat effort is being put in shrinking the analysis techniques to chip size. Although there are few examples of such systems competitive with traditional analysis techniques, potential advantages include size/portability, speed, and cost. (micro total analysis system (\u00b5TAS) or lab-on-a-chip). Microscale chemistry reduces the amounts of chemicals used.\nMany developments improve the analysis of biological systems. Examples of rapidly expanding fields in this area are genomics, DNA sequencing and related research in genetic fingerprinting and DNA microarray; proteomics, the analysis of protein concentrations and modifications, especially in response to various stressors, at various developmental stages, or in various parts of the body, metabolomics, which deals with metabolites; transcriptomics, including mRNA and associated fields; lipidomics - lipids and its associated fields; peptidomics - peptides and its associated fields; and metalomics, dealing with metal concentrations and especially with their binding to proteins and other molecules.\nAnalytical chemistry has played critical roles in the understanding of basic science to a variety of practical applications, such as biomedical applications, environmental monitoring, quality control of industrial manufacturing, forensic science and so on.\nThe recent developments of computer automation and information technologies have extended analytical chemistry into a number of new biological fields. For example, automated DNA sequencing machines were the basis to complete human genome projects leading to the birth of genomics. Protein identification and peptide sequencing by mass spectrometry opened a new field of proteomics. In addition to automating specific processes, there is effort to automate larger sections of lab testing, such as in companies like Emerald Cloud Lab and Transcriptic.\nAnalytical chemistry has been an indispensable area in the development of nanotechnology. Surface characterization instruments, electron microscopes and scanning probe microscopes enables scientists to visualize atomic structures with chemical characterizations."}
{"id": "2411", "revid": "18915484", "url": "https://en.wikipedia.org/wiki?curid=2411", "title": "A cappella", "text": "A cappella (, , ; ) music is a performance by a singer or a singing group without instrumental accompaniment, or a piece intended to be performed in this way. The term \"a cappella\" was originally intended to differentiate between Renaissance polyphony and Baroque concertato musical styles. In the 19th century, a renewed interest in Renaissance polyphony coupled with an ignorance of the fact that vocal parts were often doubled by instrumentalists led to the term coming to mean unaccompanied vocal music. The term is also used, albeit rarely, as a synonym for \"alla breve\".\nEarly history.\nA cappella could be as old as humanity itself. Research suggests that singing and vocables may have been what early humans used to communicate before the invention of language. The earliest piece of sheet music is thought to have originated from times as early as 2000 B.C. while the earliest that has survived in its entirety is from the first century A.D.: a piece from Greece called the Seikilos epitaph.\nReligious origins.\nA cappella music was originally used in religious music, especially church music as well as anasheed and zemirot. Gregorian chant is an example of a cappella singing, as is the majority of secular vocal music from the Renaissance. The madrigal, up until its development in the early Baroque into an instrumentally accompanied form, is also usually in a cappella form. The Psalms note that some early songs were accompanied by string instruments, though Jewish and Early Christian music was largely a cappella; the use of instruments has subsequently increased within both of these religions as well as in Islam.\nChristian.\nThe polyphony of Christian a cappella music began to develop in Europe around the late 15th century AD, with compositions by Josquin des Prez. The early a cappella polyphonies may have had an accompanying instrument, although this instrument would merely double the singers' parts and was not independent. By the 16th century, a cappella polyphony had further developed, but gradually, the cantata began to take the place of a cappella forms. Sixteenth-century a cappella polyphony, nonetheless, continued to influence church composers throughout this period and to the present day. Recent evidence has shown that some of the early pieces by Palestrina, such as what was written for the Sistine Chapel, was intended to be accompanied by an organ \"doubling\" some or all of the voices. Such is seen in the life of Palestrina becoming a major influence on Bach, most notably in the \"Mass in B Minor\".\nOther composers that utilized the a cappella style, if only for the occasional piece, were Claudio Monteverdi and his masterpiece, \"Lagrime d'amante al sepolcro dell'amata\" (A lover's tears at his beloved's grave), which was composed in 1610, and Andrea Gabrieli when upon his death many choral pieces were discovered, one of which was in the unaccompanied style. Learning from the preceding two composeres, Heinrich Sch\u00fctz utilized the a cappella style in numerous pieces, chief among these were the pieces in the oratorio style, which were traditionally performed during the Easter week and dealt with the religious subject matter of that week, such as Christ's suffering and the Passion. Five of Schutz's \"Historien\" were Easter pieces, and of these the latter three, which dealt with the passion from three different viewpoints, those of Matthew, Luke and John, were all done a cappella style. This was a near requirement for this type of piece, and the parts of the crowd were sung while the solo parts which were the quoted parts from either Christ or the authors were performed in a plainchant.\nByzantine Rite.\nIn the Byzantine Rite of the Eastern Orthodox Church and the Eastern Catholic Churches, the music performed in the liturgies is exclusively sung without instrumental accompaniment. Bishop Kallistos Ware says, \"The service is sung, even though there may be no choir... In the Orthodox Church today, as in the early Church, singing is unaccompanied and instrumental music is not found.\" This a cappella behavior arises from strict interpretation of Psalms 150, which states, \"Let every thing that hath breath praise the Lord. Praise ye the Lord.\" In keeping with this philosophy, early Russian \"musika\" which started appearing in the late 17th century, in what was known as \"khorov\u00efye kontsert\u00ef\" (choral concertos) made a cappella adaptations of Venetian-styled pieces, such as the treatise, \"Grammatika musikiyskaya\" (1675), by Nikolai Diletsky. Divine Liturgies and Western Rite masses composed by famous composers such as Peter Tchaikovsky, Sergei Rachmaninoff, Alexander Arkhangelsky, and Mykola Leontovych are fine examples of this.\nOpposition to instruments in worship.\nPresent-day Christian religious bodies known for conducting their worship services without musical accompaniment include many Oriental Orthodox Churches (such as the Coptic Orthodox Church), many Anabaptist communities (such as the Amish, Old German Baptist Brethren, Old Order Mennonites and Conservative Mennonites), some Presbyterian churches devoted to the regulative principle of worship, Old Regular Baptists, Primitive Baptists, Plymouth Brethren, Churches of Christ, Church of God (Guthrie, Oklahoma), the Reformed Free Methodists, Doukhobors, and the Byzantine Rite of Eastern Christianity. Certain high church services and other musical events in liturgical churches (such as the Roman Catholic Mass and the Lutheran Divine Service) may be a cappella, a practice remaining from apostolic times. Many Mennonites also conduct some or all of their services without instruments. Sacred Harp, a type of folk music, is an a cappella style of religious singing with shape notes, usually sung at singing conventions.\nOpponents of musical instruments in the Christian worship believe that such opposition is supported by the Christian scriptures and Church history. The scriptures typically referenced are Matthew 26:30; Acts 16:25; Romans 15:9; 1 Corinthians 14:15; Ephesians 5:19; Colossians 3:16; Hebrews 2:12, 13:15 and James 5:13, which show examples and exhortations for Christians to sing.\nThere is no reference to instrumental music in early church worship in the New Testament, or in the worship of churches for the first six centuries. Several reasons have been posited throughout church history for the absence of instrumental music in church worship.\nChristians who believe in a cappella music today believe that in the Israelite worship assembly during Temple worship only the Priests of Levi sang, played, and offered animal sacrifices, whereas in the church era, all Christians are commanded to sing praises to God. They believe that if God wanted instrumental music in New Testament worship, He would have commanded not just singing, but singing and playing like he did in the Hebrew scriptures.\nInstruments have divided Christendom since their introduction into worship. They were considered a Roman Catholic innovation, not widely practiced until the 18th century, and were opposed vigorously in worship by a number of Protestant Reformers, including Martin Luther (1483\u20131546), Ulrich Zwingli, John Calvin (1509\u20131564) and John Wesley (1703\u20131791). Alexander Campbell referred to the use of an instrument in worship as \"a cow bell in a concert\". In Sir Walter Scott's \"The Heart of Midlothian\", the heroine, Jeanie Deans, a Scottish Presbyterian, writes to her father about the church situation she has found in England (bold added):\nAcceptance of instruments in worship.\nThose who do not adhere to the regulative principle of interpreting Christian scripture, believe that limiting praise to the unaccompanied chant of the early church is not commanded in scripture, and that churches in any age are free to offer their songs with or without musical instruments.\nThose who subscribe to this interpretation believe that since the Christian scriptures never counter instrumental language with any negative judgment on instruments, opposition to instruments instead comes from an interpretation of history. There is no written opposition to musical instruments in any setting in the first century and a half of Christian churches (33\u2013180 AD). The use of instruments for Christian worship during this period is also undocumented. Toward the end of the 2nd century, Christians began condemning the instruments themselves. Those who oppose instruments today believe these Church Fathers had a better understanding of God's desire for the church, but there are significant differences between the teachings of these Church Fathers and Christian opposition to instruments today.\nSince \"a cappella\" singing brought a new polyphony (more than one note at a time) with instrumental accompaniment, it is not surprising that Protestant reformers who opposed the instruments (such as Calvin and Zwingli) also opposed the polyphony. While Zwingli was destroying organs in Switzerland\u00a0\u2013 Luther called him a fanatic\u00a0\u2013 the Church of England was burning books of polyphony.\nSome Holiness Churches such as the Free Methodist Church opposed the use of musical instruments in church worship until the mid-20th century. The Free Methodist Church allowed for local church decision on the use of either an organ or piano in the 1943 Conference before lifting the ban entirely in 1955. The Reformed Free Methodist Church and Evangelical Wesleyan Church were formed as a result of a schism with the Free Methodist Church, with the former retaining a cappella worship and the latter retaining the rule limiting the number of instruments in the church to the piano and organ.\nJewish.\nWhile worship in the Temple in Jerusalem included musical instruments, traditional Jewish religious services in the Synagogue, both before and after the last destruction of the Temple, did not include musical instruments given the practice of scriptural cantillation. The use of musical instruments is traditionally forbidden on the Sabbath out of concern that players would be tempted to repair (or tune) their instruments, which is forbidden on those days. (This prohibition has been relaxed in many Reform and some Conservative congregations.) Similarly, when Jewish families and larger groups sing traditional Sabbath songs known as zemirot outside the context of formal religious services, they usually do so a cappella, and Bar and Bat Mitzvah celebrations on the Sabbath sometimes feature entertainment by a cappella ensembles. During the Three Weeks musical instruments are prohibited. Many Jews consider a portion of the 49-day period of the counting of the omer between Passover and Shavuot to be a time of semi-mourning and instrumental music is not allowed during that time. This has led to a tradition of a cappella singing sometimes known as \"sefirah\" music.\nThe popularization of the Jewish chant may be found in the writings of the Jewish philosopher Philo, born 20 BC. Weaving together Jewish and Greek thought, Philo promoted praise without instruments, and taught that \"silent singing\" (without even vocal chords) was better still. This view parted with the Jewish scriptures, where Israel offered praise with instruments by God's own command The shofar is the only temple instrument still being used today in the synagogue, and it is only used from Rosh Chodesh Elul through the end of Yom Kippur. The shofar is used by itself, without any vocal accompaniment, and is limited to a very strictly defined set of sounds and specific places in the synagogue service. However, silver trumpets, as described in Numbers 10:1-18, have been made in recent years and used in prayer services at the Western Wall.\nIn the United States.\nPeter Christian Lutkin, dean of the Northwestern University School of Music, helped popularize a cappella music in the United States by founding the Northwestern A Cappella Choir in 1906. The A Cappella Choir was \"the first permanent organization of its kind in America.\"\nAn a cappella tradition was begun in 1911 by F. Melius Christiansen, a music faculty member at St. Olaf College in Northfield, Minnesota. The St. Olaf College Choir was established as an outgrowth of the local St. John's Lutheran Church, where Christiansen was organist and the choir was composed, at least partially, of students from the nearby St. Olaf campus. The success of the ensemble was emulated by other regional conductors, and a tradition of a cappella choral music was born in the region at colleges like Concordia College (Moorhead, Minnesota), Augustana College (Rock Island, Illinois), Waldorf University (Forest City, Iowa), Luther College (Decorah, Iowa), Gustavus Adolphus College (St. Peter, Minnesota), Augustana College (Sioux Falls, South Dakota), and Augsburg University (Minneapolis, Minnesota). The choirs typically range from 40 to 80 singers and are recognized for their efforts to perfect blend, intonation, phrasing and pitch in a large choral setting.\nMovements in modern a cappella over the past century include barbershop and doo wop. The Barbershop Harmony Society, Sweet Adelines International, and Harmony Inc. host educational events including Harmony University, Directors University, and the International Educational Symposium, and international contests and conventions, recognizing international champion choruses and quartets.\nMany a cappella groups can be found in high schools and colleges. There are amateur Barbershop Harmony Society and professional groups that sing a cappella exclusively. Although a cappella is technically defined as singing without instrumental accompaniment, some groups use their voices to emulate instruments; others are more traditional and focus on harmonizing. A cappella styles range from gospel music to contemporary to barbershop quartets and choruses.\nThe Contemporary A Cappella Society (CASA) is a membership option for former students, whose funds support hosted competitions and events.\nA cappella music was popularized between the late 2000s and the early to mid-2010s with media hits such as the 2009\u20132014 TV show \"The Sing-Off\" and the musical comedy film series \"Pitch Perfect\".\nRecording artists.\nIn July 1943, as a result of the American Federation of Musicians boycott of US recording studios, the a cappella vocal group \"The Song Spinners\" had a best-seller with \"Comin' In on a Wing and a Prayer\". In the 1950s, several recording groups, notably The Hi-Los and the Four Freshmen, introduced complex jazz harmonies to a cappella performances. The King's Singers are credited with promoting interest in small-group a cappella performances in the 1960s. Frank Zappa loves Doo wop and A cappella, so Zappa released The Persuasions' first album from his label in 1970. In 1983, an a cappella group known as The Flying Pickets had a Christmas 'number one' in the UK with a cover of Yazoo's (known in the US as Yaz) \"Only You\". A cappella music attained renewed prominence from the late 1980s onward, spurred by the success of Top 40 recordings by artists such as The Manhattan Transfer, Bobby McFerrin, Huey Lewis and the News, All-4-One, The Nylons, Backstreet Boys, Boyz II Men, and *NSYNC.\nContemporary a cappella includes many vocal groups and bands who add vocal percussion or beatboxing to create a pop/rock/gospel sound, in some cases very similar to bands with instruments. Examples of such professional groups include Straight No Chaser, Pentatonix, The House Jacks, Rockapella, Mosaic, Home Free and M-pact. There also remains a strong a cappella presence within Christian music, as some denominations purposefully do not use instruments during worship. Examples of such groups are Take 6, Glad and Acappella. Arrangements of popular music for small a cappella ensembles typically include one voice singing the lead melody, one singing a rhythmic bass line, and the remaining voices contributing chordal or polyphonic accompaniment.\nA cappella can also describe the isolated vocal track(s) from a multitrack recording that originally included instrumentation. These vocal tracks may be remixed or put onto vinyl records for DJs, or released to the public so that fans can remix them. One such example is the a cappella release of Jay-Z's \"Black Album\", which Danger Mouse mixed with The Beatles' \"White Album\" to create \"The Grey Album\".\nOn their 1966 album titled \"Album\", Peter, Paul and Mary included the song \"Norman Normal.\" All the sounds on that song, both vocals and instruments, were created by Paul's voice, with no actual instruments used.\nIn 2013, an artist by the name Smooth McGroove rose to prominence with his style of a cappella music. He is best known for his a cappella covers of video game music tracks on YouTube.\nin 2015, an a cappella version of Jerusalem by multi-instrumentalist Jacob Collier was selected for Beats by Dre \"The Game Starts Here\" for the England Rugby World Cup campaign.\nMusical theatre.\nA cappella has been used as the sole orchestration for original works of musical theatre that have had commercial runs Off-Broadway (theatres in New York City with 99 to 500 seats) only four times. The first was Avenue X which opened on 28 January 1994 and ran for 77 performances. It was produced by Playwrights Horizons with book by John Jiler, music and lyrics by Ray Leslee. The musical style of the show's score was primarily Doo-Wop as the plot revolved around Doo-Wop group singers of the 1960s.\nIn 2001, The Kinsey Sicks, produced and starred in the critically acclaimed off-Broadway hit, \"DRAGAPELLA! Starring the Kinsey Sicks\" at New York's legendary Studio 54. That production received a nomination for a Lucille Lortel award as Best Musical and a Drama Desk nomination for Best Lyrics. It was directed by Glenn Casale with original music and lyrics by Ben Schatz.\nThe a cappella musical Perfect Harmony, a comedy about two high school a cappella groups vying to win the National championship, made its Off Broadway debut at Theatre Row's Acorn Theatre on 42nd Street in New York City in October 2010 after a successful out-of-town run at the Stoneham Theatre, in Stoneham, Massachusetts. Perfect Harmony features the hit music of The Jackson 5, Pat Benatar, Billy Idol, Marvin Gaye, Scandal, Tiffany, The Romantics, The Pretenders, The Temptations, The Contours, The Commodores, Tommy James &amp; the Shondells and The Partridge Family, and has been compared to a cross between Altar Boyz and The 25th Annual Putnam County Spelling Bee.\nThe fourth a cappella musical to appear Off-Broadway, In Transit, premiered 5 October 2010 and was produced by Primary Stages with book, music, and lyrics by Kristen Anderson-Lopez, James-Allen Ford, Russ Kaplan, and Sara Wordsworth. Set primarily in the New York City subway system its score features an eclectic mix of musical genres (including jazz, hip hop, Latin, rock, and country). In Transit incorporates vocal beat boxing into its contemporary a cappella arrangements through the use of a subway beat boxer character. Beat boxer and actor Chesney Snow performed this role for the 2010 Primary Stages production. According to the show's website, it is scheduled to reopen for an open-ended commercial run in the Fall of 2011. In 2011, the production received four Lucille Lortel Award nominations including Outstanding Musical, Outer Critics Circle and Drama League nominations, as well as five Drama Desk nominations including Outstanding Musical and won for Outstanding Ensemble Performance.\nIn December 2016, In Transit became the first a cappella musical on Broadway.\nBarbershop style.\nBarbershop music is one of several uniquely American art forms. The earliest reports of this style of a cappella music involved African Americans. The earliest documented quartets all began in barber shops. In 1938, the first formal men's barbershop organization was formed, known as the Society for the Preservation and Encouragement of Barber Shop Quartet Singing in America (S.P.E.B.S.Q.S.A), and in 2004 rebranded itself and officially changed its public name to the Barbershop Harmony Society (BHS). Today the BHS has about 22,000 members in approximately 800 chapters across the United States and Canada, and the barbershop style has spread around the world with organizations in many other countries. The Barbershop Harmony Society provides a highly organized competition structure for a cappella quartets and choruses singing in the barbershop style.\nIn 1945, the first formal women's barbershop organization, Sweet Adelines, was formed. In 1953, Sweet Adelines became an international organization, although it didn't change its name to Sweet Adelines International until 1991. The membership of nearly 25,000 women, all singing in English, includes choruses in most of the fifty United States as well as in Australia, Canada, Finland, Germany, Ireland, Japan, New Zealand, Spain, Sweden, the United Kingdom, and the Netherlands. Headquartered in Tulsa, Oklahoma, the organization encompasses more than 1,200 registered quartets and 600 choruses.\nIn 1959, a second women's barbershop organization started as a break off from Sweet Adelines due to ideological differences. Based on democratic principles which continue to this day, Harmony, Inc. is smaller than its counterpart, but has an atmosphere of friendship and competition. With about 2,500 members in the United States and Canada, Harmony, Inc. uses the same rules in contest that the Barbershop Harmony Society uses. Harmony, Inc. is registered in Providence, Rhode Island.\nAmateur and high school.\nThe popularity of a cappella among high schools and amateurs was revived by television shows and movies such as \"Glee\" and \"Pitch Perfect\". High school groups may have conductors or student leaders who keep the tempo for the group, or beatboxers/vocal percussionists. \nSince 2013, summer training programs have appeared, such as A Cappella Academy in Los Angeles, California (founded by Ben Bram, Rob Dietz, and Avi Kaplan) and Camp A Cappella in Dayton, Ohio (founded by Deke Sharon and Brody McDonald). These programs teach about different aspects of a cappella music, including vocal performance, arranging, and beatboxing/vocal percussion.\nIn other countries.\nPakistan.\nThe musical show \"Strepsils Stereo\" is credited for introducing the art of a cappella in Pakistan.\nSri Lanka.\nComposer Dinesh Subasinghe became the first Sri Lankan to write a cappella pieces for SATB choirs. He wrote \"The Princes of the Lost Tribe\" and \"Ancient Queen of Somawathee\" for Menaka De Sahabandu and Bridget Helpe's choirs, respectively, based on historical incidents in ancient Sri Lanka. Voice Print is also a professional a cappella music group in Sri Lanka.\nSweden.\nThe European a cappella tradition is especially strong in the countries around the Baltic and perhaps most so in Sweden as described by Richard Sparks in his doctoral thesis \"The Swedish Choral Miracle\" in 2000.\nSwedish a cappella choirs have over the last 25 years won around 25% of the annual prestigious European Grand Prix for Choral Singing (EGP) that despite its name is open to choirs from all over the world (see list of laureates in the Wikipedia article on the EGP competition).\nThe reasons for the strong Swedish dominance are as explained by Richard Sparks manifold; suffice to say here that there is a long-standing tradition, an unusually large proportion of the populations (5% is often cited) regularly sing in choirs, the Swedish choral director Eric Ericson had an enormous impact on a cappella choral development not only in Sweden but around the world, and finally there are a large number of very popular primary and secondary schools ('music schools') with high admission standards based on auditions that combine a rigid academic regimen with high level choral singing on every school day, a system that started with Adolf Fredrik's Music School in Stockholm in 1939 but has spread over the country.\nUnited Kingdom.\nA cappella has gained attention in the UK in recent years, with many groups forming at British universities by students seeking an alternative singing pursuit to traditional choral and chapel singing. This movement has been bolstered by organisations such as The Voice Festival UK.\nCollegiate.\nIt is not clear exactly where collegiate a cappella began. The Rensselyrics of Rensselaer Polytechnic Institute (formerly known as the RPI Glee Club), established in 1873 is perhaps the oldest known collegiate a cappella group. The longest continuously-singing group is probably The Whiffenpoofs of Yale University, which was formed in 1909 and once included Cole Porter as a member. Collegiate a cappella groups grew throughout the 20th century. Some notable historical groups formed along the way include Colgate University's The Colgate 13 (1942), Dartmouth College's Aires (1946), Cornell University's Cayuga's Waiters (1949) and The Hangovers (1968), the University of Maine Maine Steiners (1958), the Columbia University Kingsmen (1949), the Jabberwocks of Brown University (1949), and the University of Rochester YellowJackets (1956).\nAll-women a cappella groups followed shortly, frequently as a parody of the men's groups: the Smiffenpoofs of Smith College (1936), The Shwiffs of Connecticut College (The She-Whiffenpoofs, 1944), and The Chattertocks of Brown University (1951). A cappella groups exploded in popularity beginning in the 1990s, fueled in part by a change in style popularized by the Tufts University Beelzebubs and the Boston University Dear Abbeys. The new style used voices to emulate modern rock instruments, including vocal percussion/\"beatboxing\". Some larger universities now have multiple groups. Groups often join one another in on-campus concerts, such as the Georgetown Chimes' Cherry Tree Massacre, a 3-weekend a cappella festival held each February since 1975, where over a hundred collegiate groups have appeared, as well as International Quartet Champions The Boston Common and the contemporary commercial a cappella group Rockapella. Co-ed groups have produced many up-and-coming and major artists, including John Legend, an alumnus of the Counterparts at the University of Pennsylvania, Sara Bareilles, an alumna of Awaken A Cappella at University of California, Los Angeles, and Mindy Kaling, an alumna of the Rockapellas at Dartmouth College. Mira Sorvino is an alumna of the Harvard-Radcliffe Veritones of Harvard College, where she had the solo on Only You by Yaz.\nA cappella is gaining popularity among South Asians with the emergence of primarily Hindi-English College groups. The first South Asian a cappella group was Penn Masala, founded in 1996 at the University of Pennsylvania. Co-ed South Asian a cappella groups are also gaining in popularity. The first co-ed south Asian a cappella was Anokha, from the University of Maryland, formed in 2001. Also, Dil se, another co-ed a cappella from UC Berkeley, hosts the \"Anahat\" competition at the University of California, Berkeley annually. Maize Mirchi, the co-ed a cappella group from the University of Michigan hosts \"Sa Re Ga Ma Pella\", an annual South Asian a cappella invitational with various groups from the Midwest. Another South Asian group from the Midwest is Chai Town who is based in the University of Illinois at Urbana- Champaign.\nJewish-interest groups such as Queens College's Tizmoret, Tufts University's Shir Appeal, University of Chicago's Rhythm and Jews, Binghamton University's Kaskeset, Ohio State University's Meshuganotes, Rutgers University's Kol Halayla, New York University's Ani V'Ata and Yale University's Magevet are also gaining popularity across the U.S.\nIncreased interest in modern a cappella (particularly collegiate a cappella) can be seen in the growth of awards such as the Contemporary A Cappella Recording Awards (overseen by the Contemporary A Cappella Society) and competitions such as the International Championship of Collegiate A Cappella for college groups and the Harmony Sweepstakes for all groups. In December 2009, a new television competition series called \"The Sing-Off\" aired on NBC. The show featured eight a cappella groups from the United States and Puerto Rico vying for the prize of $100,000 and a recording contract with Epic Records/Sony Music. The show was judged by Ben Folds, Shawn Stockman, and Nicole Scherzinger and was won by an all-male group from Puerto Rico called Nota. The show returned for a second, third, fourth, and fifth season, won by Committed, Pentatonix, Home Free, and The Melodores from Vanderbilt University respectively.\nEach year, hundreds of Collegiate a cappella groups submit their strongest songs in a competition to be on The Best of College A Cappella (BOCA), an album compilation of tracks from the best college a cappella groups around the world. The album is produced by Varsity Vocals\u00a0\u2013 which also produces the International Championship of Collegiate A Cappella\u00a0\u2013 and Deke Sharon. ). According to ethnomusicologist Joshua S. Dunchan, \"BOCA carries considerable cache and respect within the field despite the appearance of other compilations in part, perhaps, because of its longevity and the prestige of the individuals behind it.\"\nCollegiate a cappella groups may also submit their tracks to Voices Only, a two-disc series released at the beginning of each school year. A Voices Only album has been released every year since 2005.\nIn addition, all women's a cappella groups can send their strongest song tracks to the Women's A Cappella Association (WACA) for its annual best of women's a cappella album. WACA offers another medium for women's voices to receive recognition and has released an album every year since 2014, featuring women's groups from across the United States.\nEmulating instruments.\nIn addition to singing words, some a cappella singers also emulate instrumentation by reproducing instrumental sounds with their vocal cords and mouth, often pitched using specialised pitch pipes. One of the earliest 20th century practitioners of this method were The Mills Brothers whose early recordings of the 1930s clearly stated on the label that all instrumentation was done vocally. More recently, \"Twilight Zone\" by 2 Unlimited was sung a cappella to the instrumentation on the comedy television series \"Tompkins Square\". Another famous example of emulating instrumentation instead of singing the words is the theme song for \"The New Addams Family\" series on Fox Family Channel (now Freeform). Groups such as Vocal Sampling and Undivided emulate Latin rhythms a cappella. In the 1960s, the Swingle Singers used their voices to emulate musical instruments to Baroque and Classical music. Vocal artist Bobby McFerrin is famous for his instrumental emulation. A cappella group Naturally Seven recreates entire songs using vocal tones for every instrument.\nThe Swingle Singers used ad libs to sound like instruments, but have been known to produce non-verbal versions of musical instruments. Beatboxing, more accurately known as vocal percussion, is a technique used in a cappella music popularized by the hip-hop community, where rap is often performed a cappella. The advent of vocal percussion added new dimensions to the a cappella genre and has become very prevalent in modern arrangements. \nBeatboxing is performed often by shaping the mouth, making pops and clicks as pseudo-drum sounds. A popular phrase that beat boxers use to begin their training is the phrase \"boots and cats\". As the beat boxer progresses in their training, they remove the vowels and continue on from there, emulating a \"bts n cts n\" sound, a solid base for beginner beat boxers. The phrase has become popular enough to where Siri recites \"Boots and Cats\" when you ask it to beatbox. \nJazz vocalist Petra Haden used a four-track recorder to produce an a cappella version of \"The Who Sell Out\" including the instruments and fake advertisements on her album \"\" in 2005. Haden has also released a cappella versions of Journey's \"Don't Stop Believin'\", The Beach Boys' \"God Only Knows\" and Michael Jackson's \"Thriller\".\nChristian rock group Relient K recorded the song \"Plead the Fifth\" a cappella on their album \"Five Score and Seven Years Ago\". The group recorded lead singer Matt Thiessen making drum noises and played them with an electronic drum machine to record the song, blurring the lines between true a cappella and instrument use."}
{"id": "2414", "revid": "1021736994", "url": "https://en.wikipedia.org/wiki?curid=2414", "title": "Arrangement", "text": "In music, an arrangement is a musical reconceptualization of a previously composed work. It may differ from the original work by means of reharmonization, melodic paraphrasing, orchestration, or development of the formal structure. Arranging differs from orchestration in that the latter process is limited to the assignment of notes to instruments for performance by an orchestra, concert band, or other musical ensemble. Arranging \"involves adding compositional techniques, such as new thematic material for introductions, transitions, or modulations, and endings. Arranging is the art of giving an existing melody musical variety\".\nClassical music.\nArrangement and transcriptions of classical and serious music go back to the early history of this genre.\nEighteenth century.\nJ.S. Bach frequently made arrangements of his own and other composers\u2019 pieces. One striking example is the arrangement that he made of the Prelude from his Partita No. 3 for solo violin, BWV 1006.\nBach transformed this solo piece into an orchestral Sinfonia that introduces his Cantata BWV29. \u201cThe initial violin composition was in E major but both arranged versions are transposed down to D, the better to accommodate the wind instruments.\u201d\n\u201cThe transformation of material conceived for a single string instrument into a fully orchestrated concerto-type movement is so successful that it is unlikely that anyone hearing the latter for the first time would suspect the existence of the former.\u201d\nNineteenth and twentieth centuries.\nPiano music.\nIn particular, music written for the piano has frequently undergone this treatment, as it has been arranged for orchestra, chamber ensemble or concert band. Beethoven made an arrangement of his Piano Sonata No.9 for string quartet. Conversely, Beethoven also arranged his Grosse Fuge (a movement from one of his late string quartets) for piano duet. \nDue to his lack of expertise in orchestration, the American composer George Gershwin had his \"Rhapsody in Blue\" arranged and orchestrated by Ferde Grof\u00e9.\nErik Satie wrote his three \"Gymnop\u00e9dies\" for solo piano in 1888.\nEight years later, Debussy arranged two of them, exploiting the range of instrumental timbres available in a late 19th century orchestra. \"It was Debussy whose 1896 orchestrations of the Gymnop\u00e9dies put their composer on the map.\"\n\"Pictures at an Exhibition\", a suite of ten piano pieces by Modest Mussorgsky, has been arranged over twenty times, notably by Maurice Ravel. Ravel's arrangement demonstrates an \"ability to create unexpected, memorable orchestral sonorities.\u201d In the second movement, \u201cGnomus\u201d, Mussorgsky's original piano piece simply repeats the following passage:Ravel initially orchestrates it as follows:\nRepeating the passage, Ravel provides a fresh orchestration \u201cthis time with the celesta (replacing the woodwinds) accompanied by string glissandos on the fingerboard.\u201d\nSongs.\nA number of Franz Schubert's songs, originally for voice with piano accompaniment, were arranged by other composers. For example, Schubert's \"highly charged, graphic\" song \"Erlk\u00f6nig\" (the Erl King) has a piano introduction that conveys \u201cunflagging energy\u201d from the start:The arrangement of this song by Hector Berlioz uses strings to convey faithfully the driving urgency and threatening atmosphere of the original.\nBerlioz adds colour in bars 6-8 through the addition of woodwind, horns and ominously rumbling timpani. With typical flamboyance, Berlioz adds spice to the harmony in bar 6 with an E flat in the horn part, creating a half-diminished seventh chord which is not in Schubert's original piano part.\nThere are subtle differences between this and the arrangement of the song by Franz Liszt. The upper string sound is thicker, with violins and violas playing the fierce repeated octaves in unison and bassoons compensating for this by doubling the cellos and basses. There are no timpani, but trumpets and horns add a small jolt to the rhythm of the opening bar, reinforcing the bare octaves of the strings by playing on the second main beat.\nUnlike Berlioz, Liszt does not alter the harmony, but changes the emphasis somewhat in bar 6, with the note A in the oboes and clarinets grating against rather than blending with the G in the strings. \u201cSchubert has come in for his fair share of transcriptions and arrangements. Most, like Liszt\u2019s transcriptions of the Lieder or Berlioz\u2019s orchestration for \"Erlk\u00f6nig\", tell us more about the arranger that about the original composer, but they can be diverting so long as they are in no way a replacement for the original.\u201d\nGustav Mahler\u2019s \"Lieder eines fahrenden Gesellen\" (Songs of a Wayfarer) were originally written for voice with piano accompaniment. The composer\u2019s later arrangement of the piano part shows a typical ear for clarity and transparency in re-writing for an ensemble. Here is the original piano version of the closing bars of the second song, \u201cGieng heit\u2019 Morgen \u00fcber's Feld\u201d:\nThe orchestration shows Mahler's attention to detail in bringing out differentiated orchestral colours supplied by woodwind, strings and horn. Mahler uses a harp to convey the original arpeggios supplied by the left hand of the piano part. Mahler also extracts a descending chromatic melodic line, implied by the left hand in bars 2-4 (above) and gives it to the horn.\nPopular music.\nPopular music recordings often include parts for brass horn sections, bowed strings, and other instruments that were added by arrangers and not composed by the original songwriters. Some pop arrangers even add sections using full orchestra, though this is less common due to the expense. Popular music arrangements may also be considered to include new releases of existing songs with a new musical treatment. These changes can include alterations to tempo, meter, key, instrumentation, and other musical elements.\nWell-known examples include Joe Cocker's version of the Beatles' \"With a Little Help from My Friends,\" Cream's \"Crossroads\", and Ike and Tina Turner's version of Creedence Clearwater Revival's \"Proud Mary\". The American group Vanilla Fudge and British group Yes based their early careers on radical re-arrangements of contemporary hits. Bonnie Pointer performed disco and Motown-themed versions of \"Heaven Must Have Sent You.\" Remixes, such as in dance music, can also be considered arrangements.\nJazz.\nArrangements for small jazz combos are usually informal, minimal, and uncredited. Larger ensembles have generally had greater requirements for notated arrangements, though the early Count Basie big band is known for its many \"head\" arrangements, so called because they were worked out by the players themselves, memorized (\"in the player's \"head\"\"), and never written down. Most arrangements for big bands, however, were written down and credited to a specific arranger, as with arrangements by Sammy Nestico and Neal Hefti for Count Basie's later big bands.\nDon Redman made innovations in jazz arranging as a part of Fletcher Henderson's orchestra in the 1920s. Redman's arrangements introduced a more intricate melodic presentation and \"soli\" performances for various sections of the big band. Benny Carter became Henderson's primary arranger in the early 1930s, becoming known for his arranging abilities in addition to his previous recognition as a performer. Beginning in 1938, Billy Strayhorn became an arranger of great renown for the Duke Ellington orchestra. Jelly Roll Morton is sometimes considered the earliest jazz arranger. While he toured around the years 1912 to 1915, he wrote down parts to enable \"pickup bands\" to perform his compositions.\nBig-band arrangements are informally called \"charts\". In the swing era they were usually either arrangements of popular songs or they were entirely new compositions. Duke Ellington's and Billy Strayhorn's arrangements for the Duke Ellington big band were usually new compositions, and some of Eddie Sauter's arrangements for the Benny Goodman band and Artie Shaw's arrangements for his own band were new compositions as well. It became more common to arrange sketchy jazz combo compositions for big band after the bop era.\nAfter 1950, the big bands declined in number. However, several bands continued and arrangers provided renowned arrangements. Gil Evans wrote a number of large-ensemble arrangements in the late 1950s and early 1960s intended for recording sessions only. Other arrangers of note include Vic Schoen, Pete Rugolo, Oliver Nelson, Johnny Richards, Billy May, Thad Jones, Maria Schneider, Bob Brookmeyer, Lou Marini, Nelson Riddle, Ralph Burns, Billy Byers, Gordon Jenkins, Ray Conniff, Henry Mancini, Ray Reach, Vince Mendoza, and Claus Ogerman.\nIn the 21st century, the big-band arrangement has made a modest comeback. Gordon Goodwin, Roy Hargrove, and Christian McBride have all rolled out new big bands with both original compositions and new arrangements of standard tunes.\nFor instrumental groups.\nStrings.\nThe string section is a body of instruments composed of various bowed stringed instruments. By the 19th century orchestral music in Europe had standardized the string section into the following homogeneous instrumental groups: first violins, second violins (the same instrument as the first violins, but typically playing an accompaniment or harmony part to the first violins, and often at a lower pitch range), violas, cellos, and double basses. The string section in a multi-sectioned orchestra is sometimes referred to as the \"string choir.\"\nThe harp is also a stringed instrument, but is not a member of nor homogeneous with the violin family and is not considered part of the string choir. Samuel Adler classifies the harp as a plucked string instrument in the same category as the guitar (acoustic or electric), mandolin, banjo, or zither. Like the harp these instruments do not belong to the violin family and are not homogeneous with the string choir. In modern arranging these instruments are considered part of the rhythm section. The electric bass and upright string bass\u2014depending on the circumstance\u2014can be treated by the arranger as either string section or rhythm section instruments.\nA group of instruments in which each member plays a unique part\u2014rather than playing in unison with other like instruments\u2014is referred to as a chamber ensemble. A chamber ensemble made up entirely of strings of the violin family is referred to by its size. A string trio consists of three players, a string quartet four, a string quintet five, and so on.\nIn most circumstances the string section is treated by the arranger as one homogeneous unit and its members are required to play preconceived material rather than improvise.\nA string section can be utilized on its own (this is referred to as a string orchestra) or in conjunction with any of the other instrumental sections. More than one string orchestra can be utilized.\nA standard string section (vln., vln 2., vla., vcl, cb.) with each section playing unison allows the arranger to create a five-part texture. Often an arranger will divide each violin section in half or thirds to achieve a denser texture. It is possible to carry this division to its logical extreme in which each member of the string section plays his or her own unique part.\nSize of the string section.\nArtistic, budgetary and logistical concerns, including the size of the orchestra pit or hall will determine the size and instrumentation of a string section. The Broadway musical \"West Side Story\", in 1957, was booked into the Winter Garden theater; composer Leonard Bernstein disliked the playing of \"house\" viola players he would have to use there, and so he chose to leave them out of the show's instrumentation; a benefit was the creation of more space in the pit for an expanded percussion section.\nGeorge Martin, producer and arranger for The Beatles, warns arrangers about the intonation problems when only two like instruments play in unison: \"After a string quartet, I do not think there is a satisfactory sound for strings until one has at least three players on each line . . . as a rule two stringed instruments together create a slight 'beat' which does not give a smooth sound.\" Different music directors may use different numbers of string players and different balances between the sections to create different musical effects.\nWhile any combination and number of string instruments is possible in a section, a traditional string section sound is achieved with a violin-heavy balance of instruments."}
{"id": "2416", "revid": "7007500", "url": "https://en.wikipedia.org/wiki?curid=2416", "title": "Athanasian Creed", "text": "The Athanasian Creed, also called the Pseudo-Athanasian Creed and sometimes known as Quicunque Vult (or Quicumque Vult) which is both its Latin name and opening words meaning \"Whosoever wishes\", is a Christian statement of belief focused on Trinitarian doctrine and Christology. The creed has been used by Christian churches since the sixth century. It is the first creed in which the equality of the three persons of the Trinity is explicitly stated. It differs from the Nicene-Constantinopolitan and Apostles' Creeds in the inclusion of anathemas, or condemnations of those who disagree with the creed (like the original Nicene Creed).\nWidely accepted among Western Christians, including the Roman Catholic Church as well as some Anglican churches, Lutheran churches (it is considered part of Lutheran confessions in the \"Book of Concord\"), and ancient liturgical churches, the Athanasian Creed has been used in public worship less and less frequently. However, part of it can be found as an \"Authorized Affirmation of Faith\" in the 2000 main volume of the \"Common Worship\" liturgy of the Church of England. \nIt was designed to distinguish Nicene Christianity from the heresy of Arianism. Liturgically, this Creed was recited at the Sunday Office of Prime in the Western Church; it is not in common use in the Eastern Church. The creed has never gained acceptance in liturgy among Eastern Christians since it was considered as one of many unorthodox fabrications that contained the Filioque clause. Today, the Athanasian Creed is rarely used even in the Western Church. When used, one common practice is to use it once a year on Trinity Sunday.\nOrigin.\nA medieval account credited Athanasius of Alexandria, the famous defender of Nicene theology, as the author of the Creed. According to that account, Athanasius composed it during his exile in Rome and presented it to Pope Julius I as a witness to his orthodoxy. The traditional attribution of the Creed to Athanasius was first called into question in 1642 by the Dutch Protestant theologian Gerhard Johann Vossius. \nIt has since been widely accepted by modern scholars that the creed was not authored by Athanasius, that it was not originally called a creed at all and that Athanasius's name was not originally attached to it. Athanasius's name seems to have become attached to the creed as a sign of its strong declaration of Trinitarian faith. The reasoning for rejecting Athanasius as the author usually relies on a combination of the following:\nThe use of the creed in a sermon by Caesarius of Arles, as well as a theological resemblance to works by Vincent of L\u00e9rins, point to Southern Gaul as its origin. The most likely time frame is in the late fifth or early sixth century AD, at least 100 years after Athanasius lived. The Christian theology of the creed is firmly rooted in the Augustinian tradition and uses the exact terminology of Augustine's \"On the Trinity\" (published 415 AD). In the late 19th century, there was a great deal of speculation about who might have authored the creed, with suggestions, including Ambrose of Milan, Venantius Fortunatus and Hilary of Poitiers. \nThe 1940 discovery of a lost work by Vincent of L\u00e9rins, which bears a striking similarity to much of the language of the Athanasian Creed, have led many to conclude that the creed originated with Vincent or his students. For example, in the authoritative modern monograph about the creed, J. N. D. Kelly asserts that Vincent of L\u00e9rins was not its author but that it may have come from the same milieu, the area of L\u00e9rins in southern Gaul.\nThe oldest surviving manuscripts of the Athanasian Creed date from the late 8th century.\nContent.\nThe Athanasian Creed is usually divided into two sections: lines 1\u201328 address the doctrine of the Trinity, and lines 29\u201344 address the doctrine of Christology. Enumerating the three persons of the Trinity (Father, the Son, and the Holy Spirit), the first section of the creed ascribes the divine attributes to each individually. Thus, each person of the Trinity is described as uncreated (\"increatus\"), limitless (\"Immensus\"), eternal (\"\u00e6ternus\"), and omnipotent (\"omnipotens\"). \nWhile ascribing the divine attributes and divinity to each person of the Trinity, thus avoiding subordinationism, the first half of the Athanasian Creed also stresses the unity of the three persons in the one Godhead, thus avoiding a theology of tritheism. Furthermore, although one God, the Father, Son, and Holy Spirit are distinct from one another since the Father is neither made nor begotten; the Son is not made but is begotten from the Father; the Holy Spirit is neither made nor begotten but proceeds from the Father \u2013 Western churches include \"and the Son\" (filioque), a concept that Eastern and Oriental Orthodox reject.\nThe text of the Athanasian Creed is as follows:\nThe Christology of the second section is more detailed than that of the Nicene Creed and reflects the teaching of the First Council of Ephesus (431) and the definition of the Council of Chalcedon (451). The Athanasian Creed uses the term \"substantia\" (a Latin translation of the Nicene \"homoousios\": 'same being' or 'consubstantial') with respect to the relation of the Son to the Father according to his divine nature, but it also says that the Son is \"substantia\" of his mother Mary according to his human nature.\nThe Creed's wording thus excludes not only Sabellianism and Arianism but also the Christological heresies of Nestorianism and Eutychianism. A need for a clear confession against Arianism arose in Western Europe when the Ostrogoths and Visigoths, who had Arian beliefs, invaded at the beginning of the 5th century.\nThe final section of this Creed also moved beyond the Nicene (and Apostles') Creeds in making negative statements about the people's fate: \"They that have done good shall go into life everlasting: and they that have done evil into everlasting fire.\" That caused considerable debate in England in the mid-19th century, centred on the teaching of Frederick Denison Maurice.\nUses.\nComposed of 44 rhythmic lines, the Athanasian Creed appears to have been intended as a liturgical document, the original purpose of the creed being for it to be spoken or sung as a part of worship. The creed itself uses the language of public worship by speaking of the worship of God rather than the language of belief (\"Now this is the catholic faith: We worship one God\"). In the mediaeval Catholic Church, the creed was recited following the Sunday sermon or at the Sunday Office of Prime. The creed was often set to music and used in the place of a Psalm.\nEarly Protestants inherited the late mediaeval devotion to the Athanasian Creed, and it was considered to be authoritative in many Protestant churches. The statements of Protestant belief (confessional documents) of various Reformers commend the Athanasian Creed to their followers, including the Augsburg Confession, the Formula of Concord, the Second Helvetic Confession, the Belgic Confession, the Bohemian Confession and the Thirty-nine Articles. A metric version, \"Quicumque vult\", with a musical setting, was published in \"The Whole Booke of Psalmes\" printed by John Day in 1562. Among modern Lutheran and Reformed churches adherence to the Athanasian Creed is prescribed by the earlier confessional documents, but the creed does not receive much attention outside occasional use, especially on Trinity Sunday.\nIn Reformed circles, it is included, for example, in the Christian Reformed Churches of Australia's Book of Forms (publ. 1991). However, it is rarely recited in public worship.\nIn the successive Books of Common Prayer of the reformed Church of England, from 1549 to 1662, its recitation was provided for on 19 occasions each year, a practice that continued until the 19th century, when vigorous controversy regarding its statement about 'eternal damnation' saw its use gradually decline. It remains one of the three Creeds approved in the Thirty-Nine Articles, and it is printed in several current Anglican prayer books, such as \"A Prayer Book for Australia\" (1995). As with Roman Catholic practice, its use is now generally only on Trinity Sunday or its octave. An Anglican devotional manual published by The Church Union, \"A Manual of Catholic Devotion: For Members of the Church of England\", includes the Athanasian Creed with the prayers for Mattins, with the note: \"Said on certain feasts at Mattins instead of the Apostles' Creed\". The Episcopal Church, based in the United States, has never provided for its use in worship, but added it to its Book of Common Prayer for the first time in 1979, where it is included in small print in a reference section, \"Historical Documents of the Church\". The Anglo-Catholic devotional manual Saint Augustine's Prayer Book, first published in 1947 and revised in 1967, includes the Athanasian Creed under \"Devotions to the Holy Trinity\".\nIn Roman Catholic churches, it was traditionally said at Prime on Sundays when the Office was of the Sunday. The 1911 reforms reduced that to Sundays after Epiphany and Pentecost and on Trinity Sunday, except when a commemoration of a double feast or a day within an Octave occurred. The 1960 reforms further reduced its use to once a year, on Trinity Sunday. It has been effectively dropped from the Catholic liturgy since the Second Vatican Council. It is, however, maintained in the \"Forma Extraordinaria\", per the decree \"Summorum Pontificum\", and also in the rite of exorcism both the \"Forma Ordinaria\" and the \"Forma Extraordinaria\" of the Roman Rite.\nIn Lutheranism, the Athanasian Creed is, along with the Apostles' and the Nicene Creed, one of the three ecumenical creeds and is placed at the beginning of the 1580 Book of Concord, the historic collection of authoritative doctrinal statements (confessions) of the Lutheran Church. It is still used in the liturgy on Trinity Sunday.\nA common visualisation of the first half of the Creed is the Shield of the Trinity."}
{"id": "2417", "revid": "17997358", "url": "https://en.wikipedia.org/wiki?curid=2417", "title": "Alicante", "text": "Alicante (, , ) is a city and municipality in the Valencian Community, Spain. It is the capital of the province of Alacant and a historic Mediterranean port. The population of the city was 330,525 , the second-largest in Valencian Community.\nGeography.\nAlicante is located in the southeast of the Iberian Peninsula, on the shores of the Mediterranean Sea. Some orographic features rising over the largely flat terrain where the city is built on include the , the , the and the Benacantil hills.\nLocated in an arid territory, Alicante lacks any meaningful permanent water stream. There are however several stream beds correspondent to intermittent \"ramblas\". There was a swamp area in the northeast of the municipality, \"L'Albufereta\", yet it was dried up in 1928.\nThe municipality has two exclaves in the mainland: Monnegre (between the municipalities of Sant Vicent del Raspeig, Mutxamel, Busot and Xixona), and Cabe\u00e7\u00f3 d'Or; the latter comprises part of the namesake mountain (including the summit, 1209 metres above sea level). The small island of Tabarca, 8 nautical miles to the south of the city, also belongs to the municipality.\nToponymy.\nThe name of the city echoes the Arabic name \"Laqant\" (\u0644\u064e\u0642\u064e\u0646\u0652\u062a) or \"Al-Laqant\" (\u0623\u0644\u064e\u0644\u064e\u0642\u064e\u0646\u0652\u062a), which in turn reflects the Latin \"Lucentum\".\nHistory.\nThe area around Alicante has been inhabited for over 7000 years. The first tribes of hunter-gatherers moved down gradually from Central Europe between 5000 and 3000 BC. Some of the earliest settlements were made on the slopes of Mount Benacantil. By 1000 BC Greek and Phoenician traders had begun to visit the eastern coast of Spain, establishing small trading ports and introducing the native Iberian tribes to the alphabet, iron and the pottery wheel. The Carthaginian general Hamilcar Barca established the fortified settlement of \"Akra Leuka\" (Greek: , meaning \"White Mountain\" or \"White Point\"), in the mid-230s BC, which is generally presumed to have been on the site of modern Alicante.\nAlthough the Carthaginians conquered much of the land around Alicante, the Romans would eventually rule Hispania Tarraconensis for over 700 years. By the 5th century AD, Rome was in decline and the Roman predecessor town of Alicante, known as \"Lucentum\" (Latin), was more or less under the control of the Visigothic warlord Theudimer and thereafter under Visigothic rule from 400 to 700 A.D. The Goths did not put up much resistance to the Arab conquest of \"Medina Laqant\" in the beginning of the 8th century. The Moors ruled southern and eastern Spain until the 13th century \"Reconquista\" (Reconquest). Alicante was finally taken in 1247 by the Castilian king Alfonso X, but it passed soon and definitively to the Kingdom of Valencia in 1296 with King James II of Aragon. It gained the status of Royal Village (\"Vila Reial\") with representation in the medieval Valencian Parliament (\"Corts Valencianes\").\nAfter several decades of being the battlefield where the Kingdom of Castile and the Crown of Aragon clashed, Alicante became a major Mediterranean trading station exporting rice, wine, olive oil, oranges and wool. But between 1609 and 1614 King Felipe III expelled thousands of Moriscos who had remained in Valencia after the Reconquista, due to their cooperation with Barbary pirates who continually attacked coastal cities and caused much harm to trade. This act cost the region dearly; with so many skilled artisans and agricultural labourers gone, the feudal nobility found itself sliding into bankruptcy.\nConditions worsened in the early 18th century; after the War of Spanish Succession, Alicante went into a long, slow decline, surviving through the 18th and 19th centuries by making shoes and growing agricultural produce such as oranges and almonds, and thanks to its fisheries. The end of the 19th century witnessed a sharp recovery of the local economy with increasing international trade and the growth of the city harbour leading to increased exports of several products (particularly during World War I when Spain was a neutral country).\nDuring the early 20th century, Alicante was a minor capital that took profit from the benefit of Spain's neutrality during World War I, and that provided new opportunities for local industry and agriculture. The Rif War in the 1920s saw numerous \"alicantinos\" drafted to fight in the long and bloody campaigns in the former Spanish protectorate (Northern Morocco) against the Rif rebels. The political unrest of the late 1920s led to the victory of Republican candidates in local council elections throughout the country, and the abdication of King Alfonso XIII. The proclamation of the Second Spanish Republic was much celebrated in the city on 14 April 1931. The Spanish Civil War broke out on 17 July 1936. Alicante was the last city loyal to the Republican government to be occupied by General Franco's troops on 1 April 1939, and its harbour saw the last Republican government officials fleeing the country. Vicious air bombings were targeted on Alicante during the three years of civil conflict, most notably the bombing by the Italian \"Aviazione Legionaria\" of the Mercado de Abastos on 25 May 1938 in which more than 300 civilians perished.\nFrom 1954 onwards many \"pied-noirs\" settled in the city (as many as 30,000, although other sources decrease the amount tenfold). Alicante had fostered strong links with Oran in the past, and a notable share of the population of the latter city during the French colonial period had ancestry in the province of Alicante. The immigration process accelerated after the independence of Algeria in 1962.\nThe late 1950s and early 1960s saw the onset of a lasting transformation of the city by the tourist industry. Large buildings and complexes rose in nearby Albufereta (e.g. El Barco) and Playa de San Juan, with the benign climate being the biggest draw to attract prospective buyers and tourists who kept the hotels reasonably busy. New construction benefited the whole economy, as the development of the tourism sector also spawned new businesses such as restaurants, bars and other tourist-oriented enterprises. Also, the old airfield at Rabassa was closed and air traffic moved to the new El Altet Airport, which made a more convenient and modern facility for charter flights bringing tourists from northern European countries.\nWhen Franco died in 1975, his successor Juan Carlos I played his part as the living symbol of the transition of Spain to a democratic constitutional monarchy. The governments of regional communities were given constitutional status as \"nationalities\", and their governments were given more autonomy, including that of the Valencian region, the \"Generalitat Valenciana\".\nThe Port of Alicante has been reinventing itself since the industrial decline the city suffered in the 1980s (with most mercantile traffic lost to Valencia's harbour). In recent years, the Port Authority has established it as one of the most important ports in Spain for cruises, with 72 calls to port made by cruise ships in 2007 bringing some 80,000 passengers and 30,000 crew to the city each year. The moves to develop the port for more tourism have been welcomed by the city and its residents, but the latest plans to develop an industrial estate in the port have caused great controversy.\nEconomy.\nUntil the global recession which started in 2008, Alicante was one of the fastest-growing cities in Spain. The boom depended partly on tourism directed to the beaches of the Costa Blanca and particularly on the second residence-construction boom which started in the 1960s and revived again by the late 1990s. Services and public administration also play a major role in the city's economy. The construction boom has raised many environmental concerns and both the local autonomous government and city council are under scrutiny by the European Union. The construction surge was the subject of hot debates among politicians and citizens alike. The latest of many public battles concerns the plans of the Port Authority of Alicante to construct an industrial estate on reclaimed land in front of the city's coastal strip, in breach of local, national and European regulations. (See Port of Alicante for details).\nThe city serves as the headquarters of the European Union Intellectual Property Office and a sizeable population of European public workers live there.\nThe campus of the University of Alicante lies in San Vicente del Raspeig, bordering the city of Alicante to the north. More than 25,000 students attend the University.\nBetween 2005 and 2012 Ciudad de la Luz, one of the largest film studios in Europe, had its base in Alicante. The studio shot Spanish and international movies such as \"Asterix at the Olympic Games\" by Fr\u00e9d\u00e9ric Forestier and Thomas Langmann, and \"Manolete\" by Menno Meyjes. It was shut down in 2012 for violating European competition law.\nGovernment and administration.\nLuis Barcala of the People's Party has been the mayor of Alicante since 19 April 2018. He became mayor after the resignation of Gabriel Ech\u00e1varri, when the councilor Nerea Belmonte defected from Guanyar Alacant and refused to support the Socialist Party replacement candidate Eva Montesinos.\nGabriel Ech\u00e1varri of the Socialist Party (PSOE) was the mayor of the city from 13 June 2015 until April 2018, following the municipal elections on 24 May 2015. He was supported by the votes from his own group (6), plus those from leftist parties Guanyar Alacant (6) and Comprom\u00eds (3), as well as from centre-right party Ciudadanos (6). The People's Party (\"Partido Popular\", PP), with only 8 elected seats, lost the majority. On April resignation due to various judicial issues and was temporarily substituted by the councilor Eva Montesinos.\nIn the previous municipal elections of May 2011, Sonia Castedo of People's Party won the elections with an absolute majority, but resigned in December 2014 due to her involvement in several corruption scandals, at present being under investigation. Her fellow party member Miguel Valor went on to become mayor up until Ech\u00e1varri's election.\nAt the foot of the main staircase of the City Hall Building (\"Ayuntamiento\") is the zero point (\"cota cero\"), used as the point of reference for measuring the height above or below sea level of any point in Spain, due to the marginal tidal variations of the Mediterranean sea in Alicante.\nClimate.\nAlicante has mild winter temperatures, hot summers and little rain, concentrated in equinoctial periods. Like much of the Province of Alicante itself, the city has a hot semi-arid climate (\"BSh\") according to the K\u00f6ppen climate classification. Daily variations in temperature are generally small because of the stabilising influence of the sea, although occasional periods of westerly wind can produce temperature changes of or more. Seasonal variations in temperature are also relatively small, meaning that winters are mild and summers are hot.\nThe average rainfall is per year. The cold drop means that September and October are the wettest months. Rarely, the rainfall can be torrential, reaching over in a 24-hour period, leading to severe flooding. Because of this irregularity, only 35 rainy days are observed on average per year, and the annual number of sunshine hours is 2,851.\nThe record maximum temperature of was observed on 4 July 1994. The record minimum temperature of was recorded on 12 February 1956. The worst flooding in modern history occurred on 30 September 1997 when of rain fell within six hours. Temperatures under are very rare. Snow is unknown since 1926. Alicante enjoys one of the sunniest and warmest winter daytime temperatures in mainland Europe.\nDemographics.\nThe official population of Alicante in 2014 was 332,067 inhabitants and 757,085 in the metropolitan area \"Alicante-Elche\", and 1,863 million in 2019. About 15% of the population is foreign, most of them immigrants from Argentina, Ecuador, United Kingdom and Colombia who have arrived in the previous 20 years. There are also immigrants from other countries such as Germany, Romania, Russia, Algeria, Ukraine, Morocco and Italy, many of whom, coming from countries outside the EU, are under illegal alien status and therefore are not accounted for in official population figures. The real percentage of foreign residents is higher, since the Alicante metropolitan area is home to many Northern European retirees who are officially still residents of their own countries. A sizable number of semi-permanent residents are Spanish nationals who officially still live in Madrid, Castilla y Le\u00f3n, the Basque country, or other areas of Spain.\nTransportation.\nAlicante Airport outranks its Valencian counterpart, being among the busiest airports in Spain after Madrid, Barcelona, Palma de Mallorca and M\u00e1laga. It is connected with Madrid and Barcelona by frequent Iberia and Vueling flights, and with many Western European cities through carriers such as Ryanair, Easyjet and Jet2.com. There are also regular flights to Algeria and Russia.\nAlicante railway station is used by Cercan\u00edas Murcia/Alicante commuter rail services linking Alicante with suburbs and Murcia. Long-range RENFE trains run frequently to Madrid, Barcelona, and Valencia. In 2013, the Madrid\u2013Levante high-speed rail network was extended to Alicante station, allowing AVE high-speed rail services to link to Madrid via Villena AV, Albacete-Los Llanos and Cuenca-Fernando Z\u00f3bel.\nAlicante Tram connects the city with outlying settlements along Costa Blanca. , electric tram-trains run up to Benidorm, and diesel trains go further to D\u00e9nia.\nThe city has regular ferry services to the Balearic Islands and Algeria. The city is strongly fortified, with a spacious harbour.\nMain sights.\nAmongst the most notable features of the city are the Castle of Santa B\u00e1rbara, which sits high above the city, and the port of Alicante. The latter was the subject of bitter controversy in 2006\u20132007 as residents battled, successfully, to keep it from being changed into an industrial estate.\nThe Santa B\u00e1rbara castle is situated on Mount Benacantil, overlooking the city. The tower (\"La Torreta\") at the top, is the oldest part of the castle, while part of the lowest zone and the walls were constructed later in the 18th century.\nThe promenade \"Explanada de Espa\u00f1a\", lined by palm trees, is paved with 6.5 million marble floor tiles creating a wavy form and is one of the most lovely promenades in Spain. The Promenade extends from the Port of Alicante to the Gran V\u00eda and ends at the famous statue of Mark Hersch. For the people of Alicante, the promenade is the meeting place for the traditional Spanish \"paseo\", or stroll along the waterfront in the evenings, and a venue for outdoor musical concerts. At the end of the promenade is a monument by the artist Ba\u00f1uls of the 19th century.\n\"Barrio de la Santa Cruz\" is a colourful quarter of the old city, situated on the south-west of Santa B\u00e1rbara castle. Its small houses climb up the hill leading to the walls and the castle, through narrow streets decorated with flags and tubs of flowers.\n\"L'Ereta Park\" is situated on the foothills of Mount Benacantil, on the way to the castle. It runs from the Santa B\u00e1rbara castle down to the old part of Alicante and consists of several levels, routes, decks and rest stops which offer a panoramic view overlooking the city.\n\"El Palmeral Park\" is one of the favorite parks of Alicante's citizens. It includes walking trails, children's playgrounds, ponds and brooks, picnic tables and an auditorium for concerts.\nJust a few kilometers from Alicante on the Mediterranean Sea lies Tabarca island. What was once a haven for Barbary pirates is now a beautiful tourist attraction.\nOther sights include:\nThere are a dozen museums in Alicante. On exhibition at the Archaeological Museum of Alicante (MARQ) are local artifacts dating from 100,000 years ago till the early 20th century. The collection is divided into different rooms representing three divisions of archaeological methodology: ground, urban and underwater archaeology, with dioramas, audiovisual and interactive zones. The archaeological museum won the European Museum of the Year Award in 2004. Gravina Museum of Fine Arts presents a number of paintings and sculptures from the 16th century to the 19th century. Asegurada Museum of Contemporary Art houses a major collection of twentieth-century art, composed mainly of works donated by Eusebio Sempere.\nFestivals.\nThe most important festival, the \"Bonfires of Saint John\" (\"Fogueres de Sant Joan\"), takes place during the summer solstice. This is followed a week later by five nights of firework and pyrotechnic contests between companies on the urban beach \"Playa del Postiguet\". Another well-known festival is \"Moros i Cristians\" in Altozano or \"San Blas\" district. Overall, the city boasts a year-round nightlife for the enjoyment of tourists, residents, and a large student population of the University of Alicante. The nightlife social scene tends to shift to nearby Playa de San Juan (St. John's Beach) during the summer months.\nEvery summer in Alicante, a two-month-long programme of music, theatre and dance is staged in the Paseo del Puerto.\nSport.\nAlicante had two football teams, but now has only one, H\u00e9rcules CF, which currently competes in the Second Division B - Group 3. The other team, Alicante CF, which played in the Third Division was dissolved in 2014 due to economic problems. H\u00e9rcules CF is well known as it played in La Liga (the Spanish Premier Division) during the 1996/1997 season and again in 2010/2011, and has had many famous players such as David Trezeguet, Royston Drenthe and Nelson Valdez. H\u00e9rcules is also known for its victory over Barcelona in 1997 which led to Real Madrid winning the league. Home games are played at the 30,000-capacity Jos\u00e9 Rico P\u00e9rez Stadium.\nBasketball club (HLA Alicante) Lucentum Alicante participates in the Spanish basketball league. It plays in the Centro de Tecnificaci\u00f3n de Alicante.\nAlicante serves as headquarters and the starting point of the Volvo Ocean Race, a yacht race around the world. The latest race sailed in October 2017.\nTwin towns \u2013 sister cities.\nAlicante is twinned with:"}
{"id": "2418", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=2418", "title": "August 4", "text": ""}
{"id": "2419", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=2419", "title": "Alloys", "text": ""}
{"id": "2421", "revid": "7098284", "url": "https://en.wikipedia.org/wiki?curid=2421", "title": "Albrecht Achilles", "text": "Albrecht Achilles may refer to:"}
{"id": "2422", "revid": "1267919", "url": "https://en.wikipedia.org/wiki?curid=2422", "title": "Ann Widdecombe", "text": "Ann Noreen Widdecombe (born 4 October 1947) is a British politician, author and television personality. She served as the Conservative Member of Parliament (MP) for Maidstone from 1987 to 1997 and for Maidstone and The Weald from 1997 to 2010. She also served as a Member of the European Parliament (MEP) for South West England for the Brexit Party from 2019 to 2020.\nBorn in Bath, Somerset, Widdecombe read Latin at the University of Birmingham and later studied Philosophy, Politics and Economics (PPE) at Lady Margaret Hall, Oxford. She is a convert from Anglicanism to Roman Catholicism and was a member of the Conservative Christian Fellowship. She served as Under-Secretary of State for the Home Department from 1995 to 1997 and Shadow Home Secretary from 1999 to 2001. Widdecombe was appointed as a Privy Councillor in 1997.\nIdeologically, Widdecombe identifies herself as social conservative and stresses the importance of traditional values and conservatism. As a member of the House of Commons, she was known for opposing the legality of abortion, her opposition to LGBT legal rights such as an equal age of consent and the repeal of Section 28, her support for the retention of blasphemy laws and re-introduction of the death penalty, albeit applicable to a narrower class of murders than previously applied. Her general pro-life stance is amplified with supporting rigorous laws on animal protection and opposition to fox hunting.\nShe stood down from the House of Commons at the 2010 general election. Since 2002, she has made numerous television and radio appearances, including as a television presenter. A prominent Eurosceptic, in 2016 she supported the Vote Leave campaign to withdraw the United Kingdom from the European Union (EU). Widdecombe returned to politics as the lead candidate for the Brexit Party in South West England at the 2019 European Parliament election, winning the seat in line with results nationally, serving until the country left the EU on 31 January 2020. In the general election of December 2019 \u2013 as with all other candidates for the Commons fielded by the Brexit Party \u2013 she did not win Plymouth Sutton and Devonport, but retained her deposit and came third.\nEarly life.\nBorn in Bath, Somerset, Widdecombe is the daughter of Rita Noreen (\"n\u00e9e\" Plummer; 1911\u20132007) and Ministry of Defence civil servant James Murray Widdecombe. Widdecombe's maternal grandfather, James Henry Plummer, was born to a Catholic family of English descent in Crosshaven, County Cork, Ireland in 1874.\nShe attended the Royal Naval School in Singapore, and La Sainte Union Convent School in Bath. She then read Latin at the University of Birmingham and later attended Lady Margaret Hall, Oxford, to read Philosophy, Politics and Economics (PPE). In 1971, she was the secretary of the Oxford Union for one term, and became its treasurer for one term in 1972; she never became president. While studying at Oxford, she lived next door to Mary Archer, Edwina Currie, and Gyles Brandreth's wife Mich\u00e8le Brown. She worked for Unilever (1973\u201375) and then as an administrator at the University of London (1975\u201387) before entering Parliament.\nPolitical career.\nIn 1974, Widdecombe was personal assistant to Michael Ancram in the February and October general elections of that year. From 1976 to 1978, Widdecombe was a councillor on Runnymede District Council in Surrey.\nShe contested the seat of Burnley in Lancashire in the 1979 general election and then, against David Owen, the Plymouth Devonport seat in the 1983 general election. In 1983, she (along with Lady Olga Maitland and Virginia Bottomley) was co-founder of Women and Families for Defence, a group founded in opposition to the anti-nuclear Greenham Common Women's Peace Camp.\nWiddecombe was first elected to the House of Commons, for the Conservatives, in the 1987 general election as member for the constituency of Maidstone (which became Maidstone and The Weald in 1997).\nIn government.\nWiddecombe joined John Major's government as Parliamentary Under-Secretary of State for Social Security in 1990. In 1993, she was moved to the Department of Employment, and she was promoted to Minister of State the following year. In 1995, she joined the Home Office as Minister of State for Prisons and visited every prison in the UK.\nShadow Cabinet.\nAfter the Conservative landslide defeat at the 1997 general election, she served as Shadow Health Secretary between 1998\u20131999 and later as Shadow Home Secretary from 1999 to 2001 under the leadership of William Hague.\nLeadership contest and backbenches.\nDuring the 2001 Conservative leadership election, she could not find sufficient support amongst Conservative MPs for her leadership candidacy. She first supported Michael Ancram, who was eliminated in the first round, and then Kenneth Clarke, who lost in the final round. She afterwards declined to serve in Iain Duncan Smith's Shadow Cabinet (although she indicated on the television programme \"When Louis Met...\", prior to the leadership contest, that she wished to retire to the backbenches anyway).\nIn the 2005 leadership election, she initially supported Kenneth Clarke again. Once he was eliminated, she turned support towards Liam Fox. Following Fox's subsequent elimination, she took time to reflect before finally declaring for David Davis. She expressed reservations over the eventual winner David Cameron, feeling that he did not, like the other candidates, have a proven track record, and she was later a leading figure in parliamentary opposition to his A-List policy. At the October 2006 Conservative Conference, she was Chief Dragon in a political version of the television programme \"Dragons' Den\", in which A-list candidates were invited to put forward a policy proposal, which was then torn apart by her team of Rachel Elnaugh, Oliver Letwin and Michael Brown.\nIn an interview with \"Metro\" in September 2006 she stated that if Parliament were of a normal length, it was likely she would retire at the next general election. She confirmed her intention to stand down to \"The Observer\"'s Pendennis diary in September 2007, and again in October 2007 after Prime Minister Gordon Brown quashed speculation of an autumn 2007 general election.\nIn November 2006, she moved into the house of an Islington Labour Councillor to experience life on a council estate, her response to her experience being \"Five years ago I made a speech in the House of Commons about the forgotten decents. I have spent the last week on estates in the Islington area finding out that they are still forgotten.\"\nWiddecombe was one of the 98 MPs who voted to keep their expense details secret. When the expenses claims were leaked, however, Widdecombe was described by \"The Daily Telegraph\" as one of the \"saints\" amongst all MPs.\nIn May 2009, following the resignation of Michael Martin as Speaker of the House of Commons, it was reported that Widdecombe was gathering support for election as interim Speaker until the next general election. On 11 June 2009, she confirmed her bid to be the Speaker. She made it through to the second ballot but came last and was eliminated.\nWiddecombe retired from politics at the 2010 general election. It was rumoured that she would be a Conservative candidate for Police and Crime Commissioner in 2012, but she refused. She has since spoken about her opposition to the Coalition Government and her surprise at not being given a peerage by David Cameron.\nIn 2016, she supported Brexit during the 2016 EU referendum and, following the resignation of David Cameron, endorsed Andrea Leadsom in her candidacy for election for the leadership of the governing Conservative Party.\nReturn to politics \u2013 Brexit Party.\nIn 2019 she returned to politics as a candidate for the Brexit Party in the European parliament elections in South West England, which were held on 23 May, though she maintained that she would still vote for the Conservatives in the local elections that took place three weeks before. She was expelled by the Conservative Party immediately after her announcement. Widdecombe had considered joining the Brexit Party in March 2019, but joined later, in May.\nWiddecombe said that her decision to stand resulted from the Government's failure to deliver Britain's departure from the EU on schedule. \"Both major parties need a seismic shock,\" she said, \"to see the extent of public disgust.\" She subsequently won her seat.\nWiddecombe became a member of the European Parliament Committee on Civil Liberties, Justice and Home Affairs (LIBE).\nWiddecombe stood as a candidate for Plymouth Sutton and Devonport in the 2019 UK general election, coming a distant third but retaining her deposit with 5.5% of the vote. Nigel Farage claimed that she was told by the Conservative Party that she would be part of their Brexit negotiations if she stood down as a candidate.\nPolitical views.\nSocial issues.\nAs an MP, Widdecombe expressed socially conservative views, including opposition to abortion; it was understood during her time in frontline politics that she would not become Health Secretary as long as this involved responsibility for abortions. Although a committed Christian, she has characterised the issue as one of life and death on which her view had been the same when she was agnostic and was a member of the Society for the Protection of Unborn Children while studying at Oxford. During Parliament, Widdecombe was a member of the Pro-Life All Party Parliamentary Group, which met with SPUC over concerns the organisation's more strident approach to abortion policy could alienate Protestant and atheist supporters.\nShe converted from the Church of England to the Roman Catholic Church following the decision of the Church of England on the ordination of women as priests.\nCriminal justice.\nIn her speech at the 2000 Conservative conference, she called for a zero tolerance policy of prosecution, with the punishment of \u00a3100 fines for users of cannabis. This was well received by rank-and-file Conservative delegates.\nOver the years, Widdecombe has expressed her support for a reintroduction of the death penalty, which was abolished in the UK in 1965. She notably spoke of her support for its reintroduction for the worst cases of murder in the aftermath of the murder of two 10-year-old girls from Soham, Cambridgeshire, in August 2002, in the Soham murders. She supported the argument that the death penalty would have deterrent value, as within five years of its abolition the national murder rate had more than doubled.\nEnvironmental and science issues.\nShe is a committed animal lover and one of the several Conservative MPs to have consistently voted for the ban on the hunting of foxes. Widdecombe was among more than 20 high-profile people who signed a letter to Members of Parliament in 2015 to oppose David Cameron's plan to amend the Hunting Act 2004.\nShe has expressed a variety of views on scientific issues such as climate change but has been opposed to legislation reducing emissions. Her views on the subject appear to have hardened over time. In 2007, she wrote that she did not want to belittle the issue but was sceptical of the claims that specific actions would prevent catastrophe, then in 2008 that her doubts had been \"crystalised\" by Nigel Lawson's book \"An Appeal to Reason\", before stating in 2009 that \"There is no climate change, hasn\u2019t anybody looked out of their window recently?\" She was one of the five MPs who voted against the Climate Change Act 2008. In 2011 she expressed the view that \"climate change money should go to armed services\".\nThe previous year, she voted to support a parliamentary motion supporting homeopathy, criticising the Science and Technology Committee's Report on the subject.\nHomosexuality.\nWiddecombe supported the partial decriminalisation of homosexuality in 1967 in England and Wales. After that, Widdecombe consistently opposed further reforms while in Parliament. Out of the 17 parliamentary votes between 1998 and 2008 considered by the Public Whip website to concern equal rights for homosexuals, Widdecombe took the opposing position in 15 cases, not being present at the other two votes. In 1999, Widdecombe stated that \"I do not think that [homosexuality] can be promoted as an equally valid lifestyle to [heterosexual] marriage, but I would say the same about irregular heterosexual arrangements.\"\nShe has consistently argued against an equal age of consent for same-sex relationships, voting against a 1994 Act (which would have reduced the age of consent for some male-male sexual activity from 21 to 18), secondly in 1998 (arguing against a further reduction from 18 to 16, which later occurred in 2000); On the latter point, she wrote in \"The Mail on Sunday\" that \"one of the sundry horrors for which this Government is likely to be remembered will be that it gave its imprimatur to sodomy at 16\", adding that if the age of consent was equalised, \"there will be no protection for the vulnerable and confused against the predatory attentions of older men\". She later said in 2000: \"I do not believe that issues of equality should override the imperatives of protecting the young.\" In 2003, Widdecombe opposed the repeal of Section 28 of the Local Government Act 1988. In 2012, Widdecombe voiced support in the \"Daily Express\" for the practise of conversion therapy, which claims to change the orientation of homosexuals.\nWiddecombe has also expressed her opposition to the same-sex marriage, introduced by David Cameron's government in 2014, arguing that \"the state must have a preferred model\" which is \"a union that is generally open to procreation\". In 2020, she expressed her opposition to same-sex dancing on \"Strictly Come Dancing\", saying: \"I don't think it is what viewers of Strictly, especially families, are looking for. But that's up to the audience and the programme.\"\nControversies.\nIn 1990, following the assassination of the Conservative politician Ian Gow by the Provisional Irish Republican Army (IRA), the Eastbourne by-election for his seat in the House of Commons was won by the Liberal Democrat David Bellotti. Upon the announcement, Widdecombe told the voters that the IRA would be \"toasting their success\".\nIn 1996, Widdecombe, as prisons minister, defended the Government's policy to shackle pregnant prisoners with handcuffs and chains when in hospital receiving prenatal care. Widdecombe told the Commons that the restrictions were needed to prevent prisoners from escaping the hospital. \"Some MPs may like to think that a pregnant woman would not or could not escape. Unfortunately this is not true. The fact is that hospitals are not secure places in which to keep prisoners, and since 1990, 20 women have escaped from hospitals\". Jack Straw, Labour's Home Affairs spokesman at the time, said it was \"degrading and unnecessary\" for a woman to be shackled at any stage.\nIn May 1997, in the context of an inquiry into a series of prison escapes, Widdecombe remarked of former Home Secretary Michael Howard, under whom she had served, that there is \"something of the night\" about him.\nThis much quoted comment is thought to have contributed to failure of Howard's 1997 campaign for the Conservative Party leadership, including by Howard and Widdecombe and led to him being caricatured as a vampire, in part due to his Romanian ancestry. Howard became the official party leader in 2003, and Widdecombe then stated, \"I explained fully what my objections were in 1997 and I do not retract anything I said then. But ... we have to look to the future and not the past.\"\nIn 2001, when Michael Portillo was running for leader of the Conservative Party, Widdecombe described him and his allies as \"backbiters\" due to his alleged destabilising influence under Hague. She went on to say that, should he be appointed leader, she would never give him her allegiance. This was amidst a homophobic campaign led by socially conservative critics of Portillo.\nIn 2009, she partially defended Carol Thatcher's use of the racial slur golliwog on \"Any Questions?\", saying: \"There is a generation to whom a golliwog is merely a toy, a generation which was much endeared by its golliwogs which grew up with them on jam jars ... and there is a generation, a new generation for whom that word is deeply offensive and one does have to make I think some allowance for the fact.\" In December 2019, leaked WhatsApp conversations to the \"Plymouth Herald\" between her and Brexit Party activists showed Widdecombe using the term amid rumours BP campaign funding was being diverted away from Plymouth ahead of the general election of that year. Referring to throwing of one's toys out of the pram, Widdecombe said: \"Yes, I threw all my toys of the pram. Bears and gollywogs flying everywhere!!\".\nIn 2019 Widdecombe defended the comments she made in a 2012 article that supported \"gay conversion\" therapy. She told Sky News that science may yet \"provide an answer\" to the question of whether people can \"switch sexuality\". Following Widdecombe's apparent endorsement of conversion therapy, at least one venue, the Landmark theatre in Ilfracombe, Devon, cancelled a performance of her one-woman show.\nWiddecombe and two other Brexit Party figures were criticised for previous appearances on the David Icke-affiliated \"Richie Allen Show\", which has been accused of promoting Holocaust denial and antisemitic conspiracy theories about the Rothschild family and Zionism. Widdecombe appeared three times between August 2017 and April 2019 and was described as an \"old friend of the show\" by the host during one appearance. Widdecombe told \"Jewish Chronicle\" that she agreed to appear to discuss Brexit, and that she \"had never heard of the \"Richie Allen Show\" until I agreed to go on\" and distanced herself from its antisemitic content by, among other things, pointing to her membership of the Conservative Friends of Israel, B'nai B'rith event speeches, and her novel \"An Act of Treachery\", which she said is set during the Holocaust.\nWiddecombe was elected as a Member of the European Parliament for the Brexit Party on 23 May 2019 in the European elections. On 3 July 2019 she used her maiden speech in Strasbourg to compare Brexit to slaves revolting against their owners and to a colonised country rising up against occupying forces, a stance which was criticised by members of both the European Parliament and the British House of Commons.\nMedia work and appearances.\nIn 2002 she took part in the ITV programme \"Celebrity Fit Club\". Also in 2002 she took part in a Louis Theroux television documentary, depicting her life, both in and out of politics. In March 2004 she briefly became \"The Guardian\" newspaper's agony aunt, introduced with an Emma Brockes interview. In 2005 BBC Two showed six episodes of \"The Widdecombe Project\", an agony aunt television programme. In 2005, she appeared in a new series of \"Celebrity Fit Club\", but this time as a panel member dispensing wisdom and advice to the celebrities taking part. Also in 2005, she presented the show \"Ann Widdecombe to the Rescue\" in which she acted as an agony aunt, dispensing advice to disputing families, couples, and others across the UK. In 2005, she also appeared in a discussion programme on Five to discuss who had been England's greatest monarch since the Norman Conquest; her choice of monarch was Charles II.\nShe was the guest host of news quiz \"Have I Got News for You\" twice, in 2006 and 2007. Her first appearance as guest host, in 2006, was widely regarded as a success. Following her second appearance, Widdecombe vowed she would never appear on the show again because of comments made by panellist Jimmy Carr. She wrote, \"His idea of wit is a barrage of filth and the sort of humour most men grow out of in their teens... [T]here's no amount of money for which I would go through those two recording hours again. At one stage I nearly walked out.\" She did, however, stand by her appraisal of regular panellists Ian Hislop and Paul Merton, whom she has called \"the fastest wits in showbusiness\". Merton later revealed that he thought Widdecombe had been \"the worst ever presenter\" of the show, particularly on her second appearance where Merton claimed she \"thought she was Victoria Wood\".\nIn 2007 she awarded the \"University Challenge\" trophy to the winners. In the same year, she appeared in \"The Sound of Drums\", the 12th episode of the third series of the science-fiction drama \"Doctor Who\", endorsing the Master's Prime Minister campaign. Since 2007 Widdecombe has fronted a television series called \"Ann Widdecombe Versus\", on ITV1, in which she speaks to various people about things related to her as an MP, with an emphasis on confronting those responsible for problems she wished to tackle. On 15 August 2007 she talked about prostitution, the next week about benefits and the week after that about truancy. A fourth episode was screened on 18 September 2008 in which she travelled around London and Birmingham talking to girl gangs.\nIn 2009, Widdecombe appeared with Archbishop John Onaiyekan in an \"Intelligence Squared\" debate in which they defended the motion that the Catholic Church was a force for good. Arguing against the motion were Stephen Fry and Christopher Hitchens, who won the debate overall.\nIn October 2010, she appeared on BBC One's \"Strictly Come Dancing\", partnered by Anton du Beke, winning the support of some viewers despite low marks from the judges. After nine weeks of routines strongly flavoured by comedy the couple had received enough support in the public vote to stay in the contest. Widdecombe was eliminated from the competition on Sunday 5 December after the public vote had been combined with the judges' score; she was with Scott Maslen of \"EastEnders\" in the bottom two. In 2011 Widdecombe played the Lord Mayoress in an episode of Sooty.\nIn 2012, Widdecombe hosted a new quiz show for the Sky Atlantic channel, called \"Cleverdicks\". The show ran for one series with 30 one-hour episodes. It featured four contestants, usually high quality members of the UK national quiz circuit and ended with a money round for the winner of each show. In April 2012 Widdecombe presented an hour-long documentary for BBC Radio 5 Live, \"Drunk Again: Ann Widdecombe Investigates\", looking at how the British attitude to alcohol consumption has changed over the last few years. It was revealed in October 2012, that the year's Children in Need's appeal night would feature a \"Strictly Come Dancing\" special with former show favourites Russell Grant and Widdecombe. On 4 November 2012, Widdecombe guest-hosted one episode of BBC's \"Songs of Praise\" programme about singleness.\nIn October 2014, she appeared in the BBC series \"Celebrity Antiques Road Trip\", partnered with expert Mark Stacey \u2013 beating Craig Revel Horwood and Catherine Southon.\nWiddecombe took part in a television series \"24 Hours in the Past\", along with Colin Jackson, Alistair McGowan, Miquita Oliver, Tyger Drew-Honey and Zoe Lucker. The four-part series was aired from 28 April\u201319 May 2015 on BBC One and involved the celebrities experiencing life as workers in a dustyard, coachhouse, pottery and finally as workhouse inmates in 1840s Britain. She took part in an episode of \"\" in 2016. In 2017, Widdecombe took part in ITV's \"Sugar Free Farm\".\nIn January 2018, Widdecombe was the first to enter the \"Celebrity Big Brother\" house to participate as a housemate in its twenty-first series. A controversial figure in the house, she was criticised over her comments regarding the Harvey Weinstein controversy as well as comments perceived to be anti-LGBT to her fellow housemates, most notably to drag queen Courtney Act (Shane Jenek). She finished the competition in second place as runner-up to Jenek, who became popular with viewers for challenging Widdecombe's comments.\nIn 2019 Widdecombe appeared on the new celebrity version of \"The Crystal Maze\", where alongside Sunetra Sarker, Wes Nelson, Matthew Wright and Nikki Sanderson, she won money for the charity Stand Up to Cancer initiative.\nIn 2020 Widdecombe travelled to Norway for three days to visit Halden Prison, for the documentary, of \"The World\u2019s Most Luxurious Prison.\" \nStage acting career.\nFollowing her retirement, Widdecombe made her stage debut, on 9 December 2011, at the Orchard Theatre, Dartford in the Christmas pantomime \"Snow White and the Seven Dwarfs\", alongside \"Strictly Come Dancing\" judge Craig Revel Horwood. In April 2012, she had a ten-minute non-singing cameo part in Gaetano Donizetti's comic opera \"La Fille du Regiment\", playing the Duchesse de Crackentorp. Widdecombe reprised her pantomime performance, again with Revel Horwood, at the Swan Theatre, High Wycombe in December 2012.\nWiddecombe stepped in at short notice to play the Evil Queen in \"Snow White and the Seven Dwarfs\", which was published by the Brothers Grimm in 1812, at Bridlington Spa in December 2016. She replaced Lorraine Chase, who had been injured in an accident two weeks before rehearsals were due to commence. This was Widdecombe's first appearance as a pantomime 'baddie'; a role she told the press she had always hoped for.\nIn December 2017 Widdecombe played the Empress of China in the pantomime \"Aladdin\" at the Marina Theatre in Lowestoft. The production was the theatre's most successful pantomime to date.\nPersonal life and family.\nUntil her retirement following the 2010 general election, Widdecombe divided her time between her two homes\u00a0\u2013 one in London and one in the countryside village of Sutton Valence, Kent, in her constituency. She sold both of these properties, however, upon deciding to retire at the next general election. She shared her home in London with her widowed mother, Rita Widdecombe, until Rita's death, on 25 April 2007, aged 95. In March 2008, she purchased a house in Haytor Vale, on Dartmoor in Devon, where she retired. Her brother, Malcolm (1937\u20132010), who was an Anglican Canon in Bristol, retired in May 2009 and died in October 2010. Her nephew, Roger Widdecombe, is an Anglican priest. She has never married nor had any children. In November 2007 on BBC Radio 4 she described how a journalist once produced a profile on her with the assumption that she had had at least \"one sexual relationship\", to which Widdecombe replied: \"Be careful, that's the way you get sued\". When interviewer Jenni Murray asked if she had ever had a sexual relationship, Widdecombe laughed \"it's nobody else's business\".\nIn a 2001 report in \"The Guardian\" it was claimed that she had a three-year romance while studying at the University of Oxford. Widdecombe herself confirmed the liaison when she appeared, in January 2018, on the UK reality show \"Big Brother\", explaining that she had ended the romance in order to prioritise her career.\nWiddecombe has a fondness for cats and many other animals such as foxes, and has a section of her website devoted to all the pet cats with which she has shared her life. Widdecombe also adopted two goats at the Buttercups Goat Sanctuary in Boughton Monchelsea near Maidstone, although one later died. In an interview, Widdecombe talked about her appreciation of music despite describing herself as \"pretty well tone-deaf\".\nHer non-political accomplishments include being a popular novelist. Widdecombe also currently writes a weekly column for the \"Daily Express\".\nIn January 2011 Widdecombe was President of the North of England Education Conference in Blackpool, and gave a speech there supporting selective education and opposing the ban on new grammar schools being built. She has also become a patron of The Grace Charity for M.E.\nWiddecombe revealed, in an April 2012 interview with Matt Chorley of \"The Independent\", that she was writing her own autobiography, which she described as \"rude about all and sundry, but an amount of truth is always necessary\".\nWiddecombe is a Patron of the charity Safe Haven for Donkeys in the Holy Land (SHADH) and in 2014 visited the SHADH Donkey Sanctuary in the West Bank.\nReligious views.\nWiddecombe became an Anglican in her 30s, after a period of being an agnostic following her departure from religious schooling. Widdecombe is now a practising Roman Catholic; she converted in 1993 after leaving the Church of England. Her reasons for leaving the latter were many, as she explained to reporters from the \"New Statesman\":\nIn October 2006, she pledged to boycott British Airways for suspending a worker who refused to hide her cross. The matter was resolved when the company reversed the suspension.\nIn 2010, Widdecombe turned down the offer to be Britain's next ambassador to the Holy See, being prevented from accepting by suffering a detached retina. She was made a Dame of the Order of St. Gregory the Great by Pope Benedict XVI for services to politics and public life on 31 January 2013."}
{"id": "2425", "revid": "19366292", "url": "https://en.wikipedia.org/wiki?curid=2425", "title": "Aurangzeb", "text": "Muhi-ud-Din Muhammad (3 November 16183 March 1707), commonly known by the sobriquet (Persian: \"Ornament of the Throne\") or by his regnal title (Persian: \"Conqueror of the World\"), was the sixth Mughal emperor, who ruled over almost the entire Indian subcontinent for a period of 49 years. Widely considered to be the last effective ruler of the Mughal Empire, Aurangzeb compiled the Fatawa-e-Alamgiri, and was among the few monarchs to have fully established Sharia law and Islamic economics throughout the Indian subcontinent. He was an accomplished military leader whose rule has been the subject of praise, though he has also been described as the most controversial ruler in Indian history.\nHe was a notable expansionist; during his reign, the Mughal Empire reached its greatest extent, ruling over nearly all of the Indian subcontinent. During his lifetime, victories in the south expanded the Mughal Empire to 4 million square kilometres, and he ruled over a population estimated to be over 158 million subjects, . Under his reign, India surpassed Qing China to become the world's largest economy and biggest manufacturing power, worth nearly a quarter of global GDP and more than the entirety of Western Europe, and its largest and wealthiest subdivision, the Bengal Subah, signaled proto-industrialization.\nAurangzeb was noted for his religious piety; he memorized the entire Quran, studied hadiths and stringently observed the rituals of Islam.\nUnlike his predecessors, including his father Shah Jahan, Aurangzeb considered the royal treasury to be held in trust for the citizens of his empire. He did not enjoy a luxurious life and his personal expenses and constructions of small mosques were covered by his own earnings, which included the sewing of caps and trade of his written copies of the Quran. He also patronized works of Islamic and Arabic calligraphy.\nAurangzeb has been subject to criticism. Critics argue that his policies abandoned his predecessors' legacy of pluralism and religious tolerance, citing his introduction of the \"jizya\" tax and other policies based on Islamic ethics, demolition of Hindu temples, the executions of his elder brother Dara Shikoh, Maratha king Sambhaji and the Sikh Guru Tegh Bahadur, and the prohibition and supervision of behaviour and activities that are forbidden in Islam such as gambling, fornication, and consumption of alcohol and narcotics. Some historians question the historicity of the claims of his critics, arguing that his destruction of temples has been exaggerated, and noting that he also built temples, paid for their maintenance, employed significantly more Hindus in his imperial bureaucracy than his predecessors did, and opposed bigotry against Hindus and Shia Muslims.\nEarly life.\nAurangzeb was born on 3 November 1618, in Dahod, Gujarat. He was the third son and sixth child of Shah Jahan and Mumtaz Mahal. In June 1626, after an unsuccessful rebellion by his father, Aurangzeb and his brother Dara Shukoh were kept as hostages under their grandparents' (Nur Jahan and Jahangir) Lahore court. On 26 February 1628, Shah Jahan was officially declared the Mughal Emperor, and Aurangzeb returned to live with his parents at Agra Fort, where Aurangzeb received his formal education in Arabic and Persian. His daily allowance was fixed at Rs. 500, which he spent on religious education and the study of history.\nOn 28 May 1633, Aurangzeb escaped death when a powerful war elephant stampeded through the Mughal Imperial encampment. He rode against the elephant and struck its trunk with a lance, and successfully defended himself from being crushed. Aurangzeb's valour was appreciated by his father who conferred him the title of \"Bahadur\" (Brave) and had him weighed in gold and presented gifts worth Rs. 200,000. This event was celebrated in Persian and Urdu verses, and Aurangzeb said:\nEarly military campaigns and administration.\nBundela War.\nAurangzeb was nominally in charge of the force sent to Bundelkhand with the intent of subduing the rebellious ruler of Orchha, Jhujhar Singh, who had attacked another territory in defiance of Shah Jahan's policy and was refusing to atone for his actions. By arrangement, Aurangzeb stayed in the rear, away from the fighting, and took the advice of his generals as the Mughal Army gathered and commenced the Siege of Orchha in 1635. The campaign was successful and Singh was removed from power.\nViceroy of the Deccan.\nAurangzeb was appointed viceroy of the Deccan in 1636. After Shah Jahan's vassals had been devastated by the alarming expansion of Ahmednagar during the reign of the Nizam Shahi boy-prince Murtaza Shah III, the emperor dispatched Aurangzeb, who in 1636 brought the Nizam Shahi dynasty to an end. In 1637, Aurangzeb married the Safavid princess Dilras Banu Begum, posthumously known as Rabia-ud-Daurani. She was his first wife and chief consort as well as his favourite. He also had an infatuation with a slave girl, Hira Bai, whose death at a young age greatly affected him. In his old age, he was under the charms of his concubine, Udaipuri Bai. The latter had formerly been a companion to Dara Shukoh. In the same year, 1637, Aurangzeb was placed in charge of annexing the small Rajput kingdom of Baglana, which he did with ease.\nIn 1644, Aurangzeb's sister, Jahanara, was burned when the chemicals in her perfume were ignited by a nearby lamp while in Agra. This event precipitated a family crisis with political consequences. Aurangzeb suffered his father's displeasure by not returning to Agra immediately but rather three weeks later. Shah Jahan had been nursing Jahanara back to health in that time and thousands of vassals had arrived in Agra to pay their respects. Shah Jahan was outraged to see Aurangzeb enter the interior palace compound in military attire and immediately dismissed him from his position of viceroy of the Deccan; Aurangzeb was also no longer allowed to use red tents or to associate himself with the official military standard of the Mughal emperor. Other sources tell us that Aurangzeb was dismissed from his position because Aurangzeb left the life of luxury and became a Faqir.\nIn 1645, he was barred from the court for seven months and mentioned his grief to fellow Mughal commanders. Thereafter, Shah Jahan appointed him governor of Gujarat where he served well and was rewarded for bringing stability.\nIn 1647, Shah Jahan moved Aurangzeb from Gujarat to be governor of Balkh, replacing a younger son, Murad Baksh, who had proved ineffective there. The area was under attack from Uzbek and Turkmen tribes. While the Mughal artillery and muskets were a formidable force, so too were the skirmishing skills of their opponents. The two sides were in stalemate and Aurangzeb discovered that his army could not live off the land, which was devastated by war. With the onset of winter, he and his father had to make a largely unsatisfactory deal with the Uzbeks, giving away territory in exchange for nominal recognition of Mughal sovereignty. The Mughal force suffered still further with attacks by Uzbeks and other tribesmen as it retreated through the snow to Kabul. By the end of this two-year campaign, into which Aurangzeb had been plunged at a late stage, a vast sum of money had been expended for little gain.\nFurther inauspicious military involvements followed, as Aurangzeb was appointed governor of Multan and Sindh. His efforts in 1649 and 1652 to dislodge the Safavids at Kandahar, which they had recently retaken after a decade of Mughal control, both ended in failure as winter approached. The logistical problems of supplying an army at the extremity of the empire, combined with the poor quality of armaments and the intransigence of the opposition have been cited by John Richards as the reasons for failure, and a third attempt in 1653, led by Dara Shikoh, met with the same outcome.\nAurangzeb became viceroy of the Deccan again after he was replaced by Dara Shukoh in the attempt to recapture Kandahar. Aurangzeb regretted this and harboured feelings that Shikoh had manipulated the situation to serve his own ends. Aurangbad's two \"jagirs\" (land grants) were moved there as a consequence of his return and, because the Deccan was a relatively impoverished area, this caused him to lose out financially. So poor was the area that grants were required from Malwa and Gujarat in order to maintain the administration and the situation caused ill-feeling between father and son. Shah Jahan insisted that things could be improved if Aurangzeb made efforts to develop cultivation. Aurangzeb appointed Murshid Quli Khan to extend to the Deccan the \"zabt\" revenue system used in northern India. Murshid Quli Khan organised a survey of agricultural land and a tax assessment on what it produced. To increase revenue, Murshid Quli Khan granted loans for seed, livestock, and irrigation infrastructure. The Deccan returned to prosperity,\nAurangzeb proposed to resolve the situation by attacking the dynastic occupants of Golconda (the Qutb Shahis) and Bijapur (the Adil Shahis). As an adjunct to resolving the financial difficulties, the proposal would also extend Mughal influence by accruing more lands. Aurangzeb advanced against the Sultan of Bijapur and besieged Bidar. The \"Kiladar\" (governor or captain) of the fortified city, Sidi Marjan, was mortally wounded when a gunpowder magazine exploded. After twenty-seven days of hard fighting, Bidar was captured by the Mughals and Aurangzeb continued his advance. Again, he was to feel that Dara had exerted influence on his father: believing that he was on the verge of victory in both instances, Aurangzeb was frustrated that Shah Jahan chose then to settle for negotiations with the opposing forces rather than pushing for complete victory.\nWar of Succession.\nThe four sons of Shah Jahan all held governorships during their father's reign. The emperor favoured the eldest, Dara Shukoh. This had caused resentment among the younger three, who sought at various times to strengthen alliances between themselves and against Dara. There was no Mughal tradition of primogeniture, the systematic passing of rule, upon an emperor's death, to his eldest son. Instead it was customary for sons to overthrow their father and for brothers to war to the death among themselves. Historian Satish Chandra says that \"In the ultimate resort, connections among the powerful military leaders, and military strength and capacity [were] the real arbiters\". The contest for power was primarily between Dara Shikoh and Aurangzeb because, although all four sons had demonstrated competence in their official roles, it was around these two that the supporting cast of officials and other influential people mostly circulated. There were ideological differences\u00a0\u2014 Dara was an intellectual and a religious liberal in the mould of Akbar, while Aurangzeb was much more conservative\u00a0\u2014\u00a0but, as historians Barbara D. Metcalf and Thomas R. Metcalf say, \"To focus on divergent philosophies neglects the fact that Dara was a poor general and leader. It also ignores the fact that factional lines in the succession dispute were not, by and large, shaped by ideology.\" Marc Gaborieau, professor of Indian studies at l'\u00c9cole des Hautes \u00c9tudes en Sciences Sociales, explains that \"The loyalties of [officials and their armed contingents] seem to have been motivated more by their own interests, the closeness of the family relation and above all the charisma of the pretenders than by ideological divides.\" Muslims and Hindus did not divide along religious lines in their support for one pretender or the other nor, according to Chandra, is there much evidence to support the belief that Jahanara and other members of the royal family were split in their support. Jahanara, certainly, interceded at various times on behalf of all of the princes and was well-regarded by Aurangzeb even though she shared the religious outlook of Dara.\nIn 1656, a general under Qutb Shahi dynasty named Musa Khan led an army of 12,000 musketeers to attack Aurangzeb, and later on the same campaign Aurangzeb, in turn, rode against an army consisting 8,000 horsemen and 20,000 Karnataka musketeers.\nHaving made clear that he wanted Dara to succeed him, Shah Jahan became ill with stranguary in 1657 and was closeted under the care of his favourite son in the newly built city of Shahjahanabad (Old Delhi). Rumours of the death of Shah Jahan abounded and the younger sons were concerned that Dara might be hiding it for Machiavellian reasons. Thus, they took action: Shah Shuja In Bengal, where he had been governor since 1637, Prince Muhammad Shuja crowned himself King at RajMahal, and brought his cavalry, artillery and river flotilla upriver towards Agra. Near Varanasi his forces confronted a defending army sent from Delhi under the command of Prince Sulaiman Shukoh, son of Dara Shukoh, and Raja Jai Singh while Murad did the same in his governorship of Gujarat and Aurangzeb did so in the Deccan. It is not known whether these preparations were made in the mistaken belief that the rumours of death were true or whether the challengers were just taking advantage of the situation.\nAfter regaining some of his health, Shah Jahan moved to Agra and Dara urged him to send forces to challenge Shah Shuja and Murad, who had declared themselves rulers in their respective territories. While Shah Shuja was defeated at Banares in February 1658, the army sent to deal with Murad discovered to their surprise that he and Aurangzeb had combined their forces, the two brothers having agreed to partition the empire once they had gained control of it. The two armies clashed at Dharmat in April 1658, with Aurangzeb being the victor. Shuja was being chased through Bihar and the victory of Aurangzeb proved this to be a poor decision by Dara Shikoh, who now had a defeated force on one front and a successful force unnecessarily pre-occupied on another. Realising that his recalled Bihar forces would not arrive at Agra in time to resist the emboldened Aurangzeb's advance, Dara scrambled to form alliances in order but found that Aurangzeb had already courted key potential candidates. When Dara's disparate, hastily concocted army clashed with Aurangzeb's well-disciplined, battle-hardened force at the Battle of Samugarh in late May, neither Dara's men nor his generalship were any match for Aurangzeb. Dara had also become over-confident in his own abilities and, by ignoring advice not to lead in battle while his father was alive, he cemented the idea that he had usurped the throne. \"After the defeat of Dara, Shah Jahan was imprisoned in the fort of Agra where he spent eight long years under the care of his favourite daughter Jahanara.\"\nAurangzeb then broke his arrangement with Murad Baksh, which probably had been his intention all along. Instead of looking to partition the empire between himself and Murad, he had his brother arrested and imprisoned at Gwalior Fort. Murad was executed on 4 December 1661, ostensibly for the murder of the \"diwan\" of Gujarat sometime earlier. The allegation was encouraged by Aurangzeb, who caused the \"diwan's\" son to seek retribution for the death under the principles of Sharia law. Meanwhile, Dara gathered his forces, and moved to the Punjab. The army sent against Shuja was trapped in the east, its generals Jai Singh and Dilir Khan submitted to Aurangzeb, but Dara's son, Suleiman Shikoh, escaped. Aurangzeb offered Shah Shuja the governorship of Bengal. This move had the effect of isolating Dara Shikoh and causing more troops to defect to Aurangzeb. Shah Shuja, who had declared himself emperor in Bengal began to annex more territory and this prompted Aurangzeb to march from Punjab with a new and large army that fought during the Battle of Khajwa, where Shah Shuja and his chain-mail armoured war elephants were routed by the forces loyal to Aurangzeb. Shah Shuja then fled to Arakan (in present-day Burma), where he was executed by the local rulers.\nWith Shuja and Murad disposed of, and with his father immured in Agra, Aurangzeb pursued Dara Shikoh, chasing him across the north-western bounds of the empire. Aurangzeb claimed that Dara was no longer a Muslim and accused him of poisoning the Mughal Grand Vizier Saadullah Khan. After a series of battles, defeats and retreats, Dara was betrayed by one of his generals, who arrested and bound him. In 1658, Aurangzeb arranged his formal coronation in Delhi.\nOn 10 August 1659, Dara was executed on grounds of apostasy and his head was sent to Shahjahan. Having secured his position, Aurangzeb confined his frail father at the Agra Fort but did not mistreat him. Shah Jahan was cared for by Jahanara and died in 1666.\nReign.\nBureaucracy.\nAurangzeb's imperial bureaucracy employed significantly more Hindus than that of his predecessors.\nBetween 1679 and 1707, the number of Hindu officials in the Mughal administration rose by half, to represent 31.6% of Mughal nobility, the highest in the Mughal era. Many of them were Marathas and Rajputs, who were his political allies.\nEstablishment of Islamic law.\nAurangzeb was an orthodox Muslim ruler. Subsequent to the policies of his three predecessors, he endeavored to make Islam a dominant force in his reign. However these efforts brought him into conflict with the forces that were opposed to this revival.\nHistorian Katherine Brown has noted that \"The very name of Aurangzeb seems to act in the popular imagination as a signifier of politico-religious bigotry and repression, regardless of historical accuracy.\" The subject has also resonated in modern times with popularly accepted claims that he intended to destroy the Bamiyan Buddhas. As a political and religious conservative, Aurangzeb chose not to follow the secular-religious viewpoints of his predecessors after his ascension. Shah Jahan had already moved away from the liberalism of Akbar, although in a token manner rather than with the intent of suppressing Hinduism, and Aurangzeb took the change still further. Though the approach to faith of Akbar, Jahangir and Shah Jahan was more syncretic than Babur, the founder of the empire, Aurangzeb's position is not so obvious.\nHis emphasis on sharia competed, or was directly in conflict, with his insistence that \"zawabit\" or secular decrees could supersede sharia. The chief qazi refusing to crown him in 1659, Aurangzeb had a political need to present himself as a \"defender of the sharia\" due to popular opposition to his actions against his father and brothers. Despite claims of sweeping edicts and policies, contradictory accounts exist. Historian Katherine Brown has argued that Aurangzeb never imposed a complete ban on music. He sought to codify Hanafi law by the work of several hundred jurists, called Fatawa-e-Alamgiri. It is possible the War of Succession and continued incursions combined with Shah Jahan's spending made cultural expenditure impossible.\nHe learnt that at Multan, Thatta, and particularly at Varanasi, the teachings of Hindu Brahmins attracted numerous Muslims. He ordered the subahdars of these provinces to demolish the schools and the temples of non-Muslims. Aurangzeb also ordered subahdars to punish Muslims who dressed like non-Muslims. The executions of the antinomian Sufi mystic Sarmad Kashani and the ninth Sikh Guru Tegh Bahadur bear testimony to Aurangzeb's religious policy; the former was beheaded on multiple accounts of heresy, the latter, according to Sikhs, because he objected to Aurangzeb's forced conversions.\nTaxation policy.\nShortly after coming to power, Aurangzeb remitted more than 80 long-standing taxes affecting all of his subjects.\nIn 1679, Aurangzeb chose to re-impose \"jizya\", a military tax on non-Muslim subjects in lieu of military service, after an abatement for a span of hundred years, in what was critiqued by many Hindu rulers, family-members of Aurangzeb, and Mughal court-officials. The specific amount varied with the socioeconomic status of a subject and tax-collection were often waived for regions hit by calamities; also, Brahmins, women, children, elders, the handicapped, the unemployed, the ill, and the insane were all perpetually exempted. The collectors were mandated to be Muslims. A majority of modern scholars reject that religious bigotry influenced the imposition; rather, realpolitik \u2014 economic constraints as a result of multiple ongoing battles and establishment of credence with the orthodox Ulemas \u2014 are held to be primary agents.\nAurangzeb also enforced differential taxation on Hindu merchants at the rate of 5% (as against 2.5% on Muslim merchants).\nPolicy on temples and mosques.\nAurangzeb issued land grants and provided funds for the maintenance of shrines of worship but also (often) ordered their destruction. Modern historians reject the thought-school of colonial and nationalist historians about these destruction being guided by religious zealotry; rather, the association of temples with sovereignty, power and authority is emphasized upon.\nWhilst constructing mosques were considered an act of royal duty to subjects, there are also several \"firmans\" in Aurangzeb's name, supporting temples, \"maths\", chishti shrines, and gurudwaras, including Mahakaleshwar temple of Ujjain, a gurudwara at Dehradun, Balaji temple of Chitrakoot, Umananda Temple of Guwahati and the Shatrunjaya Jain temples, among others. Numerous new temples were built, as well.\nContemporary court-chronicles mention hundreds of temple which were demolished by Aurangzab or his chieftains, upon his order. In September 1669, he ordered the destruction of Vishvanath Temple at Varanasi, which was established by Raja Man Singh, whose grandson Jai Singh was believed to have facilitated Shivaji's escape. After the Jat rebellion in Mathura (early 1670), which killed the patron of the town-mosque, Aurangzeb suppressed the rebels and ordered for the city's Kesava Deo temple to be demolished, and replaced with an \"Eidgah\". In around 1679, he ordered destruction of several prominent temples, including those of Khandela, Udaipur, Chittor and Jodhpur, which were patronaged by rebels. The Jama Masjid at Golkunda was similarly treated, after it was found that its ruler had built it to hide revenues from the state; however desecration of mosques are rare due to their complete lack of political capital contra temples.\nIn an order specific to Benaras, Aurangzeb invokes Sharia to declare that Hindus will be granted state-protection and temples won't be razed (but prohibits construction of any new temple); other orders to similar effect can be located. Richard Eaton, upon a critical evaluation of primary sources, counts 15 temples to have been destroyed during Aurangzeb's reign. Ian Copland and others reiterate Iqtidar Alam Khan who notes that, overall, Aurangzeb built more temples than he destroyed.\nExecution of opponents.\nThe first prominent execution during the long reign of Aurangzeb started with that of his brother Prince Dara Shikoh, who was accused of being influenced by Hinduism although some sources argue it was done for political reasons. Aurangzeb had his allied brother Prince Murad Baksh held for murder, judged and then executed. Aurangzeb is accused of poisoning his imprisoned nephew Sulaiman Shikoh.\nIn 1689, the second Maratha Chhatrapati (King) Sambhaji was brutally executed by Aurangzeb. In a sham trial, he was found guilty of murder and violence, atrocities against the Muslims of Burhanpur and Bahadurpur in Berar by Marathas under his command.\nIn 1675 the Sikh leader Guru Tegh Bahadur was arrested on orders by Aurangzeb, found guilty of blasphemy by a Qadi's court and executed.\nThe 32nd Da'i al-Mutlaq (Absolute Missionary) of the Dawoodi Bohra sect of Musta'l\u012b Islam Syedna Qutubkhan Qutubuddin was executed by Aurangzeb, then governor of Gujarat, for heresy; on 27 Jumadil Akhir 1056 AH (1648 AD), Ahmedabad, India.\nExpansion of the Mughal Empire.\nIn 1663, during his visit to Ladakh, Aurangzeb established direct control over that part of the empire and loyal subjects such as Deldan Namgyal agreed to pledge tribute and loyalty. Deldan Namgyal is also known to have constructed a Grand Mosque in Leh, which he dedicated to Mughal rule.\nIn 1664, Aurangzeb appointed Shaista Khan subedar (governor) of Bengal. Shaista Khan eliminated Portuguese and Arakanese pirates from the region, and in 1666 recaptured the port of Chittagong from the Arakanese king, Sanda Thudhamma. Chittagong remained a key port throughout Mughal rule.\nIn 1685, Aurangzeb dispatched his son, Muhammad Azam Shah, with a force of nearly 50,000 men to capture Bijapur Fort and defeat Sikandar Adil Shah (the ruler of Bijapur) who refused to be a vassal. The Mughals could not make any advancements upon Bijapur Fort, mainly because of the superior usage of cannon batteries on both sides. Outraged by the stalemate Aurangzeb himself arrived on 4 September 1686 and commanded the Siege of Bijapur; after eight days of fighting, the Mughals were victorious.\nOnly one remaining ruler, Abul Hasan Qutb Shah (the Qutbshahi ruler of Golconda), refused to surrender. He and his servicemen fortified themselves at Golconda and fiercely protected the Kollur Mine, which was then probably the world's most productive diamond mine, and an important economic asset. In 1687, Aurangzeb led his grand Mughal army against the Deccan Qutbshahi fortress during the Siege of Golconda. The Qutbshahis had constructed massive fortifications throughout successive generations on a granite hill over 400\u00a0ft high with an enormous eight-mile long wall enclosing the city. The main gates of Golconda had the ability to repulse any war elephant attack. Although the Qutbshahis maintained the impregnability of their walls, at night Aurangzeb and his infantry erected complex scaffolding that allowed them to scale the high walls. During the eight-month siege the Mughals faced many hardships including the death of their experienced commander Kilich Khan Bahadur. Eventually, Aurangzeb and his forces managed to penetrate the walls by capturing a gate, and their entry into the fort led Abul Hasan Qutb Shah to surrender peacefully.\nMilitary equipment.\nMughal cannon making skills advanced during the 17th century. One of the most impressive Mughal cannons is known as the Zafarbaksh, which is a very rare \"composite cannon\", that required skills in both wrought-iron forge welding and bronze-casting technologies and the in-depth knowledge of the qualities of both metals.\nAurangzeb military entourage consisted of 16 cannons including the \"Azdaha Paikar\" (which, was capable of firing a 33.5\u00a0kg ordnance) and \"Fateh Rahber\" (20 feet long with Persian and Arabic inscriptions).\nThe \"Ibrahim Rauza\" was also a famed cannon, which was well known for its multi-barrels. Fran\u00e7ois Bernier, the personal physician to Aurangzeb, observed versatile Mughal gun-carriages each drawn by two horses.\nDespite these innovations, most soldiers used bows and arrows, the quality of sword manufacture was so poor that they preferred to use ones imported from England, and the operation of the cannons was entrusted not to Mughals but to European gunners. Other weapons used during the period included rockets, cauldrons of boiling oil, muskets and manjaniqs (stone-throwing catapults).\nInfantry who were later called Sepoy and who specialised in siege and artillery emerged during the reign of Aurangzeb\nWar elephants.\nIn 1703, the Mughal commander at Coromandel, Daud Khan Panni spent 10,500 coins to purchase 30 to 50 war elephants from Ceylon.\nArt and culture.\nAurangzeb had a more austere nature than his predecessors, and greatly reduced imperial patronage of the figurative Mughal miniature. This had the effect of dispersing the court atelier to other regional courts. Being religious he encouraged Islamic calligraphy. His reign also saw the building of the Lahore Badshahi Masjid and Bibi Ka Maqbara in Aurangabad for his wife Rabia-ud-Daurani.\nCalligraphy.\nThe Mughal Emperor Aurangzeb is known to have patronised works of Islamic calligraphy during his reign particularly Syed Ali Tabrizi.\nArchitecture.\nUnlike his father, Aurangzeb was not much interested in architecture. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. He ordered the construction of the Badshahi Mosque in Lahore. He also constructed a mosque on Benares. The mosque he constructed in Srinagar is still the largest in Kashmir. The structure of Bibi Ka Maqbara in Aurangabad, which now is a historical monument was constructed by the sons of Aurangzeb in remembrance of their mother. The inspiration came from Taj mahal as is quite visible from its architecture.\nTextiles.\nThe textile industry in the Mughal Empire emerged very firmly during the reign of the Mughal Emperor Aurangzeb and was particularly well noted by Francois Bernier, a French physician of the Mughal Emperor. Francois Bernier writes how \"Karkanahs\", or workshops for the artisans, particularly in textiles flourished by \"employing hundreds of embroiderers, who were superintended by a master\". He further writes how \"Artisans manufacture of silk, fine brocade, and other fine muslins, of which are made turbans, robes of gold flowers, and tunics worn by females, so delicately fine as to wear out in one night, and cost even more if they were well embroidered with fine needlework\".\nHe also explains the different techniques employed to produce such complicated textiles such as \"Himru\" (whose name is Persian for \"brocade\"), \"Paithani\" (whose pattern is identical on both sides), \"Mushru\" (satin weave) and how \"Kalamkari\", in which fabrics are painted or block-printed, was a technique that originally came from Persia. Francois Bernier provided some of the first, impressive descriptions of the designs and the soft, delicate texture of Pashmina shawls also known as \"Kani\", which were very valued for their warmth and comfort among the Mughals, and how these textiles and shawls eventually began to find their way to France and England.\nForeign relations.\nAurangzeb sent diplomatic missions to Mecca in 1659 and 1662, with money and gifts for the Sharif. He also sent alms in 1666 and 1672 to be distributed in Mecca and Medina. Historian Naimur Rahman Farooqi writes that, \"By 1694, Aurangzeb's ardour for the Sharifs of Mecca had begun to wane; their greed and rapacity had thoroughly disillusioned the Emperor ... Aurangzeb expressed his disgust at the unethical behavior of the Sharif who appropriated all the money sent to the Hijaz for his own use, thus depriving the needy and the poor.\"\nRelations with the Uzbek.\nSubhan Quli, Balkh's Uzbek ruler was the first to recognise him in 1658 and requested for a general alliance, he worked alongside the new Mughal Emperor since 1647, when Aurangzeb was the Subedar of Balkh.\nRelations with the Safavid dynasty.\nAurangzeb received the embassy of Abbas II of Persia in 1660 and returned them with gifts. However, relations between the Mughal Empire and the Safavid dynasty were tense because the Persians attacked the Mughal army positioned near Kandahar. Aurangzeb prepared his armies in the Indus River Basin for a counteroffensive, but Abbas II's death in 1666 caused Aurangzeb to end all hostilities. Aurangzeb's rebellious son, Sultan Muhammad Akbar, sought refuge with Suleiman I of Persia, who had rescued him from the Imam of Musqat and later refused to assist him in any military adventures against Aurangzeb.\nRelations with the French.\nIn 1667, the French East India Company ambassadors Le Gouz and Bebert presented Louis XIV of France's letter which urged the protection of French merchants from various rebels in the Deccan. In response to the letter, Aurangzeb issued a Firman allowing the French to open a factory in Surat.\nRelations with the Sultanate of Maldives.\nIn the 1660s, the Sultan of the Maldives, Ibrahim Iskandar I, requested help from Aurangzeb's representative, the Faujdar of Balasore. The Sultan wished to gain his support in possible future expulsions of Dutch and English trading ships, as he was concerned with how they might impact the economy of the Maldives. However, as Aurangzeb did not possess a powerful navy and had no interest in providing support to Ibrahim in a possible future war with the Dutch or English, the request came to nothing.\nRelations with the Ottoman Empire.\nLike his father, Aurangzeb was not willing to acknowledge the Ottoman claim to the caliphate. He often supported the Ottoman Empire's enemies, extending cordial welcome to two rebel Governors of Basra, and granting them and their families a high status in the imperial service. Sultan Suleiman II's friendly postures were ignored by Aurangzeb. The Sultan urged Aurangzeb to wage holy war against Christians.\nRelations with the English and the Anglo-Mughal War.\nIn 1686, the Honourable East India Company, which had unsuccessfully tried to obtain a firman that would grant them regular trading privileges throughout the Mughal Empire, initiated the Anglo-Mughal War. This war ended in disaster for the English, particularly in 1689 when Aurangzeb dispatched a large fleet of grabs from Janjira that blockaded Bombay. The ships, commanded by Sidi Yaqub, were manned by Mappila (loyal to Ali Raja Ali II) and Abyssinian sailors. In 1690, realising the war was not going favourably for them, the Company sent envoys to Aurangzeb's camp to plead for a pardon. The company's envoys prostrated themselves before the emperor, agreed pay a large indemnity, and promise to refrain from such actions in the future.\nIn September 1695, English pirate Henry Every conducted one of the most profitable pirate raids in history with his capture of a Grand Mughal grab convoy near Surat. The Indian ships had been returning home from their annual pilgrimage to Mecca when the pirate struck, capturing the \"Ganj-i-Sawai\", reportedly the largest ship in the Muslim fleet, and its escorts in the process. When news of the capture reached the mainland, a livid Aurangzeb nearly ordered an armed attack against the English-governed city of Bombay, though he finally agreed to compromise after the Company promised to pay financial reparations, estimated at \u00a3600,000 by the Mughal authorities. Meanwhile, Aurangzeb shut down four of the English East India Company's factories, imprisoned the workers and captains (who were nearly lynched by a rioting mob), and threatened to put an end to all English trading in India until Every was captured. The Privy Council and East India Company offered a massive bounty for Every's apprehension, leading to the first worldwide manhunt in recorded history. However, Every successfully eluded capture.\nIn 1702, Aurangzeb sent Daud Khan Panni, the Mughal Empire's Subhedar of the Carnatic region, to besiege and blockade Fort St. George for more than three months. The governor of the fort Thomas Pitt was instructed by the East India Company to sue for peace.\nAdministrative reforms.\nTribute.\nAurangzeb received tribute from all over the Indian subcontinent, using this wealth to establish bases and fortifications in India, particularly in the Carnatic, Deccan, Bengal and Lahore.\nRevenue.\nAurangzeb's exchequer raised a record \u00a3100\u00a0million in annual revenue through various sources like taxes, customs and land revenue, \"et al.\" from 24 provinces. He had an annual yearly revenue of $450 million, more than ten times that of his contemporary Louis XIV of France.\nCoins.\nAurangzeb felt that verses from the \"Quran\" should not be stamped on coins, as done in former times, because they were constantly touched by the hands and feet of people. His coins had the name of the mint city and the year of issue on one face, and, the following couplet on other:\nRebellions.\nTraditional and newly coherent social groups in northern and western India, such as the Marathas, Rajputs, Hindu Jats, Pashtuns, and Sikhs, gained military and governing ambitions during Mughal rule, which, through collaboration or opposition, gave them both recognition and military experience.\nJat rebellion.\nIn 1669, Hindu Jats began to organise a rebellion that is believed to have been caused by the re-imposition of \"jizya\" and destruction of Hindu temples in Mathura. The Jats were led by Gokula, a rebel landholder from Tilpat. By the year 1670 20,000 Jat rebels were quelled and the Mughal Army took control of Tilpat, Gokula's personal fortune amounted to 93,000 gold coins and hundreds of thousands of silver coins.\nGokula was caught and executed. But the Jats once again attempted began their rebellion. Raja Ram Jat, in order to avenge his father Gokula's death, plundered Akbar's tomb of its gold, silver and fine carpets, opened Akbar's grave and dragged his bones and burned them in retaliation. Jats also shot off the tops of the minarets on the gateway to Akbar's Tomb and melted down two silver doors from the Taj Mahal. Aurangzeb appointed Mohammad Bidar Bakht as commander to crush the Jat rebellion. On 4 July 1688, Raja Ram Jat was captured and beheaded. His head was sent to Aurangzeb as proof.\nHowever, after Aurangeb's death, Jats under Badan Singh later established their independent state of Bharatpur.\nMughal\u2013Maratha Wars.\nIn 1657, while Aurangzeb attacked Golconda and Bijapur in the Deccan, the Hindu Maratha warrior, Shivaji, used guerrilla tactics to take control of three Adil Shahi forts formerly under his father's command. With these victories, Shivaji assumed de facto leadership of many independent Maratha clans. The Marathas harried the flanks of the warring Adil Shahis, gaining weapons, forts, and territory. Shivaji's small and ill-equipped army survived an all out Adil Shahi attack, and Shivaji personally killed the Adil Shahi general, Afzal Khan. With this event, the Marathas transformed into a powerful military force, capturing more and more Adil Shahi territories. Shivaji went on to neutralise Mughal power in the region.\nIn 1659, Aurangzeb sent his trusted general and maternal uncle Shaista Khan, the Wali in Golconda to recover forts lost to the Maratha rebels. Shaista Khan drove into Maratha territory and took up residence in Pune. But in a daring raid on the governor's palace in Pune during a midnight wedding celebration, led by Shivaji himself, the Marathas killed Shaista Khan's son and Shivaji maimed Shaista Khan by cutting off three fingers of his hand. Shaista Khan, however, survived and was re-appointed the administrator of Bengal going on to become a key commander in the war against the Ahoms.\nShivaji captured forts belonging to both Mughals and Bijapur. At last Aurangzeb ordered the armament of the Daulatabad Fort with two bombards (the Daulatabad Fort was later used as a Mughal bastion during the Deccan Wars). Aurangzeb also sent his general Raja Jai Singh of Amber, a Hindu Rajput, to attack the Marathas. Jai Singh won the fort of Purandar after fierce battle in which the Maratha commander Murarbaji fell. Foreseeing defeat, Shivaji agreed for a truce and a meeting with Aurangzeb at Delhi. Jai Singh also promised Shivaji his safety, placing him under the care of his own son, the future Raja Ram Singh I. However, circumstances at the Mughal court were beyond the control of the Raja, and when Shivaji and his son Sambhaji went to Agra to meet Aurangzeb, they were placed under house arrest because of Shivaji's apparent misbehaviour, from which they managed to effect a daring escape.\nShivaji returned to the Deccan, and crowned himself \"Chhatrapati\" or the ruler of the Maratha Kingdom in 1674. While Aurangzeb continued to send troops against him, Shivaji expanded Maratha control throughout the Deccan until his death in 1680. Shivaji was succeeded by his son, Sambhaji. Militarily and politically, Mughal efforts to control the Deccan continued to fail.\nOn the other hand, Aurangzeb's third son Akbar left the Mughal court along with a few Muslim Mansabdar supporters and joined Muslim rebels in the Deccan. Aurangzeb in response moved his court to Aurangabad and took over command of the Deccan campaign. The rebels were defeated and Akbar fled south to seek refuge with Sambhaji, Shivaji's successor. More battles ensued, and Akbar fled to Persia and never returned.\nIn 1689, Aurangzeb's forces captured and executed Sambhaji. His successor Rajaram, later Rajaram's widow Tarabai and their Maratha forces fought individual battles against the forces of the Mughal Empire. Territory changed hands repeatedly during the years (1689\u20131707) of interminable warfare . As there was no central authority among the Marathas, Aurangzeb was forced to contest every inch of territory, at great cost in lives and money. Even as Aurangzeb drove west, deep into Maratha territory\u00a0\u2013 notably conquering Satara\u00a0\u2014 the Marathas expanded eastwards into Mughal lands\u00a0\u2013 Malwa and Hyderabad. The Marathas also expanded further South into Southern India defeating the independent local rulers there capturing Jinji in Tamil Nadu. Aurangzeb waged continuous war in the Deccan for more than two decades with no resolution. He thus lost about a fifth of his army fighting rebellions led by the Marathas in Deccan India. He travelled a long distance to the Deccan to conquer the Marathas and eventually died at the age of 88, still fighting the Marathas.\nAurangzeb's shift from conventional warfare to anti-insurgency in the Deccan region shifted the paradigm of Mughal military thought. There were conflicts between Marathas and Mughals in Pune, Jinji, Malwa and Vadodara. The Mughal Empire's port city of Surat was sacked twice by the Marathas during the reign of Aurangzeb and the valuable port was in ruins.\nMatthew White estimates that about 2.5 million of Aurangzeb's army were killed during the Mughal\u2013Maratha Wars (100,000 annually during a quarter-century), while 2 million civilians in war-torn lands died due to drought, plague and famine.\nAhom campaign.\nWhile Aurangzeb and his brother Shah Shuja had been fighting against each other, the Hindu rulers of Kuch Behar and Assam took advantage of the disturbed conditions in the Mughal Empire, had invaded imperial dominions. For three years they were not attacked, but in 1660 Mir Jumla II, the viceroy of Bengal, was ordered to recover the lost territories.\nThe Mughals set out in November 1661. Within weeks they occupied the capital of Kuch Behar, which they annexed. Leaving a detachment to garrison it, the Mughal army began to retake their territories in Assam. Mir Jumla II advanced on Garhgaon, the capital of the Ahom kingdom, and reached it on 17 March 1662. The ruler, Raja Sutamla, had fled before his approach. The Mughals captured 82 elephants, 300,000 rupees in cash, 1000 ships, and 173 stores of rice.\nOn his way back to Dacca, in March 1663, Mir Jumla II died of natural causes. Skirmishes continued between the Mughals and Ahoms after the rise of Chakradhwaj Singha, who refused to pay further indemnity to the Mughals and during the wars that continued the Mughals suffered great hardships. Munnawar Khan emerged as a leading figure and is known to have supplied food to vulnerable Mughal forces in the region near Mathurapur. Although the Mughals under the command of Syed Firoz Khan the Faujdar at Guwahati were overrun by two Ahom armies in 1667, but they continued to hold and maintain presence in their eastern territories even after the Battle of Saraighat in 1671.\nThe Battle of Saraighat was fought in 1671 between the Mughal empire (led by the Kachwaha king, Raja Ramsingh I), and the Ahom Kingdom (led by Lachit Borphukan) on the Brahmaputra river at Saraighat, now in Guwahati. Although much weaker, the Ahom Army defeated the Mughal Army by brilliant uses of the terrain, clever diplomatic negotiations to buy time, guerrilla tactics, psychological warfare, military intelligence and by exploiting the sole weakness of the Mughal forces\u2014its navy.\nThe Battle of Saraighat was the last battle in the last major attempt by the Mughals to extend their empire into Assam. Though the Mughals managed to regain Guwahati briefly after a later Borphukan deserted it, the Ahoms wrested control in the Battle of Itakhuli in 1682 and maintained it till the end of their rule.\nSatnami opposition.\nIn May 1672, the Satnami sect obeying the commandments of an \"old toothless woman\" (according to Mughal accounts) organised a massive revolt in the agricultural heartlands of the Mughal Empire. The Satnamis were known to have shaved off their heads and even eyebrows and had temples in many regions of Northern India. They began a large-scale rebellion 75 miles southwest of Delhi.\nThe Satnamis believed they were invulnerable to Mughal bullets and believed they could multiply in any region they entered. The Satnamis initiated their march upon Delhi and overran small-scale Mughal infantry units.\nAurangzeb responded by organising a Mughal army of 10,000 troops and artillery, and dispatched detachments of his own personal Mughal imperial guards to carry out several tasks. To boost Mughal morale, Aurangzeb wrote Islamic prayers, made amulets, and drew designs that would become emblems in the Mughal Army. This rebellion would have a serious aftermath effect on the Punjab.\nSikh opposition.\nThe ninth Sikh Guru, Guru Tegh Bahadur, like his predecessors was opposed to forced conversion of the local population as he considered it wrong. Approached by Kashmiri Pandits to help them retain their faith and avoid forced religious conversions, Guru Tegh Bahadur sent a message to the emperor that if he could convert Teg Bagadur to Islam, every Hindu will become a Muslim. In response, Aurangzeb ordered arrest of the Guru. He was then brought to Delhi and tortured so as to convert him. On his refusal to convert, he was beheaded in 1675. \nIn response, Guru Tegh Bahadur's son and successor, Guru Gobind Singh, further militarised his followers, starting with the establishment of Khalsa in 1699, eight years before Aurangzeb's death. In 1705, Guru Gobind Singh sent a letter entitled \"Zafarnamah\", which accused Aurangzeb of cruelty and betraying Islam. The letter caused him much distress and remorse. Guru Gobind Singh's formation of Khalsa in 1699 led to the establishment of the Sikh Confederacy and later Sikh Empire.\nPashtun opposition.\nThe Pashtun revolt in 1672 under the leadership of the warrior poet Khushal Khan Khattak of Kabul, was triggered when soldiers under the orders of the Mughal Governor Amir Khan allegedly molested women of the Pashtun tribes in modern-day Kunar Province of Afghanistan. The Safi tribes retaliated against the soldiers. This attack provoked a reprisal, which triggered a general revolt of most of tribes. Attempting to reassert his authority, Amir Khan led a large Mughal Army to the Khyber Pass, where the army was surrounded by tribesmen and routed, with only four men, including the Governor, managing to escape.\nAurangzeb's incursions into the Pashtun areas were described by Khushal Khan Khattak as \"Black is the Mughal's heart towards all of us Pathans\". Aurangzeb employed the scorched earth policy, sending soldiers who massacred, looted and burnt many villages. Aurangzeb also proceeded to use bribery to turn the Pashtun tribes against each other, with the aim that they would distract a unified Pashtun challenge to Mughal authority, and the impact of this was to leave a lasting legacy of mistrust among the tribes.\nAfter that the revolt spread, with the Mughals suffering a near total collapse of their authority in the Pashtun belt. The closure of the important Attock-Kabul trade route along the Grand Trunk road was particularly disastrous. By 1674, the situation had deteriorated to a point where Aurangzeb camped at Attock to personally take charge. Switching to diplomacy and bribery along with force of arms, the Mughals eventually split the rebels and partially suppressed the revolt, although they never managed to wield effective authority outside the main trade route.\nDeath.\nBy 1689, the conquest of Golconda, Mughal victories in the south expanded the Mughal Empire to 4\u00a0million square kilometres, with a population estimated to be over 158\u00a0million. But this supremacy was short-lived. Jos Gommans, Professor of Colonial and Global History at the University of Leiden, says that \"...\u00a0the highpoint of imperial centralisation under emperor Aurangzeb coincided with the start of the imperial downfall.\"\nUnlike his predecessors, Aurangzeb considered the royal treasury to be held in trust for the citizens of his empire. He made caps and copied the Quran to earn money for his use. Aurangzeb constructed a small marble mosque known as the Moti Masjid (Pearl Mosque) in the Red Fort complex in Delhi. However, his constant warfare, especially with the Marathas, drove his empire to the brink of bankruptcy just as much as the wasteful personal spending and opulence of his predecessors.\nThe Indologist Stanley Wolpert, emeritus professor at UCLA, says that:\nEven when ill and dying, Aurangzeb made sure that the populace knew he was still alive, for if they had thought otherwise then the turmoil of another war of succession was likely. He died at his military camp in Bhingar near Ahmednagar on 3 March 1707 at the age of 88, having outlived many of his children. He had only 300 rupees with him which were later given to charity as per his instructions and he prior to his death requested not to spend extravagantly on his funeral but to keep it simple.\n His modest open-air grave in Khuldabad, Aurangabad, Maharashtra expresses his deep devotion to his Islamic beliefs. It is sited in the courtyard of the shrine of the Sufi saint Shaikh Burhan-u'd-din Gharib, who was a disciple of Nizamuddin Auliya of Delhi.\nBrown writes that after his death, \"a string of weak emperors, wars of succession, and coups by noblemen heralded the irrevocable weakening of Mughal power\". She notes that the populist but \"fairly old-fashioned\" explanation for the decline is that there was a reaction to Aurangzeb's oppression. Aurangzeb's son, Bahadur Shah I, succeeded him and the empire, both because of Aurangzeb's over-extension and because of Bahadur Shah's weak military and leadership qualities, entered a period of terminal decline. Immediately after Bahadur Shah occupied the throne, the Maratha Empire\u00a0\u2013 which Aurangzeb had held at bay, inflicting high human and monetary costs even on his own empire \u2013 consolidated and launched effective invasions of Mughal territory, seizing power from the weak emperor. Within decades of Aurangzeb's death, the Mughal Emperor had little power beyond the walls of Delhi.\nLegacy.\nHis critics argue that his ruthlessness and religious bigotry made him unsuitable to rule the mixed population of his empire. Some critics assert that the persecution of Shias, Sufis and non-Muslims to impose practices of orthodox Islamic state, such as imposition of sharia and \"jizya\" religious tax on non-Muslims, doubling of custom duties on Hindus while abolishing it for Muslims, executions of Muslims and non-Muslims alike, and destruction of temples eventually led to numerous rebellions. G. N. Moin Shakir and Sarma Festschrift argue that he often used political opposition as pretext for religious persecution, and that, as a result, groups of Jats, Marathas, Sikhs, Satnamis and Pashtuns rose against him.\nModern reception.\nIn Pakistan, author Haroon Khalid writes that, \"Aurangzeb is presented as a hero who fought and expanded the frontiers of the Islamic empire\" and \"is imagined to be a true believer who removed corrupt practices from religion and the court, and once again purified the empire.\" The academic Munis Faruqui also opines that the \"Pakistani state and its allies in the religious and political establishments include him in the pantheon of premodern Muslim heroes, especially lauding him for his militarism, personal piety, and seeming willingness to accommodate Islamic morality within state goals.\"\nMuhammad Iqbal, considered the spiritual founder of Pakistan, compared him favorably to the prophet Abraham for his warfare against Akbar's \"Din-i Ilahi\" and idolatry, while Iqbal Singh Sevea, in his book on the political philosophy of the thinker, says that \"Iqbal considered that the life and activities of Aurangzeb constituted the starting point of Muslim nationality in India.\" Maulana Shabbir Ahmad Usmani, in his funeral oration, hailed M.A. Jinnah, the founder of Pakistan, to be the greatest Muslim since Aurangzeb. President Zia-ul-Haq, known for his Islamization drive, has been described as \"a conceptual descendent of Aurangzeb.\"\nBeyond the individual appreciations, Aurangzeb is seminal to Pakistan's national self-consciousness, as historian Ayesha Jalal, while referring to the Pakistani textbooks controversy, mentions M. D. Zafar's \"A Text Book of Pakistan Studies\" where we can read that, under Aurangzeb, \"Pakistan spirit gathered in strength\", while his death \"weakened the Pakistan spirit.\" Another historian from Pakistan, Mubarak Ali, also looking at the textbooks, and while noting that Akbar \"is conveniently ignored and not mentioned in any school textbook from class one to matriculation\", contrasts him with Aurangzeb, who \"appears in different textbooks of Social Studies and Urdu language as an orthodox and pious Muslim copying the Holy Quran and sewing caps for his livelihood.\"\nThis image of Aurangzeb isn't limited to Pakistan's official historiography. Historian Audrey Truschke points out that BJP and other Hindu nationalists regard him as Muslim zealot. Nehru claimed that, due to his reversal of the cultural and religious syncretism of the previous Mughal emperors, Aurangzeb acted \"more as a Moslem than an Indian ruler\".\nFull title.\nAurangzeb's full imperial title was:\n\"Al-Sultan al-Azam wal Khaqan al-Mukarram Hazrat Abul Muzaffar Muhy-ud-Din Muhammad Aurangzeb Bahadur Alamgir I\",\n\"Badshah Ghazi\",\n\"Shahanshah-e-Sultanat-ul-Hindiya Wal Mughaliya\".\nAurangzeb had also been attributed various other titles including \"Caliph of The Merciful\", \"Monarch of Islam\", and \"Living Custodian of God\".\nIn literature.\nAurangzeb has prominently featured in the following books\nReferences.\nNotes\nCitations\nBibliography"}
{"id": "2427", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=2427", "title": "Alexandrine", "text": "Alexandrine is a name used for several distinct types of verse line with related metrical structures, most of which are ultimately derived from the classical French alexandrine. The line's name derives from its use in the Medieval French \"Roman d'Alexandre\" of 1170, although it had already been used several decades earlier in \"Le P\u00e8lerinage de Charlemagne\". The foundation of most alexandrines consists of two hemistichs (half-lines) of six syllables each, separated by a caesura (a metrical pause or word break, which may or may not be realized as a stronger syntactic break):\n o o o o o o | o o o o o o\n o=any syllable; |=caesura\nHowever, no tradition remains this simple. Each applies additional constraints (such as obligatory stress or nonstress on certain syllables) and options (such as a permitted or required additional syllable at the end of one or both hemistichs). Thus a line that is metrical in one tradition may be unmetrical in another.\nScope of the term.\nThe term \"alexandrine\" may be used with greater or lesser rigor. Peureux suggests that only French syllabic verse with a 6+6 structure is, strictly speaking, an alexandrine. Preminger \"et al\". allow a broader scope: \"Strictly speaking, the term 'alexandrine' is appropriate to French syllabic meters, and it may be applied to other metrical systems only where they too espouse syllabism as their principle, introduce phrasal accentuation, or rigorously observe the medial caesura, as in French.\" Common usage within the literatures of European languages is broader still, embracing lines syllabic, accentual-syllabic, and (inevitably) stationed ambivalently between the two; lines of 12, 13, or even 14 syllables; lines with obligatory, predominant, and optional caesurae.\nFrench.\nAlthough alexandrines occurred in French verse as early as the 12th century, they were slightly looser rhythmically, and vied with the \"d\u00e9casyllabe\" and \"octosyllabe\" for cultural prominence and use in various genres. \"The alexandrine came into its own in the middle of the sixteenth century with the poets of the Pl\u00e9iade and was firmly established in the seventeenth century.\" It became the preferred line for the prestigious genres of epic and tragedy. The structure of the classical French alexandrine is\n o o o o o S | o o o o o S (e)\n S=stressed syllable; (e)=optional \"mute e\"\nClassical alexandrines are always rhymed, often in couplets alternating masculine rhymes and feminine rhymes, though other configurations (such as quatrains and sonnets) are also common.\nVictor Hugo began the process of loosening the strict two-hemistich structure. While retaining the medial caesura, he often reduced it to a mere word-break, creating a three-part line (\"alexandrin ternaire\") with this structure:\n o o o S | o o \u00a6 o S | o o o S (e)\n |=strong caesura; \u00a6=word break\nThe Symbolists further weakened the classical structure, sometimes eliminating any or all of these caesurae. However, at no point did the newer line \"replace\" the older; rather, they were used concurrently, often in the same poem. This loosening process eventually led to \"vers lib\u00e9r\u00e9\" and finally to \"vers libre\".\nEnglish.\nIn English verse, \"alexandrine\" is typically used to mean \"iambic hexameter\":\n \n /=\"ictus\", a strong syllabic position; \u00d7=\"nonictus\"\n \u00a6=often a mandatory or predominant caesura, but depends upon the author\nWhereas the French alexandrine is syllabic, the English is accentual-syllabic; and the central caesura (a defining feature of the French) is not always rigidly preserved in English.\nThough English alexandrines have occasionally provided the sole metrical line for a poem, for example in lyric poems by Henry Howard, Earl of Surrey and Sir Philip Sidney, and in two notable long poems, Michael Drayton's \"Poly-Olbion\" and Robert Browning's \"Fifine at the Fair\", they have more often featured alongside other lines. During the Middle Ages they typically occurred with heptameters (seven-beat lines), both exhibiting metrical looseness. Around the mid-16th century stricter alexandrines were popular as the first line of poulter's measure couplets, fourteeners (strict iambic heptameters) providing the second line.\nThe strict English alexandrine may be exemplified by a passage from \"Poly-Olbion\", which features a rare caesural enjambment (symbolized codice_1) in the first line:\n&lt;poem style=\"margin-left:2em\"&gt;\nYe sacred Bards, that to \u00a6 your harps' melodious strings\nSung th'ancient Heroes' deeds (the monuments of Kings)\nAnd in your dreadful verse ingrav'd the prophecies,\nThe ag\u00e8d world's descents, and genealogies; (lines 31-34)\n&lt;/poem&gt;\nThe Faerie Queene by Edmund Spenser, with its stanzas of eight iambic pentameter lines followed by one alexandrine, exemplifies what came to be its chief role: as a somewhat infrequent variant line in an otherwise iambic pentameter context. Alexandrines provide occasional variation in the blank verse of William Shakespeare and his contemporaries (but rarely; they constitute only about 1% of Shakespeare's blank verse). John Dryden and his contemporaries and followers likewise occasionally employed them as the second (rarely the first) line of heroic couplets, or even more distinctively as the third line of a triplet. In his \"Essay on Criticism\", Alexander Pope denounced (and parodied) the excessive and unskillful use of this practice:\n&lt;poem style=\"margin-left:2em\"&gt;\nThen at the last and only couplet fraught\nWith some unmeaning thing they call a thought,\nA needless Alexandrine ends the song,\nThat, like a wounded snake, drags its slow length along. (lines 354-357)\n&lt;/poem&gt;\nOther languages.\nSpanish.\nThe Spanish \"alejandrino\" is a line of 7+7 syllables, probably developed in imitation of the French alexandrine. Its structure is:\n o o o o o S o | o o o o o S o\nIt was used beginning about 1200 for \"mester de clerec\u00eda\" (clerical verse), typically occurring in the \"cuaderna v\u00eda\", a stanza of four \"alejandrinos\" all with a single end-rhyme.\nThe \"alejandrino\" was most prominent during the 13th and 14th centuries, after which time it was eclipsed by the metrically more flexible \"arte mayor\". Juan Ruiz's Book of Good Love is one of the best-known examples of \"cuaderna v\u00eda\", though other verse forms also appear in the work.\nDutch.\nThe mid-16th-century poet Jan van der Noot pioneered syllabic Dutch alexandrines on the French model, but within a few decades Dutch alexandrines had been transformed into strict iambic hexameters with a caesura after the third foot. From Holland the accentual-syllabic alexandrine spread to other continental literatures.\nGerman.\nSimilarly, in early 17th-century Germany, Georg Rudolf Weckherlin advocated for an alexandrine with free rhythms, reflecting French practice; whereas Martin Opitz advocated for a strict accentual-syllabic iambic alexandrine in imitation of contemporary Dutch practice \u2014 and German poets followed Opitz. The alexandrine (strictly iambic with a consistent medial caesura) became the dominant long line of the German baroque.\nPolish.\nUnlike many similar lines, the Polish alexandrine developed not from French verse but from Latin, specifically, the 13-syllable goliardic line:\n Latin goliardic: o o o s S s s | o o o s S s\n Polish alexandrine: o o o o o S s | o o o s S s\n s=unstressed syllable\nThough looser instances of this (nominally) 13-syllable line were occasionally used in Polish literature, it was Miko\u0142aj Rej and Jan Kochanowski who, in the 16th century, introduced the syllabically strict line as a vehicle for major works.\nCzech.\nThe Czech alexandrine is a comparatively recent development, based on the French alexandrine and introduced by Karel Hynek M\u00e1cha in the 19th century. Its structure forms a halfway point between features usual in syllabic and in accentual-syllabic verse, being more highly constrained than most syllabic verse, and less so than most accentual-syllabic verse. Moreover, it equally encourages the very different rhythms of iambic hexameter and dactylic tetrameter to emerge by preserving the constants of both measures:\n iambic hexameter: s S s S s S | s S s S s S (s)\n dactylic tetrameter: S s s S s s | S s s S s s (s)\n Czech alexandrine: o o s S s o | o o s S s o (s)\nModern references.\nIn the comic book \"Asterix and Cleopatra\", the author Goscinny inserted a pun about alexandrines: when the Druid Panoramix (\"Getafix\" in the English translation) meets his Alexandrian (Egyptian) friend the latter exclaims \"Je suis, mon cher ami, || tr\u00e8s heureux de te voir\" at which Panoramix observes \"C'est un Alexandrin\" (\"That's an alexandrine!\"/\"He's an Alexandrian!\"). The pun can also be heard in the theatrical adaptations. The English translation renders this as \"My dear old Getafix || I hope I find you well\", with the reply \"An Alexandrine\"."}
{"id": "2428", "revid": "1021378850", "url": "https://en.wikipedia.org/wiki?curid=2428", "title": "Analog computer", "text": "An analog computer or analogue computer is a type of computer that uses the continuously changeable aspects of physical phenomena such as electrical, mechanical, or hydraulic quantities to model the problem being solved. In contrast, digital computers represent varying quantities symbolically and by discrete values of both time and amplitude.\nAnalog computers can have a very wide range of complexity. Slide rules and nomograms are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Systems for process control and protective relays used analog computation to perform control and protective functions.\nAnalog computers were widely used in scientific and industrial applications even after the advent of digital computers, because at the time they were typically much faster, but they started to become obsolete as early as the 1950s and 1960s, although they remained in use in some specific applications, such as aircraft flight simulators, the flight computer in aircraft, and for teaching control systems in universities. More complex applications, such as aircraft flight simulators and synthetic-aperture radar, remained the domain of analog computing (and hybrid computing) well into the 1980s, since digital computers were insufficient for the task.\nTimeline of analog computers.\nPrecursors.\nThis is a list of examples of early computation devices considered precursors of the modern computers. Some of them may even have been dubbed 'computers' by the press, though they may fail to fit modern definitions.\nThe Antikythera mechanism was an orrery and is considered an early mechanical analog computer, according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to during the Hellenistic period of Greece. Devices of a level of complexity comparable to that of the Antikythera mechanism would not reappear until a thousand years later.\nMany mechanical aids to calculation and measurement were constructed for astronomical and navigation use.\nThe planisphere was first described by Ptolemy in the 2nd century AD. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235. Ab\u016b Rayh\u0101n al-B\u012br\u016bn\u012b invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, . The castle clock, a hydropowered mechanical astronomical clock invented by Al-Jazari in 1206, was the first programmable analog computer.\nThe sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.\nThe planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.\nThe slide rule was invented around 1620\u20131630, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Aviation is one of the few fields where slide rules are still in widespread use, particularly for solving time\u2013distance problems in light aircraft.\nCharles Babbage is considered by some to be \"father of the computer\". In 1822, Babbage began design on the first mechanical computer, the Difference Engine, that eventually led to more complex electronic designs, though all the essential ideas of modern computers are to be found in Babbage's Analytical Engine.\nIn 1831\u20131835, mathematician and engineer Giovanni Plana devised a perpetual-calendar machine, which, through a system of pulleys and cylinders could predict the perpetual calendar for every year from AD\u00a00 (that is, 1\u00a0BC) to AD\u00a04000, keeping track of leap years and varying day length.\nThe tide-predicting machine invented by Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.\nThe differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876 James Thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.\nModern era.\nThe Dumaresq was a mechanical calculating device invented around 1902 by Lieutenant John Dumaresq of the Royal Navy. It was an analog computer that related vital variables of the fire control problem to the movement of one's own ship and that of a target ship. It was often used with other devices, such as a Vickers range clock to generate range and deflection data so the gun sights of the ship could be continuously set. A number of versions of the Dumaresq were produced of increasing complexity as development proceeded.\nBy 1912 Arthur Pollen had developed an electrically driven mechanical analog computer for fire-control systems, based on the differential analyser. It was used by the Imperial Russian Navy in World War I.\nStarting in 1929, AC network analyzers were constructed to solve calculation problems related to electrical power systems that were too large to solve with numerical methods at the time. These were essentially scale models of the electrical properties of the full-size system. Since network analyzers could handle problems too large for analytic methods or hand computation, they were also used to solve problems in nuclear physics and in the design of structures. More than 50 large network analyzers were built by the end of the 1950s.\nWorld War II era gun directors, gun data computers, and bomb sights used mechanical analog computers. In 1942 Helmut H\u00f6lzer built a fully electronic analog computer at Peenem\u00fcnde Army Research Center as an embedded control system (\"mixing device\") to calculate V-2 rocket trajectories from the accelerations and orientations (measured by gyroscopes) and to stabilize and guide the missile. Mechanical analog computers were very important in gun fire control in World War II, The Korean War and well past the Vietnam War; they were made in significant numbers.\nIn the period 1930\u20131945 in the Netherlands Johan van Veen developed an analogue computer to calculate and predict tidal currents when the geometry of the channels are changed. Around 1950 this idea was developed into the Deltar, an analogue computer supporting the closure of estuaries in the southwest of the Netherlands (the Delta Works).\nThe FERMIAC was an analog computer invented by physicist Enrico Fermi in 1947 to aid in his studies of neutron transport. Project Cyclone was an analog computer developed by Reeves in 1950 for the analysis and design of dynamic systems. Project Typhoon was an analog computer developed by RCA in 1952. It consisted of over 4000 electron tubes and used 100 dials and 6000 plug-in connectors to program. The MONIAC Computer was a hydraulic model of a national economy first unveiled in 1949.\nComputer Engineering Associates was spun out of Caltech in 1950 to provide commercial services using the \"Direct Analogy Electric Analog Computer\" (\"the largest and most impressive general-purpose analyzer facility for the solution of field problems\") developed there by Gilbert D. McCann, Charles H. Wilts, and Bart Locanthi.\nEducational analog computers illustrated the principles of analog calculation. The Heathkit EC-1, a $199 educational analog computer, was made by the Heath Company, US . It was programmed using patch cords that connected nine operational amplifiers and other components. General Electric also marketed an \"educational\" analog computer kit of a simple design in the early 1960s consisting of a two transistor tone generators and three potentiometers wired such that the frequency of the oscillator was nulled when the potentiometer dials were positioned by hand to satisfy an equation. The relative resistance of the potentiometer was then equivalent to the formula of the equation being solved. Multiplication or division could be performed, depending on which dials were inputs and which was the output. Accuracy and resolution was limited and a simple slide rule was more accurate\u2014however, the unit did demonstrate the basic principle.\nAnalog computer designs were published in electronics magazines. One example is the PE Analogue Computer, published in Practical Electronics in the September 1978 edition. Another more modern hybrid computer design was published in Everyday Practical Electronics in 2002. An example described in the EPE Hybrid Computer was the flight of a VTOL aircraft like the Harrier jump jet. The altitude and speed of the aircraft were calculated by the analog part of the computer and sent to a PC via a digital microprocessor and displayed on the PC screen.\nIn industrial process control, analog loop controllers were used to automatically regulate temperature, flow, pressure, or other process conditions. The technology of these controllers ranged from purely mechanical integrators, through vacuum-tube and solid-state devices, to emulation of analog controllers by microprocessors.\nElectronic analog computers.\nThe similarity between linear mechanical components, such as springs and dashpots (viscous-fluid dampers), and electrical components, such as capacitors, inductors, and resistors is striking in terms of mathematics. They can be modeled using equations of the same form.\nHowever, the difference between these systems is what makes analog computing useful. If one considers a simple mass\u2013spring system, constructing the physical system would require making or modifying the springs and masses. This would be followed by attaching them to each other and an appropriate anchor, collecting test equipment with the appropriate input range, and finally, taking measurements. In more complicated cases, such as suspensions for racing cars, experimental construction, modification, and testing is both complicated and expensive.\nThe electrical equivalent can be constructed with a few operational amplifiers (op amps) and some passive linear components; all measurements can be taken directly with an oscilloscope. In the circuit, the (simulated) stiffness of the spring, for instance, can be changed by adjusting the parameters of an integrator. The electrical system is an analogy to the physical system, hence the name, but it is less expensive to construct, generally safer, and typically much easier to modify.\nAs well, an electronic circuit can typically operate at higher frequencies than the system being simulated. This allows the simulation to run faster than real time (which could, in some instances, be hours, weeks, or longer). Experienced users of electronic analog computers said that they offered a comparatively intimate control and understanding of the problem, relative to digital simulations.\nThe drawback of the mechanical-electrical analogy is that electronics are limited by the range over which the variables may vary due to the fixed supply voltage. Therefore, each problem must be scaled to its parameters and dimensions\u2014e.g., the expected magnitudes of the velocity and the position of a spring pendulum. Improperly scaled problems might suffer from higher noise levels. Floating-point digital calculations have a huge dynamic range but might also suffer from imprecision if tiny differences of huge values lead to numerical instability.\nThese electric circuits can also easily perform a wide variety of simulations. For example, voltage can simulate water pressure and electric current can simulate rate of flow in terms of cubic metres per second. An integrator can provide the total accumulated volume of liquid, using an input current proportional to the (possibly varying) flow rate.\nAnalog computers are especially well-suited to representing situations described by differential equations. Occasionally, they were used when a system of differential equations proved very difficult to solve by traditional means. As a simple example, the dynamics of a spring-mass system can be described by the equation formula_1, with formula_2 as the vertical position of a mass formula_3, formula_4 the damping coefficient, formula_5 the spring constant and formula_6 the gravity of Earth. For analog computing, the equation is programmed as formula_7. The equivalent analog circuit consists of two integrators for the state variables formula_8 (speed) and formula_2 (position), one inverter, and three potentiometers. The circuit has to consider that both integration and addition units invert the signal polarity.\nThe accuracy of an analog computer is limited by its computing elements as well as quality of the internal power and electrical interconnections. The precision of the analog computer readout was limited chiefly by the precision of the readout equipment used, generally three or four significant figures. The precision of a digital computer is limited by the word size; arbitrary-precision arithmetic, while relatively slow, provides any practical degree of precision that might be needed. However, in most cases the precision of an analog computer is absolutely sufficient given the uncertainty of the model characteristics and its technical parameters.\nMany small computers dedicated to specific computations are still part of industrial regulation equipment, but from the 1950s to the 1970s, general-purpose analog computers were the only systems fast enough for real time simulation of dynamic systems, especially in the aircraft, military and aerospace field.\nIn the 1960s, the major manufacturer was Electronic Associates of Princeton, New Jersey, with its 231R Analog Computer (vacuum tubes, 20 integrators) and subsequently its EAI 8800 Analog Computer (solid state operational amplifiers, 64 integrators). Its challenger was Applied Dynamics of Ann Arbor, Michigan.\nAlthough the basic technology for analog computers is usually operational amplifiers (also called \"continuous current amplifiers\" because they have no low frequency limitation), in the 1960s an attempt was made in the French ANALAC computer to use an alternative technology: medium frequency carrier and non dissipative reversible circuits.\nIn the 1970s every big company and administration concerned with problems in dynamics had a big analog computing center, for example:\nAnalog\u2013digital hybrids.\nAnalog computing devices are fast, digital computing devices are more versatile and accurate, so the idea is to combine the two processes for the best efficiency. An example of such hybrid elementary device is the hybrid multiplier where one input is an analog signal, the other input is a digital signal and the output is analog. It acts as an analog potentiometer upgradable digitally. This kind of hybrid technique is mainly used for fast dedicated real time computation when computing time is very critical as signal processing for radars and generally for controllers in embedded systems.\nIn the early 1970s analog computer manufacturers tried to tie together their analog computer with a digital computer to get the advantages of the two techniques. In such systems, the digital computer controlled the analog computer, providing initial set-up, initiating multiple analog runs, and automatically feeding and collecting data. The digital computer may also participate to the calculation itself using analog-to-digital and digital-to-analog converters.\nThe largest manufacturer of hybrid computers was Electronics Associates. Their hybrid computer model 8900 was made of a digital computer and one or more analog consoles. These systems were mainly dedicated to large projects such as the Apollo program and Space Shuttle at NASA, or Ariane in Europe, especially during the integration step where at the beginning everything is simulated, and progressively real components replace their simulated part.\nOnly one company was known as offering general commercial computing services on its hybrid computers, CISI of France, in the 1970s.\nThe best reference in this field is the 100,000 simulation runs for each certification of the automatic landing systems of Airbus and Concorde aircraft.\nAfter 1980, purely digital computers progressed more and more rapidly and were fast enough to compete with analog computers.\nOne key to the speed of analog computers was their fully parallel computation, but this was also a limitation. The more equations required for a problem, the more analog components were needed, even when the problem wasn't time critical. \"Programming\" a problem meant interconnecting the analog operators; even with a removable wiring panel this was not very versatile. Today there are no more big hybrid computers, but only hybrid components.\nImplementations.\nMechanical analog computers.\nWhile a wide variety of mechanisms have been developed throughout history, some stand out because of their theoretical importance, or because they were manufactured in significant quantities.\nMost practical mechanical analog computers of any significant complexity used rotating shafts to carry variables from one mechanism to another. Cables and pulleys were used in a Fourier synthesizer, a tide-predicting machine, which summed the individual harmonic components. Another category, not nearly as well known, used rotating shafts only for input and output, with precision racks and pinions. The racks were connected to linkages that performed the computation. At least one U.S. Naval sonar fire control computer of the later 1950s, made by Librascope, was of this type, as was the principal computer in the Mk.\u00a056 Gun Fire Control System.\nOnline, there is a remarkably clear illustrated reference (OP\u00a01140) that describes the fire control computer mechanisms.\nFor adding and subtracting, precision miter-gear differentials were in common use in some computers; the Ford Instrument Mark I Fire Control Computer contained about 160 of them.\nIntegration with respect to another variable was done by a rotating disc driven by one variable. Output came from a pick-off device (such as a wheel) positioned at a radius on the disc proportional to the second variable. (A carrier with a pair of steel balls supported by small rollers worked especially well. A roller, its axis parallel to the disc's surface, provided the output. It was held against the pair of balls by a spring.)\nArbitrary functions of one variable were provided by cams, with gearing to convert follower movement to shaft rotation.\nFunctions of two variables were provided by three-dimensional cams. In one good design, one of the variables rotated the cam. A hemispherical follower moved its carrier on a pivot axis parallel to that of the cam's rotating axis. Pivoting motion was the output. The second variable moved the follower along the axis of the cam. One practical application was ballistics in gunnery.\nCoordinate conversion from polar to rectangular was done by a mechanical resolver (called a \"component solver\" in US Navy fire control computers). Two discs on a common axis positioned a sliding block with pin (stubby shaft) on it. One disc was a face cam, and a follower on the block in the face cam's groove set the radius. The other disc, closer to the pin, contained a straight slot in which the block moved. The input angle rotated the latter disc (the face cam disc, for an unchanging radius, rotated with the other (angle) disc; a differential and a few gears did this correction).\nReferring to the mechanism's frame, the location of the pin corresponded to the tip of the vector represented by the angle and magnitude inputs. Mounted on that pin was a square block.\nRectilinear-coordinate outputs (both sine and cosine, typically) came from two slotted plates, each slot fitting on the block just mentioned. The plates moved in straight lines, the movement of one plate at right angles to that of the other. The slots were at right angles to the direction of movement. Each plate, by itself, was like a Scotch yoke, known to steam engine enthusiasts.\nDuring World War II, a similar mechanism converted rectilinear to polar coordinates, but it was not particularly successful and was eliminated in a significant redesign (USN, Mk.\u00a01 to Mk.\u00a01A).\nMultiplication was done by mechanisms based on the geometry of similar right triangles. Using the trigonometric terms for a right triangle, specifically opposite, adjacent, and hypotenuse, the adjacent side was fixed by construction. One variable changed the magnitude of the opposite side. In many cases, this variable changed sign; the hypotenuse could coincide with the adjacent side (a zero input), or move beyond the adjacent side, representing a sign change.\nTypically, a pinion-operated rack moving parallel to the (trig.-defined) opposite side would position a slide with a slot coincident with the hypotenuse. A pivot on the rack let the slide's angle change freely. At the other end of the slide (the angle, in trig. terms), a block on a pin fixed to the frame defined the vertex between the hypotenuse and the adjacent side.\nAt any distance along the adjacent side, a line perpendicular to it intersects the hypotenuse at a particular point. The distance between that point and the adjacent side is some fraction that is the product of \"1\" the distance from the vertex, and \"2\" the magnitude of the opposite side.\nThe second input variable in this type of multiplier positions a slotted plate perpendicular to the adjacent side. That slot contains a block, and that block's position in its slot is determined by another block right next to it. The latter slides along the hypotenuse, so the two blocks are positioned at a distance from the (trig.) adjacent side by an amount proportional to the product.\nTo provide the product as an output, a third element, another slotted plate, also moves parallel to the (trig.) opposite side of the theoretical triangle. As usual, the slot is perpendicular to the direction of movement. A block in its slot, pivoted to the hypotenuse block positions it.\nA special type of integrator, used at a point where only moderate accuracy was needed, was based on a steel ball, instead of a disc. It had two inputs, one to rotate the ball, and the other to define the angle of the ball's rotating axis. That axis was always in a plane that contained the axes of two movement pick-off rollers, quite similar to the mechanism of a rolling-ball computer mouse (in that mechanism, the pick-off rollers were roughly the same diameter as the ball). The pick-off roller axes were at right angles.\nA pair of rollers \"above\" and \"below\" the pick-off plane were mounted in rotating holders that were geared together. That gearing was driven by the angle input, and established the rotating axis of the ball. The other input rotated the \"bottom\" roller to make the ball rotate.\nEssentially, the whole mechanism, called a component integrator, was a variable-speed drive with one motion input and two outputs, as well as an angle input. The angle input varied the ratio (and direction) of coupling between the \"motion\" input and the outputs according to the sine and cosine of the input angle.\nAlthough they did not accomplish any computation, electromechanical position servos were essential in mechanical analog computers of the \"rotating-shaft\" type for providing operating torque to the inputs of subsequent computing mechanisms, as well as driving output data-transmission devices such as large torque-transmitter synchros in naval computers.\nOther readout mechanisms, not directly part of the computation, included internal odometer-like counters with interpolating drum dials for indicating internal variables, and mechanical multi-turn limit stops.\nConsidering that accurately controlled rotational speed in analog fire-control computers was a basic element of their accuracy, there was a motor with its average speed controlled by a balance wheel, hairspring, jeweled-bearing differential, a twin-lobe cam, and spring-loaded contacts (ship's AC power frequency was not necessarily accurate, nor dependable enough, when these computers were designed).\nElectronic analog computers.\nElectronic analog computers typically have front panels with numerous jacks (single-contact sockets) that permit patch cords (flexible wires with plugs at both ends) to create the interconnections that define the problem setup. In addition, there are precision high-resolution potentiometers (variable resistors) for setting up (and, when needed, varying) scale factors. In addition, there is usually a zero-center analog pointer-type meter for modest-accuracy voltage measurement. Stable, accurate voltage sources provide known magnitudes.\nTypical electronic analog computers contain anywhere from a few to a hundred or more operational amplifiers (\"op amps\"), named because they perform mathematical operations. Op amps are a particular type of feedback amplifier with very high gain and stable input (low and stable offset). They are always used with precision feedback components that, in operation, all but cancel out the currents arriving from input components. The majority of op amps in a representative setup are summing amplifiers, which add and subtract analog voltages, providing the result at their output jacks. As well, op amps with capacitor feedback are usually included in a setup; they integrate the sum of their inputs with respect to time.\nIntegrating with respect to another variable is the nearly exclusive province of mechanical analog integrators; it is almost never done in electronic analog computers. However, given that a problem solution does not change with time, time can serve as one of the variables.\nOther computing elements include analog multipliers, nonlinear function generators, and analog comparators.\nElectrical elements such as inductors and capacitors used in electrical analog computers had to be carefully manufactured to reduce non-ideal effects. For example, in the construction of AC power network analyzers, one motive for using higher frequencies for the calculator (instead of the actual power frequency) was that higher-quality inductors could be more easily made. Many general-purpose analog computers avoided the use of inductors entirely, re-casting the problem in a form that could be solved using only resistive and capacitive elements, since high-quality capacitors are relatively easy to make.\nThe use of electrical properties in analog computers means that calculations are normally performed in real time (or faster), at a speed determined mostly by the frequency response of the operational amplifiers and other computing elements. In the history of electronic analog computers, there were some special high-speed types.\nNonlinear functions and calculations can be constructed to a limited precision (three or four digits) by designing function generators\u2014special circuits of various combinations of resistors and diodes to provide the nonlinearity. Typically, as the input voltage increases, progressively more diodes conduct.\nWhen compensated for temperature, the forward voltage drop of a transistor's base-emitter junction can provide a usably accurate logarithmic or exponential function. Op amps scale the output voltage so that it is usable with the rest of the computer.\nAny physical process that models some computation can be interpreted as an analog computer. Some examples, invented for the purpose of illustrating the concept of analog computation, include using a bundle of spaghetti as a model of sorting numbers; a board, a set of nails, and a rubber band as a model of finding the convex hull of a set of points; and strings tied together as a model of finding the shortest path in a network. These are all described in Dewdney (1984).\nComponents.\nAnalog computers often have a complicated framework, but they have, at their core, a set of key components that perform the calculations. The operator manipulates these through the computer's framework.\nKey hydraulic components might include pipes, valves and containers.\nKey mechanical components might include rotating shafts for carrying data within the computer, miter gear differentials, disc/ball/roller integrators, cams (2-D and 3-D), mechanical resolvers and multipliers, and torque servos.\nKey electrical/electronic components might include:\nThe core mathematical operations used in an electric analog computer are:\nIn some analog computer designs, multiplication is much preferred to division. Division is carried out with a multiplier in the feedback path of an Operational Amplifier.\nDifferentiation with respect to time is not frequently used, and in practice is avoided by redefining the problem when possible. It corresponds in the frequency domain to a high-pass filter, which means that high-frequency noise is amplified; differentiation also risks instability.\nLimitations.\nIn general, analog computers are limited by non-ideal effects. An analog signal is composed of four basic components: DC and AC magnitudes, frequency, and phase. The real limits of range on these characteristics limit analog computers. Some of these limits include the operational amplifier offset, finite gain, and frequency response, noise floor, non-linearities, temperature coefficient, and parasitic effects within semiconductor devices. For commercially available electronic components, ranges of these aspects of input and output signals are always figures of merit.\nDecline.\nIn the 1950s to 1970s, digital computers based on first vacuum tubes, transistors, integrated circuits and then micro-processors became more economical and precise. This led digital computers to largely replace analog computers. Even so, some research in analog computation is still being done. A few universities still use analog computers to teach control system theory. The American company Comdyna manufactured small analog computers. At Indiana University Bloomington, Jonathan Mills has developed the Extended Analog Computer based on sampling voltages in a foam sheet. At the Harvard Robotics Laboratory, analog computation is a research topic. Lyric Semiconductor's error correction circuits use analog probabilistic signals. Slide rules are still popular among aircraft personnel.\nResurgence.\nWith the development of very-large-scale integration (VLSI) technology, Yannis Tsividis' group at Columbia University has been revisiting analog/hybrid computers design in standard CMOS process. Two VLSI chips have been developed, an 80th-order analog computer (250\u00a0nm) by Glenn Cowan in 2005 and a 4th-order hybrid computer (65\u00a0nm) developed by Ning Guo in 2015, both targeting at energy-efficient ODE/PDE applications. Glenn's chip contains 16 macros, in which there are 25 analog computing blocks, namely integrators, multipliers, fanouts, few nonlinear blocks. Ning's chip contains one macro block, in which there are 26 computing blocks including integrators, multipliers, fanouts, ADCs, SRAMs and DACs. Arbitrary nonlinear function generation is made possible by the ADC+SRAM+DAC chain, where the SRAM block stores the nonlinear function data. The experiments from the related publications revealed that VLSI analog/hybrid computers demonstrated about 1\u20132 orders magnitude of advantage in both solution time and energy while achieving accuracy within 5%, which points to the promise of using analog/hybrid computing techniques in the area of energy-efficient approximate computing. In 2016, a team of researchers developed a compiler to solve differential equations using analog circuits.\nPractical examples.\nThese are examples of analog computers that have been constructed or practically used:\nAnalog (audio) synthesizers can also be viewed as a form of analog computer, and their technology was originally based in part on electronic analog computer technology. The ARP 2600's Ring Modulator was actually a moderate-accuracy analog multiplier.\nThe Simulation Council (or Simulations Council) was an association of analog computer users in US. It is now known as The Society for Modeling and Simulation International. The Simulation Council newsletters from 1952 to 1963 are available online and show the concerns and technologies at the time, and the common use of analog computers for missilry."}
{"id": "2429", "revid": "22041646", "url": "https://en.wikipedia.org/wiki?curid=2429", "title": "Audio", "text": "Audio most commonly refers to sound, as it is transmitted in signal form. It may also refer to:"}
{"id": "2431", "revid": "37247652", "url": "https://en.wikipedia.org/wiki?curid=2431", "title": "Minute and second of arc", "text": "A minute of arc, arcminute (arcmin), arc minute, or minute arc, denoted by the symbol formula_1, is a unit of angular measurement equal to of one degree. Since one degree is of a turn (or complete rotation), one minute of arc is of a turn. The nautical mile was originally defined as a minute of latitude on a spherical Earth, so the actual Earth circumference is very near 21 600 nautical miles. A minute of arc is of a radian.\nA second of arc, arcsecond (arcsec), or arc second, denoted by the symbol formula_2, is of an arcminute, of a degree, of a turn, and (about ) of a radian.\nThese units originated in Babylonian astronomy as sexagesimal subdivisions of the degree; they are used in fields that involve very small angles, such as astronomy, optometry, ophthalmology, optics, navigation, land surveying, and marksmanship.\nTo express even smaller angles, standard SI prefixes can be employed; the milliarcsecond (mas) and microarcsecond (\u03bcas), for instance, are commonly used in astronomy.\nThe number of square arcminutes in a complete sphere is formula_3 square arcminutes (the surface area of a unit sphere in square units, divided by the solid angle area subtended by a square arcminute (also in square units), so that the final result is a dimensionless number).\nThe fact that the terms \"minute\" and \"second\" also denote units of time derives from Babylonian astronomy, where the corresponding time-related terms denoted the duration of the Sun's apparent motion of one minute or one second of arc, respectively, through the ecliptic. In present terms, the Babylonian degree of time was four minutes long, so the \"minute\" of time was four seconds long and the \"second\" of a second.\nSymbols and abbreviations.\nThe prime symbol (\u2032) (U+2032) designates the arcminute, though a single quote (') (U+0027) is commonly used where only ASCII characters are permitted. One arcminute is thus written as 1\u2032. It is also abbreviated as arcmin or amin or, less commonly, the prime with a circumflex over it (formula_4).\nSimilarly, double prime (\u2033) (U+2033) designates the arcsecond, though a double quote (\") (U+0022) is commonly used where only ASCII characters are permitted. One arcsecond is thus written as 1\u2033. It is also abbreviated as arcsec or asec.\nIn celestial navigation, seconds of arc are rarely used in calculations, the preference usually being for degrees, minutes and decimals of a minute, for example, written as 42\u00b0 25.32\u2032 or 42\u00b0 25.322\u2032. This notation has been carried over into marine GPS receivers, which normally display latitude and longitude in the latter format by default.\nCommon examples.\nThe full moon's average apparent size is about 31 arcminutes (or 0.52\u00b0).\nAn arcminute is approximately the resolution of the human eye.\nAn arcsecond is approximately the angle subtended by a U.S. dime coin (18\u00a0mm) at a distance of . An arcsecond is also the angle subtended by\nA milliarcsecond is about the size of a dime atop the Eiffel Tower, as seen from New York City.\nA microarcsecond is about the size of a period at the end of a sentence in the Apollo mission manuals left on the Moon as seen from Earth.\nA nanoarcsecond is about the size of a penny on Neptune's moon Triton as observed from Earth.\nAlso notable examples of size in arcseconds are:\nUses.\nAstronomy.\nSince antiquity, the arcminute and arcsecond have been used in astronomy: in the ecliptic coordinate system as latitude (\u03b2) and longitude (\u03bb); in the horizon system as altitude (Alt) and azimuth (Az); and in the equatorial coordinate system as declination (\u03b4). All are measured in degrees, arcminutes and arcseconds. The principal exception is right ascension (RA) in equatorial coordinates, which is measured in time units of hours, minutes, and seconds.\nThe arcsecond is also often used to describe small astronomical angles such as the angular diameters of planets (e.g. the angular diameter of Venus which varies between 10\u2033 and 60\u2033), the proper motion of stars, the separation of components of binary star systems, and parallax, the small change of position of a star in the course of a year, or of a solar system body as the Earth rotates. These small angles may also be written in milliarcseconds (mas), or thousandths of an arcsecond. The unit of distance, the parsec, named from the \"par\"allax of one arc \"sec\"ond, was developed for such parallax measurements. It is the distance at which the mean radius of the Earth's orbit (more precisely, one astronomical unit) would subtend an angle of one arcsecond.\nThe ESA astrometric satellite Gaia, launched in 2013, can approximate star positions to 7 microarcseconds (\u00b5as).\nApart from the Sun, the star with the largest angular diameter from Earth is R Doradus, a red giant with a diameter of 0.05\u2033. Because of the effects of atmospheric blurring, ground-based telescopes will smear the image of a star to an angular diameter of about 0.5\u2033; in poor conditions this increases to 1.5\u2033 or even more. The dwarf planet Pluto has proven difficult to resolve because its angular diameter is about 0.1\u2033.\nSpace telescopes are not affected by the Earth's atmosphere but are diffraction limited. For example, the Hubble Space Telescope can reach an angular size of stars down to about 0.1\u2033. Techniques exist for improving seeing on the ground. Adaptive optics, for example, can produce images around 0.05\u2033 on a 10\u00a0m class telescope.\nCartography.\nMinutes (\u2032) and seconds (\u2033) of arc are also used in cartography and navigation. At sea level one minute of arc along the equator equals exactly one geographical mile along the Earth's equator or approximately . A second of arc, one sixtieth of this amount, is roughly . The exact distance varies along meridian arcs or any other great circle arcs because the figure of the Earth is slightly oblate (bulges a third of a percent at the equator).\nPositions are traditionally given using degrees, minutes, and seconds of arcs for latitude, the arc north or south of the equator, and for longitude, the arc east or west of the Prime Meridian. Any position on or above the Earth's reference ellipsoid can be precisely given with this method. However, when it is inconvenient to use base-60 for minutes and seconds, positions are frequently expressed as decimal fractional degrees to an equal amount of precision. Degrees given to three decimal places ( of a degree) have about the precision of degrees-minutes-seconds ( of a degree) and specify locations within about . For navigational purposes positions are given in degrees and decimal minutes, for instance The Needles lighthouse is at 50\u00ba 39.734\u2019N 001\u00ba 35.500\u2019W.\nProperty cadastral surveying.\nRelated to cartography, property boundary surveying using the metes and bounds system relies on fractions of a degree to describe property lines' angles in reference to cardinal directions. A boundary \"mete\" is described with a beginning reference point, the cardinal direction North or South followed by an angle less than 90 degrees and a second cardinal direction, and a linear distance. The boundary runs the specified linear distance from the beginning point, the direction of the distance being determined by rotating the first cardinal direction the specified angle toward the second cardinal direction. For example, \"North\u00a065\u00b0\u00a039\u2032 18\u2033 West\u00a085.69\u00a0feet\" would describe a line running from the starting point 85.69 feet in a direction 65\u00b0 39\u2032 18\u2033 (or 65.655\u00b0) away from north toward the west.\nFirearms.\nThe arcminute is commonly found in the firearms industry and literature, particularly concerning the precision of rifles, though the industry refers to it as minute of angle (MOA). It is especially popular as a unit of measurement with shooters familiar with the imperial measurement system because 1\u00a0MOA subtends a circle with a diameter of 1.047 inches (which is often rounded to just 1 inch) at 100 yards ( at or 2.908\u00a0cm at 100\u00a0m), a traditional distance on American target ranges. The subtension is linear with the distance, for example, at 500 yards, 1\u00a0MOA subtends 5.235 inches, and at 1000 yards 1\u00a0MOA subtends 10.47 inches.\nSince many modern telescopic sights are adjustable in half (), quarter () or eighth () MOA increments, also known as \"clicks\", zeroing and adjustments are made by counting 2, 4 and 8 clicks per MOA respectively.\nFor example, if the point of impact is 3 inches high and 1.5 inches left of the point of aim at 100 yards (which for instance could be measured by using a spotting scope with a calibrated reticle), the scope needs to be adjusted 3 MOA down, and 1.5 MOA right. Such adjustments are trivial when the scope's adjustment dials have a MOA scale printed on them, and even figuring the right number of clicks is relatively easy on scopes that \"click\" in fractions of MOA. This makes zeroing and adjustments much easier:\nAnother common system of measurement in firearm scopes is the milliradian (mrad). Zeroing an mrad based scope is easy for users familiar with base ten systems. The most common adjustment value in mrad based scopes is \u00a0mrad (which approximates MOA).\nOne thing to be aware of is that some MOA scopes, including some higher-end models, are calibrated such that an adjustment of 1 MOA on the scope knobs corresponds to exactly 1 inch of impact adjustment on a target at 100 yards, rather than the mathematically correct 1.047 inches. This is commonly known as the Shooter's MOA (SMOA) or Inches Per Hundred Yards (IPHY). While the difference between one true MOA and one SMOA is less than half of an inch even at 1000 yards, this error compounds significantly on longer range shots that may require adjustment upwards of 20\u201330 MOA to compensate for the bullet drop. If a shot requires an adjustment of 20 MOA or more, the difference between true MOA and SMOA will add up to 1 inch or more. In competitive target shooting, this might mean the difference between a hit and a miss.\nThe physical group size equivalent to \"m\" minutes of arc can be calculated as follows: group size = tan()\u00a0\u00d7\u00a0distance. In the example previously given, for 1 minute of arc, and substituting 3,600\u00a0inches for 100 yards, 3,600 tan() \u2248 1.047\u00a0inches. In metric units 1 MOA at 100 metres \u2248 2.908 centimetres.\nSometimes, a precision-oriented firearm's performance will be measured in MOA. This simply means that under ideal conditions (i.e. no wind, high-grade ammo, clean barrel, and a stable mounting platform such as a vise or a benchrest used to eliminate shooter error), the gun is capable of producing a group of shots whose center points (center-to-center) fit into a circle, the average diameter of circles in several groups can be subtended by that amount of arc. For example, a \"1 MOA rifle\" should be capable, under ideal conditions, of repeatably shooting 1-inch groups at 100 yards. Most higher-end rifles are warrantied by their manufacturer to shoot under a given MOA threshold (typically 1 MOA or better) with specific ammunition and no error on the shooter's part. For example, Remington's M24 Sniper Weapon System is required to shoot 0.8 MOA or better, or be rejected from sale by quality control.\nRifle manufacturers and gun magazines often refer to this capability as \"sub-MOA\", meaning a gun consistently shooting groups under 1 MOA. This means that a single group of 3 to 5 shots at 100 yards, or the average of several groups, will measure less than 1 MOA between the two furthest shots in the group, i.e. all shots fall within 1 MOA. If larger samples are taken (i.e., more shots per group) then group size typically increases, however this will ultimately average out. If a rifle was truly a 1 MOA rifle, it would be just as likely that two consecutive shots land exactly on top of each other as that they land 1 MOA apart. For 5-shot groups, based on 95% confidence, a rifle that normally shoots 1 MOA can be expected to shoot groups between 0.58 MOA and 1.47 MOA, although the majority of these groups will be under 1 MOA. What this means in practice is if a rifle that shoots 1-inch groups on average at 100 yards shoots a group measuring 0.7 inches followed by a group that is 1.3 inches, this is not statistically abnormal.\nThe metric system counterpart of the MOA is the milliradian (mrad or 'mil'), being equal to one 1000th of the target range, laid out on a circle that has the observer as centre and the target range as radius. The number of milliradians on a full such circle therefore always is equal to 2 \u00d7 \u00d7 1000, regardless the target range. Therefore, 1 MOA \u2248 0.2909\u00a0mrad. This means that an object which spans 1\u00a0mrad on the reticle is at a range that is in metres equal to the object's size in millimetres (e.g. an object of 100\u00a0mm subtending 1 mrad is 100 metres away). So there is no conversion factor required, contrary to the MOA system. A reticle with markings (hashes or dots) spaced with a one mrad apart (or a fraction of a mrad) are collectively called a mrad reticle. If the markings are round they are called mil-dots.\nIn the table below conversions from mrad to metric values are exact (e.g. 0.1\u00a0mrad equals exactly 10\u00a0mm at 100 metres), while conversions of minutes of arc to both metric and imperial values are approximate.\nHuman vision.\nIn humans, 20/20 vision is the ability to resolve a spatial pattern separated by a visual angle of one minute of arc.\nA 20/20 letter subtends 5 minutes of arc total.\nMaterials.\nThe deviation from parallelism between two surfaces, for instance in optical engineering, is usually measured in arcminutes or arcseconds.\nIn addition, arcseconds are sometimes used in rocking curve (\u03c9-scan) x ray diffraction measurements of high-quality epitaxial thin films.\nManufacturing.\nSome measurement devices make use of arcminutes and arcseconds to measure angles when the object being measured is too small for direct visual inspection. For instance, a toolmaker's optical comparator will often include an option to measure in \"minutes and seconds\"."}
{"id": "2432", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=2432", "title": "Albert Archilles", "text": ""}
{"id": "2433", "revid": "5229428", "url": "https://en.wikipedia.org/wiki?curid=2433", "title": "Alberto Giacometti", "text": "Alberto Giacometti (, , ; 10 October 1901 \u2013 11 January 1966) was a Swiss sculptor, painter, draftsman and printmaker. Beginning in 1922, he lived and worked mainly in Paris but regularly visited his hometown Borgonovo to see his family and work on his art.\nGiacometti was one of the most important sculptors of the 20th century. His work was particularly influenced by artistic styles such as Cubism and Surrealism. Philosophical questions about the human condition, as well as existential and phenomenological debates played a significant role in his work. Around 1935 he gave up on his Surrealistic influences in order to pursue a more deepened analysis of figurative compositions. Giacometti wrote texts for periodicals and exhibition catalogues and recorded his thoughts and memories in notebooks and diaries. His critical nature led to self-doubt about his own work and his self-perceived inability to do justice to his own artistic vision. His insecurities nevertheless remained a powerful motivating artistic force throughout his entire life.\nBetween 1938 and 1944 Giacometti's sculptures had a maximum height of seven centimeters (2.75 inches). Their small size reflected the actual distance between the artist's position and his model. In this context he self-critically stated: \"But wanting to create from memory what I had seen, to my terror the sculptures became smaller and smaller\". After World War II, Giacometti created his most famous sculptures: his extremely tall and slender figurines. These sculptures were subject to his individual viewing experience\u2014between an imaginary yet real, a tangible yet inaccessible space.\nIn Giacometti's whole body of work, his painting constitutes only a small part. After 1957, however, his figurative paintings were equally as present as his sculptures. His almost monochromatic paintings of his late work do not refer to any other artistic styles of modernity.\nEarly life.\nGiacometti was born in Borgonovo, Switzerland, the eldest of four children of Giovanni Giacometti, a well-known post-Impressionist painter, and Annetta Giacometti-Stampa. He was a descendant of Protestant refugees escaping the inquisition. Coming from an artistic background, he was interested in art from an early age. Alberto attended the Geneva School of Fine Arts. His brothers Diego (1902\u20131985) and Bruno (1907\u20132012) would go on to become artists and architects as well. Additionally, his cousin Zaccaria Giacometti, later professor of constitutional law and chancellor of the University of Zurich, grew up together with them, having been orphaned at the age of 12 in 1905.\nCareer.\nIn 1922, he moved to Paris to study under the sculptor Antoine Bourdelle, an associate of Rodin. It was there that Giacometti experimented with Cubism and Surrealism and came to be regarded as one of the leading Surrealist sculptors. Among his associates were Mir\u00f3, Max Ernst, Picasso, Bror Hjorth, and Balthus.\nBetween 1936 and 1940, Giacometti concentrated his sculpting on the human head, focusing on the sitter's gaze. He preferred models he was close to\u2014his sister and the artist Isabel Rawsthorne (then known as Isabel Delmer). This was followed by a phase in which his statues of Isabel became stretched out; her limbs elongated. Obsessed with creating his sculptures exactly as he envisioned through his unique view of reality, he often carved until they were as thin as nails and reduced to the size of a pack of cigarettes, much to his consternation. A friend of his once said that if Giacometti decided to sculpt you, \"he would make your head look like the blade of a knife\".\nDuring World War II, Giacometti took refuge in Switzerland. There, in 1946, he met Annette Arm, a secretary for the Red Cross. They married in 1949.\nAfter his marriage his tiny sculptures became larger, but the larger they grew, the thinner they became. For the remainder of Giacometti's life, Annette was his main female model. His paintings underwent a parallel procedure. The figures appear isolated and severely attenuated, as the result of continuous reworking.\nHe frequently revisited his subjects: one of his favourite models was his younger brother Diego.\nLater years.\nIn 1958 Giacometti was asked to create a monumental sculpture for the Chase Manhattan Bank building in New York, which was beginning construction. Although he had for many years \"harbored an ambition to create work for a public square\", he \"had never set foot in New York, and knew nothing about life in a rapidly evolving metropolis. Nor had he ever laid eyes on an actual skyscraper\", according to his biographer James Lord. Giacometti's work on the project resulted in the four figures of standing women\u2014his largest sculptures\u2014entitled \"Grande femme debout\" I through IV (1960). The commission was never completed, however, because Giacometti was unsatisfied by the relationship between the sculpture and the site, and abandoned the project.\nIn 1962, Giacometti was awarded the grand prize for sculpture at the Venice Biennale, and the award brought with it worldwide fame. Even when he had achieved popularity and his work was in demand, he still reworked models, often destroying them or setting them aside to be returned to years later. The prints produced by Giacometti are often overlooked but the catalogue raisonn\u00e9, \"Giacometti \u2013 The Complete Graphics and 15 Drawings by Herbert Lust\" (Tudor 1970), comments on their impact and gives details of the number of copies of each print. Some of his most important images were in editions of only 30 and many were described as rare in 1970.\nIn his later years Giacometti's works were shown in a number of large exhibitions throughout Europe. Riding a wave of international popularity, and despite his declining health, he traveled to the United States in 1965 for an exhibition of his works at the Museum of Modern Art in New York. As his last work he prepared the text for the book \"Paris sans fin\", a sequence of 150 lithographs containing memories of all the places where he had lived.\nDeath.\nGiacometti died in 1966 of heart disease (pericarditis) and Chronic Obstructive Pulmonary Disease at the Kantonsspital in Chur, Switzerland. His body was returned to his birthplace in Borgonovo, where he was interred close to his parents.\nWith no children, Annette Giacometti became the sole holder of his property rights. She worked to collect a full listing of authenticated works by her late husband, gathering documentation on the location and manufacture of his works and working to fight the rising number of counterfeited works. When she died in 1993, the Fondation Giacometti was set up by the French state.\nIn May 2007 the executor of his widow's estate, former French foreign minister Roland Dumas, was convicted of illegally selling Giacometti's works to a top auctioneer, Jacques Tajan, who was also convicted. Both were ordered to pay \u20ac850,000 to the Alberto and Annette Giacometti Foundation.\nArtistic analysis.\nRegarding Giacometti's sculptural technique and according to the Metropolitan Museum of Art: \"The rough, eroded, heavily worked surfaces of Three Men Walking (II), 1949, typify his technique. Reduced, as they are, to their very core, these figures evoke lone trees in winter that have lost their foliage. Within this style, Giacometti would rarely deviate from the three themes that preoccupied him\u2014the walking man; the standing, nude woman; and the bust\u2014or all three, combined in various groupings\".\"\"\nIn a letter to Pierre Matisse, Giacometti wrote: \"Figures were never a compact mass but like a transparent construction\". In the letter, Giacometti writes about how he looked back at the realist, classical busts of his youth with nostalgia, and tells the story of the existential crisis which precipitated the style he became known for.\n\"[I rediscovered] the wish to make compositions with figures. For this I had to make (quickly I thought; in passing), one or two studies from nature, just enough to understand the construction of a head, of a whole figure, and in 1935 I took a model. This study should take, I thought, two weeks and then I could realize my compositions...I worked with the model all day from 1935 to 1940...Nothing was as I imagined. A head, became for me an object completely unknown and without dimensions.\"\nSince Giacometti achieved exquisite realism with facility when he was executing busts in his early adolescence, Giacometti's difficulty in re-approaching the figure as an adult is generally understood as a sign of existential struggle for meaning, rather than as a technical deficit.\nGiacometti was a key player in the Surrealist art movement, but his work resists easy categorization. Some describe it as formalist, others argue it is expressionist or otherwise having to do with what Deleuze calls \"blocs of sensation\" (as in Deleuze's analysis of Francis Bacon). Even after his excommunication from the Surrealist group, while the intention of his sculpting was usually imitation, the end products were an expression of his emotional response to the subject. He attempted to create renditions of his models the way he saw them, and the way he thought they ought to be seen. He once said that he was sculpting not the human figure but \"the shadow that is cast\".\nScholar William Barrett in \"Irrational Man: A Study in Existential Philosophy\" (1962), argues that the attenuated forms of Giacometti's figures reflect the view of 20th century modernism and existentialism that modern life is increasingly empty and devoid of meaning. \"All the sculptures of today, like those of the past, will end one day in pieces...So it is important to fashion one's work carefully in its smallest recess and charge every particle of matter with life.\"\nA 2011\u20132012 exhibition at the Pinacoth\u00e8que de Paris focused on showing how Giacometti was inspired by Etruscan art.\nArtworks by Giacometti at the 31\u00b0 Venice Biennale in 1962, photographed by Paolo Monti (above)\n\u2018Walking Man\u2019 and other human figures.\nGiacometti is best known for the bronze sculptures of tall, thin human figures, made in the years 1945 to 1960.\u00a0 Giacometti was influenced by the impressions he took from the people hurrying in the big city. People in motion he saw as \u2018a succession of moments of stillness\u2019.\nThe emaciated figures are often interpreted as an expression of the existential fear, insignificance and loneliness of mankind. The mood of fear in the period of the 1940s and the Cold War is reflected in this figure.\u00a0It feels sad, lonely and difficult to relate to.\nLegacy.\nExhibitions.\nGiacometti's work has been the subject of numerous solo exhibitions including Vancouver Art Gallery, Vancouver BC (2019); \u201cAlberto Giacometti: A Line Through Time\u201d, Pera Museum, Istanbul (2015), Pushkin Museum, Moscow (2008); \u201cThe Studio of Alberto Giacometti: Collection of the Fondation Alberto et Annette Giacometti\u201d, Centre Pompidou, Paris (2007\u20132008); Kunsthal Rotterdam (2008); Fondation Beyeler, Basel (2009), Buenos Aires (2012); Kunsthalle Hamburg (2013), and the High Museum of Art, Atlanta (1970).\nThe National Portrait Gallery, London's first solo exhibition of Giacometti's work, \"Pure Presence\" opened to five star reviews on 13 October 2015 (to 10 January 2016, in honour of the fiftieth anniversary of the artist's death).\nFrom April 2019, the Prado Museum in Madrid, has been highlighting Giacometti in an exhibition.\nPublic collections.\nGiacometti's work is displayed in numerous public collections, including:\nArt foundations.\nThe Fondation Alberto et Annette Giacometti, having received a bequest from Alberto Giacometti's widow Annette, holds a collection of circa 5,000 works, frequently displayed around the world through exhibitions and long-term loans. A public interest institution, the Foundation was created in 2003 and aims at promoting, disseminating, preserving and protecting Alberto Giacometti's work.\nThe Alberto-Giacometti-Stiftung established in Z\u00fcrich in 1965, holds a smaller collection of works acquired from the collection of the Pittsburgh industrialist G. David Thompson.\nNotable sales.\nIn November 2000 a Giacometti bronze, \"Grande Femme Debout I\", sold for $14.3 million. \"Grande Femme Debout II\" was bought by the Gagosian Gallery for $27.4 million at Christie's auction in New York City on 6 May 2008.\n\"L'Homme qui marche I\", a life-sized bronze sculpture of a man, became one of the most expensive works of art and the most expensive sculpture ever sold at auction on 2 February 2010, when it sold for \u00a365 million (US$104.3 million) at Sotheby's, London. \"Grande t\u00eate mince\", a large bronze bust, sold for $53.3 million just three months later.\n\"L'Homme au doigt\" (\"Pointing Man\") sold for $126 million (\u00a381,314,455.32), or $141.3 million with fees, in Christie's 11 May 2015 Looking Forward to the Past sale in New York, a record for a sculpture at auction. The work had been in the same private collection for 45 years.\nAfter being showcased on the BBC programme \"Fake or Fortune\", a plaster sculpture, titled \"Gazing Head\", sold in 2019 for half a million pounds.\nIn April 2021, Giacometti's small-scale bronze sculpture, Nu debout II (1953), was sold from a Japanese private collection and went for \u00a31.5 million ($2 million), against an estimate of \u00a3800,000 ($1.1 million).\nOther legacy.\nGiacometti created the monument on the grave of Gerda Taro at P\u00e8re Lachaise Cemetery.\nIn 2001 he was included in the exhibition held at the National Portrait Gallery, London.\nGiacometti and his sculpture \"L'Homme qui marche I\" appear on the current 100 Swiss franc banknote.\nAccording to a lecture by Michael Peppiatt at Cambridge University on 8 July 2010, Giacometti, who had a friendship with author/playwright Samuel Beckett, created a tree for the set of a 1961 Paris production of \"Waiting for Godot\".\nThe 2017 movie \"Final Portrait\" retells the story of his friendship with the biographer James Lord. Giacometti is played by Geoffrey Rush."}
{"id": "2439", "revid": "1084610", "url": "https://en.wikipedia.org/wiki?curid=2439", "title": "Anthem", "text": "An anthem is a musical composition of celebration, usually used as a symbol for a distinct group, particularly the national anthems of countries. Originally, and in music theory and religious contexts, it also refers more particularly to short sacred choral work (still frequently seen in Sacred Harp and other types of shape note singing) and still more particularly to a specific form of liturgical music. In this sense, its use began ca. 1550 in English-speaking churches; it uses English language words, in contrast to the originally Roman Catholic 'motet' which sets a Latin text.\nEtymology.\n\"Anthem\" is derived from the Greek (\"ant\u00edph\u014dna\") via Old English . Both words originally referred to antiphons, a call-and-response style of singing. The adjectival form is \"anthemic\".\nHistory.\nAnthems were originally a form of liturgical music. In the Church of England, the rubric appoints them to follow the third collect at morning and evening prayer. Several anthems are included in the British coronation service. The words are selected from Holy Scripture or in some cases from the Liturgy and the music is generally more elaborate and varied than that of psalm or hymn tunes. Being written for a trained choir rather than the congregation, the Anglican anthem is analogous to the motet of the Catholic and Lutheran Churches but represents an essentially English musical form. Anthems may be described as \"verse\", \"full\", or \"full with verse\", depending on whether they are intended for soloists, the full choir, or both. Another way of describing an anthem is that it is a piece of music written specifically to fit a certain accompanying text, and it is often difficult to make any other text fit that same melodic arrangement. It also often changes melody and/or meter, frequently multiple times within a single song, and is sung straight through from start to finish, without repeating the melody for following verses like a normal song (although certain sections may be repeated when marked). An example of an anthem with multiple meter shifts a, fuguing, and repeated sections is \"Claremont\", or \"Vital Spark of Heav'nly Flame\". Another well known example is William Billing's \"Easter Anthem\", also known as \"The Lord Is Risen Indeed!\" after the opening lines. This anthem is still one of the more popular songs in the Sacred Harp tune book.\nThe anthem developed as a replacement for the Catholic \"votive antiphon\" commonly sung as an appendix to the main office to the Blessed Virgin Mary or other saints. \nNotable composers of liturgical anthems: historic context.\nDuring the Elizabethan period, notable anthems were composed by Thomas Tallis, William Byrd, Tye, and Farrant but they were not mentioned in the Book of Common Prayer until 1662 when the famous rubric \"In quires and places where they sing here followeth the Anthem\" first appears. Early anthems tended to be simple and homophonic in texture, so that the words could be clearly heard. During the 17th century, notable anthems were composed by Orlando Gibbons, Henry Purcell, and John Blow, with the verse anthem becoming the dominant musical form of the Restoration. In the 18th century, famed anthems were composed by Croft, Boyce, James Kent, James Nares, Benjamin Cooke, and Samuel Arnold. In the 19th, Samuel Sebastian Wesley wrote anthems influenced by contemporary oratorio which stretch to several movements and last twenty minutes or longer. Later in the century, Charles Villiers Stanford used symphonic techniques to produce a more concise and unified structure. Many anthems have been composed since this time, generally by organists rather than professional composers and often in a conservative style. Major composers have usually composed anthems in response to commissions and for special occasions. Examples include Edward Elgar's 1912 \"Great is the Lord\" and 1914 \"Give unto the Lord\" (both with orchestral accompaniment), Benjamin Britten's 1943 \"Rejoice in the Lamb\" (a modern example of a multi-movement anthem, today heard mainly as a concert piece), and, on a much smaller scale, Ralph Vaughan Williams's 1952 \"O Taste and See\" written for the coronation of Queen Elizabeth II. With the relaxation of the rule, in England at least, that anthems should be only in English, the repertoire has been greatly enhanced by the addition of many works from the Latin repertoire.\nTypes.\nThe word \"anthem\" is commonly used to describe any celebratory song or composition for a distinct group, as in national anthems. Many pop songs are used as sports anthems, notably including Queen's \"We Are the Champions\" and \"We Will Rock You\", and some sporting events have their own anthems, most notably including UEFA Champions League. Further, some songs are artistically styled as anthems, whether or not they are used as such, including Marilyn Manson's \"Irresponsible Hate Anthem\", Silverchair's \"Anthem for the Year 2000\", and Toto's \"Child's Anthem\".\nNational anthem.\nA national anthem (also state anthem, national hymn, national song, etc.) is generally a patriotic musical composition that evokes and eulogizes the history, traditions, and struggles of a country's people, recognized either by that state's government as the official national song, or by convention through use by the people. The majority of national anthems are marches or hymns in style. The countries of Latin America, Central Asia, and Europe tend towards more ornate and operatic pieces, while those in the Middle East, Oceania, Africa, and the Caribbean use a simpler fanfare. Some countries that are devolved into multiple constituent states have their own official musical compositions for them (such as with the United Kingdom, Russian Federation, and the former Soviet Union); their constituencies' songs are sometimes referred to as national anthems even though they are not sovereign states.\nFlag anthem.\nA flag anthem is generally a patriotic musical composition that extols and praises a flag, typically one of a country, in which case it is sometimes called a national flag anthem. It is often either sung or performed during or immediately before the raising or lowering of a flag during a ceremony. Most countries use their respective national anthems or some other patriotic song for this purpose. However, some countries, particularly in South America, use a discrete flag anthem for such purposes. Not all countries have flag anthems. Some used them in the past but no longer do, such as Iran, China, and South Africa. Flag anthems can be officially codified in law, or unofficially recognized as such through mere custom and convention. In some countries, the flag anthem may be just another song, and in others, it may be an official symbol of the state akin to a second national anthem, such as in Taiwan.\nShared anthems.\nAlthough anthems are used to distinguish states and territories, there are instances of shared anthems. \"Nkosi Sikelel' iAfrika\" became a pan-African liberation anthem and was later adopted as the national anthem of five countries in Africa including Zambia, Tanzania, Namibia and Zimbabwe after independence. Zimbabwe and Namibia have since adopted new national anthems. Since 1997, the South African national anthem has been a hybrid song combining new English lyrics with extracts of \"Nkosi Sikelel' iAfrika\" and the former state anthem \"Die Stem van Suid-Afrika\".\n\"Hymn to Liberty\" is the longest national anthem in the world by length of text. In 1865, the first three stanzas and later the first two officially became the national anthem of Greece and later also that of the Republic of Cyprus.\n\"Forged from the Love of Liberty\" was composed as the national anthem for the short-lived West Indies Federation (1958\u20131962) and was adopted by Trinidad and Tobago when it became independent in 1962.\n\"Esta \u00c9 a Nossa P\u00e1tria Bem Amada\" is the national anthem of Guinea-Bissau and was also the national anthem of Cape Verde until 1996.\n\"Oben am jungen Rhein\", the national anthem of Liechtenstein, is set to the tune of \"God Save the Queen\". Other anthems that have used the same melody include \"Heil dir im Siegerkranz\", \"Kongesangen\", \"My Country, 'Tis of Thee\", \"Rufst du, mein Vaterland\", \"E Ola Ke Alii Ke Akua\", and \"The Prayer of Russians\"F.\nThe Estonian anthem \"Mu isamaa, mu \u00f5nn ja r\u00f5\u00f5m\" is set to a melody composed in 1848 by Fredrik (Friedrich) Pacius which is also that of the national anthem of Finland: \"Maamme\" (\"V\u00e5rt Land\" in Swedish). It is also considered to be ethnic anthem for the Livonian people with lyrics \"Min iz\u0101m\u014d, min sindim\u014d\" (\"My Fatherland, my native land\").\n\"Hey, Slavs\" is dedicated to Slavic peoples. Its first lyrics were written in 1834 under the title \"Hey, Slovaks\" (\"Hej, Slov\u00e1ci\") by Samuel Tom\u00e1\u0161ik and it has since served as the ethnic anthem of the Pan-Slavic movement, the organizational anthem of the Sokol physical education and political movement, the national anthem of Yugoslavia and the transitional anthem of the State Union of Serbia and Montenegro. The song is also considered to be the second, unofficial anthem of the Slovaks. Its melody is based on Mazurek D\u0105browskiego, which has been also the anthem of Poland since 1926, but the Yugoslav variation is much slower and more accentuated.\nBetween 1991 and 1994 \"De\u0219teapt\u0103-te, rom\u00e2ne!\" was the national anthem of both Romania (which adopted it in 1990) and Moldova, but in the case of the latter was replaced by the current Moldovan national anthem, \"Limba noastr\u0103\".\nThe modern national anthem of Germany, \"Das Lied der Deutschen\", uses the same tune as the 19th and early 20th-century Austro-Hungarian imperial anthem \"Gott erhalte Franz den Kaiser\".\nThe \"Hymn of the Soviet Union\", used until its dissolution in 1991, which was given new words and adopted by the Russian Federation in 2000 to replace an instrumental national anthem that had been introduced in 1990.\n\"Bro Gozh ma Zado\u00f9\", the regional anthem of Brittany and, \"Bro Goth Agan Tasow\", the Cornish regional anthem, are sung to the same tune as that of the Welsh regional anthem \"Hen Wlad Fy Nhadau\", with similar words.\nFor parts of states.\nSome countries, such as the former Soviet Union, Spain, and the United Kingdom, among others, are held to be unions of several \"nations\" by various definitions. Each of the different \"nations\" may have their own (regional) anthem and these songs may or may not be officially recognized; these compositions are typically referred to as regional anthems though may be known by other names as well (e.g. \"state songs\" in the United States).\nAustria.\nIn Austria, the situation is similar to that in Germany. The regional anthem of Upper Austria, the \"Hoamatgsang\" (), is notable in the way that it is the only (official) German-language anthem written \u2013 and sung \u2013 entirely in dialect.\nBelgium.\nIn Belgium, Wallonia uses \"Le Chant des Wallons\" and Flanders uses \"De Vlaamse Leeuw\".\nCanada.\nThe Canadian province of Newfoundland and Labrador, having been the independent Dominion of Newfoundland before 1949, also has its own regional anthem from its days as a dominion and colony of the UK, the \"Ode to Newfoundland\". It was the only Canadian province with its own anthem until 2010, when Prince Edward Island adopted the 1908 song \"The Island Hymn\" as its provincial anthem.\nCzechoslovakia.\nCzechoslovakia had a national anthem composed of two parts, the Czech regional anthem followed by one verse of the Slovak one. After the dissolution of Czechoslovakia, the Czech Republic adopted its own regional anthem as its national one, whereas Slovakia did so with slightly changed lyrics and an additional stanza.\nGermany.\nIn Germany, many of the L\u00e4nder have their own anthems, some of which predate the unification of Germany in 1871. A prominent example is the Hymn of Bavaria, which also has the status of an official anthem (and thus enjoys legal protection). There are also several unofficial regional anthems, like the \"Badnerlied\" or the \"Niedersachsenlied\".\nMalaysia.\nAll the individual states of Malaysia have their own anthems.\nMexico.\nIn Mexico, after the national anthem was established in 1854, most of the states of the federation adopted their own regional anthems, which often emphasize heroes, virtues or particular landscapes. In particular, the regional anthem of Zacatecas, the \"Marcha de Zacatecas\", is one of the more well-known of Mexico's various regional anthems.\nSerbia and Montenegro.\nIn 2005 and 2004 respectively, the Serbian and Montenegrin regions of Serbia and Montenegro adopted their own regional anthems. When the two regions both became independent countries in mid-2006, their regional anthems became their national ones.\nSoviet Union.\nFourteen of the fifteen constituent states of the Soviet Union had their own official song which was used at events connected to that region, and also written and sung in that region's own language. The Russian Soviet Federative Socialist Republic used the Soviet Union's national anthem as its regional anthem (\"The Internationale\" from 1917 to 1944 and the \"National Anthem of the Soviet Union\" from 1944 to 1990) until 1990, the last of the Soviet constituent states to do so. After the Soviet Union disbanded in the early 1990s, some of its former constituent states, now sovereign nations in their own right, retained the melodies of their old Soviet-era regional anthems until replacing them or, in some cases, still use them today.\nUnlike most national anthems, few of which were composed by renowned composers, the Soviet Union's various regional anthems were composed by some of the best Soviet composers, including world-renowned Gustav Ernesaks (Estonia), Aram Khachaturian (Armenia), Otar Taktakishvili (Georgia), and Uzeyir Hajibeyov (Azerbaijan).\nThe lyrics present great similarities, all having mentions to Vladimir Lenin (and most, in their initial versions, to Joseph Stalin, the Armenian and Uzbek anthems being exceptions), to the guiding role of the Communist Party of the Soviet Union, and to the brotherhood of the Soviet peoples, including a specific reference to the friendship of the Russian people (the Estonian, Georgian and Karelo-Finnish anthems were apparently an exception to this last rule).\nSome of the Soviet regional anthems' melodies can be sung in the Soviet Union anthem lyrics (Ukrainian and Belarus are the most fitted in this case).\nMost of these regional anthems were replaced with new national ones during or after the dissolution of the Soviet Union; Belarus, Kazakhstan (until 2006), Tajikistan, Turkmenistan (until 1997), and Uzbekistan kept the melodies, but with different lyrics. Russia itself had abandoned the Soviet hymn, replacing it with a tune by Glinka. However, with Vladimir Putin coming to power, the old Soviet tune was restored, with new lyrics written to it.\nLike the hammer and sickle and red star, the public performance of the anthems of the Soviet Union's various regional anthems the national anthem of the Soviet Union itself are considered as occupation symbols as well as symbols of totalitarianism and state terror by several countries formerly either members of or occupied by the Soviet Union. Accordingly, Latvia, Lithuania, Hungary, and Ukraine have banned those anthems amongst other things deemed to be symbols of fascism, socialism, communism, and the Soviet Union and its republics. In Poland, dissemination of items which are \u201cmedia of fascist, communist, or other totalitarian symbolism\u201d was criminalized in 1997. However, in 2011 the Constitutional Tribunal found this sanction to be unconstitutional. In contrast to this treatment of the \"symbolism\", promotion of fascist, communist and other totalitarian \"ideology\" remains illegal. Those laws do not apply to the anthems of Russia, Belarus, Uzbekistan, Kazakhstan, and Tajikistan which used the melody with different lyrics.\nSpain.\nIn Spain, the situation is similar to that in Austria and Germany. Unlike the national anthem, most of the anthems of the autonomous communities have words. All are official. Three prominent examples are \"Els Segadors\" of Catalonia, \"Eusko Abendaren Ereserkia\" of the Basque Country, and \"Os Pinos\" of Galicia, all written and sung in the local languages.\nUnited Kingdom.\nThe United Kingdom's national anthem is \"God Save the Queen\" but its constituent countries and Crown Dependencies also have their own national anthems which have varying degrees of official recognition. England, Scotland, Wales, and Northern Ireland, each has a number of anthems which are played at occasions such as sports matches and official events. \"God Save the Queen\" is usually presumed to be, and often played as, the English regional anthem; but \"Jerusalem\", \"I Vow To Thee, My Country\" and \"Land of Hope and Glory\" are also sung. Scotland variously uses \"Flower of Scotland\", \"Auld Lang Syne\", and \"Scotland the Brave\" as its unofficial national anthems; while Wales has sung \"Hen Wlad Fy Nhadau\" since 1856 when it was written by father and son Evan and James James. The music and a Breton translation, \"Bro Gozh ma Zado\u00f9\", were adopted by Brittany as its regional anthem; and there is also a Cornish version, \"Bro Goth agan Tasow\", sung alongside \"Trelawney\" as an unofficial Cornish anthem. In Wales, \"Hen Wlad fy Nhadau\" is sometimes accompanied by the hymn, \"Guide Me, O thou Great Redeemer\" (also referred to as \"Bread of Heaven\" from repeated words in its first verse), especially at rugby matches. Northern Ireland currently uses \"God Save the Queen\" but previously used \"Danny Boy/Londonderry Air\".\nUnited States.\nAlthough the United States has \"The Star-Spangled Banner\" as its official national anthem, its constituent states and territories also has their own regional anthem (referred to by most US states as a \"state song\"), along with Washington, DC. A notable exception is New Jersey, which is the only US state to be without a regional anthem.\nForty-nine of the United States' fifty constituent states have one or more regional anthems (usually referred to as a \"state song\" in US parlance), which are selected by each state legislature, and/or state governor, as a symbol (or emblem) of that particular US state. \nSome US states have more than one official state song, and may refer to some of their official songs by other names; for example, Arkansas officially has two state songs, plus a state anthem, and a state historical song. Tennessee has the most state songs, with 9 official state songs and an official bicentennial rap.\nArizona has a song that was written specifically as a state anthem in 1915, as well as the 1981 country hit \"Arizona\", which it adopted as the alternate state anthem in 1982.\nTwo individuals, Stephen Foster, and John Denver, have written or co-written two state songs. Foster's two state songs, \"Old Folks at Home\" (better known as \"Swanee Ribber\" or \"Suwannee River\"), adopted by Florida, and \"My Old Kentucky Home\" are among the best-known songs in the US On March 12, 2007, the Colorado Senate passed a resolution to make Denver's trademark 1972 hit \"Rocky Mountain High\" one of the state's two official state songs, sharing duties with its predecessor, \"Where the Columbines Grow\". On March 7, 2014, the West Virginia Legislature approved a resolution to make Denver's \"Take Me Home, Country Roads\" one of four official state songs of West Virginia. Governor Earl Ray Tomblin signed the resolution into law on March 8, 2014.\nAdditionally, Woody Guthrie wrote or co-wrote two state \"folk songs\" \u2013 Roll On, Columbia, Roll On and Oklahoma Hills \u2013 but they have separate status from the official state \"songs\" of Washington and Oklahoma, respectively. Other well-known state songs include \"Yankee Doodle\", \"You Are My Sunshine\", \"Rocky Top\", and \"Home on the Range\"; a number of others are popular standards, including \"Oklahoma\" (from the Rodgers and Hammerstein musical), Hoagy Carmichael's \"Georgia on My Mind\", \"Tennessee Waltz\", \"Missouri Waltz\", and \"On the Banks of the Wabash, Far Away\". Many of the others are much less well-known, especially outside the state.\nNew Jersey has no official state song, while Virginia's previous state song, \"Carry Me Back to Old Virginny\", adopted in 1940, was later rescinded in 1997 due to its racist language by the Virginia General Assembly. In 2015, \"Our Great Virginia\" was made the new state song of Virginia.\nMaryland (\"Maryland, My Maryland\") and Iowa (\"The Song of Iowa\") use the tune from the song \"O Tannenbaum\" as the melody to their official state songs.\nYugoslavia.\nIn Yugoslavia, each of the country's constituent states (except for Bosnia and Herzegovina) had the right to have its own anthem, but only the Croatian one actually did so initially, later joined by the Slovene one on the brink of the breakup of Yugoslavia. Before 1989, Macedonia did not officially use a regional anthem, even though one was proclaimed during the World War II by ASNOM.\nInternational organizations.\nLarger entities also sometimes have anthems, in some cases known as 'international anthems'. \"Lullaby\" is the official anthem of UNICEF composed by Steve Barakatt. \"The Internationale\" is the organizational anthem of the socialist movement and the communist movement. Before March 1944, it was also the anthem of the Soviet Union and the Comintern. ASEAN Way is the official anthem of ASEAN. The tune of the \"Ode to Joy\" from Beethoven's Symphony No. 9 is the official anthem of the European Union and of the Council of Europe. Let's All Unite and Celebrate is the official anthem of the African Union (\"Let Us All Unite and Celebrate Together\").\nThe Olympic Movement also has its own organizational anthem. Esperanto speakers at meetings often use the song \"La Espero\" as their linguistic anthem. The first South Asian Anthem by poet-diplomat Abhay K may inspire SAARC to come up with an official SAARC Anthem.\n\"Ireland's Call\" was commissioned as the sporting anthem of both the Ireland national rugby union team and the Ireland national rugby league team, which are composed of players from both jurisdictions on the island of Ireland, in response to dissatisfaction among Northern Ireland unionists with the use of the Irish national anthem. \"Ireland's Call\" has since been used by some other all-island bodies.\nAn international anthem also unifies a group of organizations sharing the same appellation such as the International Anthem of the Royal Golf Clubs composed by Steve Barakatt. Same applies to the European Broadcasting Union: the prelude of Te Deum in D Major by Marc-Antoine Charpentier is played before each official Eurovision and Euroradio broadcast. The prelude's first bars are heavily associated with the Eurovision Song Contest.\nGlobal anthem.\nVarious artists have created \"Earth Anthems\" for the entire planet, typically extolling the ideas of planetary consciousness. Though UNESCO have praised the idea of a global anthem, the UN has never adopted an official song."}
{"id": "2440", "revid": "3174456", "url": "https://en.wikipedia.org/wiki?curid=2440", "title": "Albrecht Altdorfer", "text": "Albrecht Altdorfer (12 February 1538) was a German painter, engraver and architect of the Renaissance working in Regensburg, Bavaria. Along with Lucas Cranach the Elder and Wolf Huber he is regarded to be the main representative of the Danube School setting biblical and historical subjects against landscape backgrounds of expressive colours. He is remarkable as one of the first artists to take an interest in landscape as an independent subject. As an artist also making small intricate engravings he is seen to belong to the Nuremberg Little Masters.\nBiography.\nAltdorfer was born in Regensburg or Altdorf around 1480.\nHe acquired an interest in art from his father, Ulrich Altdorfer, who was a painter and miniaturist. At the start of his career, he won public attention by creating small, intimate modestly scaled works in unconventional media and with eccentric subject matter. He settled in the free imperial city of Regensburg, a town located on the Danube River in 1505, eventually becoming the town architect and a town councillor. His first signed works date to c. 1506, including engravings and drawings such the \"Stygmata of St. Francis\" and \"St. Jerome\". His models were niellos and copper engravings from the workshops of Jacopo de Barbari and Albrecht D\u00fcrer.\nAround 1511 or earlier, he travelled down the river and south into the Alps, where the scenery moved him so deeply that he became the first landscape painter in the modern sense, making him the leader of the Danube School, a circle that pioneered landscape as an independent genre, in southern Germany. From 1513 he was at the service of Maximilian I in Innsbruck, where he received several commissions from the imperial court. During the turmoil of the Protestant Reformation, he dedicated mostly to architecture; paintings of the period, showing his increasing attention to architecture, include the \"Nativity of the Virgin\".\nIn 1529, he executed \"The Battle of Alexander at Issus\" for Duke William IV of Bavaria. In the 1520s he returned to Regensburg as a wealthy man, and became a member of the city's council. He was also responsible for the fortifications of Regensburg.\nIn that period his works are influenced by artists such as Giorgione and Lucas Cranach, as shown by his \"Crucifixion\". In 1535, he was in Vienna. He died at Regensburg in 1538.\nThe remains of Altdorfer's surviving work comprises 55 panels, 120 drawings, 125 woodcuts, 78 engravings, 36 etchings, 24 paintings on parchment, and fragments from a mural for the bathhouse of the Kaiserhof in Regensburg. This production extends at least over the period 1504\u20131537. He signed and dated each one of his works.\nPainting.\nAltdorfer was the pioneer painter of pure landscape, making them the subject of the painting, as well as compositions dominated by their landscape; these comprise much of his oeuvre. He believed that the human figure should not disrupt nature, but rather participate in it or imitate its natural processes. Taking and developing the landscape style of Lucas Cranach the Elder, he shows the hilly landscape of the Danube valley with thick forests of drooping and crumbling firs and larches hung with moss, and often dramatic colouring from a rising or setting sun. His \"Landscape with Footbridge\" (National Gallery, London) of 1518\u20131520 is claimed to be the first pure landscape in oil. In this painting, Altdorfer places a large tree that is cut off by the margins at the center of the landscape, making it the central axis and focus within the piece. Some viewers perceive anthropomorphic stylisation\u2014the tree supposedly exhibiting human qualities such as the drapery of its limbs. He also made many fine finished drawings, mostly landscapes, in pen and watercolour such as the \"Landscape with the Woodcutter\" in 1522. The drawing opens at ground level on a clearing surrounding an enormous tree that is placed in the center, dominating the picture. Some see the tree pose and gesticulate as if it was human, splaying its branches out in every corner. Halfway up the tree trunk, hangs a gabled shrine. At the time, a shrine like this might shelter an image of the Crucifixion or the Virgin Mary, but since it is turned away from the viewer, we are not sure what it truly is. At the bottom of the tree, a tiny figure of a seated man, crossed legged, holds a knife and axe, declaring his status in society/occupation.\nAlso, he often painted scenes of historical and biblical subjects, set in atmospheric landscapes. His best religious scenes are intense, with their glistening lights and glowing colours sometimes verging on the expressionistic. They often depict moments of intimacy between Christ and his mother, or various saints. His sacral masterpiece and one of the most famous religious works of art of the later Middle Ages is \"The Legend of St. Sebastian\" and \"The Passion of Christ\" of the so-called \"Sebastian Altar\" in \"St. Florian's Priory\" (\"Stift Sankt Florian\") near Linz, Upper Austria. When closed the altarpiece displayed the four panels of the legend of St. Sebastian's Martyrdom, while the opened wings displayed the Stations of the Cross. Today the altarpiece is dismantled and the predellas depicting the two final scenes, \"Entombment\" and \"Resurrection\" were sold to Kunsthistorisches Museum in Vienna in 1923 and 1930. Both these paintings share a similar formal structure that consists of an open landscape that is seen beyond and through the opening of a dark grotto. The date of completion on the resurrection panel is 1518.\nAltdorfer often distorts perspective to subtle effect. His donor figures are often painted completely out of scale with the main scene, as in paintings of the previous centuries. He also painted some portraits; overall his painted oeuvre was not large. In his later works, Altdorfer moved more towards mannerism and began to depict the human form to the conformity of the Italian model, as well as dominate the picture with frank colors.\nPaintings in Munich.\nHis rather atypical \"Battle of Issus\" (or of \"Alexander\") of 1529 was commissioned by William IV, Duke of Bavaria as part of a series of eight historical battle scenes destined to hang in the Residenz in Munich. Albrecht Altdorfer's depiction of the moment in 333 BCE when Alexander the Great routed Darius III for supremacy in Asia Minor is vast in ambition, sweeping in scope, vivid in imagery, rich in symbols, and obviously heroic\u2014the Iliad of painting, as literary critic Friedrich Schlegel suggested In the painting, a swarming cast of thousands of soldiers surround the central action: Alexander on his white steed, leading two rows of charging cavalrymen, dashes after a fleeing Darius, who looks anxiously over his shoulder from a chariot. The opposing armies are distinguished by the colors of their uniforms: Darius' army in red and Alexander's in blue. The upper half of \"The Battle of Alexander\" expands with unreal rapidity into an arcing panorama comprehending vast coiling tracts of globe and sky. The victory also lies on the planar surface; The sun outshone the moon just as the Imperial and allied army successfully repel the Turks.\nBy making the mass number of soldiers blend within the landscape/painting, it shows that he believed that the usage and depiction of landscape was just as significant as a historical event, such as a war. He renounced the office of \"Mayor of Regensburg\" to accept the commission. Few of his other paintings resemble this apocalyptic scene of two huge armies dominated by an extravagant landscape seen from a very high viewpoint, which looks south over the whole Mediterranean from modern Turkey to include the island of Cyprus and the mouths of the Nile and the Red Sea (behind the isthmus to the left) on the other side. However his style here is a development of that of a number of miniatures of battle-scenes he had done much earlier for Maximilian I in his illuminated manuscript \"Triumphal Procession\" in 1512\u201314. It is thought to be the earliest painting to show the curvature of the Earth from a great height.\nThe \"Battle\" is now in the Alte Pinakothek, which has the best collection of Altdorfer's paintings, including also his small \"St. George and the Dragon\" (1510), in oil on parchment, where the two figures are tiny and almost submerged in the lush, dense forest that towers over them. Altdorfer seems to exaggerate the measurements of the forest in comparison to the figures: the leaves appear to be larger than the horse, showing the significance of nature and landscape. He also emphasizes line within the work, by displaying the upward growth of the forest with the vertical and diagonal lines of the trunks. There is a small opening of the forest on the lower right hand corner that provides a rest for your eyes. It serves to create depth within the painting and is the only place you can see the characters. The human form is completely absorbed by the thickness of the forest. Fantastic light effects provide a sense of mystery and dissolve the outline of objects. Without the contrast of light, the figures would blend in with its surrounding environment. Altdorfer's figures are invariably the complement of his romantic landscapes; for them he borrowed Albrecht D\u00fcrer's inventive iconography, but the panoramic setting is personal and has nothing to do with the fantasy landscapes of the Netherlands A \"\" (1526) set outside an Italianate skyscraper of a palace shows his interest in architecture. Another small oil on parchment, \"Danube Landscape with Castle W\u00f6rth\" (c. 1520) is one of the earliest accurate topographical paintings of a particular building in its setting, of a type that was to become a clich\u00e9 in later centuries.\nPrintmaking.\nAltdorfer was a significant printmaker, with numerous engravings and about ninety-three woodcuts. These included some for the \"Triumphs of Maximilian\", where he followed the overall style presumably set by Hans Burgkmair, although he was able to escape somewhat from this in his depictions of the more disorderly baggage-train, still coming through a mountain landscape. However most of his best prints are etchings, many of landscapes; in these he was able most easily to use his drawing style. He was one of the most successful early etchers, and was unusual for his generation of German printmakers in doing no book illustrations. He often combined etching and engraving techniques in a single plate, and produced about 122 intaglio prints altogether. Many of Altdorfer's prints are quite small in size, and he is considered to be of the main members of the group of artists known as the Little Masters. Arthur Mayger Hind considers his graphical work to be somewhat lacking in technical skill but with an \"intimate personal touch\", and notes his characteristic feeling for landscape.\nPublic life.\nAs the superintendent of the municipal buildings Altdorfer had overseen the construction of several commercial structures, such as a slaughterhouse and a building for wine storage, possibly even designing them. He was considered to be an outstanding politician of his day. In 1517 he was a member of the \"Ausseren Rates\", the council on external affairs, and in this capacity was involved in the expulsion of the Jews, the destruction of the synagogue and in its place the construction of a church and shrine to the Sch\u00f6ne Maria that occurred in 1519. Altdorfer made etchings of the interior of the synagogue and designed a woodcut of the cult image of the Sch\u00f6ne Maria. In 1529\u20131530 he was also charged with reinforcing certain city fortifications in response to the Turkish threat.\nAlbrecht's brother, Erhard Altdorfer, was also a painter and printmaker in woodcut and engraving, and a pupil of Lucas Cranach the Elder."}
{"id": "2441", "revid": "37247652", "url": "https://en.wikipedia.org/wiki?curid=2441", "title": "House of Ascania", "text": "The House of Ascania () is a dynasty of German rulers. It is also known as the House of Anhalt, which refers to its longest-held possession, Anhalt.\nThe Ascanians are named after Ascania (or Ascaria) Castle, known as \"Schloss Askanien\" in German, which was located near and named after Aschersleben. The castle was the seat of the County of Ascania, a title that was later subsumed into the titles of the princes of Anhalt.\nHistory.\nThe earliest known member of the house, Esiko, Count of Ballenstedt, first appears in a document of 1036. He is assumed to have been a grandson (through his mother) of Odo I, Margrave of the Saxon Ostmark. From Odo, the Ascanians inherited large properties in the Saxon Eastern March.\nEsiko's grandson was Otto, Count of Ballenstedt, who died in 1123. By Otto's marriage to Eilika, daughter of Magnus, Duke of Saxony, the Ascanians became heirs to half of the property of the House of Billung, former dukes of Saxony.\nOtto's son, Albert the Bear, became, with the help of his mother's inheritance, the first Ascanian duke of Saxony in 1139. However, he soon lost control of Saxony to the rival House of Guelph.\nAlbert inherited the Margraviate of Brandenburg in 1157 from its last Wendish ruler, Pribislav, and he became the first Ascanian margrave. Albert, and his descendants of the House of Ascania, then made considerable progress in Christianizing and Germanizing the lands. As a borderland between German and Slavic cultures, the country was known as a march.\nIn 1237 and 1244, two towns, C\u00f6lln and Berlin, were founded during the rule of Otto and Johann, grandsons of Margrave Albert the Bear. Later, they were united into one city, Berlin. The emblem of the House of Ascania, a red eagle and bear, became the heraldic emblems of Berlin. In 1320, the Brandenburg Ascanian line came to an end.\nAfter the Emperor had deposed the Guelph rulers of Saxony in 1180, Ascanians returned to rule the Duchy of Saxony, which had been reduced to its eastern half by the Emperor. However, even in eastern Saxony, the Ascanians could establish control only in limited areas, mostly near the River Elbe.\nIn the 13th century, the Principality of Anhalt was split off from the Duchy of Saxony. Later, the remaining state was split into Saxe-Lauenburg and Saxe-Wittenberg. The Ascanian dynasties in the two Saxon states became extinct in 1689 and in 1422, respectively, but Ascanians continued to rule in the smaller state of Anhalt and its various subdivisions until the monarchy was abolished in 1918.\nCatherine the Great, Empress of Russia from 1762 to 1796, was a member of the House of Ascania, herself the daughter of Christian August, Prince of Anhalt-Zerbst."}
{"id": "2443", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=2443", "title": "Acceleration", "text": "In mechanics, acceleration is the rate of change of the velocity of an object with respect to time.\nAccelerations are vector quantities (in that they have magnitude and direction). The orientation of an object's acceleration is given by the orientation of the \"net\" force acting on that object. The magnitude of an object's acceleration, as described by Newton's Second Law, is the combined effect of two causes:\nThe SI unit for acceleration is metre per second squared (, formula_1).\nFor example, when a vehicle starts from a standstill (zero velocity, in an inertial frame of reference) and travels in a straight line at increasing speeds, it is \"accelerating\" in the direction of travel. If the vehicle turns, an acceleration occurs toward the new direction and changes its motion vector. The acceleration of the vehicle in its current direction of motion is called a \"linear\" (or \"tangential\" during circular motions) acceleration, the reaction to which the passengers on board experience as a force pushing them back into their seats. When changing direction, the effecting acceleration is called \"radial\" (or \"orthogonal\" during circular motions) acceleration, the reaction to which the passengers experience as a centrifugal force. If the speed of the vehicle decreases, this is an acceleration in the opposite direction and mathematically a negative, sometimes called \"deceleration\", and passengers experience the reaction to deceleration as an inertial force pushing them forward. Such negative accelerations are often achieved by retrorocket burning in spacecraft. Both acceleration and deceleration are treated the same, they are both changes in velocity. Each of these accelerations (tangential, radial, deceleration) is felt by passengers until their relative (differential) velocity are neutralized in reference to the vehicle. \na=d\\dt v\nDefinition and properties.\nAverage acceleration.\nAn object's average acceleration over a period of time is its change in velocity formula_2 divided by the duration of the period formula_3. Mathematically,\nInstantaneous acceleration.\nInstantaneous acceleration, meanwhile, is the limit of the average acceleration over an infinitesimal interval of time. In the terms of calculus, instantaneous acceleration is the derivative of the velocity vector with respect to time:\nAs acceleration is defined as the derivative of velocity, , with respect to time and velocity is defined as the derivative of position, , with respect to time, acceleration can be thought of as the second derivative of with respect to :\nBy the fundamental theorem of calculus, it can be seen that the integral of the acceleration function is the velocity function ; that is, the area under the curve of an acceleration vs. time ( vs. ) graph corresponds to velocity.\nLikewise, the integral of the jerk function , the derivative of the acceleration function, can be used to find acceleration at a certain time:\nUnits.\nAcceleration has the dimensions of velocity (L/T) divided by time, i.e. L T\u22122. The SI unit of acceleration is the metre per second squared (m s\u22122); or \"metre per second per second\", as the velocity in metres per second changes by the acceleration value, every second.\nOther forms.\nAn object moving in a circular motion\u2014such as a satellite orbiting the Earth\u2014is accelerating due to the change of direction of motion, although its speed may be constant. In this case it is said to be undergoing \"centripetal\" (directed towards the center) acceleration.\nProper acceleration, the acceleration of a body relative to a free-fall condition, is measured by an instrument called an accelerometer.\nIn classical mechanics, for a body with constant mass, the (vector) acceleration of the body's center of mass is proportional to the net force vector (i.e. sum of all forces) acting on it (Newton's second law):\nwhere F is the net force acting on the body, \"m\" is the mass of the body, and a is the center-of-mass acceleration. As speeds approach the speed of light, relativistic effects become increasingly large.\nTangential and centripetal acceleration.\nThe velocity of a particle moving on a curved path as a function of time can be written as:\nwith \"v\"(\"t\") equal to the speed of travel along the path, and\na unit vector tangent to the path pointing in the direction of motion at the chosen moment in time. Taking into account both the changing speed \"v(t)\" and the changing direction of u\"t\", the acceleration of a particle moving on a curved path can be written using the chain rule of differentiation for the product of two functions of time as:\nwhere un is the unit (inward) normal vector to the particle's trajectory (also called \"the principal normal\"), and r is its instantaneous radius of curvature based upon the osculating circle at time \"t\". These components are called the tangential acceleration and the normal or radial acceleration (or centripetal acceleration in circular motion, see also circular motion and centripetal force).\nGeometrical analysis of three-dimensional space curves, which explains tangent, (principal) normal and binormal, is described by the Frenet\u2013Serret formulas.\nSpecial cases.\nUniform acceleration.\n\"Uniform\" or \"constant\" acceleration is a type of motion in which the velocity of an object changes by an equal amount in every equal time period.\nA frequently cited example of uniform acceleration is that of an object in free fall in a uniform gravitational field. The acceleration of a falling body in the absence of resistances to motion is dependent only on the gravitational field strength \"g\" (also called \"acceleration due to gravity\"). By Newton's Second Law the force formula_13 acting on a body is given by:\nBecause of the simple analytic properties of the case of constant acceleration, there are simple formulas relating the displacement, initial and time-dependent velocities, and acceleration to the time elapsed:\nwhere\nIn particular, the motion can be resolved into two orthogonal parts, one of constant velocity and the other according to the above equations. As Galileo showed, the net result is parabolic motion, which describes, e.\u00a0g., the trajectory of a projectile in a vacuum near the surface of Earth.\nCircular motion.\nIn uniform circular motion, that is moving with constant \"speed\" along a circular path, a particle experiences an acceleration resulting from the change of the direction of the velocity vector, while its magnitude remains constant. The derivative of the location of a point on a curve with respect to time, i.e. its velocity, turns out to be always exactly tangential to the curve, respectively orthogonal to the radius in this point. Since in uniform motion the velocity in the tangential direction does not change, the acceleration must be in radial direction, pointing to the center of the circle. This acceleration constantly changes the direction of the velocity to be tangent in the neighboring point, thereby rotating the velocity vector along the circle.\n\u2022 For a given speed formula_26, the magnitude of this geometrically caused acceleration (centripetal acceleration) is inversely proportional to the radius formula_27 of the circle, and increases as the square of this speed:\n\u2022 Note that, for a given angular velocity formula_29, the centripetal acceleration is directly proportional to radius formula_27. This is due to the dependence of velocity formula_26 on the radius formula_27.\nExpressing centripetal acceleration vector in polar components, where formula_34 is a vector from the centre of the circle to the particle with magnitude equal to this distance, and considering the orientation of the acceleration towards the center, yields\nAs usual in rotations, the speed formula_26 of a particle may be expressed as an \"angular speed\" with respect to a point at the distance formula_27 as\nThus formula_39\nThis acceleration and the mass of the particle determine the necessary centripetal force, directed \"toward\" the centre of the circle, as the net force acting on this particle to keep it in this uniform circular motion. The so-called 'centrifugal force', appearing to act outward on the body, is a so-called pseudo force experienced in the frame of reference of the body in circular motion, due to the body's linear momentum, a vector tangent to the circle of motion.\nIn a nonuniform circular motion, i.e., the speed along the curved path is changing, the acceleration has a non-zero component tangential to the curve, and is not confined to the principal normal, which directs to the center of the osculating circle, that determines the radius formula_27 for the centripetal acceleration. The tangential component is given by the angular acceleration formula_41, i.e., the rate of change formula_42 of the angular speed formula_29 times the radius formula_27. That is,\nThe sign of the tangential component of the acceleration is determined by the sign of the angular acceleration (formula_41), and the tangent is always directed at right angles to the radius vector.\nRelation to relativity.\nSpecial relativity.\nThe special theory of relativity describes the behavior of objects traveling relative to other objects at speeds approaching that of light in a vacuum. Newtonian mechanics is exactly revealed to be an approximation to reality, valid to great accuracy at lower speeds. As the relevant speeds increase toward the speed of light, acceleration no longer follows classical equations.\nAs speeds approach that of light, the acceleration produced by a given force decreases, becoming infinitesimally small as light speed is approached; an object with mass can approach this speed asymptotically, but never reach it.\nGeneral relativity.\nUnless the state of motion of an object is known, it is impossible to distinguish whether an observed force is due to gravity or to acceleration\u2014gravity and inertial acceleration have identical effects. Albert Einstein called this the equivalence principle, and said that only observers who feel no force at all\u2014including the force of gravity\u2014are justified in concluding that they are not accelerating."}
{"id": "2444", "revid": "10521907", "url": "https://en.wikipedia.org/wiki?curid=2444", "title": "Conservation and restoration of cultural heritage", "text": "The conservation and restoration of cultural heritage focuses on protection and care of tangible cultural heritage, including artworks, architecture, archaeology, and museum collections. Conservation activities include preventive conservation, examination, documentation, research, treatment, and education. This field is closely allied with conservation science, curators and registrars.\nDefinition.\nConservation of cultural heritage involves protection and restoration using \"any methods that prove effective in keeping that property in as close to its original condition as possible for as long as possible.\" Conservation of cultural heritage is often associated with art collections and museums and involves collection care and management through tracking, examination, documentation, exhibition, storage, preventive conservation, and restoration.\nThe scope has widened from art conservation, involving protection and care of artwork and architecture, to conservation of cultural heritage, also including protection and care of a broad set of other cultural and historical works. Conservation of cultural heritage can be described as a type of ethical stewardship.\nConservation of cultural heritage applies simple ethical guidelines:\nOften there are compromises between preserving appearance, maintaining original design and material properties, and ability to reverse changes. Reversibility is now emphasized so as to reduce problems with future treatment, investigation, and use.\nIn order for conservators to decide upon an appropriate conservation strategy and apply their professional expertise accordingly, they must take into account views of the stakeholder, the values, artist's intent, meaning of the work, and the physical needs of the material.\nCesare Brandi in his \"Theory of Restoration\", describes restoration as \"the methodological moment in which the work of art is appreciated in its material form and in its historical and aesthetic duality, with a view to transmitting it to the future\".\nHistory.\nKey dates.\nSome consider the tradition of conservation of cultural heritage in Europe to have begun in 1565 with the restoration of the Sistine Chapel frescoes, but more ancient examples include the work of Cassiodorus.\nBrief history.\nThe care of cultural heritage has a long history, one that was primarily aimed at fixing and mending objects for their continued use and aesthetic enjoyment. Until the early 20th century, artists were normally the ones called upon to repair damaged artworks. During the 19th century, however, the fields of science and art became increasingly intertwined as scientists such as Michael Faraday began to study the damaging effects of the environment to works of art. Louis Pasteur carried out scientific analysis on paint as well. However, perhaps the first organized attempt to apply a theoretical framework to the conservation of cultural heritage came with the founding in the United Kingdom of the Society for the Protection of Ancient Buildings in 1877. The society was founded by William Morris and Philip Webb, both of whom were deeply influenced by the writings of John Ruskin. During the same period, a French movement with similar aims was being developed under the direction of Eug\u00e8ne Viollet-le-Duc, an architect and theorist, famous for his restorations of medieval buildings.\nConservation of cultural heritage as a distinct field of study initially developed in Germany, where in 1888 Friedrich Rathgen became the first chemist to be employed by a Museum, the Koniglichen Museen, Berlin (Royal Museums of Berlin). He not only developed a scientific approach to the care of objects in the collections, but disseminated this approach by publishing a Handbook of Conservation in 1898. The early development of conservation of cultural heritage in any area of the world is usually linked to the creation of positions for chemists within museums. In British archaeology, key research and technical experimentation in conservation was undertaken by women such as Ione Gedye both in the field and in archaeological collections, particularly those of the Institute of Archaeology, London.\nIn the United Kingdom, pioneering research into painting materials and conservation, ceramics, and stone conservation was conducted by Arthur Pillans Laurie, academic chemist and Principal of Heriot-Watt University from 1900. Laurie's interests were fostered by William Holman Hunt. In 1924 the chemist Dr Harold Plenderleith began to work at the British Museum with Dr. Alexander Scott in the recently created Research Laboratory, although he was actually employed by the Department of Scientific and Industrial Research in the early years. Plenderleith's appointment may be said to have given birth to the conservation \"profession\" in the UK, although there had been craftsmen in many museums and in the commercial art world for generations. This department was created by the museum to address the deteriorating condition of objects in the collection, damages which were a result of their being stored in the London Underground tunnels during the First World War. The creation of this department moved the focus for the development of conservation theory and practice from Germany to Britain, and made the latter a prime force in this fledgling field. In 1956 Plenderleith wrote a significant handbook called The Conservation of Antiquities and Works of Art, which supplanted Rathgen's earlier tome and set new standards for the development of art and conservation science.\nIn the United States, the development of conservation of cultural heritage can be traced to the Fogg Art Museum, and Edward Waldo Forbes, its director from 1909 to 1944. He encouraged technical investigation, and was Chairman of the Advisory Committee for the first technical journal, Technical Studies in the Field of the Fine Arts, published by the Fogg from 1932 to 1942. Importantly he also brought onto the museum staff chemists. Rutherford John Gettens was the first of such in the US to be permanently employed by an art museum. He worked with George L. Stout, the founder and first editor of Technical Studies. Gettens and Stout co-authored Painting Materials: A Short Encyclopaedia in 1942, reprinted in 1966. This compendium is still cited regularly. Only a few dates and descriptions in Gettens' and Stout's book are now outdated.\nGeorge T. Oliver, of Oliver Brothers Art Restoration and Art Conservation-Boston\n(Est. 1850 in New York City) invented the vacuum hot table for relining paintings in 1920s; he filed a patent for the table in 1937. Taylor's prototype table, which he designed and constructed, is still in operation. Oliver Brothers is believed to be the first and the oldest continuously operating art restoration company in the United States.\nThe focus of conservation development then accelerated in Britain and America, and it was in Britain that the first International Conservation Organisations developed. The International Institute for Conservation of Historic and Artistic Works (IIC) was incorporated under British law in 1950 as \"a permanent organization to co-ordinate and improve the knowledge, methods, and working standards needed to protect and preserve precious materials of all kinds.\" The rapid growth of conservation professional organizations, publications, journals, newsletters, both internationally and in localities, has spearheaded the development of the conservation profession, both practically and theoretically. Art historians and theorists such as Cesare Brandi have also played a significant role in developing conservation science theory. In recent years ethical concerns have been at the forefront of developments in conservation. Most significantly has been the idea of preventive conservation. This concept is based in part on the pioneering work by Garry Thomson CBE, and his book the Museum Environment, first published in 1978. Thomson was associated with the National Gallery in London; it was here that he established a set of guidelines or environmental controls for the best conditions in which objects could be stored and displayed within the museum environment. Although his exact guidelines are no longer rigidly followed, they did inspire this field of conservation.\nEthics.\nThe conservator's work is guided by ethical standards. These take the form of applied ethics. Ethical standards have been established across the world, and national and international ethical guidelines have been written. One such example is:\nConservation OnLine provides resources on ethical issues in conservation, including examples of codes of ethics and guidelines for professional conduct in conservation and allied fields; and charters and treaties pertaining to ethical issues involving the preservation of cultural property.\nAs well as standards of practice conservators deal with wider ethical concerns, such as the debates as to whether all art is worth preserving.\nCaring for cultural heritage.\nCollections care.\nMany cultural works are sensitive to environmental conditions such as temperature, humidity and exposure to visible light and ultraviolet radiation. These works must be protected in controlled environments where such variables are maintained within a range of damage-limiting levels. For example, watercolour paintings usually require shielding from sunlight to prevent fading of pigments.\nCollections care is an important element of museum policy. It is an essential responsibility of members of the museum profession to create and maintain a protective environment for the collections in their care, whether in store, on display, or in transit. A museum should carefully monitor the condition of collections to determine when an artifact requires conservation work and the services of a qualified conservator.\nInterventive conservation.\nA teaching programme of interventive conservation was established in the UK at the Institute of Archaeology by Ione Gedye, which is still teaching interventive conservators today.\nA principal aim of a cultural conservator is to reduce the rate of deterioration of an object. Both non-interventive and interventive methodologies may be employed in pursuit of this goal. Interventive conservation refers to any direct interaction between the conservator and the material fabric of the object. Interventive actions are carried out for a variety of reasons, including aesthetic choices, stabilization needs for structural integrity, or cultural requirements for intangible continuity. Examples of interventive treatments include the removal of discolored varnish from a painting, the application of wax to a sculpture, and the washing and rebinding of a book. Ethical standards within the field require that the conservator fully justify interventive actions and carry out documentation before, during, and after the treatment.\nOne of the guiding principles of conservation of cultural heritage has traditionally been the idea of reversibility, that all interventions with the object should be fully reversible and that the object should be able to be returned to the state in which it was prior to the conservator's intervention. Although this concept remains a guiding principle of the profession, it has been widely critiqued within the conservation profession and is now considered by many to be \"a fuzzy concept.\" Another important principle of conservation is that all alterations should be well documented and should be clearly distinguishable from the original object.\nAn example of a highly publicized interventive conservation effort would be the conservation work conducted on the Sistine Chapel.\nConservation laboratories.\nConservators routinely use chemical and scientific analysis for the examination and treatment of cultural works. The modern conservation laboratory uses equipment such as microscopes, spectrometers, and various x-ray regime instruments to better understand objects and their components. The data thus collected helps in deciding the conservation treatments to be provided to the object.\nCountry by country look.\nUnited States.\nHeritage Preservation, in partnership with the Institute of Museum and Library Services, a U.S. federal agency, produced The Heritage Health Index. The results of this work was the report A Public Trust at Risk: The Heritage Health Index Report on the State of America's Collections, which was published in December 2005 and concluded that immediate action is needed to prevent the loss of 190 million artifacts that are in need of conservation treatment. The report made four recommendations:\nUnited Kingdom.\nIn October 2006, the Department for Culture, Media and Sport, a governmental department, authored a document: \"Understanding the Future: Priorities for England's Museums\". This document was based on several years of consultation aimed to lay out the government's priorities for museums in the 21st century.\nThe document listed the following as priorities for the next decade:\nThe conservation profession response to this report was on the whole less than favourable, the Institute of Conservation (ICON) published their response under the title \"A Failure of Vision\". It had the following to say:\nConcluding: \nFurther to this the ICON website summary report lists the following specific recommendations:\nIn November 2008, the UK-based think tank Demos published an influential pamphlet entitled \"It's a material world: caring for the public realm\", in which they argue for integrating the public directly into efforts to conserve material culture, particularly that which is in the public, their argument, as stated on page 16, demonstrates their belief that society can benefit from conservation as a paradigm as well as a profession:\nTraining.\nTraining in conservation of cultural heritage for many years took the form of an apprenticeship, whereby an apprentice slowly developed the necessary skills to undertake their job. For some specializations within conservation this is still the case. However, it is more common in the field of conservation today that the training required to become a practicing conservator comes from a recognized university course in conservation of cultural heritage.\nThe University can rarely provide all the necessary training in first hand experience that an apprenticeship can, and therefore in addition to graduate level training the profession also tends towards encouraging conservation students to spend time as an intern.\nConservation of cultural heritage is an interdisciplinary field as conservators have backgrounds in the fine arts, sciences (including chemistry, biology, and materials science), and closely related disciplines, such as art history, archaeology, and anthropology. They also have design, fabrication, artistic, and other special skills necessary for the practical application of that knowledge.\nWithin the various schools that teach conservation of cultural heritage, the approach differs according to the educational and vocational system within the country, and the focus of the school itself. This is acknowledged by the American Institute for Conservation who advise \"Specific admission requirements differ and potential candidates are encouraged to contact the programs directly for details on prerequisites, application procedures, and program curriculum\".\nIn France, training for heritage conservation is taught by four schools : , L\u2019\u00c9cole sup\u00e9rieure des Beaux-Arts Tours, Angers, Le Mans, L\u2019Universit\u00e9 Paris 1 Panth\u00e9on-Sorbonne, Institut national du patrimoine.\nAssociations and professional organizations.\nSocieties devoted to the care of cultural heritage have been in existence around the world for many years. One early example is the founding in 1877 of the Society for the Protection of Ancient Buildings in Britain to protect the built heritage, this society continues to be active today. The 14th Dalai Lama and the Tibetan people work to preserve their cultural heritage with organizations including the Tibetan Institute of Performing Arts and an international network of eight Tibet Houses.\nThe built heritage was at the forefront of the growth of member based organizations in the United States. Preservation Virginia, founded in Richmond in 1889 as the Association for the Preservation of Virginia Antiquities, was the United States' first statewide historic preservation group.\nToday, professional conservators join and take part in the activities of numerous conservation associations and professional organizations with the wider field, and within their area of specialization.\nThese organizations exist to \"support the conservation professionals who preserve our cultural heritage\".\nThis involves upholding professional standards, promoting research and publications, providing educational opportunities, and fostering the exchange of knowledge among cultural conservators, allied professionals, and the public.\nExternal links.\nExternal lists.\nExternal lists of international cultural heritage documents:"}
{"id": "2446", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=2446", "title": "Appalachian Dulcimer", "text": ""}
