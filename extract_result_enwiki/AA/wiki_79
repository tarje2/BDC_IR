{"id": "9420", "revid": "1013787425", "url": "https://en.wikipedia.org/wiki?curid=9420", "title": "Eindhoven", "text": "Eindhoven ( , ) is the fifth-largest city and a municipality of the Netherlands, located in the south of the country. It had a population of 231,469 in 2019, making it the largest city in the province of North Brabant. Eindhoven was originally located at the confluence of the Dommel and Gender.\nNeighbouring cities and towns include Son en Breugel, Nuenen, Geldrop-Mierlo, Helmond, Heeze-Leende, Waalre, Veldhoven, Eersel, Oirschot and Best. The agglomeration has a population of . The metropolitan area consists of inhabitants. The city region has a population of 753,426. The Brabantse Stedenrij combined metropolitan area has about two million inhabitants.\nEtymology.\nThe name may derive from the contraction of the regional words \"eind\" (meaning \"last\" or \"end\") and \"hove\" (or \"hoeve\", a section of some 14 hectares of land). Toponymically, \"eind\" occurs commonly as a prefix and postfix in local place- and streetnames. A \"hove\" comprised a parcel of land which a local lord might lease to private persons (such as farmers). Given that a string of such parcels existed around Woensel, the name \"Eindhoven\" may have originated with the meaning \"last hoves on the land of Woensel\".\nAnother explanation is that \"Eind\" is derived from \"Gender\", a river that goes through the city.\nHistory.\n13th\u201315th centuries.\nThe written history of Eindhoven started in 1232, when Duke Hendrik I of Brabant granted city rights to \"Eindhoven\", then a small town right on the confluence of the Dommel and Gender streams. At the time of granting of its charter, Eindhoven had approximately 170 houses enclosed by a rampart. Just outside the city walls stood a small castle. The city was also granted the right to organize a weekly market and the farmers in nearby villages were obliged to come to Eindhoven to sell their produce. Another factor in its establishment was its location on the trade route from Holland to Li\u00e8ge.\nAround 1388, the city's fortifications were strengthened further. And between 1413 and 1420, a new castle was built within the city walls. In 1486, Eindhoven was plundered and burned by troops from Guelders.\n16th\u201318th centuries.\nThe reconstruction of Eindhoven was finished in 1502, with a stronger rampart and a new castle. However, in 1543 it fell again, its defense works having been neglected due to poverty.\nA big fire in 1554 destroyed 75% of the houses but by 1560 these had been rebuilt with the help of William I of Orange. During the Dutch Revolt, Eindhoven changed hands between the Dutch and the Spanish several times during which it was burned down by renegade Spanish soldiers, until finally in 1583 it was captured once more by Spanish troops and its city walls were demolished.\nEindhoven did not become part of the Netherlands until 1629. During the French occupation, Eindhoven suffered again with many of its houses destroyed by the invading forces. Eindhoven remained a minor city after that until the start of the Industrial Revolution.\n19th century.\nThe Industrial Revolution of the 19th century provided a major growth impulse. Canals, roads and railroads were constructed. Eindhoven was connected to the major Zuid-Willemsvaart canal through the Eindhovens Kanaal branch in 1843 and was connected by rail to Tilburg, 's-Hertogenbosch, Venlo and Belgium between 1866 and 1870. Industrial activities initially centred around tobacco and textiles and boomed with the rise of lighting and electronics giant Philips, which was founded as a light bulb manufacturing company in Eindhoven in 1891.\nIndustrialisation brought population growth to Eindhoven. On the establishment of the Kingdom of the Netherlands in 1815, Eindhoven had 2,310 inhabitants.\n20th century.\nBy 1920, the population was 47,946; by 1925 it was 63,870 and in 1935 that had ballooned to 103,030. The explosive growth of industry in the region and the subsequent housing needs of workers called for radical changes in administration, as the City of Eindhoven was still confined to its medieval moat city limits. In 1920, the five neighbouring municipalities of Woensel (to the north), Tongelre (northeast and east), Stratum (southeast), Gestel en Blaarthem (southwest) and Strijp (west), which already bore the brunt of the housing needs and related problems, were incorporated into the new Groot-Eindhoven (\"Greater Eindhoven\") municipality. The prefix \"Groot-\" was later dropped.\nAfter the incorporation of 1920, the five former municipalities became districts of the Municipality of Eindhoven, with Eindhoven-Centrum (the City proper) forming the sixth. Since then, an additional seventh district has been formed by dividing the largest district, that of Woensel, into Woensel-Zuid and Woensel-Noord.\nThe early 20th century saw additions in technical industry with the advent of car and truck manufacturing company Van Doorne's Automobiel Fabriek (DAF) and the subsequent shift towards electronics and engineering, with the traditional tobacco and textile industries waning and finally disappearing in the 1970s.\nA first air raid in World War II was flown by the RAF on 6 December 1942 targeting the Philips factory downtown, in which 148 civilians died, even though the attack was carried out on a Sunday by low-flying Mosquito bombers. Large-scale air raids, including the bombing by the Luftwaffe on 18 September 1944 during Operation Market Garden, destroyed large parts of the city. The reconstruction that followed left very little historical remains and the postwar reconstruction period saw drastic renovation plans in highrise style, some of which were implemented. At the time, there was little regard for historical heritage. During the 1960s, a new city hall was built and its Neo-gothic predecessor (1867) demolished to make way for a planned arterial road that never materialised.\nThe 1970s, 1980s, and 1990s saw large-scale housing developments in the districts of Woensel-Zuid and Woensel-Noord, making Eindhoven the fifth-largest city in the Netherlands. At the start of the 21st century, a whole new housing development called Meerhoven was constructed at the site of the old airport of Welschap, west of Eindhoven. The airport itself, now called Eindhoven Airport, had moved earlier to a new location, paving the way for much needed new houses. Meerhoven is part of the Strijp district and partially lies on lands annexed from the municipality of Veldhoven.\nGeography.\nThe villages and city that make up modern Eindhoven were originally built on sandy elevations between the Dommel, Gender and Tongelreep rivers. Beginning in the 19th century, the basins of the rivers themselves have also been used as housing land, resulting in occasional flooding in the city centre. Partly to reduce flooding, the bed of the Gender stream, which flowed directly through the city centre, was dammed off and filled up after the War, and the course of the Dommel was regulated. New ecological and socio-historical insights have led to parts of the Dommel's course being restored to their original states, and plans to have the Gender flow through the centre once again.\nThe large-scale housing developments of the 20th century saw residential areas being built on former agricultural lands and woods, former heaths that had been turned into cultivable lands in the 19th century.\nThe city is currently divided into seven districts:\nClimate.\nEindhoven has an oceanic climate with slightly warmer summers and colder winters than the coastal parts of the Netherlands. Its all-time record is set on 25 July 2019 and set on 13 January 1968, while winter lows have dipped below during extreme cold snaps. Although frosts are frequent in winter, there is no lasting snow cover in a normal winter due to the mild daytime temperatures.\nDemographics.\nPopulation.\nAs of 2020, the population of Eindhoven consisted of 355,889 people (according to Worldpopulationreview). Of these, 29.5% or some 63,873 people are of foreign descent. People are classified as being of foreign descent when they were born outside of the Netherlands, or when at least one of their parents was born outside of the Netherlands.\nThe municipal agglomeration of Eindhoven (an administrative construct which includes only some of the surrounding towns and villages) has 327,245 inhabitants as of 1 January 2010.\nThe spoken language is a combination of Kempenlands (a Dutch dialect spoken in a large area east and south east of the city, including Arendonk and Lommel in Belgium) and North Meierijs (between the south of Den Bosch and into Eindhoven). Both dialects belong to the East Brabantian dialect group), which is very similar to colloquial Dutch).\nDistricts.\nOf all Eindhoven districts, the historical centre is by far the smallest in size and population, numbering only 5,419 in 2006. Woensel-Noord is the largest, having been the city's main area of expansion for several decades.\nPopulation figures for all districts, as of 1 January 2008, ranked by size:\nReligion.\nEindhoven is located in the southeast of the province of North Brabant. This area is historically Catholic and the population of Eindhoven was similarly mostly Catholic for a very long time until the late 1970s. However, the internationalizing influence of the university, Philips and other companies have created a more mixed population over the last few decades.\nThe spiritual needs of the Eindhoven population are tended to by a steadily shrinking number of churches, two mosques and one synagogue.\nCrime.\nIn research by the Dutch newspaper Algemeen Dagblad based on the police's statistical data on crime rates, Eindhoven was found to have the highest crime rate in the Netherlands for 2006, 2007, 2009, and 2010. In 2011, Eindhoven has slipped down the list to number six.\nIn 2009, in the Eindhoven agglomeration, the following numbers of crimes were recorded:\nEconomy.\nEindhoven has grown from a little town in 1232 to one of the biggest cities in the Netherlands with around 230,000 inhabitants in 2020. Much of its growth is due to Philips, DAF Trucks and Brabantia.\nAfter the resurrection of the Netherlands in 1815 and the end of the Belgian Revolution, Eindhoven was a small village of some 1250 people in an economically backward and mostly agricultural area. Cheap land, cheap labor and the existence of pre-industrial homesourcing (\"huisnijverheid\" in Dutch) made Eindhoven an attractive area for the developing industries which were being stimulated by the government of King William I. During the 19th century, Eindhoven grew into an industrial town with factories for textile weaving, cigar manufacturing, match making and hat making. Most of these industries disappeared again after World War II, though.\nIn 1891, brothers Gerard and Anton Philips founded the small light bulb factory that would grow into one of the largest electronics firms in the world. Philips' presence is probably the largest single contributing factor to the major growth of Eindhoven in the 20th century. It attracted and spun off many hi-tech companies, making Eindhoven a major technology and industrial hub. In 2005, a full third of the total amount of money spent on research in the Netherlands was spent in or around Eindhoven. A quarter of the jobs in the region are in technology and ICT, with companies such as FEI Company (once Philips Electron Optics), NXP Semiconductors (formerly Philips Semiconductors), ASML, ALTEN, Simac, Neways Electronics and the aforementioned Philips and DAF.\nEindhoven has long been a centre of cooperation between research institutes and industry. This tradition started with Philips (the NatLab was a physical expression of this) and has since expanded to large cooperative networks. The Eindhoven University of Technology hosts an incubator for technology startups and the NatLab has developed into the High Tech Campus Eindhoven. Also, TNO has opened a branch on the university campus. This tradition has also fostered inter-industry cooperation in the region; one example of this is the announcement in September 2010 of a new research lab for high-grade packaging materials, a cooperation of IPS Packaging and Thales Cryognetics.\nThis cooperative tradition has also developed into a different direction than the traditional technology research done at the university. Starting in 2002, the university, the Catharina hospital, Philips Medical and the University of Maastricht joined forces and started joint research into biomedical science, technology and engineering. Within Eindhoven, this research has been concentrated in a new university faculty (BioMedical Technology or BMT). This development has also made Eindhoven a biomedical technology hub within the country and its (European) region.\nPrime examples of industrial heritage in Eindhoven are the renovated Witte Dame (\"White Lady\") complex, a former Philips lamp factory; and the Admirant building (informally known as Bruine Heer or \"Brown Gentleman\" in reference to the Witte Dame across the street), the former Philips main offices. The Witte Dame currently houses the municipal library, the Design Academy and a selection of shops. The Admirant has been renovated into an Office building for small companies. Across the street from the Witte Dame and next to the Admirant is Philips' first light bulb factory (nicknamed Roze Baby, or \"Pink Baby\", in reference to its pink colour and much smaller size when compared to the \"White Lady\" and \"Brown Gentleman\"). The small building now houses the \"Centrum Kunstlicht in de Kunst\" (centre artificial light in art) and the \"Philips Incandescent Lamp Factory of 1891\" museum.\nKnowledge economy initiatives.\nDue to its high-tech environment, Eindhoven is part of several initiatives to develop, foster and increase a knowledge economy. Chief among these are:\nAs a result of these efforts, the Intelligent Community Forum named the Eindhoven metro region the No. 21 intelligent community in 2008 and the No. 7 intelligent community in 2009 and 2010. In 2011, the ICF named Eindhoven the Intelligent Community of the Year.\nEIT Co-location.\nEindhoven is one of the co-location centres of the European Institute of Innovation and Technology (EIT). It hosts two Knowledge and Innovation Communities (KICs): Innoenergy (Sustainable Energy) and EIT ICT Labs (Information and Communication Technology). The co-locations are on the High Tech Campus Eindhoven.\nEducation.\nEindhoven, being a city with a 200,000+ population, is served by a large number of schools both at primary and secondary education levels. In addition, Eindhoven is a higher-education hub within the southern Netherlands, with several institutes of higher education that serve students from the extended region of North Brabant, Zeeland, Limburg and parts of the surrounding provinces.\nPrimary education.\nPrimary education is provided to the children aged 4 to 12 in Eindhoven through a large number of primary schools:\nSecondary education.\nSecondary education is provided to the children aged 12 to 18 in Eindhoven through several highschools:\nSpecial needs secondary education:\nHigher and adult education.\nEindhoven hosts four different public institutions for higher and adult education, as well as a number of private institutions offering courses and trainings. The public institutions hosted in Eindhoven are:\nThe Open University also has a study center in Eindhoven.\nAmong the private institutions is the Centrum voor Kunsten Eindhoven, which offers art-related courses to adults (including a DJ-education).\nPolitics.\nMunicipal council.\nThe municipal council is the legislative council at the municipal level in Eindhoven; its existence is mandated by the Constitution of the Netherlands. The Eindhoven city council consists of 45 elected representatives from the Eindhoven municipality. These are elected during municipal elections from candidates running in Eindhoven. Eindhoven politics consists of local branches of the national political parties and purely local parties with strictly local interests. The city council reflects this mix in its makeup.\nThe last three municipal elections were held on 7 March 2006, 3 March 2010 and 19 March 2014. The division of the 45 seats in the Eindhoven city council after these elections is shown below:\nMunicipal executive-.\nAldermen.\nThe executive council in Dutch municipalities is called the \"College of the Mayor and Aldermen\" (Dutch: \"College van Burgemeester en Wethouders\" or \"College van B&amp;W\" for short). The mayor is appointed by the monarch, but the council of aldermen is composed as a result of the formation of a local coalition government. This coalition is formed in such a way as to be able to rely on a majority of the votes in the city council.\nIn May 2014, a coalition was formed between PvdA, D66, SP and GroenLinks. Together they have 26 seats in the city council. The council of aldermen consists of the following people:\nMayor.\nThe mayors of the Netherlands are not elected but appointed by the crown. Nevertheless, there has been a movement over the last few years to give the municipalities more say in who will be their mayor, which has resulted in consultative referenda being held in the larger cities to \"suggest\" a candidate for the post. This was also tried in Eindhoven and as a result the previous mayor was Rob van Gijzel (PvdA).\nOn 23 January 2008, a referendum to elect a mayor was held in Eindhoven. This referendum, the second of its kind in the Netherlands, was attended by 24.6% of the inhabitants. This was less than the required 30% needed to make a referendum binding. Nevertheless, the city council would choose the winner of the referendum as the preferred candidate. The main reason for the low attendance was that the candidates, Leen Verbeek and Rob van Gijzel, were from the same party. Rob van Gijzel won the referendum with 61.8% of the votes and was appointed the city's new mayor.\nThe mayor is the chairman of the Council of B&amp;W. He also has responsibility for a number of specific posts (like the aldermen). In the previous council, mayor Van Gijzel held responsibility for the following posts:\nIf unavailable, the mayor is temporarily replaced by one of the aldermen.\nCulture and recreation.\nCulturally and recreationally, Eindhoven was formed by two forces:\nEindhoven is also known as the City of Light, due to Philips originating from there and because of several projects involving lighting up buildings of the city. During Carnival, Eindhoven is rechristened \"Lampegat\" (Hamlet of Lamps, although for the ironic purposes of carnival the translation \"Hole in the ground with lamps\" is closer to the mark); this refers again to the important role of Philips in the Eindhoven community.\nCultural institutions.\nThere are several cultural institutions in and around the city.\nMuseums.\nEindhoven was home to the Evoluon science museum, sponsored by Philips. The Evoluon building has evolved into a conference centre.\nOpen-air art.\nThe Eindhoven public space contains many forms of artistic expression (a book published by the Eindhoven tourist board records 550 as of 2001 and more have been added since), with high \"concentrations\" of them in the parks. The Stadswandelpark for instance, contains over 30 works of modern art. There are also several other works of art on permanent display throughout the city, such as \"Flying Pins\" (by Claes Oldenburg and Coosje van Bruggen, who considered the location on the southern stretch of the John F. Kennedylaan to be like a bowling alley) and \"Swing\" (a construct on the Karel de Grotelaan, which morphs into different geometric shapes as you move around it). There are also a number of statues of famous city inhabitants, such as Jan van Hooff (by Auke Hettema, 1992) and Frits Philips (by Kees Verkade) on the Market Square. There is a statue of Anton Philips in front of the central railway station.\nEindhoven is also, to some degree, open to forms of impromptu and alternative art. For example, the Berenkuil is a freezone for graffiti artists in the city.\nLight art.\nStrijp-S is a place for experimentation with LED lighting, which keeps the historic connection with Philips' past. Some light art includes the project Fakkel by Har Hollands. In the underground passage to NatLab artist Daan Roosegaarde installed his project Crystal.\nStrijp-S is a regular location for the light festival GLOW.\nMusic and theatre.\nThe Effenaar is a popular music venue and cultural center in Eindhoven, and is located at the Dommelstraat.\nIn 1992, the Muziekcentrum Frits Philips was opened as a stage for classical and popular music in Eindhoven, reviewed by critics as a concert hall with acoustics that rival the best halls in Europe. Before that, Philips sponsored the POC.\nParktheater Eindhoven is Eindhoven's stage for opera, cabaret, ballet etc. Opened in 1964, it has received over 250,000 visitors every year. With its 1,000 m2 it has one of the largest stages in the Netherlands. With a major renovation ending in 2007, the new Parktheater will receive an estimated 300,000 visitors a year.\nEindhoven's Plaza Futura is now a cinema featuring cultural movies, lectures and special cultural events.\nEspecially for students, Studium Generale Eindhoven organizes \"socially, culturally and intellectually formative events\". From within the student body, two Tunas provide entertainment from time to time at university and city events: Tuna Ciudad de Luz (\"Tuna of the City of Light\") and the ladies tuna La Tuni\u00f1a.\nThe general music and theatre scene in Eindhoven (in the broadest sense) is supported by a foundation called PopEi. The purpose of this foundation is to support artistic groups with facilities, especially rehearsal stages and areas (housed in the old Philips location of Strijp-S) but also storage facilities. PopEi also provides a working environment for groups (through cafeteria facilities in Strijp-S, so groups can have real working days) and provides some logistical support for organizing events.\nRecreation.\nEindhoven has a lively recreational scene. For going out, there are numerous bars on the Market square, Stratumseind (Stratum's End) which is the largest pub-street in the Netherlands, Dommelstraat, Wilhelmina square and throughout the rest of the city. In addition to the more culturally oriented Plaza Futura, there are three cinemas in the centre of town (\"Servicebioscoop Zien\", \"Vue\" and Path\u00e9 Eindhoven, which offers THX sound, IMAX screens and 3D movie viewing).\nEindhoven also hosts a large number of cultural and entertainment-oriented festivals. The biggest festivals in Eindhoven are:\nParks.\nEindhoven contains several parks and a lot of open, green space. Of the five largest cities in the Netherlands, it has the highest percentage of green area (encompassing about \u2153 of all public space). It is also the greenest of the five largest cities in North Brabant. The green area per house is about .\nSome of the major parks in Eindhoven are the Stadswandelpark, Genneper Parken, the Philips van Lenneppark, Philips de Jongh Wandelpark and the Henri Dunantpark. There is also a green area surrounding the Karpendonkse Plas (a water area). The combination of park area, water and general atmosphere got the Ooievaarsnest neighborhood elected the \"Best large-city neighborhood of the Netherlands\" by the NRC Handelsblad in 1997.\nAdult-orientated entertainment.\nThe centre of town features two casinos (one branch of Holland Casino and the independent Casino4Events). At the A67 a Jack's casino is located.\nThere is a red light district on the Baekelandplein, as well as four brothels throughout the city. There is also a blue movie theater.\nStrijp-S.\nThe old Philips factory complex has been transformed into a multi-purpose cultural and residential complex called Strijp-S. This includes conference and event space, space for concerts and events, art of lighting, space for sports such as BMX, bouldering, and more, a walking promenade, etc.\nMedia.\nEindhoven features several print media. The local newspaper, called the Eindhovens Dagblad, is a daily newspaper with over 110,000 subscribers in the Samenwerkingsverband Regio Eindhoven region. It has a national and international section, as well as a section dedicated to regional news; the editorial department is located in Eindhoven.\nIn addition to the newspaper, Eindhoven is served by a number of weekly door-to-door publications. Chief among these is \"Groot Eindhoven\" (which carries publications of the city council, as well as other articles and advertisements). Other than that there are \"de Trompetter\", \"d\u00e9 Weekendkrant\" and the \"ZondagsNieuws\". The first two are delivered midweek, the last two are weekend publications.\nThere are several regional and municipal radio stations. The local radio station is Studio040, whereas Omroep Brabant and RoyaalFM provide regional radio.\nLocal television is provided by Studio040. Omroep Brabant broadcasts regionally from its television studio in Son.\nInternet, television and telephone connectivity is available via cable television, optic fiber and ADSL.\nTransport.\nEindhoven Airport is the closest airport, located approximately from the town centre. The airport serves as a military air base and a civilian commercial airport. Eindhoven Airport is the second-busiest in the Netherlands (after Schiphol).\nRyanair serves London Stansted Airport, Dublin, Kyiv, Rome, Milan, Pisa, Bordeaux, Marseille, Glasgow, Madrid, Valencia, Stockholm, Kaunas, Malta, Sofia and Barcelona. Wizz air serves Belgrade, Brno, Bucharest-Baneasa, Budapest, Cluj-Napoca, Debrecen, Gda\u0144sk, Katowice, Prague, Riga, Sofia, Timi\u0219oara, Vilnius, Wroc\u0142aw. In the summer season, Reykjav\u00edk is served with 2 weekly flights operated by Iceland Express. Transavia services Alicante, Antalya, Bodrum, Corfu, Dalaman, Faro, Gran Canaria, Innsbruck, M\u00e1laga, Majorca, Munich, Prague, Rhodes and Salzburg, though some destinations are served only seasonally. Eindhoven Airport served more than 6.2\u00a0million passengers in 2018.\nEindhoven is a rail transport hub. Eindhoven Centraal railway station is the main station in Eindhoven. It has connections in the directions of:\nEindhoven Centraal is served by both intercity and local services while the smaller station, Eindhoven Strijp-S is only served by local trains. Towards 's-Hertogenbosch, Utrecht and Amsterdam trains run every ten minutes, on every day of the week. Eindhoven Stadion is a small station that serves Philips Stadion in the event of football matches or other special events at the stadium. It is located 900m west of the main station.\nUp until World War II, a train service connected Amsterdam to Li\u00e8ge via Eindhoven and Valkenswaard, but the service was discontinued and the line broken up. Recently, talks have resumed to have a service to Neerpelt, Belgium via Weert.\nThe A2/E25 motorway from Amsterdam to Luxembourg passes Eindhoven to the west and south of the city. The A2 connects to the highway A58 to Tilburg and Breda just north of the city. Just south of Eindhoven, the A2 connects to the A67 / E34 between Antwerp and Duisburg. In 2006, the A50 was completed connecting Eindhoven to Nijmegen and Zwolle.\nThe public transport of Eindhoven consists of more than 20 city bus lines, which also serve neighbouring villages such as Veldhoven, Geldrop and Nuenen. Seven of these buslines (400\u2013407) are marketed as high quality public transport and run with 43 electric articulated busses. Two specially built separated busways (HOV1 &amp; HOV2) are used by lines 401 to 406. Line 401 to the airport runs almost completely on separated busways. Apart from the city lines there are some 30 regional and rush-hour lines.\nLike all large Dutch cities, Eindhoven has an extensive network of bicycle paths. Since 2012, the Eindhoven bicycle path network has incorporated the Hovenring.\nMedical care.\nEindhoven has two hospitals in three locations: the Catharina Hospital and the M\u00e1xima Medisch Centrum, which has a branch in Woensel-Zuid (the old Diaconessenhuis) and one in Veldhoven (the old Sint Joseph Hospital). These three have an extensive cooperation and have divided specialties among each other. Emergency medicine, for example, is concentrated in the MMC Veldhoven branch and the Catharina Hospital, the MMC Eindhoven branch has no emergency department. Cardiac procedures are done in the Catharina.\nCatharina is also an academic and research hospital and participates in a shared research program with Philips Medical, the Eindhoven University of Technology and the Maastricht University into biomedical science, technology and engineering.\nTwin towns \u2013 sister cities.\nEindhoven is twinned with:"}
{"id": "9421", "revid": "47947", "url": "https://en.wikipedia.org/wiki?curid=9421", "title": "Helsing\u00f8r", "text": "Helsing\u00f8r ( , ; ), classically known in English as Elsinore , is a city in eastern Denmark. Helsing\u00f8r Municipality had a population of 62,686 on 1 January 2018. Helsing\u00f8r and Helsingborg in Sweden together form the northern reaches of the \u00d8resund Region, centered on Copenhagen and Malm\u00f6. The HH Ferry route connects Helsing\u00f8r with Helsingborg, 4\u00a0km (2 miles) across the \u00d8resund.\nIt is known for its castle Kronborg, which William Shakespeare presumably had in mind for his famous play \"Hamlet.\"\nHistory.\nThe name \"Helsing\u00f8r\" is derived from the word \"hals\" meaning \"neck\" or \"narrow strait\", referring to the narrowest point of the \n\"\u00d8resund\" (\u00d8re Sound) between what is now Helsing\u00f8r and Helsingborg, Sweden. \nThe people were mentioned as \"Helsinger\" (which may mean \"the people of the strait\") for the first time in King Valdemar the Victorious's \"Liber Census Dani\u00e6\" from 1231 (not to be confused with the Helsings of H\u00e4lsingland in Sweden). \nPlacenames show that the Helsinger may have had their main fort at Helsingborg and a fortified landing place at Helsing\u00f8r, to control the ferry route across the strait.\nHelsing\u00f8r as it is known today was founded in the 1420s by the Danish king Eric of Pomerania. He established the Sound Dues in 1429, meaning all foreign ships passing through the strait had to pay a toll, which constituted up to two-thirds of Denmark's state income. With this income Eric of Pomerania built the castle Krogen. The castle was expanded in the 1580s and renamed Kronborg. All ships had to stop in Helsing\u00f8r to get their cargo taxed and pay a toll to the Danish Crown, but it also generated a significant trade for the town. In 1672 Helsing\u00f8r had grown into the third biggest town in Denmark. \nJohan Isaksson Pontanus (\"Rerum Danicarum Historica\", 1631) attributes a long and partially fictitious history to Helsing\u00f8r.\nThe Sound Dues were abolished in 1857 with the Copenhagen Convention, where all naval nations agreed to pay a one-time fee.\nThe oldest known fortified building of Helsing\u00f8r is \"Flynderborg\", an early medieval fortress situated on a hill just south of the medieval city.\nAround 1200, the first church, Saint Olaf's Church, was built. \nA number of convents once surrounded the church, but now all that remains is the church building, today the cathedral of the Diocese of Helsing\u00f8r. The oldest parts of the cathedral of Helsing\u00f8r date back to the 13th century and tell us that the fishing village, as Helsing\u00f8r was then, had grown to a town of importance.\nIn World War II, Helsing\u00f8r was among the most important transport points for the rescue of Denmark's Jewish population during the Holocaust. Adolf Hitler had ordered that all Danish Jews were to be arrested and deported to the concentration camps on Rosh HaShanah, the Jewish New Year which fell on 2 October 1943. When Georg Ferdinand Duckwitz, a diplomatic attach\u00e9 of Nazi Germany to Denmark, received word of the order on 28 September 1943, he shared it with political and Jewish community leaders. Using the name Elsinore Sewing Club (Danish: \"Helsing\u00f8r Syklub\") as a cover for messages, the Danish population formed an underground railroad of sorts, moving Jews away from the closely watched Copenhagen docks to spots further away, especially Helsing\u00f8r, just two miles across the \u00d8resund from Helsingborg in neutral Sweden. Hundreds of civilians hid their fellow Danish citizens\u2014Jews\u2014in their houses, farm lofts and churches until they could board them onto Danish fishing boats, personal pleasure boats and ferry boats. Over the course of three nights, Danes had smuggled over 7,200 Jews and 680 non-Jews (gentile family members of Jews or political activists) across the \u00d8resund, to safety in Helsingborg and Malm\u00f6 in Sweden.\nTransport.\nThe car ferry line between Helsing\u00f8r and Helsingborg, Scania, Sweden is the busiest in the world with more than 70 departures in each direction every day. The route is known as the HH Ferry route and has been sailed by several shipping lines throughout history. The car ferry terminal is connected to the town's main railway station. From the station, trains depart to Copenhagen every 20 minutes. Trains also depart to Hiller\u00f8d and Gilleleje. There are another six stations or train stops within the city and connected suburbs. Apart from \"Helsing\u00f8r Station and Ferry Terminal\" also \"Snekkersten station\", \"Esperg\u00e6rde station\", \"Mordrup station\" and the train stops at the line to Gilleleje, \"Gr\u00f8nnehave\", \"Marienlyst\" and \"H\u00f8jstrup\".\nThe E47 motorway towards Copenhagen begins just outside the city limits. The town and surrounding areas also have a network of local and regional buses.\nIndustrialisation.\nFor a century the or Elsinore shipyard was a prominent landmark, which covered the whole area between the town and Kronborg Castle. It was founded in 1882. At its height in 1957, it had 3,600 employees. The last ship left the shipyard in 1983 and it closed the same year following substantial losses.\nThe brewery, founded in 1840, was the second brewery in Denmark to ship bottled beer, just three years after Carlsberg. The last beer was brewed at in Helsing\u00f8r in 1998. Carlsberg continues to brew beer under the Wiibroe \u00c5rgangs\u00f8l label.\nPost-industrialisation.\nAfter the end of the industrial era, the town of Helsing\u00f8r had to redefine itself, and came up with an ambitious project: Kulturhavn Kronborg, literally \"Culture-harbour of Kronborg\". It officially opened on 26 May 2013, intended to appeal to tourists with an interest in culture. The main attraction of Kulturhavn Kronborg is Kronborg Castle, a UNESCO World Heritage Site. Besides the historical attractions of the site, William Shakespeare's play \"Hamlet\" has been performed annually in its courtyard since 1937. There is a longstanding tradition of performing the play in English, and notable actors in the title role have included Laurence Olivier, John Gielgud, Christopher Plummer, Derek Jacobi, and in 2009 Jude Law. At the heart of Kulturhavn Kronborg lies kulturv\u00e6rftet or The Culture Yard, a new cultural centre and a public library located in the old . It opened in 2010. The former dry dock now houses the Danish Maritime Museum.\nIn the centre of the harbour basin stands the polished steel sculpture \"Han\" (\"He\") by artist duo Elmgreen and Dragset, commissioned by the City of Helsing\u00f8r in 2012. It was inaugurated by then Minister of culture, Uffe Elb\u00e6k, in June 2012. It is seen as the counterpart (and even little brother) to Edvard Eriksen's world-famous \"The Little Mermaid\" statue in Copenhagen, and has caused both praise and protests among locals.\nThe Swedish city of Helsingborg lies a short distance across the \u00d8resund from Helsing\u00f8r, approximately . European route E55 joins the two cities; ferries connect the two sides.\nMusic.\nDieterich Buxtehude organist and composer of the Baroque period. \nHe was born Diderich Buxtehude presumably in Helsingborg, he serving as organist from 1660 to 1668 in Helsing\u00f8r as his father that held the position as organist at St. Olaf's cathedral.\nDiderich Buxtehude compositions and style became of significant influence, among others on his student Johann Sebastian Bach.\nArchitecture.\nThe new Danish Maritime Museum was designed by Danish prize-winning architects Bjarke Ingels Group (BIG).\nJ\u00f8rn Utzon lived in Helsing\u00f8r in his youth because his father was an engineer at . Utzon designed The Kingo Houses (1956\u201360) and The Hammersh\u00f8j Care Centre (1962) in the city. The project was completed by Birger Schmidt (1966) after Utzon moved to Sydney to work on the Sydney Opera House.\nDistricts.\nCentrum\nTwin towns \u2013 sister cities.\nHelsing\u00f8r practices twinning on the municipal level. For the twin towns, see twin towns of Helsing\u00f8r Municipality."}
{"id": "9422", "revid": "1416331", "url": "https://en.wikipedia.org/wiki?curid=9422", "title": "European route E4", "text": "European route E4 passes from north to south through Sweden from the border with Finland, with a total length of . The Finnish part lies entirely within Tornio in northern Finland, and is only long. The Swedish part traverses most of Sweden except the extreme north and the west coast region, and is commonly considered the highway backbone of Sweden, since it passes in the vicinity of many of its largest cities and through the capital Stockholm. In particular, it is the mainline road used by most vehicle traffic, both cars and lorries, between the north (Norrland) and south of Sweden or beyond.\nFrom Haparanda on the Finnish border, it stretches south along the Gulf of Bothnia to G\u00e4vle, then on a more inland route southwards. It ends in Helsingborg in Sweden, at the port for the ferry to Helsing\u00f8r in Denmark. The route intersects with European route E6 just outside Helsingborg, which continues to Trelleborg on the southern coast of Sweden.\nHistory and naming.\nUnder the new system of European routes it was planned to have been a part of E55, but it remains in the pre-1992 designation (E4) within Sweden, because the expenses connected with re-signing this long road portion would be too great. Besides the signs along the road, there are thousands of signs, especially in cities, showing how to reach the E4 road. The road is now fully authorised as E4 by the relevant authority, not as E55.\nRoute.\nNorth of G\u00e4vle the road is of mixed standard. Depending on the fashion at the time of construction it is either a single standard carriageway road, usually wide, or a 2+1 road, a wide road with two lanes in one direction and one in the other with a steel wire barrier in between, or sometimes a motorway with two lanes in each direction. North of Sundsvall, the road passes through several of the larger cities as city streets. \nSouth of G\u00e4vle, the road becomes an almost continuous motorway, with the only non-motorway part being a long section past Ljungby, currently a 2+1 limited-access road. Upgrade to motorway standard will start in 2018. With the exception of the Ljungby bypass, the final stretch of the motorway to be opened was the road between Uppsala and Mehedeby, which was inaugurated on 17 October 2007. South of G\u00e4vle, the speed limit is on 60% and on 30% of the road. North of G\u00e4vle there are varying speed limits, with , and as the most common. The speed limits on the main roads in Sweden were changed on many stretches in October 2008, which saw the introduction of the 120\u00a0km/h limit.\nThe E4 is the fastest road to go from Germany/Denmark to areas north of the Arctic Circle, including places in Norway such as Troms\u00f8 or the North Cape.\nThe route passes through or nearby the cities\nTornio,\nHaparanda,\nLule\u00e5,\nPite\u00e5,\nSkellefte\u00e5,\nUme\u00e5,\n\u00d6rnsk\u00f6ldsvik,\nH\u00e4rn\u00f6sand,\nSundsvall,\nHudiksvall,\nS\u00f6derhamn,\nG\u00e4vle,\nUppsala,\nStockholm,\nS\u00f6dert\u00e4lje,\nNyk\u00f6ping,\nNorrk\u00f6ping,\nLink\u00f6ping,\nJ\u00f6nk\u00f6ping,\nV\u00e4rnamo,\nLjungby,\nand Helsingborg."}
{"id": "9424", "revid": "31976439", "url": "https://en.wikipedia.org/wiki?curid=9424", "title": "Ericsson", "text": " (lit. \"Telephone Stock Company of LM Ericsson\"), commonly known as Ericsson, is a Swedish multinational networking and telecommunications company headquartered in Stockholm. \nThe company offers services, software and infrastructure in information and communications technology for telecommunications operators, traditional telecommunications and Internet Protocol (IP) networking equipment, mobile and fixed broadband, operations and business support services, cable television, IPTV, video systems, and an extensive services operation.\nEricsson had a 27% market share in the 2G/3G/4G mobile network infrastructure market in 2018, thus being the largest such non-Chinese company.\nThe company was founded in 1876 by Lars Magnus Ericsson and was taken over by the Wallenberg family in 1960; today, the family, through its holding company Investor AB, owns a controlling 22.53% voting power. it is headquartered in Stockholm, Sweden. The company employs around 95,000 people and operates in around 180 countries. Ericsson holds over 49,000 granted patents as of September 2019, including many in wireless communications. Ericsson is the inventor of Bluetooth technology. Ericsson leads the implementation of 5G worldwide, partly through the use of massive MIMO technology.\nHistory.\nFoundation.\nLars Magnus Ericsson began his association with telephones in his youth as an instrument maker. He worked for a firm that made telegraph equipment for the Swedish government agency Telegrafverket. In 1876, at the age of 30, he started a telegraph repair shop with help from his friend Carl Johan Andersson in central Stockholm and repaired foreign-made telephones. In 1878 Ericsson began making and selling his own telephone equipment. His telephones were not technically innovative. In 1878 he made an agreement to supply telephones and switchboards to Sweden's first telecommunications operating company, Stockholms Allm\u00e4nna Telefonaktiebolag.\nInternational expansion.\nAs production grew in the late 1890s, and the Swedish market seemed to be reaching saturation, Ericsson expanded into foreign markets through a number of agents. The UK (Ericsson Telephones Ltd.) and Russia were early markets, where factories were later established improve the chances of gaining local contracts and to augment the output of the Swedish factory. In the UK, the National Telephone Company was a major customer; by 1897 sold 28% of its output in the UK. The Nordic countries were also Ericsson customers; they were encouraged by the growth of telephone services in Sweden.\nOther countries and colonies were exposed to Ericsson products through the influence of their parent countries. These included Australia and New Zealand, which by the late 1890s were Ericsson's largest non-European markets. Mass production techniques now firmly established; telephones were losing some of their ornate finish and decoration.\nDespite their successes elsewhere, Ericsson did not make significant sales into the United States. The Bell Group, Kellogg and Automatic Electric dominated the market. Ericsson eventually sold its U.S. assets. Sales in Mexico led to inroads into South American countries. South Africa and China were also generating significant sales. With his company now multinational, Lars Ericsson stepped down from the company in 1901.\nAutomatic equipment.\nEricsson ignored the growth of automatic telephony in the United States and concentrated on manual exchange designs. Their first dial telephone was produced in 1921, although sales of the early automatic switching systems were slow until the equipment had proven itself on the world's markets. Telephones of this period had a simpler design and finish, and many of the early automatic desk telephones in Ericsson's catalogues were magneto styles with a dial on the front and appropriate changes to the electronics. Elaborate decals decorated the cases. World War I, the subsequent Great Depression, and the loss of its Russian assets after the Revolution slowed the company's development while sales to other countries fell by about half.\nShareholding changes.\nThe acquisition of other telecommunications companies put pressure on Ericsson's finances; in 1925, Karl Fredric Wincrantz took control of the company by acquiring most of the shares. Wincrantz was partly funded by Ivar Kreuger, an international financier. The company was renamed \"Telefonaktiebolaget L M Ericsson\". Kreuger started showing interest in the company, being a major owner of Wincrantz holding companies.\nWallenberg era begins.\nEricsson was saved from bankruptcy and closure with the help of banks including Stockholms Enskilda Bank (now Skandinaviska Enskilda Banken) and other Swedish investment banks controlled by the Wallenberg family, and some Swedish government backing. Marcus Wallenberg Jr. negotiated a deal with several Swedish banks to rebuild Ericsson financially. The banks gradually increased their possession of LM Ericsson \"A\" shares, while ITT was still the largest shareholder. In 1960, the Wallenberg family bought ITT\u2018s shares in Ericsson, and has since controlled the company.\nMarket development.\nIn the 1920s and 1930s, the world telephone markets were being organized and stabilized by many governments. The fragmented town-by-town systems serviced by small, private companies that had evolved were integrated and offered for lease to a single company. Ericsson obtained some leases, which represented further sales of equipment to the growing networks. Ericsson got almost one-third of its sales under the control of its telephone operating companies.\nFurther development.\nEricsson introduced the world's first fully automatic mobile telephone system, MTA, in 1956. It released one of the world's first hands-free speaker telephones in the 1960s. In 1954, it released the Ericofon. Ericsson crossbar switching equipment was used in telephone administrations in many countries. In 1983 the company introduced the ERIPAX suite of network products and services.\nEmergence of the Internet (1995\u20132003).\nIn the 1990s, during the emergence of the Internet, Ericsson was regarded as slow to realize its potential and falling behind in the area of IP technology. But the company had established an Internet project in 1995 called Infocom Systems to exploit opportunities leading from fixed-line telecom and IT. CEO Lars Ramqvist wrote in the 1996 annual report that in all three of its business areas \u2013 Mobile Telephones and Terminals, Mobile Systems, and Infocom Systems \u2013 \"we will expand our operations as they relate to customer service and Internet Protocol (IP) access (Internet and intranet access)\".\nThe growth of GSM, which became a \"de facto\" world standard, combined with Ericsson's other mobile standards, such as D-AMPS and PDC, meant that by the start of 1997, Ericsson had an estimated 40% share of the world's mobile market, with around 54 million subscribers. There were also around 188\u00a0million AXE lines in place or on order in 117 countries. Telecom and chip companies worked in the 1990s to provide Internet access over mobile telephones. Early versions such as Wireless Application Protocol (WAP) used packet data over the existing GSM network, in a form known as GPRS (General Packet Radio Service), but these services, known as 2.5G, were fairly rudimentary and did not achieve much mass-market success.\nThe International Telecommunication Union (ITU) had prepared the specifications for a 3G mobile service that included several technologies. Ericsson pushed hard for the WCDMA (wideband CDMA) form based on the GSM standard, and began testing it in 1996. Japanese operator NTT DoCoMo signed deals to partner with Ericsson and Nokia, who came together in 1997 to support WCDMA over rival standards. DoCoMo was the first operator with a live 3G network, using its own version of WCDMA called FOMA. Ericsson was a significant developer of the WCDMA version of GSM, while US-based chip developer Qualcomm promoted the alternative system CDMA2000, building on the popularity of CDMA in the US market. This resulted in a patent infringement lawsuit that was resolved in March 1999 when the two companies agreed to pay each other royalties for the use of their respective technologies and Ericsson purchased Qualcomm's wireless infrastructure business and some R&amp;D resources.\nEricsson issued a profit warning in March 2001. Over the coming year, sales to operators halved. Mobile telephones became a burden; the company's telephones unit made a loss of SEK 24 million in 2000. A fire in a Philips chip factory in New Mexico in March 2000 caused severe disruption to Ericsson's phone production, dealing a \"coup de gr\u00e2ce\" to Ericsson's mobile phone hopes. Mobile phones would be spun off into a joint venture with Sony, Sony Ericsson Mobile Communications, in October 2001.\nEricsson launched several rounds of restructuring, refinancing and job-cutting; during 2001, staff numbers fell from 107,000 to 85,000. A further 20,000 went the next year, and 11,000 more in 2003. A new rights issue raised SEK 30\u00a0billion to keep the company afloat. The company had survived as mobile Internet started growing. With record profits, it was in better shape than many of its competitors.\nRebuilding and growing (2003\u20132018).\nThe emergence of full mobile Internet began a period of growth for the global telecom industry, including Ericsson. After the launch of 3G services during 2003, people started to access the Internet using their telephones.\nEricsson was working on ways to improve WCDMA as operators were buying and rolling it out; it was the first generation of 3G access. New advances included IMS (IP Multimedia Subsystem) and the next evolution of WCDMA, called High-Speed Packet Access (HSPA). It was initially deployed in the download version called HSDPA; the technology spread from the first test calls in the US in late 2005 to 59 commercial networks in September 2006. HSPA would provide the world's first mobile broadband.\nIn July 2016, Hans Vestberg stepped down as Ericsson's CEO after heading the company for six years. Jan Frykhammar, who has been working for the company since 1991 will be stepping in as interim CEO as Ericsson searches for a full-time replacement. On 16 January 2017, following Ericsson's announcement on 26 October 2016, new CEO B\u00f6rje Ekholm started and interim CEO Jan Frykhammar stepped down the following day.\nIn June 2018, Ericsson, Inc. and Ericsson AB have agreed to pay $145,893 to settle potential civil liability for an apparent violation of the International Emergency Economic Powers Act (IEEPA) and the Sudanese Sanctions Regulations, 31 C.F.R. part 538 (SSR).1\nAcquisitions and cooperation.\nAround 2000, companies and governments began to push for standards for mobile Internet. In May 2000, the European Commission created the Wireless Strategic Initiative, a consortium of four telecommunications suppliers in Europe \u2013 Ericsson, Nokia, Alcatel (France), and Siemens AG (Germany) \u2013 to develop and test new prototypes for advanced wireless communications systems. Later that year, the consortium partners invited other companies to join them in a Wireless World Research Forum in 2001. In December 1999, Microsoft\nand Ericsson announced a strategic partnership to combine the former's web browser and server software with the latter's mobile-internet technologies. In 2000, the Dot-com bubble burst with marked economic implications for Sweden. Ericsson, the world's largest producer of mobile telecommunications equipment, shed thousands of jobs, as did the country's Internet consulting firms and dot-com start-ups. In the same year, Intel, the world's largest semiconductor chip manufacturer, signed a $1.5\u00a0billion deal to supply flash memory to Ericsson over the next three years.\nThe short-lived joint venture called Ericsson Microsoft Mobile Venture AB, owned 70/30 percent by Ericsson and Microsoft, respectively, ended in October 2001 when Ericsson announced it would absorb the former joint venture and adopt a licensing agreement with Microsoft instead. The same month, Ericsson announced the launch of Sony Ericsson, a joint venture mobile telephone business, together with Sony Corporation. Sony Ericsson remained in operation until February 2012, when Sony bought out Ericsson's share; Ericsson said it wanted to focus on the global wireless market as a whole.\nLower stock prices and job losses affected many telecommunications companies in 2001. The major equipment manufacturers \u2013 Motorola (U.S.), Lucent Technologies (U.S.), Cisco Systems (U.S.), Marconi (UK), Siemens AG (Germany), Nokia (Finland), as well as Ericsson \u2013 all announced job cuts in their home countries and in subsidiaries around the world. Ericsson's workforce worldwide fell during 2001 from 107,000 to 85,000.\nIn September 2001, Ericsson purchased the remaining shares in EHPT from Hewlett Packard. Founded in 1993, Ericsson Hewlett Packard Telecom (EHPT) was a joint venture made up of 60% Ericsson interests and 40% Hewlett-Packard interests.\nIn 2002, ICT investor losses topped $2\u00a0trillion and share prices fell by 95% until August that year. More than half a million people lost their jobs in the global telecom industry over the two years. The collapse of U.S. carrier WorldCom, with more than $107\u00a0billion in assets, was the biggest in U.S. history. The sector's problems caused bankruptcies and job losses, and led to changes in the leadership of a number of major companies. Ericsson made 20,000 more staff redundant and raised about $3\u00a0billion from its shareholders. In June 2002, Infineon Technologies AG (then the sixth-largest semiconductor supplier and a subsidiary of Siemens) bought Ericsson's microelectronics unit for $400\u00a0million.\nEricsson was an official backer in the 2005 launch of the .mobi top level domain created specifically for the mobile internet.\nCo-operation with Hewlett-Packard did not end with EHPT; in 2003 Ericsson outsourced its IT to HP, which included Managed Services, Help Desk Support, Data Center Operations, and HP Utility Data Center. The contract was extended in 2008. There have also been a number of joint Ericsson/HP Telecoms outsourcing deals with telecoms operators including H3G and Vodafone. In October 2005, Ericsson acquired the bulk of the troubled UK telecommunications manufacturer Marconi Company, including its brand name that dates back to the creation of the original Marconi Company by the \"father of radio\" Guglielmo Marconi. In September 2006, Ericsson sold the greater part of its defense business Ericsson Microwave Systems, which mainly produced sensor and radar systems, to Saab AB, which renamed the company to Saab Microwave Systems.\nIn 2007, Ericsson acquired carrier edge-router maker Redback Networks, and then Entrisphere, a US-based company providing fiber-access technology. In September 2007, Ericsson acquired an 84% interest in German customer-care and billing software firm LHS, a stake later raised to 100%. In 2008, Ericsson sold its enterprise PBX division to Aastra Technologies, and acquired Tandberg Television, the television technology division of Norwegian company Tandberg. That same year \"Ericsson Field Service Organization\" was launched to simplify all processes more cost effective for Ericsson to handle than any other available external service provider.\nIn 2009, Ericsson bought the CDMA2000 and LTE business of Nortel\u2019s carrier networks division for US$1.18\u00a0billion; Bizitek, a Turkish business support systems integrator; the Estonian manufacturing operations of electronic manufacturing company Elcoteq; and completed its acquisition of LHS. Acquisitions in 2010 included assets from the Strategy and Technology Group of inCode, a North American business and consulting-services company; Nortel's majority shareholding (50% plus one share) in LG-Nortel, a joint venture between LG Electronics and Nortel Networks providing sales, R&amp;D and industrial capacity in South Korea, now known as Ericsson-LG; further Nortel carrier-division assets, relating from Nortel's GSM business in the United States and Canada; Optimi Corporation, a U.S.\u2013Spanish telecommunications vendor specializing in network optimization and management; and Pride, a consulting and systems-integration company operating in Italy.\nIn 2011, Ericsson acquired manufacturing and research facilities, and staff from the Guangdong Nortel Telecommunication Equipment Company (GDNT) as well as Nortel's Multiservice Switch business. Ericsson acquired U.S. company Telcordia Technologies in January 2012, an operations and business support systems (OSS/BSS) company. In March, Ericsson announced it was buying the broadcast-services division of Technicolor, a media broadcast technology company. In April 2012 Ericsson completed the acquisition of BelAir Networks a strong Wi-Fi network technology company.\nOn 3 May 2013, Ericsson announced it would divest its power cable operations to Danish company NKT Holding. On 1 July 2013, Ericsson announced it would acquire the media management company Red Bee Media, subject to regulatory approval. The acquisition was completed on 9 May 2014. In September 2013, Ericsson completed its acquisition of Microsoft's Mediaroom business and televisions services, originally announced in April the same year. The acquisition makes Ericsson the largest provider of IPTV and multi-screen services in the world, by market share; it was renamed Ericsson Mediaroom. In September 2014, Ericsson acquired majority stake in Apcera for cloud policy compliance. In October 2015, Ericsson completed the acquisition of Envivio, a software encoding company. In April 2016, Ericsson acquired Polish and Ukrainian operations of software development company Ericpol, a long-time supplier to Ericsson. Approximately 2,300 Ericpol employees joined Ericsson, bringing software development competence in radio, cloud, and IP.\nOn 20 June 2017, Bloomberg disclosed that Ericsson hired Morgan Stanley to explore the sale of its media businesses. The Red Bee Media business was kept in-house as an independent subsidiary company, as no suitable buyer was found, but a 51% stake of the remainder of the Media Solution division was sold to private equity firm One Equity Partners, the new company being named MediaKind. The transaction was completed on 31 January 2019. In February 2018, Ericsson acquired the location-based mobile data management platform Placecast. Ericsson has since integrated Placecast's platform and capabilities with its programmatic mobile ad subsidiary, Emodo. In May 2018, SoftBank partnered with Ericsson to trial new radio technology. In September 2020, Ericsson acquired US-based carrier equipment manufacturer Cradlepoint for $1.1 billion.\nCorporate governance.\n, members of the board of directors of LM Ericsson were: Leif Johansson, Jacob Wallenberg, Kristin S. Rinne, Helena Stjernholm, Sukhinder Singh Cassidy, B\u00f6rje Ekholm, Ulf J. Johansson, Mikael L\u00e4nnqvist, Zlatko Hadzic, Kjell-\u00c5ke Soting, Nora Denzel, Kristin Skogen Lund, Pehr Claesson, Karin \u00c5berg and Roger Svensson.\nResearch and development.\nEricsson has structured its R&amp;D in three levels depending on when products or technologies will be introduced to customers and users. Its research and development organization is part of 'Group Function Technology' and addresses several facets of network architecture: wireless access networks; radio access technologies; broadband technologies; packet technologies; multimedia technologies; services software; EMF safety and sustainability; security; and global services. The head of research since 2012 is Sara Mazur.\nGroup Function Technology holds research co-operations with several major universities and research institutes including: Lund University in Sweden, E\u00f6tv\u00f6s Lor\u00e1nd University in Hungary and Beijing Institute of Technology in China. Ericsson also holds research co-operations within several European research programs such as GigaWam and OASE. Ericsson holds 33,000 granted patents, and is the number-one holder of GSM/GPRS/EDGE, WCDMA/HSPA, and LTE essential patents.\nEricsson hosts a developer program called Ericsson Developer Connection designed to encourage development of applications and services. Ericsson also has an open innovation initiative for beta applications and beta API's &amp; tools called Ericsson Labs. The company hosts several internal innovation competitions among its employees.\nProducts and services.\nEricsson's business includes technology research, development, network systems and software development, and running operations for telecom service providers. and software Ericsson offers end-to-end services for all major mobile communication standards, and has three main business units.\nBusiness Area Networks.\nBusiness Area Networks, previously called Business Unit Networks, develops network infrastructure for communication needs over mobile and fixed connections. Its products include radio base stations, radio network controllers, mobile switching centers and service application nodes. Operators use Ericsson products to migrate from 2G to 3G and, most recently, to 4G networks.\nThe company's network division has been described as a driver in the development of 2G, 3G, 4G/LTE and 5G technology, and the evolution towards all-IP, and it develops and deploys advanced LTE systems, but it is still developing the older GSM, WCDMA, and CDMA technologies. The company's networks portfolio also includes microwave transport, Internet Protocol (IP) networks, fixed-access services for copper and fiber, and mobile broadband modules, several levels of fixed broadband access, radio access networks from small pico cells to high-capacity macro cells and controllers for radio base stations.\nNetwork services.\nEricsson's network rollout services employ in-house capabilities, subcontractors and central resources to make changes to live networks. Services such as technology deployment, network transformation, support services and network optimization are also provided.\nBusiness Area Digital Services.\nThis unit provides core networks, Operations Support Systems such as network management and analytics, and Business Support Systems such as billing and mediation. Within the Digital Services unit, there is an m-Commerce offering, which focuses on service providers and facilitates their working with financial institutions and intermediaries. Ericsson has announced m-commerce deals with Western Union and African wireless carrier MTN.\nBusiness Area Managed Services.\nThe unit is active in 180 countries; it supplies managed services, systems integration, consulting, network rollout, design and optimization, broadcast services, learning services and support.\nThe company also works with television and media, public safety, and utilities. Ericsson claims to manage networks that serve more than 1\u00a0billion subscribers worldwide, and to support customer networks that serve more than 2.5\u00a0billion subscribers.\nBroadcast services.\nEricsson's Broadcast Services unit was evolved into a unit called Red Bee Media, which has been spun out into a joint venture. It deals with the playout of live and pre-recorded, commercial and public service television programmes, including presentation (continuity announcements), trailers, and ancillary access services such as closed-caption subtitles, audio description and in-vision sign language interpreters. Its media management services consist of Managed Media Preparation and Managed Media Internet Delivery.\nDivested businesses.\nSony Ericsson Mobile Communications AB (Sony Ericsson) was a joint venture with Sony that merged the previous mobile telephone operations of both companies. It manufactured mobile telephones, accessories and personal computer (PC) cards. Sony Ericsson was responsible for product design and development, marketing, sales, distribution and customer services. On 16 February 2012, Sony announced it had completed the full acquisition of Sony Ericsson, after which it changed name to Sony Mobile Communications, and nearly a year later it moved headquarters from Sweden to Japan.\nMobile (cell) telephones.\nAs a joint venture with Sony, Ericsson's mobile telephone production was moved into the company Sony Ericsson in 2001. The following is a list of mobile phones marketed under the brand name Ericsson.\nEricsson Mobile Platforms.\nEricsson Mobile Platforms existed for eight years; on 12 February 2009, Ericsson announced it would be merged with the mobile platform company of STMicroelectronics, ST-NXP Wireless, to create a 50/50 joint venture owned by Ericsson and STMicroelectronics.\nThis joint venture was divested in 2013 and remaining activities can be found in Ericsson Modems and STMicroelectronics. Ericsson Mobile Platform ceased being a legal entity early 2009.\nEricsson Enterprise.\nStarting in 1983 Ericsson Enterprise provided communications systems and services for businesses, public entities and educational institutions. It produced products for voice over Internet protocol (VoIP)-based private branch exchanges (PBX), wireless local area networks (WLAN), and mobile intranets.\nEricsson Enterprise operated mainly from Sweden but also operated through regional units and other partners/distributors. In 2008 it was sold to Aastra.\nControversies.\nOn 7 December 2019, Ericsson agreed to pay more than $1.2 billion (\u20ac1.09 billion) to settle US Department of Justice criminal and civil investigations into foreign corruption. US authorities accused the company of conducting a campaign of corruption between 2000 and 2016 across China, Indonesia, Vietnam, Kuwait and Djibouti. Ericsson admitted to paying bribes, falsifying books and records and failing to implement reasonable internal accounting controls in an attempt to strengthen its position in the telecommunications industry."}
{"id": "9425", "revid": "36083290", "url": "https://en.wikipedia.org/wiki?curid=9425", "title": "Ethology", "text": "Ethology is the scientific and objective study of animal behaviour, usually with a focus on behaviour under natural conditions, and viewing behaviour as an evolutionarily adaptive trait. Behaviourism as a term also describes the scientific and objective study of animal behaviour, usually referring to measured responses to stimuli or to trained behavioural responses in a laboratory context, without a particular emphasis on evolutionary adaptivity. Throughout history, different naturalists have studied aspects of animal behaviour. Ethology has its scientific roots in the work of Charles Darwin (1809\u20131882) and of American and German ornithologists of the late 19th and early 20th century, including Charles O. Whitman, Oskar Heinroth (1871\u20131945), and Wallace Craig. The modern discipline of ethology is generally considered to have begun during the 1930s with the work of Dutch biologist Nikolaas Tinbergen (1907\u20131988) and of Austrian biologists Konrad Lorenz and Karl von Frisch (1886\u20131982), the three recipients of the 1973 Nobel Prize in Physiology or Medicine. Ethology combines laboratory and field science, with a strong relation to some other disciplines such as neuroanatomy, ecology, and evolutionary biology. Ethologists typically show interest in a behavioural process rather than in a particular animal group, and often study one type of behaviour, such as aggression, in a number of unrelated species.\nEthology is a rapidly growing field. Since the dawn of the 21st century researchers have re-examined and reached new conclusions in many aspects of animal communication, emotions, culture, learning and sexuality that the scientific community long thought it understood. New fields, such as neuroethology, have developed.\nUnderstanding ethology or animal behaviour can be important in animal training. Considering the natural behaviours of different species or breeds enables trainers to select the individuals best suited to perform the required task. It also enables trainers to encourage the performance of naturally occurring behaviours and the discontinuance of undesirable behaviours.\nEtymology.\nThe term \"ethology\" derives from the Greek language: \u1f26\u03b8\u03bf\u03c2, \"ethos\" meaning \"character\" and , \"-logia\" meaning \"the study of\". The term was first popularized by American myrmecologist (a person who studies ants) William Morton Wheeler in 1902.\nHistory.\nThe beginnings of ethology.\nBecause ethology is considered a topic of biology, ethologists have been concerned particularly with the evolution of behaviour and its understanding in terms of natural selection. In one sense, the first modern ethologist was Charles Darwin, whose 1872 book \"The Expression of the Emotions in Man and Animals\" influenced many ethologists. He pursued his interest in behaviour by encouraging his prot\u00e9g\u00e9 George Romanes, who investigated animal learning and intelligence using an anthropomorphic method, anecdotal cognitivism, that did not gain scientific support.\nOther early ethologists, such as Charles O. Whitman, Oskar Heinroth, Wallace Craig and Julian Huxley, instead concentrated on behaviours that can be called instinctive, or natural, in that they occur in all members of a species under specified circumstances. Their beginning for studying the behaviour of a new species was to construct an ethogram (a description of the main types of behaviour with their frequencies of occurrence). This provided an objective, cumulative database of behaviour, which subsequent researchers could check and supplement.\nGrowth of the field.\nDue to the work of Konrad Lorenz and Niko Tinbergen, ethology developed strongly in continental Europe during the years prior to World War II. After the war, Tinbergen moved to the University of Oxford, and ethology became stronger in the UK, with the additional influence of William Thorpe, Robert Hinde, and Patrick Bateson at the Sub-department of Animal Behaviour of the University of Cambridge. In this period, too, ethology began to develop strongly in North America.\nLorenz, Tinbergen, and von Frisch were jointly awarded the Nobel Prize in Physiology or Medicine in 1973 for their work of developing ethology.\nEthology is now a well-recognized scientific discipline, and has a number of journals covering developments in the subject, such as \"Animal Behaviour\", \"Animal Welfare\", \"Applied Animal Behaviour Science\", \"Animal Cognition\", \"Behaviour\", \"Behavioral Ecology\" and \"Journal of Ethology\", \"Ethology\". In 1972, the International Society for Human Ethology was founded to promote exchange of knowledge and opinions concerning human behaviour gained by applying ethological principles and methods and published their journal, \"The Human Ethology Bulletin\". In 2008, in a paper published in the journal \"Behaviour\", ethologist Peter Verbeek introduced the term \"Peace Ethology\" as a sub-discipline of Human Ethology that is concerned with issues of human conflict, conflict resolution, reconciliation, war, peacemaking, and peacekeeping behaviour.\nSocial ethology and recent developments.\nIn 1972, the English ethologist John H. Crook distinguished comparative ethology from social ethology, and argued that much of the ethology that had existed so far was really comparative ethology\u2014examining animals as individuals\u2014whereas, in the future, ethologists would need to concentrate on the behaviour of social groups of animals and the social structure within them.\nE. O. Wilson's book \"\" appeared in 1975, and since that time, the study of behaviour has been much more concerned with social aspects. It has also been driven by the stronger, but more sophisticated, Darwinism associated with Wilson, Robert Trivers, and W. D. Hamilton. The related development of behavioural ecology has also helped transform ethology. Furthermore, a substantial rapprochement with comparative psychology has occurred, so the modern scientific study of behaviour offers a more or less seamless spectrum of approaches: from animal cognition to more traditional comparative psychology, ethology, sociobiology, and behavioural ecology. In 2020, Dr. Tobias Starzak and Professor Albert Newen from the Institute of Philosophy II at the Ruhr University Bochum postulated that animals may have beliefs.\nRelationship with comparative psychology.\nComparative psychology also studies animal behaviour, but, as opposed to ethology, is construed as a sub-topic of psychology rather than as one of biology. Historically, where comparative psychology has included research on animal behaviour in the context of what is known about human psychology, ethology involves research on animal behaviour in the context of what is known about animal anatomy, physiology, neurobiology, and phylogenetic history. Furthermore, early comparative psychologists concentrated on the study of learning and tended to research behaviour in artificial situations, whereas early ethologists concentrated on behaviour in natural situations, tending to describe it as instinctive.\nThe two approaches are complementary rather than competitive, but they do result in different perspectives, and occasionally conflicts of opinion about matters of substance. In addition, for most of the twentieth century, comparative psychology developed most strongly in North America, while ethology was stronger in Europe. From a practical standpoint, early comparative psychologists concentrated on gaining extensive knowledge of the behaviour of very few species. Ethologists were more interested in understanding behaviour across a wide range of species to facilitate principled comparisons across taxonomic groups. Ethologists have made much more use of such cross-species comparisons than comparative psychologists have.\nInstinct.\nThe Merriam-Webster dictionary defines instinct as \"A largely inheritable and unalterable tendency of an organism to make a complex and specific response to environmental stimuli without involving reason\".\nFixed action patterns.\nAn important development, associated with the name of Konrad Lorenz though probably due more to his teacher, Oskar Heinroth, was the identification of fixed action patterns. Lorenz popularized these as instinctive responses that would occur reliably in the presence of identifiable stimuli called sign stimuli or \"releasing stimuli\". Fixed action patterns are now considered to be instinctive behavioural sequences that are relatively invariant within the species and that almost inevitably run to completion.\nOne example of a releaser is the beak movements of many bird species performed by newly hatched chicks, which stimulates the mother to regurgitate food for her offspring. Other examples are the classic studies by Tinbergen on the egg-retrieval behaviour and the effects of a \"supernormal stimulus\" on the behaviour of graylag geese.\nOne investigation of this kind was the study of the waggle dance (\"dance language\") in bee communication by Karl von Frisch.\nLearning.\nHabituation.\nHabituation is a simple form of learning and occurs in many animal taxa. It is the process whereby an animal ceases responding to a stimulus. Often, the response is an innate behaviour. Essentially, the animal learns not to respond to irrelevant stimuli. For example, prairie dogs (\"Cynomys ludovicianus\") give alarm calls when predators approach, causing all individuals in the group to quickly scramble down burrows. When prairie dog towns are located near trails used by humans, giving alarm calls every time a person walks by is expensive in terms of time and energy. Habituation to humans is therefore an important adaptation in this context.\nAssociative learning.\nAssociative learning in animal behaviour is any learning process in which a new response becomes associated with a particular stimulus. The first studies of associative learning were made by Russian physiologist Ivan Pavlov, who observed that dogs trained to associate food with the ringing of a bell would salivate on hearing the bell.\nImprinting.\nImprinting enables the young to discriminate the members of their own species, vital for reproductive success. This important type of learning only takes place in a very limited period of time. Lorenz observed that the young of birds such as geese and chickens followed their mothers spontaneously from almost the first day after they were hatched, and he discovered that this response could be imitated by an arbitrary stimulus if the eggs were incubated artificially and the stimulus were presented during a critical period that continued for a few days after hatching.\nCultural learning.\nImitation.\nImitation is an advanced behaviour whereby an animal observes and exactly replicates the behaviour of another.\nThe National Institutes of Health reported that capuchin monkeys preferred the company of researchers who imitated them to that of researchers who did not. The monkeys not only spent more time with their imitators but also preferred to engage in a simple task with them even when provided with the option of performing the same task with a non-imitator. Imitation has been observed in recent research on chimpanzees; not only did these chimps copy the actions of another individual, when given a choice, the chimps preferred to imitate the actions of the higher-ranking elder chimpanzee as opposed to the lower-ranking young chimpanzee.\nStimulus and local enhancement.\nThere are various ways animals can learn using observational learning but without the process of imitation. One of these is \"stimulus enhancement\" in which individuals become interested in an object as the result of observing others interacting with the object. Increased interest in an object can result in object manipulation which allows for new object-related behaviours by trial-and-error learning. Haggerty (1909) devised an experiment in which a monkey climbed up the side of a cage, placed its arm into a wooden chute, and pulled a rope in the chute to release food. Another monkey was provided an opportunity to obtain the food after watching a monkey go through this process on four occasions. The monkey performed a different method and finally succeeded after trial-and-error. Another example familiar to some cat and dog owners is the ability of their animals to open doors. The action of humans operating the handle to open the door results in the animals becoming interested in the handle and then by trial-and-error, they learn to operate the handle and open the door.\nIn local enhancement, a demonstrator attracts an observer's attention to a particular location. Local enhancement has been observed to transmit foraging information among birds, rats and pigs. The stingless bee (\"Trigona corvina\") uses local enhancement to locate other members of their colony and food resources.\nSocial transmission.\nA well-documented example of social transmission of a behaviour occurred in a group of macaques on Hachijojima Island, Japan. The macaques lived in the inland forest until the 1960s, when a group of researchers started giving them potatoes on the beach: soon, they started venturing onto the beach, picking the potatoes from the sand, and cleaning and eating them. About one year later, an individual was observed bringing a potato to the sea, putting it into the water with one hand, and cleaning it with the other. This behaviour was soon expressed by the individuals living in contact with her; when they gave birth, this behaviour was also expressed by their young - a form of social transmission.\nTeaching.\nTeaching is a highly specialized aspect of learning in which the \"teacher\" (demonstrator) adjusts their behaviour to increase the probability of the \"pupil\" (observer) achieving the desired end-result of the behaviour. For example, killer whales are known to intentionally beach themselves to catch pinniped prey. Mother killer whales teach their young to catch pinnipeds by pushing them onto the shore and encouraging them to attack the prey. Because the mother killer whale is altering her behaviour to help her offspring learn to catch prey, this is evidence of teaching. Teaching is not limited to mammals. Many insects, for example, have been observed demonstrating various forms of teaching to obtain food. Ants, for example, will guide each other to food sources through a process called \"tandem running,\" in which an ant will guide a companion ant to a source of food. It has been suggested that the pupil ant is able to learn this route to obtain food in the future or teach the route to other ants. This behaviour of teaching is also exemplified by crows, specifically New Caledonian crows. The adults (whether individual or in families) teach their young adolescent offspring how to construct and utilize tools. For example, \"Pandanus\" branches are used to extract insects and other larvae from holes within trees.\nMating and the fight for supremacy.\nIndividual reproduction is the most important phase in the proliferation of individuals or genes within a species: for this reason, there exist complex mating rituals, which can be very complex even if they are often regarded as fixed action patterns. The stickleback's complex mating ritual, studied by Tinbergen, is regarded as a notable example.\nOften in social life, animals fight for the right to reproduce, as well as social supremacy. A common example of fighting for social and sexual supremacy is the so-called pecking order among poultry. Every time a group of poultry cohabitate for a certain time length, they establish a pecking order. In these groups, one chicken dominates the others and can peck without being pecked. A second chicken can peck all the others except the first, and so on. Chickens higher in the pecking order may at times be distinguished by their healthier appearance when compared to lower level chickens. While the pecking order is establishing, frequent and violent fights can happen, but once established, it is broken only when other individuals enter the group, in which case the pecking order re-establishes from scratch.\nLiving in groups.\nSeveral animal species, including humans, tend to live in groups. Group size is a major aspect of their social environment. Social life is probably a complex and effective survival strategy. It may be regarded as a sort of symbiosis among individuals of the same species: a society is composed of a group of individuals belonging to the same species living within well-defined rules on food management, role assignments and reciprocal dependence.\nWhen biologists interested in evolution theory first started examining social behaviour, some apparently unanswerable questions arose, such as how the birth of sterile castes, like in bees, could be explained through an evolving mechanism that emphasizes the reproductive success of as many individuals as possible, or why, amongst animals living in small groups like squirrels, an individual would risk its own life to save the rest of the group. These behaviours may be examples of altruism. Of course, not all behaviours are altruistic, as indicated by the table below. For example, revengeful behaviour was at one point claimed to have been observed exclusively in \"Homo sapiens\". However, other species have been reported to be vengeful including chimpanzees, as well as anecdotal reports of vengeful camels.\nAltruistic behaviour has been explained by the gene-centred view of evolution.\nBenefits and costs of group living.\nOne advantage of group living can be decreased predation. If the number of predator attacks stays the same despite increasing prey group size, each prey may have a reduced risk of predator attacks through the dilution effect. Further, according to the selfish herd theory, the fitness benefits associated with group living vary depending on the location of an individual within the group. The theory suggests that conspecifics positioned at the centre of a group will reduce the likelihood predations while those at the periphery will become more vulnerable to attack. Additionally, a predator that is confused by a mass of individuals can find it more difficult to single out one target. For this reason, the zebra's stripes offer not only camouflage in a habitat of tall grasses, but also the advantage of blending into a herd of other zebras. In groups, prey can also actively reduce their predation risk through more effective defence tactics, or through earlier detection of predators through increased vigilance.\nAnother advantage of group living can be an increased ability to forage for food. Group members may exchange information about food sources between one another, facilitating the process of resource location. Honeybees are a notable example of this, using the waggle dance to communicate the location of flowers to the rest of their hive. Predators also receive benefits from hunting in groups, through using better strategies and being able to take down larger prey.\nSome disadvantages accompany living in groups. Living in close proximity to other animals can facilitate the transmission of parasites and disease, and groups that are too large may also experience greater competition for resources and mates.\nGroup size.\nTheoretically, social animals should have optimal group sizes that maximize the benefits and minimize the costs of group living. However, in nature, most groups are stable at slightly larger than optimal sizes. Because it generally benefits an individual to join an optimally-sized group, despite slightly decreasing the advantage for all members, groups may continue to increase in size until it is more advantageous to remain alone than to join an overly full group.\nTinbergen's four questions for ethologists.\nNiko Tinbergen argued that ethology always needed to include four kinds of explanation in any instance of behaviour:\nThese explanations are complementary rather than mutually exclusive\u2014all instances of behaviour require an explanation at each of these four levels. For example, the function of eating is to acquire nutrients (which ultimately aids survival and reproduction), but the immediate cause of eating is hunger (causation). Hunger and eating are evolutionarily ancient and are found in many species (evolutionary history), and develop early within an organism's lifespan (development). It is easy to confuse such questions\u2014for example, to argue that people eat because they're hungry and not to acquire nutrients\u2014without realizing that the reason people experience hunger is because it causes them to acquire nutrients."}
{"id": "9426", "revid": "40945993", "url": "https://en.wikipedia.org/wiki?curid=9426", "title": "Electromagnetic radiation", "text": "In physics, electromagnetic radiation (EM radiation or EMR) refers to the waves (or their quanta, photons) of the electromagnetic field, propagating through space, carrying electromagnetic radiant energy. It includes radio waves, microwaves, infrared, (visible) light, ultraviolet, X-rays, and gamma rays. All of these waves form part of the electromagnetic spectrum.\nClassically, electromagnetic radiation consists of electromagnetic waves, which are synchronized oscillations of electric and magnetic fields. Electromagnetic radiation or electromagnetic waves are created due to periodic change of electric or magnetic field. Depending on how this periodic change occurs and the power generated, different wavelengths of electromagnetic spectrum are produced.In a vacuum, electromagnetic waves travel at the speed of light, commonly denoted \"c\". In homogeneous, isotropic media, the oscillations of the two fields are perpendicular to each other and perpendicular to the direction of energy and wave propagation, forming a transverse wave. The wavefront of electromagnetic waves emitted from a point source (such as a light bulb) is a sphere. The position of an electromagnetic wave within the electromagnetic spectrum can be characterized by either its frequency of oscillation or its wavelength. Electromagnetic waves of different frequency are called by different names since they have different sources and effects on matter. In order of increasing frequency and decreasing wavelength these are: radio waves, microwaves, infrared radiation, visible light, ultraviolet radiation, X-rays and gamma rays.\nElectromagnetic waves are emitted by electrically charged particles undergoing acceleration, and these waves can subsequently interact with other charged particles, exerting force on them. EM waves carry energy, momentum and angular momentum away from their source particle and can impart those quantities to matter with which they interact. Electromagnetic radiation is associated with those EM waves that are free to propagate themselves (\"radiate\") without the continuing influence of the moving charges that produced them, because they have achieved sufficient distance from those charges. Thus, EMR is sometimes referred to as the far field. In this language, the near field refers to EM fields near the charges and current that directly produced them, specifically electromagnetic induction and electrostatic induction phenomena.\nIn quantum mechanics, an alternate way of viewing EMR is that it consists of photons, uncharged elementary particles with zero rest mass which are the quanta of the electromagnetic field, responsible for all electromagnetic interactions. Quantum electrodynamics is the theory of how EMR interacts with matter on an atomic level. Quantum effects provide additional sources of EMR, such as the transition of electrons to lower energy levels in an atom and black-body radiation. The energy of an individual photon is quantized and is greater for photons of higher frequency. This relationship is given by Planck's equation \"E\" = \"hf\", where \"E\" is the energy per photon, \"f\" is the frequency of the photon, and \"h\" is Planck's constant. A single gamma ray photon, for example, might carry ~100,000 times the energy of a single photon of visible light.\nThe effects of EMR upon chemical compounds and biological organisms depend both upon the radiation's power and its frequency. EMR of visible or lower frequencies (i.e., visible light, infrared, microwaves, and radio waves) is called \"non-ionizing radiation\", because its photons do not individually have enough energy to ionize atoms or molecules or break chemical bonds. The effects of these radiations on chemical systems and living tissue are caused primarily by heating effects from the combined energy transfer of many photons. In contrast, high frequency ultraviolet, X-rays and gamma rays are called \"ionizing radiation\", since individual photons of such high frequency have enough energy to ionize molecules or break chemical bonds. These radiations have the ability to cause chemical reactions and damage living cells beyond that resulting from simple heating, and can be a health hazard.\nPhysics.\nTheory.\nMaxwell's equations.\nJames Clerk Maxwell derived a wave form of the electric and magnetic equations, thus uncovering the wave-like nature of electric and magnetic fields and their symmetry. Because the speed of EM waves predicted by the wave equation coincided with the measured speed of light, Maxwell concluded that light itself is an EM wave. Maxwell's equations were confirmed by Heinrich Hertz through experiments with radio waves.\nMaxwell realized that since a lot of physics is symmetrical and mathematically artistic in a way, that there must also be a symmetry between electricity and magnetism. He realized that light is a combination of electricity and magnetism and thus that the two must be tied together.According to Maxwell's equations, a spatially varying electric field is always associated with a magnetic field that changes over time. Likewise, a spatially varying magnetic field is associated with specific changes over time in the electric field. In an electromagnetic wave, the changes in the electric field are always accompanied by a wave in the magnetic field in one direction, and vice versa. This relationship between the two occurs without either type of field causing the other; rather, they occur together in the same way that time and space changes occur together and are interlinked in special relativity. In fact, magnetic fields can be viewed as electric fields in another frame of reference, and electric fields can be viewed as magnetic fields in another frame of reference, but they have equal significance as physics is the same in all frames of reference, so the close relationship between space and time changes here is more than an analogy. Together, these fields form a propagating electromagnetic wave, which moves out into space and need never again interact with the source. The distant EM field formed in this way by the acceleration of a charge carries energy with it that \"radiates\" away through space, hence the term.\nNear and far fields.\nMaxwell's equations established that some charges and currents (\"sources\") produce a local type of electromagnetic field near them that does \"not\" have the behaviour of EMR. Currents directly produce a magnetic field, but it is of a magnetic dipole type that dies out with distance from the current. In a similar manner, moving charges pushed apart in a conductor by a changing electrical potential (such as in an antenna) produce an electric dipole type electrical field, but this also declines with distance. These fields make up the near-field near the EMR source. Neither of these behaviours are responsible for EM radiation. Instead, they cause electromagnetic field behaviour that only efficiently transfers power to a receiver very close to the source, such as the magnetic induction inside a transformer, or the feedback behaviour that happens close to the coil of a metal detector. Typically, near-fields have a powerful effect on their own sources, causing an increased \"load\" (decreased electrical reactance) in the source or transmitter, whenever energy is withdrawn from the EM field by a receiver. Otherwise, these fields do not \"propagate\" freely out into space, carrying their energy away without distance-limit, but rather oscillate, returning their energy to the transmitter if it is not received by a receiver.\nBy contrast, the EM far-field is composed of \"radiation\" that is free of the transmitter in the sense that (unlike the case in an electrical transformer) the transmitter requires the same power to send these changes in the fields out, whether the signal is immediately picked up or not. This distant part of the electromagnetic field \"is\" \"electromagnetic radiation\" (also called the far-field). The far-fields propagate (radiate) without allowing the transmitter to affect them. This causes them to be independent in the sense that their existence and their energy, after they have left the transmitter, is completely independent of both transmitter and receiver. Due to conservation of energy, the amount of power passing through any spherical surface drawn around the source is the same. Because such a surface has an area proportional to the square of its distance from the source, the power density of EM radiation always decreases with the inverse square of the distance from the source; this is called the inverse-square law. This is in contrast to dipole parts of the EM field close to the source (the near-field), which vary in power according to an inverse cube power law, and thus do \"not\" transport a conserved amount of energy over distances, but instead fade with distance, with its energy (as noted) rapidly returning to the transmitter or absorbed by a nearby receiver (such as a transformer secondary coil).\nThe far-field (EMR) depends on a different mechanism for its production than the near-field, and upon different terms in Maxwell's equations. Whereas the magnetic part of the near-field is due to currents in the source, the magnetic field in EMR is due only to the local change in the electric field. In a similar way, while the electric field in the near-field is due directly to the charges and charge-separation in the source, the electric field in EMR is due to a change in the local magnetic field. Both processes for producing electric and magnetic EMR fields have a different dependence on distance than do near-field dipole electric and magnetic fields. That is why the EMR type of EM field becomes dominant in power \"far\" from sources. The term \"far from sources\" refers to how far from the source (moving at the speed of light) any portion of the outward-moving EM field is located, by the time that source currents are changed by the varying source potential, and the source has therefore begun to generate an outwardly moving EM field of a different phase.\nA more compact view of EMR is that the far-field that composes EMR is generally that part of the EM field that has traveled sufficient distance from the source, that it has become completely disconnected from any feedback to the charges and currents that were originally responsible for it. Now independent of the source charges, the EM field, as it moves farther away, is dependent only upon the accelerations of the charges that produced it. It no longer has a strong connection to the direct fields of the charges, or to the velocity of the charges (currents).\nIn the Li\u00e9nard\u2013Wiechert potential formulation of the electric and magnetic fields due to motion of a single particle (according to Maxwell's equations), the terms associated with acceleration of the particle are those that are responsible for the part of the field that is regarded as electromagnetic radiation. By contrast, the term associated with the changing static electric field of the particle and the magnetic term that results from the particle's uniform velocity, are both associated with the electromagnetic near-field, and do not comprise EM radiation.\nProperties.\nElectrodynamics is the physics of electromagnetic radiation, and electromagnetism is the physical phenomenon associated with the theory of electrodynamics. Electric and magnetic fields obey the properties of superposition. Thus, a field due to any particular particle or time-varying electric or magnetic field contributes to the fields present in the same space due to other causes. Further, as they are vector fields, all magnetic and electric field vectors add together according to vector addition. For example, in optics two or more coherent light waves may interact and by constructive or destructive interference yield a resultant irradiance deviating from the sum of the component irradiances of the individual light waves.\nThe electromagnetic fields of light are not affected by traveling through static electric or magnetic fields in a linear medium such as a vacuum. However, in nonlinear media, such as some crystals, interactions can occur between light and static electric and magnetic fields\u2014these interactions include the Faraday effect and the Kerr effect.\nIn refraction, a wave crossing from one medium to another of different density alters its speed and direction upon entering the new medium. The ratio of the refractive indices of the media determines the degree of refraction, and is summarized by Snell's law. Light of composite wavelengths (natural sunlight) disperses into a visible spectrum passing through a prism, because of the wavelength-dependent refractive index of the prism material (dispersion); that is, each component wave within the composite light is bent a different amount.\nEM radiation exhibits both wave properties and particle properties at the same time (see wave-particle duality). Both wave and particle characteristics have been confirmed in many experiments. Wave characteristics are more apparent when EM radiation is measured over relatively large timescales and over large distances while particle characteristics are more evident when measuring small timescales and distances. For example, when electromagnetic radiation is absorbed by matter, particle-like properties will be more obvious when the average number of photons in the cube of the relevant wavelength is much smaller than 1. It is not so difficult to experimentally observe non-uniform deposition of energy when light is absorbed, however this alone is not evidence of \"particulate\" behavior. Rather, it reflects the quantum nature of \"matter\". Demonstrating that the light itself is quantized, not merely its interaction with matter, is a more subtle affair.\nSome experiments display both the wave and particle natures of electromagnetic waves, such as the self-interference of a single photon. When a single photon is sent through an interferometer, it passes through both paths, interfering with itself, as waves do, yet is detected by a photomultiplier or other sensitive detector only once.\nA quantum theory of the interaction between electromagnetic radiation and matter such as electrons is described by the theory of quantum electrodynamics.\nElectromagnetic waves can be polarized, reflected, refracted, diffracted or interfere with each other.\nWave model.\n In homogeneous, isotropic media, electromagnetic radiation is a transverse wave, meaning that its oscillations are perpendicular to the direction of energy transfer and travel. The electric and magnetic parts of the field stand in a fixed ratio of strengths in order to satisfy the two Maxwell equations that specify how one is produced from the other. In dissipation-less (lossless) media, these E and B fields are also in phase, with both reaching maxima and minima at the same points in space (see illustrations). A common misconception is that the E and B fields in electromagnetic radiation are out of phase because a change in one produces the other, and this would produce a phase difference between them as sinusoidal functions (as indeed happens in electromagnetic induction, and in the near-field close to antennas). However, in the far-field EM radiation which is described by the two source-free Maxwell curl operator equations, a more correct description is that a time-change in one type of field is proportional to a space-change in the other. These derivatives require that the E and B fields in EMR are in-phase (see mathematics section below).\nAn important aspect of light's nature is its frequency. The frequency of a wave is its rate of oscillation and is measured in hertz, the SI unit of frequency, where one hertz is equal to one oscillation per second. Light usually has multiple frequencies that sum to form the resultant wave. Different frequencies undergo different angles of refraction, a phenomenon known as dispersion.\nA monochromatic wave (a wave of a single frequency) consists of successive troughs and crests, and the distance between two adjacent crests or troughs is called the wavelength. Waves of the electromagnetic spectrum vary in size, from very long radio waves longer than a continent to very short gamma rays smaller than atom nuclei. Frequency is inversely proportional to wavelength, according to the equation:\nwhere \"v\" is the speed of the wave (\"c\" in a vacuum or less in other media), \"f\" is the frequency and \u03bb is the wavelength. As waves cross boundaries between different media, their speeds change but their frequencies remain constant.\nElectromagnetic waves in free space must be solutions of Maxwell's electromagnetic wave equation. Two main classes of solutions are known, namely plane waves and spherical waves. The plane waves may be viewed as the limiting case of spherical waves at a very large (ideally infinite) distance from the source. Both types of waves can have a waveform which is an arbitrary time function (so long as it is sufficiently differentiable to conform to the wave equation). As with any time function, this can be decomposed by means of Fourier analysis into its frequency spectrum, or individual sinusoidal components, each of which contains a single frequency, amplitude and phase. Such a component wave is said to be \"monochromatic\". A monochromatic electromagnetic wave can be characterized by its frequency or wavelength, its peak amplitude, its phase relative to some reference phase, its direction of propagation, and its polarization.\nInterference is the superposition of two or more waves resulting in a new wave pattern. If the fields have components in the same direction, they constructively interfere, while opposite directions cause destructive interference. An example of interference caused by EMR is electromagnetic interference (EMI) or as it is more commonly known as, radio-frequency interference (RFI). Additionally, multiple polarization signals can be combined (i.e. interfered) to form new states of polarization, which is known as parallel polarization state generation.\nThe energy in electromagnetic waves is sometimes called radiant energy.\nParticle model and quantum theory.\nAn anomaly arose in the late 19th century involving a contradiction between the wave theory of light and measurements of the electromagnetic spectra that were being emitted by thermal radiators known as black bodies. Physicists struggled with this problem unsuccessfully for many years. It later became known as the ultraviolet catastrophe. In 1900, Max Planck developed a new theory of black-body radiation that explained the observed spectrum. Planck's theory was based on the idea that black bodies emit light (and other electromagnetic radiation) only as discrete bundles or packets of energy. These packets were called quanta. In 1905, Albert Einstein proposed that light quanta be regarded as real particles. Later the particle of light was given the name photon, to correspond with other particles being described around this time, such as the electron and proton. A photon has an energy, \"E\", proportional to its frequency, \"f\", by\nwhere \"h\" is Planck's constant, formula_3 is the wavelength and \"c\" is the speed of light. This is sometimes known as the Planck\u2013Einstein equation. In quantum theory (see first quantization) the energy of the photons is thus directly proportional to the frequency of the EMR wave.\nLikewise, the momentum \"p\" of a photon is also proportional to its frequency and inversely proportional to its wavelength:\nThe source of Einstein's proposal that light was composed of particles (or could act as particles in some circumstances) was an experimental anomaly not explained by the wave theory: the photoelectric effect, in which light striking a metal surface ejected electrons from the surface, causing an electric current to flow across an applied voltage. Experimental measurements demonstrated that the energy of individual ejected electrons was proportional to the \"frequency\", rather than the \"intensity\", of the light. Furthermore, below a certain minimum frequency, which depended on the particular metal, no current would flow regardless of the intensity. These observations appeared to contradict the wave theory, and for years physicists tried in vain to find an explanation. In 1905, Einstein explained this puzzle by resurrecting the particle theory of light to explain the observed effect. Because of the preponderance of evidence in favor of the wave theory, however, Einstein's ideas were met initially with great skepticism among established physicists. Eventually Einstein's explanation was accepted as new particle-like behavior of light was observed, such as the Compton effect.\nAs a photon is absorbed by an atom, it excites the atom, elevating an electron to a higher energy level (one that is on average farther from the nucleus). When an electron in an excited molecule or atom descends to a lower energy level, it emits a photon of light at a frequency corresponding to the energy difference. Since the energy levels of electrons in atoms are discrete, each element and each molecule emits and absorbs its own characteristic frequencies. Immediate photon emission is called fluorescence, a type of photoluminescence. An example is visible light emitted from fluorescent paints, in response to ultraviolet (blacklight). Many other fluorescent emissions are known in spectral bands other than visible light. Delayed emission is called phosphorescence.\nWave\u2013particle duality.\nThe modern theory that explains the nature of light includes the notion of wave\u2013particle duality. More generally, the theory states that everything has both a particle nature and a wave nature, and various experiments can be done to bring out one or the other. The particle nature is more easily discerned using an object with a large mass. A bold proposition by Louis de Broglie in 1924 led the scientific community to realize that matter (e.g. electrons) also exhibits wave\u2013particle duality.\nWave and particle effects of electromagnetic radiation.\nTogether, wave and particle effects fully explain the emission and absorption spectra of EM radiation. The matter-composition of the medium through which the light travels determines the nature of the absorption and emission spectrum. These bands correspond to the allowed energy levels in the atoms. Dark bands in the absorption spectrum are due to the atoms in an intervening medium between source and observer. The atoms absorb certain frequencies of the light between emitter and detector/eye, then emit them in all directions. A dark band appears to the detector, due to the radiation scattered out of the beam. For instance, dark bands in the light emitted by a distant star are due to the atoms in the star's atmosphere. A similar phenomenon occurs for emission, which is seen when an emitting gas glows due to excitation of the atoms from any mechanism, including heat. As electrons descend to lower energy levels, a spectrum is emitted that represents the jumps between the energy levels of the electrons, but lines are seen because again emission happens only at particular energies after excitation. An example is the emission spectrum of nebulae. Rapidly moving electrons are most sharply accelerated when they encounter a region of force, so they are responsible for producing much of the highest frequency electromagnetic radiation observed in nature.\nThese phenomena can aid various chemical determinations for the composition of gases lit from behind (absorption spectra) and for glowing gases (emission spectra). Spectroscopy (for example) determines what chemical elements comprise a particular star. Spectroscopy is also used in the determination of the distance of a star, using the red shift.\nPropagation speed.\nWhen any wire (or other conducting object such as an antenna) conducts alternating current, electromagnetic radiation is propagated at the same frequency as the current. In many such situations it is possible to identify an electrical dipole moment that arises from separation of charges due to the exciting electrical potential, and this dipole moment oscillates in time, as the charges move back and forth. This oscillation at a given frequency gives rise to changing electric and magnetic fields, which then set the electromagnetic radiation in motion.\nAt the quantum level, electromagnetic radiation is produced when the wavepacket of a charged particle oscillates or otherwise accelerates. Charged particles in a stationary state do not move, but a superposition of such states may result in a transition state that has an electric dipole moment that oscillates in time. This oscillating dipole moment is responsible for the phenomenon of radiative transition between quantum states of a charged particle. Such states occur (for example) in atoms when photons are radiated as the atom shifts from one stationary state to another.\nAs a wave, light is characterized by a velocity (the speed of light), wavelength, and frequency. As particles, light is a stream of photons. Each has an energy related to the frequency of the wave given by Planck's relation \"E = hf\", where \"E\" is the energy of the photon, \"h\" is Planck's constant, 6.626 \u00d7 10\u221234 J\u00b7s, and \"f\" is the frequency of the wave.\nOne rule is obeyed regardless of circumstances: EM radiation in a vacuum travels at the speed of light, \"relative to the observer\", regardless of the observer's velocity. (This observation led to Einstein's development of the theory of special relativity.)\nIn a medium (other than vacuum), velocity factor or refractive index are considered, depending on frequency and application. Both of these are ratios of the speed in a medium to speed in a vacuum.\nSpecial theory of relativity.\nBy the late nineteenth century, various experimental anomalies could not be explained by the simple wave theory. One of these anomalies involved a controversy over the speed of light. The speed of light and other EMR predicted by Maxwell's equations did not appear unless the equations were modified in a way first suggested by FitzGerald and Lorentz (see history of special relativity), or else otherwise that speed would depend on the speed of observer relative to the \"medium\" (called luminiferous aether) which supposedly \"carried\" the electromagnetic wave (in a manner analogous to the way air carries sound waves). Experiments failed to find any observer effect. In 1905, Einstein proposed that space and time appeared to be velocity-changeable entities for light propagation and all other processes and laws. These changes accounted for the constancy of the speed of light and all electromagnetic radiation, from the viewpoints of all observers\u2014even those in relative motion.\nHistory of discovery.\nElectromagnetic radiation of wavelengths other than those of visible light were discovered in the early 19th century. The discovery of infrared radiation is ascribed to astronomer William Herschel, who published his results in 1800 before the Royal Society of London. Herschel used a glass prism to refract light from the Sun and detected invisible rays that caused heating beyond the red part of the spectrum, through an increase in the temperature recorded with a thermometer. These \"calorific rays\" were later termed infrared.\nIn 1801, German physicist Johann Wilhelm Ritter discovered ultraviolet in an experiment similar to Herschel's, using sunlight and a glass prism. Ritter noted that invisible rays near the violet edge of a solar spectrum dispersed by a triangular prism darkened silver chloride preparations more quickly than did the nearby violet light. Ritter's experiments were an early precursor to what would become photography. Ritter noted that the ultraviolet rays (which at first were called \"chemical rays\") were capable of causing chemical reactions.\nIn 1862\u201364 James Clerk Maxwell developed equations for the electromagnetic field which suggested that waves in the field would travel with a speed that was very close to the known speed of light. Maxwell therefore suggested that visible light (as well as invisible infrared and ultraviolet rays by inference) all consisted of propagating disturbances (or radiation) in the electromagnetic field. Radio waves were first produced deliberately by Heinrich Hertz in 1887, using electrical circuits calculated to produce oscillations at a much lower frequency than that of visible light, following recipes for producing oscillating charges and currents suggested by Maxwell's equations. Hertz also developed ways to detect these waves, and produced and characterized what were later termed radio waves and microwaves.\nWilhelm R\u00f6ntgen discovered and named X-rays. After experimenting with high voltages applied to an evacuated tube on 8 November 1895, he noticed a fluorescence on a nearby plate of coated glass. In one month, he discovered X-rays' main properties.\nThe last portion of the EM spectrum to be discovered was associated with radioactivity. Henri Becquerel found that uranium salts caused fogging of an unexposed photographic plate through a covering paper in a manner similar to X-rays, and Marie Curie discovered that only certain elements gave off these rays of energy, soon discovering the intense radiation of radium. The radiation from pitchblende was differentiated into alpha rays (alpha particles) and beta rays (beta particles) by Ernest Rutherford through simple experimentation in 1899, but these proved to be charged particulate types of radiation. However, in 1900 the French scientist Paul Villard discovered a third neutrally charged and especially penetrating type of radiation from radium, and after he described it, Rutherford realized it must be yet a third type of radiation, which in 1903 Rutherford named gamma rays. In 1910 British physicist William Henry Bragg demonstrated that gamma rays are electromagnetic radiation, not particles, and in 1914 Rutherford and Edward Andrade measured their wavelengths, finding that they were similar to X-rays but with shorter wavelengths and higher frequency, although a 'cross-over' between X and gamma rays makes it possible to have X-rays with a higher energy (and hence shorter wavelength) than gamma rays and vice versa. The origin of the ray differentiates them, gamma rays tend to be natural phenomena originating from the unstable nucleus of an atom and X-rays are electrically generated (and hence man-made) unless they are as a result of bremsstrahlung X-radiation caused by the interaction of fast moving particles (such as beta particles) colliding with certain materials, usually of higher atomic numbers.\nElectromagnetic spectrum.\nEM radiation (the designation 'radiation' excludes static electric and magnetic and near fields) is classified by wavelength into radio, microwave, infrared, visible, ultraviolet, X-rays and gamma rays. Arbitrary electromagnetic waves can be expressed by Fourier analysis in terms of sinusoidal monochromatic waves, which in turn can each be classified into these regions of the EMR spectrum.\nFor certain classes of EM waves, the waveform is most usefully treated as \"random\", and then spectral analysis must be done by slightly different mathematical techniques appropriate to random or stochastic processes. In such cases, the individual frequency components are represented in terms of their \"power\" content, and the phase information is not preserved. Such a representation is called the power spectral density of the random process. Random electromagnetic radiation requiring this kind of analysis is, for example, encountered in the interior of stars, and in certain other very wideband forms of radiation such as the Zero point wave field of the electromagnetic vacuum.\nThe behavior of EM radiation and its interaction with matter depends on its frequency, and changes qualitatively as the frequency changes. Lower frequencies have longer wavelengths, and higher frequencies have shorter wavelengths, and are associated with photons of higher energy. There is no fundamental limit known to these wavelengths or energies, at either end of the spectrum, although photons with energies near the Planck energy or exceeding it (far too high to have ever been observed) will require new physical theories to describe.\nRadio and microwave.\nRadio waves have the least amount of energy and the lowest frequency. When radio waves impinge upon a conductor, they couple to the conductor, travel along it and induce an electric current on the conductor surface by moving the electrons of the conducting material in correlated bunches of charge. Such effects can cover macroscopic distances in conductors (such as radio antennas), since the wavelength of radiowaves is long.\nElectromagnetic radiation phenomena with wavelengths ranging from as long as one meter to as short as one millimeter are called microwaves; with frequencies between 300\u00a0MHz (0.3\u00a0GHz) and 300\u00a0GHz.\nAt radio and microwave frequencies, EMR interacts with matter largely as a bulk collection of charges which are spread out over large numbers of affected atoms. In electrical conductors, such induced bulk movement of charges (electric currents) results in absorption of the EMR, or else separations of charges that cause generation of new EMR (effective reflection of the EMR). An example is absorption or emission of radio waves by antennas, or absorption of microwaves by water or other molecules with an electric dipole moment, as for example inside a microwave oven. These interactions produce either electric currents or heat, or both.\nInfrared.\nLike radio and microwave, infrared (IR) also is reflected by metals (and also most EMR, well into the ultraviolet range). However, unlike lower-frequency radio and microwave radiation, Infrared EMR commonly interacts with dipoles present in single molecules, which change as atoms vibrate at the ends of a single chemical bond. It is consequently absorbed by a wide range of substances, causing them to increase in temperature as the vibrations dissipate as heat. The same process, run in reverse, causes bulk substances to radiate in the infrared spontaneously (see thermal radiation section below).\nInfrared radiation is divided into spectral subregions. While different subdivision schemes exist, the spectrum is commonly divided as near-infrared (0.75\u20131.4 \u03bcm), short-wavelength infrared (1.4\u20133 \u03bcm), mid-wavelength infrared (3\u20138 \u03bcm), long-wavelength infrared (8\u201315 \u03bcm) and far infrared (15\u20131000 \u03bcm).\nVisible light.\nNatural sources produce EM radiation across the spectrum. EM radiation with a wavelength between approximately 400 nm and 700\u00a0nm is directly detected by the human eye and perceived as visible light. Other wavelengths, especially nearby infrared (longer than 700\u00a0nm) and ultraviolet (shorter than 400\u00a0nm) are also sometimes referred to as light.\nAs frequency increases into the visible range, photons have enough energy to change the bond structure of some individual molecules. It is not a coincidence that this happens in the visible range, as the mechanism of vision involves the change in bonding of a single molecule, retinal, which absorbs a single photon. The change in retinal, causes a change in the shape of the rhodopsin protein it is contained in, which starts the biochemical process that causes the retina of the human eye to sense the light.\nPhotosynthesis becomes possible in this range as well, for the same reason. A single molecule of chlorophyll is excited by a single photon. In plant tissues that conduct photosynthesis, carotenoids act to quench electronically excited chlorophyll produced by visible light in a process called non-photochemical quenching, in order to prevent reactions that would otherwise interfere with photosynthesis at high light levels.\nAnimals that detect infrared make use of small packets of water that change temperature, in an essentially thermal process that involves many photons.\nInfrared, microwaves and radio waves are known to damage molecules and biological tissue only by bulk heating, not excitation from single photons of the radiation.\nVisible light is able to affect only a tiny percentage of all molecules. Usually not in a permanent or damaging way, rather the photon excites an electron which then emits another photon when returning to its original position. This is the source of color produced by most dyes. Retinal is an exception. When a photon is absorbed the retinal permanently changes structure from cis to trans, and requires a protein to convert it back, i.e. reset it to be able to function as a light detector again.\nLimited evidence indicate that some reactive oxygen species are created by visible light in skin, and that these may have some role in photoaging, in the same manner as ultraviolet A.\nUltraviolet.\nAs frequency increases into the ultraviolet, photons now carry enough energy (about three electron volts or more) to excite certain doubly bonded molecules into permanent chemical rearrangement. In DNA, this causes lasting damage. DNA is also indirectly damaged by reactive oxygen species produced by ultraviolet A (UVA), which has energy too low to damage DNA directly. This is why ultraviolet at all wavelengths can damage DNA, and is capable of causing cancer, and (for UVB) skin burns (sunburn) that are far worse than would be produced by simple heating (temperature increase) effects. This property of causing molecular damage that is out of proportion to heating effects, is characteristic of all EMR with frequencies at the visible light range and above. These properties of high-frequency EMR are due to quantum effects that permanently damage materials and tissues at the molecular level.\nAt the higher end of the ultraviolet range, the energy of photons becomes large enough to impart enough energy to electrons to cause them to be liberated from the atom, in a process called photoionisation. The energy required for this is always larger than about 10 electron volt (eV) corresponding with wavelengths smaller than 124\u00a0nm (some sources suggest a more realistic cutoff of 33\u00a0eV, which is the energy required to ionize water). This high end of the ultraviolet spectrum with energies in the approximate ionization range, is sometimes called \"extreme UV.\" Ionizing UV is strongly filtered by the Earth's atmosphere.\nX-rays and gamma rays.\nElectromagnetic radiation composed of photons that carry minimum-ionization energy, or more, (which includes the entire spectrum with shorter wavelengths), is therefore termed ionizing radiation. (Many other kinds of ionizing radiation are made of non-EM particles). Electromagnetic-type ionizing radiation extends from the extreme ultraviolet to all higher frequencies and shorter wavelengths, which means that all X-rays and gamma rays qualify. These are capable of the most severe types of molecular damage, which can happen in biology to any type of biomolecule, including mutation and cancer, and often at great depths below the skin, since the higher end of the X-ray spectrum, and all of the gamma ray spectrum, penetrate matter.\nAtmosphere and magnetosphere.\nMost UV and X-rays are blocked by absorption first from molecular nitrogen, and then (for wavelengths in the upper UV) from the electronic excitation of dioxygen and finally ozone at the mid-range of UV. Only 30% of the Sun's ultraviolet light reaches the ground, and almost all of this is well transmitted.\nVisible light is well transmitted in air, as it is not energetic enough to excite nitrogen, oxygen, or ozone, but too energetic to excite molecular vibrational frequencies of water vapor.\nAbsorption bands in the infrared are due to modes of vibrational excitation in water vapor. However, at energies too low to excite water vapor, the atmosphere becomes transparent again, allowing free transmission of most microwave and radio waves.\nFinally, at radio wavelengths longer than 10 meters or so (about 30\u00a0MHz), the air in the lower atmosphere remains transparent to radio, but plasma in certain layers of the ionosphere begins to interact with radio waves (see skywave). This property allows some longer wavelengths (100 meters or 3\u00a0MHz) to be reflected and results in shortwave radio beyond line-of-sight. However, certain ionospheric effects begin to block incoming radiowaves from space, when their frequency is less than about 10\u00a0MHz (wavelength longer than about 30 meters).\nThermal and electromagnetic radiation as a form of heat.\nThe basic structure of matter involves charged particles bound together. When electromagnetic radiation impinges on matter, it causes the charged particles to oscillate and gain energy. The ultimate fate of this energy depends on the context. It could be immediately re-radiated and appear as scattered, reflected, or transmitted radiation. It may get dissipated into other microscopic motions within the matter, coming to thermal equilibrium and manifesting itself as thermal energy, or even kinetic energy, in the material. With a few exceptions related to high-energy photons (such as fluorescence, harmonic generation, photochemical reactions, the photovoltaic effect for ionizing radiations at far ultraviolet, X-ray and gamma radiation), absorbed electromagnetic radiation simply deposits its energy by heating the material. This happens for infrared, microwave and radio wave radiation. Intense radio waves can thermally burn living tissue and can cook food. In addition to infrared lasers, sufficiently intense visible and ultraviolet lasers can easily set paper afire.\nIonizing radiation creates high-speed electrons in a material and breaks chemical bonds, but after these electrons collide many times with other atoms eventually most of the energy becomes thermal energy all in a tiny fraction of a second. This process makes ionizing radiation far more dangerous per unit of energy than non-ionizing radiation. This caveat also applies to UV, even though almost all of it is not ionizing, because UV can damage molecules due to electronic excitation, which is far greater per unit energy than heating effects.\nInfrared radiation in the spectral distribution of a black body is usually considered a form of heat, since it has an equivalent temperature and is associated with an entropy change per unit of thermal energy. However, \"heat\" is a technical term in physics and thermodynamics and is often confused with thermal energy. Any type of electromagnetic energy can be transformed into thermal energy in interaction with matter. Thus, \"any\" electromagnetic radiation can \"heat\" (in the sense of increase the thermal energy temperature of) a material, when it is absorbed.\nThe inverse or time-reversed process of absorption is thermal radiation. Much of the thermal energy in matter consists of random motion of charged particles, and this energy can be radiated away from the matter. The resulting radiation may subsequently be absorbed by another piece of matter, with the deposited energy heating the material.\nThe electromagnetic radiation in an opaque cavity at thermal equilibrium is effectively a form of thermal energy, having maximum radiation entropy.\nBiological effects.\nBioelectromagnetics is the study of the interactions and effects of EM radiation on living organisms. The effects of electromagnetic radiation upon living cells, including those in humans, depends upon the radiation's power and frequency. For low-frequency radiation (radio waves to visible light) the best-understood effects are those due to radiation power alone, acting through heating when radiation is absorbed. For these thermal effects, frequency is important as it affects the intensity of the radiation and penetration into the organism (for example, microwaves penetrate better than infrared). It is widely accepted that low frequency fields that are too weak to cause significant heating could not possibly have any biological effect.\nDespite the commonly accepted results, some research has been conducted to show that weaker \"non-thermal\" electromagnetic fields, (including weak ELF magnetic fields, although the latter does not strictly qualify as EM radiation), and modulated RF and microwave fields have biological effects. Fundamental mechanisms of the interaction between biological material and electromagnetic fields at non-thermal levels are not fully understood.\nThe World Health Organization has classified radio frequency electromagnetic radiation as Group 2B - possibly carcinogenic. This group contains possible carcinogens such as lead, DDT, and styrene. For example, epidemiological studies looking for a relationship between cell phone use and brain cancer development, have been largely inconclusive, save to demonstrate that the effect, if it exists, cannot be a large one.\nAt higher frequencies (visible and beyond), the effects of individual photons begin to become important, as these now have enough energy individually to directly or indirectly damage biological molecules. All UV frequences have been classed as Group 1 carcinogens by the World Health Organization. Ultraviolet radiation from sun exposure is the primary cause of skin cancer.\nThus, at UV frequencies and higher (and probably somewhat also in the visible range), electromagnetic radiation does more damage to biological systems than simple heating predicts. This is most obvious in the \"far\" (or \"extreme\") ultraviolet. UV, with X-ray and gamma radiation, are referred to as ionizing radiation due to the ability of photons of this radiation to produce ions and free radicals in materials (including living tissue). Since such radiation can severely damage life at energy levels that produce little heating, it is considered far more dangerous (in terms of damage-produced per unit of energy, or power) than the rest of the electromagnetic spectrum.\nUse as weapon.\nThe heat ray is an application of EMR that makes use of microwave frequencies to create an unpleasant heating effect in the upper layer of the skin. A publicly known heat ray weapon called the Active Denial System was developed by the US military as an experimental weapon to deny the enemy access to an area. A death ray is a theoretical weapon that delivers heat ray based on electromagnetic energy at levels that are capable of injuring human tissue. An inventor of a death ray, Harry Grindell Matthews, claimed to have lost sight in his left eye while working on his death ray weapon based on a microwave magnetron from the 1920s (a normal microwave oven creates a tissue damaging cooking effect inside the oven at around 2 kV/m). \nDerivation from electromagnetic theory.\nElectromagnetic waves are predicted by the classical laws of electricity and magnetism, known as Maxwell's equations. There are nontrivial solutions of the homogeneous Maxwell's equations (without charges or currents), describing \"waves\" of changing electric and magnetic fields. Beginning with Maxwell's equations in free space:\nBesides the trivial solution\nuseful solutions can be derived with the following vector identity, valid for all vectors formula_16 in some vector field:\nTaking the curl of the second Maxwell equation () yields:\nEvaluating the left hand side of () with the above identity and simplifying using (), yields:\nEvaluating the right hand side of () by exchanging the sequence of derivations and inserting the fourth yields:\nCombining () and () again, gives a vector-valued differential equation for the electric field, solving the homogeneous Maxwell equations:\nTaking the curl of the fourth Maxwell equation () results in a similar differential equation for a magnetic field solving the homogeneous Maxwell equations:\nBoth differential equations have the form of the general wave equation for waves propagating with speed formula_18 where formula_19 is a function of time and location, which gives the amplitude of the wave at some time at a certain location:\nfor a generic wave traveling in the formula_24 direction.\nFrom the first of Maxwell's equations, we get\nThus,\nwhich implies that the electric field is orthogonal to the direction the wave propagates. The second of Maxwell's equations yields the magnetic field, namely,\nThus,\nThe remaining equations will be satisfied by this choice of formula_29.\nThe electric and magnetic field waves in the far-field travel at the speed of light. They have a special restricted orientation and proportional magnitudes, formula_30, which can be seen immediately from the Poynting vector. The electric field, magnetic field, and direction of wave propagation are all orthogonal, and the wave propagates in the same direction as formula_31. Also, E and B far-fields in free space, which as wave solutions depend primarily on these two Maxwell equations, are in-phase with each other. This is guaranteed since the generic wave solution is first order in both space and time, and the curl operator on one side of these equations results in first-order spatial derivatives of the wave solution, while the time-derivative on the other side of the equations, which gives the other field, is first-order in time, resulting in the same phase shift for both fields in each mathematical operation.\nFrom the viewpoint of an electromagnetic wave traveling forward, the electric field might be oscillating up and down, while the magnetic field oscillates right and left. This picture can be rotated with the electric field oscillating right and left and the magnetic field oscillating down and up. This is a different solution that is traveling in the same direction. This arbitrariness in the orientation with respect to propagation direction is known as polarization. On a quantum level, it is described as photon polarization. The direction of the polarization is defined as the direction of the electric field.\nMore general forms of the second-order wave equations given above are available, allowing for both non-vacuum propagation media and sources. Many competing derivations exist, all with varying levels of approximation and intended applications. One very general example is a form of the electric field equation, which was factorized into a pair of explicitly directional wave equations, and then efficiently reduced into a single uni-directional wave equation by means of a simple slow-evolution approximation."}
{"id": "9428", "revid": "32647130", "url": "https://en.wikipedia.org/wiki?curid=9428", "title": "Ernest Hemingway", "text": "Ernest Miller Hemingway (July 21, 1899\u00a0\u2013 July 2, 1961) was an American novelist, short-story writer, journalist, and sportsman. His economical and understated style\u2014which he termed the iceberg theory\u2014had a strong influence on 20th-century fiction, while his adventurous lifestyle and his public image brought him admiration from later generations. Hemingway produced most of his work between the mid-1920s and the mid-1950s, and he was awarded the Nobel Prize in Literature in 1954. He published seven novels, six short-story collections, and two nonfiction works. Three of his novels, four short-story collections, and three nonfiction works were published posthumously. Many of his works are considered classics of American literature.\nHemingway was raised in Oak Park, Illinois. After high school, he was a reporter for a few months for \"The Kansas City Star\" before leaving for the Italian Front to enlist as an ambulance driver in World War I. In 1918, he was seriously wounded and returned home. His wartime experiences formed the basis for his novel \"A Farewell to Arms\" (1929).\nIn 1921, Hemingway married Hadley Richardson, the first of four wives. They moved to Paris where he worked as a foreign correspondent and fell under the influence of the modernist writers and artists of the 1920s' \"Lost Generation\" expatriate community. His debut novel \"The Sun Also Rises\" was published in 1926. He divorced Richardson in 1927. He married Pauline Pfeiffer. They divorced after he returned from the Spanish Civil War (1936\u20131939), which he covered as a journalist and which was the basis for his novel \"For Whom the Bell Tolls\" (1940). Martha Gellhorn became his third wife in 1940. He and Gellhorn separated after he met Mary Welsh in London during World War II. Hemingway was present with Allied troops as a journalist at the Normandy landings and the liberation of Paris.\nHemingway maintained permanent residences in Key West, Florida (in the 1930s) and in Cuba (in the 1940s and 1950s). He almost died in 1954 after plane crashes on successive days, with injuries leaving him in pain and ill health for much of the rest of his life. In 1959 he bought a house in Ketchum, Idaho where, in mid-1961, he died by suicide with a shotgun.\nLife.\nEarly life.\nErnest Miller Hemingway was born on July 21, 1899, in Oak Park, Illinois, an affluent suburb just west of Chicago, to Clarence Edmonds Hemingway, a physician, and Grace Hall Hemingway, a musician. His parents were well-educated and well-respected in Oak Park, a conservative community about which resident Frank Lloyd Wright said, \"So many churches for so many good people to go to.\" When Clarence and Grace Hemingway married in 1896, they lived with Grace's father, Ernest Miller Hall, after whom they named their first son, the second of their six children. His sister Marcelline preceded him in 1898, followed by Ursula in 1902, Madelaine in 1904, Carol in 1911, and Leicester in 1915. Grace followed the Victorian convention of not differentiating children's clothing by gender. With only a year separating the two, Ernest and Marcelline resembled one-another strongly. Grace wanted them to appear as twins, so in Ernest's first three years she kept his hair long and dressed both children in similarly frilly feminine clothing.\nHemingway's mother, a well-known musician in the village, taught her son to play the cello despite his refusal to learn; though later in life he admitted the music lessons contributed to his writing style, evidenced for example in the \"contrapuntal structure\" of \"For Whom the Bell Tolls\". As an adult Hemingway professed to hate his mother, although biographer Michael S. Reynolds points out that he shared similar energies and enthusiasms.\nEach summer the family traveled to Windemere on Walloon Lake, near Petoskey, Michigan. There young Ernest joined his father and learned to hunt, fish, and camp in the woods and lakes of Northern Michigan, early experiences that instilled a life-long passion for outdoor adventure and living in remote or isolated areas.\nHemingway attended Oak Park and River Forest High School in Oak Park from 1913 until 1917. He was a good athlete, involved with a number of sports\u2014boxing, track and field, water polo, and football; performed in the school orchestra for two years with his sister Marcelline; and received good grades in English classes. During his last two years at high school he edited the \"Trapeze\" and \"Tabula\" (the school's newspaper and yearbook), where he imitated the language of sportswriters and used the pen name Ring Lardner Jr.\u2014a nod to Ring Lardner of the \"Chicago Tribune\" whose byline was \"Line O'Type\". Like Mark Twain, Stephen Crane, Theodore Dreiser, and Sinclair Lewis, Hemingway was a journalist before becoming a novelist. After leaving high school he went to work for \"The Kansas City Star\" as a cub reporter. Although he stayed there for only six months, he relied on the \"Star\"s style guide as a foundation for his writing: \"Use short sentences. Use short first paragraphs. Use vigorous English. Be positive, not negative.\"\nWorld War I.\nIn December 1917, after being rejected by the U.S. Army for poor eyesight, Hemingway responded to a Red Cross recruitment effort and signed on to be an ambulance driver in Italy, In May 1918, he sailed from New York, and arrived in Paris as the city was under bombardment from German artillery. That June he arrived at the Italian Front. On his first day in Milan, he was sent to the scene of a munitions factory explosion to join rescuers retrieving the shredded remains of female workers. He described the incident in his 1932 non-fiction book \"Death in the Afternoon\": \"I remember that after we searched quite thoroughly for the complete dead we collected fragments.\" A few days later, he was stationed at Fossalta di Piave.\nOn July 8, he was seriously wounded by mortar fire, having just returned from the canteen bringing chocolate and cigarettes for the men at the front line. Despite his wounds, Hemingway assisted Italian soldiers to safety, for which he was decorated with the Italian War Merit Cross, the \"Croce al Merito di Guerra\". He was still only 18 at the time. Hemingway later said of the incident: \"When you go to war as a boy you have a great illusion of immortality. Other people get killed; not you\u00a0... Then when you are badly wounded the first time you lose that illusion and you know it can happen to you.\" He sustained severe shrapnel wounds to both legs, underwent an immediate operation at a distribution center, and spent five days at a field hospital before he was transferred for recuperation to the Red Cross hospital in Milan. He spent six months at the hospital, where he met and formed a strong friendship with \"Chink\" Dorman-Smith that lasted for decades and shared a room with future American foreign service officer, ambassador, and author Henry Serrano Villard.\nWhile recuperating he fell in love with Agnes von Kurowsky, a Red Cross nurse seven years his senior. When Hemingway returned to the United States in January 1919, he believed Agnes would join him within months and the two would marry. Instead, he received a letter in March with her announcement that she was engaged to an Italian officer. Biographer Jeffrey Meyers writes Agnes's rejection devastated and scarred the young man; in future relationships, Hemingway followed a pattern of abandoning a wife before she abandoned him.\nToronto and Chicago.\nHemingway returned home early in 1919 to a time of readjustment. Before the age of 20, he had gained from the war a maturity that was at odds with living at home without a job and with the need for recuperation. As Reynolds explains, \"Hemingway could not really tell his parents what he thought when he saw his bloody knee.\" He was not able to tell them how scared he had been \"in another country with surgeons who could not tell him in English if his leg was coming off or not.\"\nIn September, he took a fishing and camping trip with high school friends to the back-country of Michigan's Upper Peninsula. The trip became the inspiration for his short story \"Big Two-Hearted River\", in which the semi-autobiographical character Nick Adams takes to the country to find solitude after returning from war. A family friend offered him a job in Toronto, and with nothing else to do, he accepted. Late that year he began as a freelancer and staff writer for the \"Toronto Star Weekly\". He returned to Michigan the following June and then moved to Chicago in September 1920 to live with friends, while still filing stories for the \"Toronto Star\". In Chicago, he worked as an associate editor of the monthly journal \"Cooperative Commonwealth\", where he met novelist Sherwood Anderson.\nWhen St. Louis native Hadley Richardson came to Chicago to visit the sister of Hemingway's roommate, Hemingway became infatuated. He later claimed, \"I knew she was the girl I was going to marry.\" Hadley, red-haired, with a \"nurturing instinct,\" was eight years older than Hemingway. Despite the age difference, Hadley, who had grown up with an overprotective mother, seemed less mature than usual for a young woman her age. Bernice Kert, author of \"The Hemingway Women\", claims Hadley was \"evocative\" of Agnes, but that Hadley had a childishness that Agnes lacked. The two corresponded for a few months and then decided to marry and travel to Europe. They wanted to visit Rome, but Sherwood Anderson convinced them to visit Paris instead, writing letters of introduction for the young couple. They were married on September 3, 1921; two months later, Hemingway was hired as a foreign correspondent for the \"Toronto Star\", and the couple left for Paris. Of Hemingway's marriage to Hadley, Meyers claims: \"With Hadley, Hemingway achieved everything he had hoped for with Agnes: the love of a beautiful woman, a comfortable income, a life in Europe.\"\nParis.\nCarlos Baker, Hemingway's first biographer, believes that while Anderson suggested Paris because \"the monetary exchange rate\" made it an inexpensive place to live, more importantly, it was where \"the most interesting people in the world\" lived. In Paris, Hemingway met American writer and art collector Gertrude Stein, Irish novelist James Joyce, American poet Ezra Pound (who \"could help a young writer up the rungs of a career\") and other writers.\nThe Hemingway of the early Paris years was a \"tall, handsome, muscular, broad-shouldered, brown-eyed, rosy-cheeked, square-jawed, soft-voiced young man.\" He and Hadley lived in a small walk-up at 74 rue du Cardinal Lemoine in the Latin Quarter, and he worked in a rented room in a nearby building. Stein, who was the bastion of modernism in Paris, became Hemingway's mentor and godmother to his son Jack; she introduced him to the expatriate artists and writers of the Montparnasse Quarter, whom she referred to as the \"Lost Generation\"\u2014a term Hemingway popularized with the publication of \"The Sun Also Rises\". A regular at Stein's salon, Hemingway met influential painters such as Pablo Picasso, Joan Mir\u00f3, and Juan Gris. He eventually withdrew from Stein's influence and their relationship deteriorated into a literary quarrel that spanned decades. Ezra Pound met Hemingway by chance at Sylvia Beach's bookshop Shakespeare and Company in 1922. The two toured Italy in 1923 and lived on the same street in 1924. They forged a strong friendship, and in Hemingway, Pound recognized and fostered a young talent. Pound introduced Hemingway to James Joyce, with whom Hemingway frequently embarked on \"alcoholic sprees\".\nDuring his first 20 months in Paris, Hemingway filed 88 stories for the \"Toronto Star\" newspaper. He covered the Greco-Turkish War, where he witnessed the burning of Smyrna, and wrote travel pieces such as \"Tuna Fishing in Spain\" and \"Trout Fishing All Across Europe: Spain Has the Best, Then Germany\". He described also the retreat of the Greek army with civilians from East Thrace.\nHemingway was devastated on learning that Hadley had lost a suitcase filled with his manuscripts at the Gare de Lyon as she was traveling to Geneva to meet him in December 1922. The following September, the couple returned to Toronto, where their son John Hadley Nicanor was born on October 10, 1923. During their absence, Hemingway's first book, \"Three Stories and Ten Poems\", was published. Two of the stories it contained were all that remained after the loss of the suitcase, and the third had been written early the previous year in Italy. Within months a second volume, \"in our time\" (without capitals), was published. The small volume included six vignettes and a dozen stories Hemingway had written the previous summer during his first visit to Spain, where he discovered the thrill of the \"corrida\". He missed Paris, considered Toronto boring, and wanted to return to the life of a writer, rather than live the life of a journalist.\nHemingway, Hadley and their son (nicknamed Bumby) returned to Paris in January 1924 and moved into a new apartment on the rue Notre-Dame des Champs. Hemingway helped Ford Madox Ford edit \"The Transatlantic Review\", which published works by Pound, John Dos Passos, Baroness Elsa von Freytag-Loringhoven, and Stein, as well as some of Hemingway's own early stories such as \"Indian Camp\". When \"In Our Time\" was published in 1925, the dust jacket bore comments from Ford. \"Indian Camp\" received considerable praise; Ford saw it as an important early story by a young writer, and critics in the United States praised Hemingway for reinvigorating the short story genre with his crisp style and use of declarative sentences. Six months earlier, Hemingway had met F. Scott Fitzgerald, and the pair formed a friendship of \"admiration and hostility\". Fitzgerald had published \"The Great Gatsby\" the same year: Hemingway read it, liked it, and decided his next work had to be a novel.\nWith his wife Hadley, Hemingway first visited the Festival of San Ferm\u00edn in Pamplona, Spain, in 1923, where he became fascinated by bullfighting. It is at this time that he began to be referred to as \"Papa\", even by much older friends. Hadley would much later recall that Hemingway had his own nicknames for everyone and that he often did things for his friends; she suggested that he liked to be looked up to. She didn't remember precisely how the nickname came into being; however, it certainly stuck. The Hemingways returned to Pamplona in 1924 and a third time in June 1925; that year they brought with them a group of American and British expatriates: Hemingway's Michigan boyhood friend Bill Smith, Donald Ogden Stewart, Lady Duff Twysden (recently divorced), her lover Pat Guthrie, and Harold Loeb. A few days after the fiesta ended, on his birthday (July 21), he began to write the draft of what would become \"The Sun Also Rises\", finishing eight weeks later. A few months later, in December 1925, the Hemingways left to spend the winter in Schruns, Austria, where Hemingway began revising the manuscript extensively. Pauline Pfeiffer joined them in January and against Hadley's advice, urged Hemingway to sign a contract with Scribner's. He left Austria for a quick trip to New York to meet with the publishers, and on his return, during a stop in Paris, began an affair with Pfeiffer, before returning to Schruns to finish the revisions in March. The manuscript arrived in New York in April; he corrected the final proof in Paris in August 1926, and Scribner's published the novel in October.\n\"The Sun Also Rises\" epitomized the post-war expatriate generation, received good reviews and is \"recognized as Hemingway's greatest work\". Hemingway himself later wrote to his editor Max Perkins that the \"point of the book\" was not so much about a generation being lost, but that \"the earth abideth forever\"; he believed the characters in \"The Sun Also Rises\" may have been \"battered\" but were not lost.\nHemingway's marriage to Hadley deteriorated as he was working on \"The Sun Also Rises\". In early 1926, Hadley became aware of his affair with Pfeiffer, who came to Pamplona with them that July. On their return to Paris, Hadley asked for a separation; in November she formally requested a divorce. They split their possessions while Hadley accepted Hemingway's offer of the proceeds from \"The Sun Also Rises\". The couple were divorced in January 1927, and Hemingway married Pfeiffer in May.\nPfeiffer, who was from a wealthy Catholic Arkansas family, had moved to Paris to work for \"Vogue\" magazine. Before their marriage, Hemingway converted to Catholicism. They honeymooned in Le Grau-du-Roi, where he contracted anthrax, and he planned his next collection of short stories, \"Men Without Women\", which was published in October 1927, and included his boxing story \"Fifty Grand\". \"Cosmopolitan\" magazine editor-in-chief Ray Long praised \"Fifty Grand\", calling it, \"one of the best short stories that ever came to my hands\u00a0... the best prize-fight story I ever read\u00a0... a remarkable piece of realism.\"\nBy the end of the year Pauline, who was pregnant, wanted to move back to America. John Dos Passos recommended Key West, and they left Paris in March 1928. Hemingway suffered a severe injury in their Paris bathroom when he pulled a skylight down on his head thinking he was pulling on a toilet chain. This left him with a prominent forehead scar, which he carried for the rest of his life. When Hemingway was asked about the scar, he was reluctant to answer. After his departure from Paris, Hemingway \"never again lived in a big city\".\nKey West and the Caribbean.\nHemingway and Pauline traveled to Kansas City, where their son Patrick was born on June 28, 1928. Pauline had a difficult delivery; Hemingway fictionalized a version of the event as a part of \"A Farewell to Arms\". After Patrick's birth, Pauline and Hemingway traveled to Wyoming, Massachusetts, and New York. In the winter, he was in New York with Bumby, about to board a train to Florida, when he received a cable telling him that his father had killed himself. Hemingway was devastated, having earlier written to his father telling him not to worry about financial difficulties; the letter arrived minutes after the suicide. He realized how Hadley must have felt after her own father's suicide in 1903, and he commented, \"I'll probably go the same way.\"\nUpon his return to Key West in December, Hemingway worked on the draft of \"A Farewell to Arms\" before leaving for France in January. He had finished it in August but delayed the revision. The serialization in \"Scribner's Magazine\" was scheduled to begin in May, but as late as April, Hemingway was still working on the ending, which he may have rewritten as many as seventeen times. The completed novel was published on September 27. Biographer James Mellow believes \"A Farewell to Arms\" established Hemingway's stature as a major American writer and displayed a level of complexity not apparent in \"The Sun Also Rises\".(The story was turned into a play by war veteran Laurence Stallings which was the basis for the film starring Gary Cooper.) In Spain in mid-1929, Hemingway researched his next work, \"Death in the Afternoon\". He wanted to write a comprehensive treatise on bullfighting, explaining the \"toreros\" and \"corridas\" complete with glossaries and appendices, because he believed bullfighting was \"of great tragic interest, being literally of life and death.\"\nDuring the early 1930s, Hemingway spent his winters in Key West and summers in Wyoming, where he found \"the most beautiful country he had seen in the American West\" and hunted deer, elk, and grizzly bear. He was joined there by Dos Passos, and in November 1930, after bringing Dos Passos to the train station in Billings, Montana, Hemingway broke his arm in a car accident. The surgeon tended the compound spiral fracture and bound the bone with kangaroo tendon. Hemingway was hospitalized for seven weeks, with Pauline tending to him; the nerves in his writing hand took as long as a year to heal, during which time he suffered intense pain.\nHis third son, Gregory Hancock Hemingway, was born a year later on November 12, 1931, in Kansas City. Pauline's uncle bought the couple a house in Key West with a carriage house, the second floor of which was converted into a writing studio. While in Key West, Hemingway frequented the local bar Sloppy Joe's. He invited friends\u2014including Waldo Peirce, Dos Passos, and Max Perkins\u2014to join him on fishing trips and on an all-male expedition to the Dry Tortugas. Meanwhile, he continued to travel to Europe and to Cuba, and\u2014although in 1933 he wrote of Key West, \"We have a fine house here, and kids are all well\"\u2014Mellow believes he \"was plainly restless\".\nIn 1933, Hemingway and Pauline went on safari to Kenya. The 10-week trip provided material for \"Green Hills of Africa\", as well as for the short stories \"The Snows of Kilimanjaro\" and \"The Short Happy Life of Francis Macomber\". The couple visited Mombasa, Nairobi, and Machakos in Kenya; then moved on to Tanganyika Territory, where they hunted in the Serengeti, around Lake Manyara, and west and southeast of present-day Tarangire National Park. Their guide was the noted \"white hunter\" Philip Percival who had guided Theodore Roosevelt on his 1909 safari. During these travels, Hemingway contracted amoebic dysentery that caused a prolapsed intestine, and he was evacuated by plane to Nairobi, an experience reflected in \"The Snows of Kilimanjaro\". On Hemingway's return to Key West in early 1934, he began work on \"Green Hills of Africa\", which he published in 1935 to mixed reviews.\nHemingway bought a boat in 1934, named it the \"Pilar\", and began sailing the Caribbean. In 1935 he first arrived at Bimini, where he spent a considerable amount of time. During this period he also worked on \"To Have and Have Not\", published in 1937 while he was in Spain, the only novel he wrote during the 1930s.\nSpanish Civil War.\nIn 1937, Hemingway left for Spain to cover the Spanish Civil War for the North American Newspaper Alliance (NANA), despite Pauline's reluctance to have him working in a war zone. He and Dos Passos both signed on to work with Dutch filmmaker Joris Ivens as screenwriters for \"The Spanish Earth\". Dos Passos left the project after the execution of Jos\u00e9 Robles, his friend and Spanish translator, which caused a rift between the two writers.\nHemingway was joined in Spain by journalist and writer Martha Gellhorn, who he had met in Key West a year earlier. Like Hadley, Martha was a St. Louis native, and like Pauline, she had worked for \"Vogue\" in Paris. Of Martha, Kert explains, \"she never catered to him the way other women did\". In July 1937 he attended the Second International Writers' Congress, the purpose of which was to discuss the attitude of intellectuals to the war, held in Valencia, Barcelona and Madrid and attended by many writers including Andr\u00e9 Malraux, Stephen Spender and Pablo Neruda. Late in 1937, while in Madrid with Martha, Hemingway wrote his only play, \"The Fifth Column\", as the city was being bombarded by Francoist forces. He returned to Key West for a few months, then back to Spain twice in 1938, where he was present at the Battle of the Ebro, the last republican stand, and he was among the British and American journalists who were some of the last to leave the battle as they crossed the river.\nCuba.\nIn early 1939, Hemingway crossed to Cuba in his boat to live in the Hotel Ambos Mundos in Havana. This was the separation phase of a slow and painful split from Pauline, which began when Hemingway met Martha Gellhorn. Martha soon joined him in Cuba, and they rented \"Finca Vig\u00eda\" (\"Lookout Farm\"), a property from Havana. Pauline and the children left Hemingway that summer, after the family was reunited during a visit to Wyoming; when his divorce from Pauline was finalized, he and Martha were married on November 20, 1940 in Cheyenne, Wyoming.\nHemingway moved his primary summer residence to Ketchum, Idaho, just outside the newly built resort of Sun Valley, and moved his winter residence to Cuba. He had been disgusted when a Parisian friend allowed his cats to eat from the table, but he became enamored of cats in Cuba and kept dozens of them on the property. Descendants of his cats live at his Key West home.\nGellhorn inspired him to write his most famous novel \"For Whom the Bell Tolls\", which he started in March 1939 and finished in July 1940. It was published in October 1940. His pattern was to move around while working on a manuscript, and he wrote \"For Whom the Bell Tolls\" in Cuba, Wyoming, and Sun Valley. It became a Book-of-the-Month Club choice, sold half a million copies within months, was nominated for a Pulitzer Prize and, in the words of Meyers, \"triumphantly re-established Hemingway's literary reputation\".\nIn January 1941, Martha was sent to China on assignment for \"Collier's\" magazine. Hemingway went with her, sending in dispatches for the newspaper \"PM\", but in general he disliked China. A 2009 book suggests during that period he may have been recruited to work for Soviet intelligence agents under the name \"Agent Argo\". They returned to Cuba before the declaration of war by the United States that December, when he convinced the Cuban government to help him refit the \"Pilar\", which he intended to use to ambush German submarines off the coast of Cuba.\nWorld War II.\nHemingway was in Europe from May 1944 to March 1945. When he arrived in London, he met \"Time\" magazine correspondent Mary Welsh, with whom he became infatuated. Martha had been forced to cross the Atlantic in a ship filled with explosives because Hemingway refused to help her get a press pass on a plane, and she arrived in London to find him hospitalized with a concussion from a car accident. She was unsympathetic to his plight; she accused him of being a bully and told him that she was \"through, absolutely finished\". The last time that Hemingway saw Martha was in March 1945 as he was preparing to return to Cuba, and their divorce was finalized later that year. Meanwhile, he had asked Mary Welsh to marry him on their third meeting.\nHemingway accompanied the troops to the Normandy Landings wearing a large head bandage, according to Meyers, but he was considered \"precious cargo\" and not allowed ashore. The landing craft came within sight of Omaha Beach before coming under enemy fire and turning back. Hemingway later wrote in \"Collier's\" that he could see \"the first, second, third, fourth and fifth waves of [landing troops] lay where they had fallen, looking like so many heavily laden bundles on the flat pebbly stretch between the sea and first cover\". Mellow explains that, on that first day, none of the correspondents were allowed to land and Hemingway was returned to the \"Dorothea Dix\".\nLate in July, he attached himself to \"the 22nd Infantry Regiment commanded by Col. Charles \"Buck\" Lanham, as it drove toward Paris\", and Hemingway became de facto leader to a small band of village militia in Rambouillet outside of Paris. Paul Fussell remarks: \"Hemingway got into considerable trouble playing infantry captain to a group of Resistance people that he gathered because a correspondent is not supposed to lead troops, even if he does it well.\" This was in fact in contravention of the Geneva Convention, and Hemingway was brought up on formal charges; he said that he \"beat the rap\" by claiming that he only offered advice.\nOn August 25, he was present at the liberation of Paris as a journalist; contrary to the Hemingway legend, he was not the first into the city, nor did he liberate the Ritz. In Paris, he visited Sylvia Beach and Pablo Picasso with Mary Welsh, who joined him there; in a spirit of happiness, he forgave Gertrude Stein. Later that year, he observed heavy fighting in the Battle of H\u00fcrtgen Forest. On December 17, 1944, he had himself driven to Luxembourg in spite of illness to cover The Battle of the Bulge. As soon as he arrived, however, Lanham handed him to the doctors, who hospitalized him with pneumonia; he recovered a week later, but most of the fighting was over.\nIn 1947, Hemingway was awarded a Bronze Star for his bravery during World War II. He was recognized for having been \"under fire in combat areas in order to obtain an accurate picture of conditions\", with the commendation that \"through his talent of expression, Mr. Hemingway enabled readers to obtain a vivid picture of the difficulties and triumphs of the front-line soldier and his organization in combat\".\nCuba and the Nobel Prize.\nHemingway said he \"was out of business as a writer\" from 1942 to 1945 during his residence in Cuba. In 1946 he married Mary, who had an ectopic pregnancy five months later. The Hemingway family suffered a series of accidents and health problems in the years following the war: in a 1945 car accident, he \"smashed his knee\" and sustained another \"deep wound on his forehead\"; Mary broke first her right ankle and then her left in successive skiing accidents. A 1947 car accident left Patrick with a head wound and severely ill. Hemingway sank into depression as his literary friends began to die: in 1939 William Butler Yeats and Ford Madox Ford; in 1940 F. Scott Fitzgerald; in 1941 Sherwood Anderson and James Joyce; in 1946 Gertrude Stein; and the following year in 1947, Max Perkins, Hemingway's long-time Scribner's editor, and friend. During this period, he suffered from severe headaches, high blood pressure, weight problems, and eventually diabetes\u2014much of which was the result of previous accidents and many years of heavy drinking. Nonetheless, in January 1946, he began work on \"The Garden of Eden\", finishing 800 pages by June. During the post-war years, he also began work on a trilogy tentatively titled \"The Land\", \"The Sea\" and \"The Air\", which he wanted to combine in one novel titled \"The Sea Book\". However, both projects stalled, and Mellow says that Hemingway's inability to continue was \"a symptom of his troubles\" during these years.\nIn 1948, Hemingway and Mary traveled to Europe, staying in Venice for several months. While there, Hemingway fell in love with the then 19-year-old Adriana Ivancich. The platonic love affair inspired the novel \"Across the River and into the Trees\", written in Cuba during a time of strife with Mary, and published in 1950 to negative reviews. The following year, furious at the critical reception of \"Across the River and Into the Trees\", he wrote the draft of \"The Old Man and the Sea\" in eight weeks, saying that it was \"the best I can write ever for all of my life\". \"The Old Man and the Sea\" became a book-of-the-month selection, made Hemingway an international celebrity, and won the Pulitzer Prize in May 1952, a month before he left for his second trip to Africa.\nIn 1954, while in Africa, Hemingway was almost fatally injured in two successive plane crashes. He chartered a sightseeing flight over the Belgian Congo as a Christmas present to Mary. On their way to photograph Murchison Falls from the air, the plane struck an abandoned utility pole and \"crash landed in heavy brush\". Hemingway's injuries included a head wound, while Mary broke two ribs. The next day, attempting to reach medical care in Entebbe, they boarded a second plane that exploded at take-off, with Hemingway suffering burns and another concussion, this one serious enough to cause leaking of cerebral fluid. They eventually arrived in Entebbe to find reporters covering the story of Hemingway's death. He briefed the reporters and spent the next few weeks recuperating and reading his erroneous obituaries. Despite his injuries, Hemingway accompanied Patrick and his wife on a planned fishing expedition in February, but pain caused him to be irascible and difficult to get along with. When a bushfire broke out, he was again injured, sustaining second-degree burns on his legs, front torso, lips, left hand and right forearm. Months later in Venice, Mary reported to friends the full extent of Hemingway's injuries: two cracked discs, a kidney and liver rupture, a dislocated shoulder and a broken skull. The accidents may have precipitated the physical deterioration that was to follow. After the plane crashes, Hemingway, who had been \"a thinly controlled alcoholic throughout much of his life, drank more heavily than usual to combat the pain of his injuries.\"\nIn October 1954, Hemingway received the Nobel Prize in Literature. He modestly told the press that Carl Sandburg, Isak Dinesen and Bernard Berenson deserved the prize, but he gladly accepted the prize money. Mellow says Hemingway \"had coveted the Nobel Prize\", but when he won it, months after his plane accidents and the ensuing worldwide press coverage, \"there must have been a lingering suspicion in Hemingway's mind that his obituary notices had played a part in the academy's decision.\" Because he was suffering pain from the African accidents, he decided against traveling to Stockholm. Instead he sent a speech to be read, defining the writer's life: \nFrom the end of the year in 1955 to early 1956, Hemingway was bedridden. He was told to stop drinking to mitigate liver damage, advice he initially followed but then disregarded. In October 1956, he returned to Europe and met Basque writer Pio Baroja, who was seriously ill and died weeks later. During the trip, Hemingway became sick again and was treated for \"high blood pressure, liver disease, and arteriosclerosis\".\nIn November 1956, while staying in Paris, he was reminded of trunks he had stored in the Ritz Hotel in 1928 and never retrieved. Upon re-claiming and opening the trunks, Hemingway discovered they were filled with notebooks and writing from his Paris years. Excited about the discovery, when he returned to Cuba in early 1957, he began to shape the recovered work into his memoir \"A Moveable Feast\". By 1959 he ended a period of intense activity: he finished \"A Moveable Feast\" (scheduled to be released the following year); brought \"True at First Light\" to 200,000 words; added chapters to \"The Garden of Eden\"; and worked on \"Islands in the Stream\". The last three were stored in a safe deposit box in Havana, as he focused on the finishing touches for \"A Moveable Feast\". Author Michael Reynolds claims it was during this period that Hemingway slid into depression, from which he was unable to recover.\nThe Finca Vig\u00eda became crowded with guests and tourists, as Hemingway, beginning to become unhappy with life there, considered a permanent move to Idaho. In 1959 he bought a home overlooking the Big Wood River, outside Ketchum, and left Cuba\u2014although he apparently remained on easy terms with the Castro government, telling \"The New York Times\" he was \"delighted\" with Castro's overthrow of Batista. He was in Cuba in November 1959, between returning from Pamplona and traveling west to Idaho, and the following year for his 61st birthday; however, that year he and Mary decided to leave after hearing the news that Castro wanted to nationalize property owned by Americans and other foreign nationals. On July 25, 1960, the Hemingways left Cuba for the last time, leaving art and manuscripts in a bank vault in Havana. After the 1961 Bay of Pigs Invasion, the Finca Vig\u00eda was expropriated by the Cuban government, complete with Hemingway's collection of \"four to six thousand books\". President Kennedy arranged for Mary Hemingway to travel to Cuba where she met Fidel Castro and obtained her husband's papers and painting in return for donating Finca Vig\u00eda to Cuba. In 1964 Mary contacted Jacqueline Kennedy to offer the Hemingway papers to the John F. Kennedy Presidential Library and Museum.\nIdaho and suicide.\nHemingway continued to rework the material that was published as \"A Moveable Feast\" through the 1950s. In mid-1959, he visited Spain to research a series of bullfighting articles commissioned by \"Life\" magazine. \"Life\" wanted only 10,000\u00a0words, but the manuscript grew out of control. He was unable to organize his writing for the first time in his life, so he asked A. E. Hotchner to travel to Cuba to help him. Hotchner helped him trim the \"Life\" piece down to 40,000 words, and Scribner's agreed to a full-length book version (\"The Dangerous Summer\") of almost 130,000 words. Hotchner found Hemingway to be \"unusually hesitant, disorganized, and confused\", and suffering badly from failing eyesight.\nHemingway and Mary left Cuba for the last time on July 25, 1960. He set up a small office in his New York City apartment and attempted to work, but he left soon after. He then traveled alone to Spain to be photographed for the front cover of \"Life\" magazine. A few days later, the news reported that he was seriously ill and on the verge of dying, which panicked Mary until she received a cable from him telling her, \"Reports false. Enroute Madrid. Love Papa.\" He was, in fact, seriously ill, and believed himself to be on the verge of a breakdown. Feeling lonely, he took to his bed for days, retreating into silence, despite having the first installments of \"The Dangerous Summer\" published in \"Life\" in September 1960 to good reviews. In October, he left Spain for New York, where he refused to leave Mary's apartment, presuming that he was being watched. She quickly took him to Idaho, where physician George Saviers met them at the train.\nAt this time, Hemingway was constantly worried about money and his safety. He worried about his taxes and that he would never return to Cuba to retrieve the manuscripts that he had left in a bank vault. He became paranoid, thinking that the FBI was actively monitoring his movements in Ketchum. The FBI had, in fact, opened a file on him during World War II, when he used the \"Pilar\" to patrol the waters off Cuba, and J. Edgar Hoover had an agent in Havana watch him during the 1950s. Unable to care for her husband, Mary had Saviers fly Hemingway to the Mayo Clinic in Minnesota at the end of November for hypertension treatments, as he told his patient. The FBI knew that Hemingway was at the Mayo Clinic, as an agent later documented in a letter written in January 1961.\nHemingway was checked in under Saviers's name to maintain anonymity. Meyers writes that \"an aura of secrecy surrounds Hemingway's treatment at the Mayo\" but confirms that he was treated with electroconvulsive therapy (ECT) as many as 15 times in December 1960 and was \"released in ruins\" in January 1961. Reynolds gained access to Hemingway's records at the Mayo, which document ten ECT sessions. The doctors in Rochester told Hemingway the depressive state for which he was being treated may have been caused by his long-term use of Reserpine and Ritalin.\nHemingway was back in Ketchum in April 1961, three months after being released from the Mayo Clinic, when Mary \"found Hemingway holding a shotgun\" in the kitchen one morning. She called Saviers, who sedated him and admitted him to the Sun Valley Hospital; and once the weather cleared Saviers flew again to Rochester with his patient. Hemingway underwent three electroshock treatments during that visit. He was released at the end of June and was home in Ketchum on June 30. Two days later he \"quite deliberately\" shot himself with his favorite shotgun in the early morning hours of July 2, 1961. He had unlocked the basement storeroom where his guns were kept, gone upstairs to the front entrance foyer, and shot himself with the \"double-barreled shotgun that he had used so often it might have been a friend\".\nMary called the Sun Valley Hospital, and a doctor quickly arrived at the house, determining that Hemingway \"had died of a self-inflicted wound to the head\". Mary was sedated and taken to the hospital, returning home the next day where she cleaned the house and saw to the funeral and travel arrangements. Bernice Kert writes that it \"did not seem to her a conscious lie\" when she told the press that his death had been accidental. In a press interview five years later, Mary confirmed that he had shot himself.\nFamily and friends flew to Ketchum for the funeral, officiated by the local Catholic priest, who believed that the death had been accidental. An altar boy fainted at the head of the casket during the funeral, and Hemingway's brother Leicester wrote: \"It seemed to me Ernest would have approved of it all.\" He is buried in the Ketchum cemetery.\nHemingway's behavior during his final years had been similar to that of his father before he killed himself; his father may have had hereditary haemochromatosis, whereby the excessive accumulation of iron in tissues culminates in mental and physical deterioration. Medical records made available in 1991 confirmed that Hemingway had been diagnosed with hemochromatosis in early 1961. His sister Ursula and his brother Leicester also killed themselves. Other theories have arisen to explain Hemingway's decline in mental health, including that multiple concussions during his life may have caused him to develop chronic traumatic encephalopathy (CTE), leading to his eventual suicide. Hemingway's health was further complicated by heavy drinking throughout most of his life.\nA memorial to Hemingway just north of Sun Valley is inscribed on the base with a eulogy Hemingway had written for a friend several decades earlier:\nArtistry.\nWriting style.\n\"The New York Times\" wrote in 1926 of Hemingway's first novel, \"No amount of analysis can convey the quality of \"The Sun Also Rises\". It is a truly gripping story, told in a lean, hard, athletic narrative prose that puts more literary English to shame.\" \"The Sun Also Rises\" is written in the spare, tight prose that made Hemingway famous, and, according to James Nagel, \"changed the nature of American writing.\" In 1954, when Hemingway was awarded the Nobel Prize for Literature, it was for \"his mastery of the art of narrative, most recently demonstrated in \"The Old Man and the Sea\", and for the influence that he has exerted on contemporary style.\"\nHenry Louis Gates believes Hemingway's style was fundamentally shaped \"in reaction to [his] experience of world war\". After World War\u00a0I, he and other modernists \"lost faith in the central institutions of Western civilization\" by reacting against the elaborate style of 19th-century writers and by creating a style \"in which meaning is established through dialogue, through action, and silences\u2014a fiction in which nothing crucial\u2014or at least very little\u2014is stated explicitly.\"\nHemingway's fiction often used grammatical and stylistic structures from languages other than English. Critics Allen Josephs, Mimi Gladstein, and Jeffrey Herlihy-Mera have studied how Spanish influenced Hemingway's prose, which sometimes appears directly in the other language (in italics, as occurs in \"The Old Man and the Sea\") or in English as literal translations. He also often used bilingual puns and crosslingual wordplay as stylistic devices.\nBecause he began as a writer of short stories, Baker believes Hemingway learned to \"get the most from the least, how to prune language, how to multiply intensities and how to tell nothing but the truth in a way that allowed for telling more than the truth.\" Hemingway called his style the iceberg theory: the facts float above water; the supporting structure and symbolism operate out of sight. The concept of the iceberg theory is sometimes referred to as the \"theory of omission\". Hemingway believed the writer could describe one thing (such as Nick Adams fishing in \"The Big Two-Hearted River\") though an entirely different thing occurs below the surface (Nick Adams concentrating on fishing to the extent that he does not have to think about anything else). Paul Smith writes that Hemingway's first stories, collected as \"In Our Time\", showed he was still experimenting with his writing style. He avoided complicated syntax. About 70 percent of the sentences are simple sentences\u2014a childlike syntax without subordination.\nJackson Benson believes Hemingway used autobiographical details as framing devices about life in general\u2014not only about his life. For example, Benson postulates that Hemingway used his experiences and drew them out with \"what if\" scenarios: \"what if I were wounded in such a way that I could not sleep at night? What if I were wounded and made crazy, what would happen if I were sent back to the front?\" Writing in \"The Art of the Short Story\", Hemingway explains: \"A few things I have found to be true. If you leave out important things or events that you know about, the story is strengthened. If you leave or skip something because you do not know it, the story will be worthless. The test of any story is how very good the stuff that you, not your editors, omit.\"\nThe simplicity of the prose is deceptive. Zoe Trodd believes Hemingway crafted skeletal sentences in response to Henry James's observation that World War\u00a0I had \"used up words\". Hemingway offers a \"multi-focal\" photographic reality. His iceberg theory of omission is the foundation on which he builds. The syntax, which lacks subordinating conjunctions, creates static sentences. The photographic \"snapshot\" style creates a collage of images. Many types of internal punctuation (colons, semicolons, dashes, parentheses) are omitted in favor of short declarative sentences. The sentences build on each other, as events build to create a sense of the whole. Multiple strands exist in one story; an \"embedded text\" bridges to a different angle. He also uses other cinematic techniques of \"cutting\" quickly from one scene to the next; or of \"splicing\" a scene into another. Intentional omissions allow the reader to fill the gap, as though responding to instructions from the author and create three-dimensional prose.\nHemingway habitually used the word \"and\" in place of commas. This use of polysyndeton may serve to convey immediacy. Hemingway's polysyndetonic sentence\u2014or in later works his use of subordinate clauses\u2014uses conjunctions to juxtapose startling visions and images. Benson compares them to haikus. Many of Hemingway's followers misinterpreted his lead and frowned upon all expression of emotion; Saul Bellow satirized this style as \"Do you have emotions? Strangle them.\" However, Hemingway's intent was not to eliminate emotion, but to portray it more scientifically. Hemingway thought it would be easy, and pointless, to describe emotions; he sculpted collages of images in order to grasp \"the real thing, the sequence of motion and fact which made the emotion and which would be as valid in a year or in ten years or, with luck and if you stated it purely enough, always\". This use of an image as an objective correlative is characteristic of Ezra Pound, T. S. Eliot, James Joyce, and Marcel Proust. Hemingway's letters refer to Proust's \"Remembrance of Things Past\" several times over the years, and indicate he read the book at least twice.\nThemes.\nHemingway's writing includes themes of love, war, travel, wilderness, and loss. Hemingway often wrote about Americans abroad. \u201cIn six of the seven novels published during his lifetime,\u201d writes Jeffrey Herlihy in \"Hemingway's Expatriate Nationalism\", \u201dthe protagonist is abroad, bilingual, and bicultural.\u201d Herlihy calls this \u201cHemingway\u2019s Transnational Archetype\u201d and argues that the foreign settings, \u201cfar from being mere exotic backdrops or cosmopolitan milieus, are motivating factors in-character action.\u201d Critic Leslie Fiedler sees the theme he defines as \"The Sacred Land\"\u2014the American West\u2014extended in Hemingway's work to include mountains in Spain, Switzerland and Africa, and to the streams of Michigan. The American West is given a symbolic nod with the naming of the \"Hotel Montana\" in \"The Sun Also Rises\" and \"For Whom the Bell Tolls\". According to Stoltzfus and Fiedler, in Hemingway's work, nature is a place for rebirth and rest; and it is where the hunter or fisherman might experience a moment of transcendence at the moment they kill their prey. Nature is where men exist without women: men fish; men hunt; men find redemption in nature. Although Hemingway does write about sports, such as fishing, Carlos Baker notes the emphasis is more on the athlete than the sport. At its core, much of Hemingway's work can be viewed in the light of American naturalism, evident in detailed descriptions such as those in \"Big Two-Hearted River\".\nFiedler believes Hemingway inverts the American literary theme of the evil \"Dark Woman\" versus the good \"Light Woman\". The dark woman\u2014Brett Ashley of \"The Sun Also Rises\"\u2014is a goddess; the light woman\u2014Margot Macomber of \"The Short Happy Life of Francis Macomber\"\u2014is a murderess. Robert Scholes says early Hemingway stories, such as \"A Very Short Story\", present \"a male character favorably and a female unfavorably\". According to Rena Sanderson, early Hemingway critics lauded his male-centric world of masculine pursuits, and the fiction divided women into \"castrators or love-slaves\". Feminist critics attacked Hemingway as \"public enemy number one\", although more recent re-evaluations of his work \"have given new visibility to Hemingway's female characters (and their strengths) and have revealed his own sensitivity to gender issues, thus casting doubts on the old assumption that his writings were one-sidedly masculine.\" Nina Baym believes that Brett Ashley and Margot Macomber \"are the two outstanding examples of Hemingway's 'bitch women.\nThe theme of women and death is evident in stories as early as \"Indian Camp\". The theme of death permeates Hemingway's work. Young believes the emphasis in \"Indian Camp\" was not so much on the woman who gives birth or the father who kills himself, but on Nick Adams who witnesses these events as a child, and becomes a \"badly scarred and nervous young man\". Hemingway sets the events in \"Indian Camp\" that shape the Adams persona. Young believes \"Indian Camp\" holds the \"master key\" to \"what its author was up to for some thirty-five years of his writing career\". Stoltzfus considers Hemingway's work to be more complex with a representation of the truth inherent in existentialism: if \"nothingness\" is embraced, then redemption is achieved at the moment of death. Those who face death with dignity and courage live an authentic life. Francis Macomber dies happy because the last hours of his life are authentic; the bullfighter in the corrida represents the pinnacle of a life lived with authenticity. In his paper \"The Uses of Authenticity: Hemingway and the Literary Field\", Timo M\u00fcller writes that Hemingway's fiction is successful because the characters live an \"authentic life\", and the \"soldiers, fishers, boxers and backwoodsmen are among the archetypes of authenticity in modern literature\".\nThe theme of emasculation is prevalent in Hemingway's work, notably in \"God Rest You Merry, Gentlemen\" and \"The Sun Also Rises\". Emasculation, according to Fiedler, is a result of a generation of wounded soldiers; and of a generation in which women such as Brett gained emancipation. This also applies to the minor character, Frances Clyne, Cohn's girlfriend in the beginning of \"The Sun Also Rises\". Her character supports the theme not only because the idea was presented early on in the novel but also the impact she had on Cohn in the start of the book while only appearing a small number of times. In \"God Rest You Merry, Gentlemen\", the emasculation is literal, and related to religious guilt. Baker believes Hemingway's work emphasizes the \"natural\" versus the \"unnatural\". In \"Alpine Idyll\" the \"unnaturalness\" of skiing in the high country late spring snow is juxtaposed against the \"unnaturalness\" of the peasant who allowed his wife's dead body to linger too long in the shed during the winter. The skiers and peasant retreat to the valley to the \"natural\" spring for redemption.\nDescriptions of food and drink feature prominently in many of Hemingway's works. In the short story \"Big Two-Hearted River\" Hemingway describes a hungry Nick Adams cooking a can of pork and beans and a can of spaghetti over a fire in a heavy cast iron pot. The primitive act of preparing the meal in solitude is a restorative act and one of Hemingway's narratives of post-war integration.\nSusan Beegel has written that some more recent critics\u2014writing through the lens of a more modern social and cultural context several decades after Hemingway's death, and more than half a century after his novels were first published\u2014have characterized the social era portrayed in his fiction as misogynistic and homophobic. In her 1996 essay, \"Critical Reception\", Beegel analyzed four decades of Hemingway criticism and found that \"critics interested in multiculturalism\", particularly in the 1980s, simply ignored Hemingway, although some \"apologetics\" of his work were written. Typical, according to Beegel, is an analysis of Hemingway's 1926 novel, \"The Sun Also Rises\", in which a critic contended: \"Hemingway never lets the reader forget that Cohn is a Jew, not an unattractive character who happens to be a Jew but a character who is unattractive because he is a Jew.\" Also during the 1980s, according to Beegel, criticism was published that focused on investigating the \"horror of homosexuality\" and the \"racism\" typical of the social era portrayed in Hemingway's fiction. In an overall assessment of Hemingway's work Beegel has written: \"Throughout his remarkable body of fiction, he tells the truth about human fear, guilt, betrayal, violence, cruelty, drunkenness, hunger, greed, apathy, ecstasy, tenderness, love and lust.\"\nInfluence and legacy.\nHemingway's legacy to American literature is his style: writers who came after him either emulated or avoided it. After his reputation was established with the publication of \"The Sun Also Rises\", he became the spokesperson for the post-World War\u00a0I generation, having established a style to follow. His books were burned in Berlin in 1933, \"as being a monument of modern decadence\", and disavowed by his parents as \"filth\". Reynolds asserts the legacy is that \"[Hemingway] left stories and novels so starkly moving that some have become part of our cultural heritage.\"\nBenson believes the details of Hemingway's life have become a \"prime vehicle for exploitation\", resulting in a Hemingway industry. Hemingway scholar Hallengren believes the \"hard-boiled style\" and the machismo must be separated from the author himself. Benson agrees, describing him as introverted and private as J. D. Salinger, although Hemingway masked his nature with braggadocio. During World War\u00a0II, Salinger met and corresponded with Hemingway, whom he acknowledged as an influence. In a letter to Hemingway, Salinger claimed their talks \"had given him his only hopeful minutes of the entire war\" and jokingly \"named himself national chairman of the Hemingway Fan Clubs.\"\nThe extent of his influence is seen from the enduring and varied tributes to Hemingway and his works. 3656 Hemingway, a minor planet discovered in 1978 by Soviet astronomer Nikolai Chernykh, was named for Hemingway, and in 2009, a crater on Mercury was also named in his honor. \"The Kilimanjaro Device\" by Ray Bradbury featured Hemingway being transported to the top of Mount Kilimanjaro, while the 1993 motion picture \"Wrestling Ernest Hemingway\" explored the friendship of two retired men, played by Robert Duvall and Richard Harris, in a seaside Florida town. His influence is further evident from the many restaurants bearing his name and the proliferation of bars called \"Harry's\", a nod to the bar in \"Across the River and Into the Trees\". Hemingway's son Jack (Bumby) promoted a line of furniture honoring his father, Montblanc created a Hemingway fountain pen, and multiple lines of clothing inspired by Hemingway have been produced. In 1977, the International Imitation Hemingway Competition was created to acknowledge his distinct style and the comical efforts of amateur authors to imitate him; entrants are encouraged to submit one \"really good page of really bad Hemingway\" and the winners are flown to Harry's Bar in Italy.\nIn 1965, Mary Hemingway established the Hemingway Foundation and in the 1970s she donated her husband's papers to the John F. Kennedy Library. In 1980, a group of Hemingway scholars gathered to assess the donated papers, subsequently forming the Hemingway Society, \"committed to supporting and fostering Hemingway scholarship\". Numerous awards have been established in Hemingway's honor to recognize significant achievement in the arts and culture, including the Hemingway Foundation/PEN Award and the Hemingway Award.\nIn 2012, he was inducted into the Chicago Literary Hall of Fame.\nAlmost exactly 35 years after Hemingway's death, on July 1, 1996, his granddaughter Margaux Hemingway died in Santa Monica, California. Margaux was a supermodel and actress, co-starring with her younger sister Mariel in the 1976 movie \"Lipstick\". Her death was later ruled a suicide, making her \"the fifth person in four generations of her family to commit suicide\".\nThree houses associated with Hemingway are listed on the U.S. National Register of Historic Places: the Ernest Hemingway Cottage on Walloon Lake, Michigan, designated in 1968; the Ernest Hemingway House in Key West, designated in 1968; and the Ernest and Mary Hemingway House in Ketchum, designated in 2015. His boyhood home, in Oak Park, Illinois, is a museum and archive dedicated to Hemingway. Hemingway's childhood home in Oak Park and his Havana residence were also converted into museums.\nOn April 5, 2021, \"Hemingway\", a three-episode, six-hour documentary, a recapitulation of Hemingway's life, labors, and loves, debuted on the Public Broadcasting System. It was co-produced and directed by Ken Burns and Lynn Novick."}
{"id": "9429", "revid": "1020214779", "url": "https://en.wikipedia.org/wiki?curid=9429", "title": "Young and Innocent", "text": "Young and Innocent, released in the US as \"The Girl Was Young\", is a 1937 British crime thriller film directed by Alfred Hitchcock and starring Nova Pilbeam and Derrick De Marney. Based on the 1936 novel \"A Shilling for Candles\" by Josephine Tey, the film is about a young man on the run from a murder charge who enlists the help of a woman who must put herself at risk for his cause. It is notable for an elaborately staged crane shot Hitchcock devised towards the end of the film, which identifies the real murderer.\nPlot.\nOn a stormy night, at a retreat on the English coast, Christine Clay (Pamela Carme), a successful actress, argues passionately with her jealous ex-husband Guy (George Curzon). Not accepting her Reno divorce as valid, he accuses her of having an affair. Finally, she slaps him and he leaves the room. While they had been arguing, his eyes twitched violently; they continue to do so when, once outside, he turns angrily to look at the closed door behind him.\nThe next morning, Robert Tisdall (Derrick De Marney) happens to be walking along the seaside when Christine's dead body washes ashore. He recognizes her, and runs for help. Two young women arrive just in time to see him racing away from the corpse. The police quickly decide that Tisdall is the only suspect. Christine was strangled with the belt from a raincoat; his raincoat is missing and he says it was recently stolen. He admits knowing the victim for three years since he sold her a story but the authorities assume the two have been having an affair. When they learn that she has left him money in her will (unbeknownst to him), they feel they have hit upon a motive and Tisdall is arrested.\nScotland Yard detectives grill him all night. The next morning, he faints and is revived with the aid of Erica Burgoyne (Nova Pilbeam), daughter of the local police Chief Constable. Tisdall is assigned an incompetent solicitor, and is taken into court for his formal arraignment. Doubting if his innocence will ever be established, he takes advantage of overcrowding in the courthouse to escape, wearing the solicitor's eyeglasses as a disguise. He gets away by riding on the running board of Erica's Morris car, revealing himself to her after the car runs out of petrol.\nHe helps push the car to a filling station, pays for petrol, and convinces her to give him a ride. Though she is initially fearful and unsure about her passenger, Erica eventually becomes convinced of his innocence and decides to help him in any way that she can. They are eventually spotted together, forcing both to stay on the run from the police. Tisdall tries to prove his innocence by tracking down the stolen coat: if it still has its belt, the one found next to Christine's body must not be his.\nThe duo succeed in tracing Tisdall's coat to Old Will (Edward Rigby), a homeless, but sociable, china-mender. But Will was not the thief; he was given the coat by a man with \"twitchy eyes\", and with its belt already missing.\nAfter becoming separated from the others, Erica is taken in by the police. Upon realizing that his daughter has fully allied herself with a murder suspect, her father chooses to resign his position as Chief Constable rather than arrest her for assisting a felon. Though mutually undeclared, by this point she and Tisdall are in love, Tisdall sneaks into their house to see her, intending to surrender and assert he kidnapped her, to save her honour and her father's reputation. But she mentions that the coat had a box of matches from the Grand Hotel in a pocket. As Tisdall has never been there, he surmises perhaps the murderer has a connection to the hotel.\nThe following evening, Erica and Will go to the hotel together, hoping to find him. In a memorably long, continuous sequence, the camera pans right from their entrance to the hotel and then moves forward from the very back of the hotel ballroom, finally focusing in extreme closeup on the drummer in a dance band performing in blackface. His eyes are twitching. He is Guy, the murderer.\nRecognizing Old Will in the audience, and seeing policemen nearby (who have actually followed Will hoping he'll lead them to Tisdall), Guy performs poorly due to fear. He is berated by the conductor and, during a break, takes medicine to try to control the twitching, but it makes him very sleepy. Eventually, in mid-performance, Guy passes out, drawing the attention of Erica and the police. Immediately after being revived and confronted, he confesses his crime and begins laughing hysterically.\nReunited once again with Tisdall, Erica then tells her father that she thinks it is time they invited him to their home for dinner.\nReception.\n\"Variety\" called the film a \"Pleasing, artless vehicle\" for Nova Pilbeam who was \"charming\" in her role and concluded, \"If the pic is not Hitchcock's best effort, it is by no means unworthy of him.\" Frank Nugent of \"The New York Times\" called it a \"crisply paced, excellently performed film.\" \"The Monthly Film Bulletin\" wrote, \"Innumerable small touches show Hitchcock's keen and penetrating observation and his knowledge of human nature. Comedy, romance, and thrills are skilfully blended.\" \"Harrison's Reports\" wrote, \"Good melodramatic entertainment. Because of the novelty of the story, the interesting plot developments, and the expert direction by Alfred Hitchcock, one's attention is held from the beginning to the end.\" John Mosher of \"The New Yorker\" wrote that it was \"rather exasperating and disappointing to me. It begins with a smart murder, but wanders off through the English rural landscape in a fashion so lacking in that sound common sense we like in our mysteries, or like to feel is there anyhow, that one's interest fades away.\"\nAggregator Rotten Tomatoes reports 100% approval of \"Young and Innocent\", with an average rating of 7.6/10.\nChanges from the novel.\nSignificant changes were made in adapting the book for the film. The novel is a whodunit centred on the Scotland Yard inspector, who is Tey's regular character Alan Grant. The storyline involving Robert Tisdall, Erica Burgoyne, and the missing coat is similar to the film story, but in the novel it is only a subplot and ends part way through the book when Erica finds the coat and it is intact. Grant then focuses on other suspects, none of whom (including the actual murderer in the novel) appear in the film. Christine Clay in the novel is not divorced, but is in an unconventional marriage to an aristocrat.\nHitchcock's cameo.\nAlfred Hitchcock's cameo is a signature occurrence in most of his films. He can be seen outside the courthouse, holding a camera, at 14 minutes into the film.\nCopyright and home video status.\n\"Young and Innocent\", like all of Hitchcock's British films, is copyrighted worldwide but has been heavily bootlegged on home video. Despite this, various licensed releases have appeared on Blu-ray, DVD and video on demand services worldwide from the likes of Network Distributing in the UK, MGM and The Criterion Collection in the US, and others."}
{"id": "9430", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9430", "title": "Things Turn Sour", "text": ""}
{"id": "9431", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9431", "title": "The Endless Dark Nothingness", "text": ""}
{"id": "9432", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=9432", "title": "The Time in Between", "text": "The Time in Between is a novel by Canadian author David Bergen. It deals with a man, who mysteriously returns to Vietnam, where he had been a soldier earlier in his life, followed by his children, who also go to Vietnam to search for him. The novel was the recipient of the Scotiabank Giller Prize and the McNally Robinson Book of the Year Award in 2005.\nPlot.\nCharles Boatman, an army veteran suddenly disappears and his daughter Ada and her younger brother Jon on finding some clues go looking out for him in Danang, Vietnam. The novel mixes various stories from different timeframes narrating Charles's days in Washington when he was young. He married Sara and had daughter Ada while living in Fraser Valley of British Columbia. He gets posted in the war time era to Vietnam and serves there and upon arrival discovers his wife's infidelity. Sara dies early and by then they also had a son Jon. Charles keeps getting nightmares of his Vietnam days on how he killed an innocent civilian boy in one of the operations and this keeps haunting him. On the other hand, Ada s on her mission to find her father and is helped by a local guy Yen who becomes her guide and guardian in the new country. She engages in a sexual relationship with an older man, Hoang Vu who is an artist by profession. Jon indulges in the nightlife of Vietnam and Ada keeps getting closer to her father as she travels across the country. Charles discovers author Dang Tho's novel chronicling wartime and this helps him find some peace.\nPublication and development.\nThe book is author David Bergen's fifth novel. Although generally called a war novel, the author states that he \"[doesn't] see \"The Time in Between\" as a war novel\". The book was released as Audio book by Blackstone Audio in December 2005 and was narrated by Anna Fields, better known as Kate Fleming.\nReviews and reception.\n\"Kirkus reviews\" called the novel a \"beautifully composed, unflinching and harrowing story\". Nicholas Dinka in their \"Quill &amp; Quire\" review mentions that the novel has \"much decency and intelligence\" and both the stories of the novel are \"entirely plausible\" but criticises for \"remarkable dourness of its prose\". While Dennis Lythgoe of \"Deseret News\" noted that \"Bergen's book lives and breathes the Vietnam experience\"; Ron Charles in his \"The Washington Post\" review mentioned that \"Bergen's ability to dramatize trauma-induced disaffection is undeniable; whether readers will want to sink down that hole with his characters is less clear\". Irene Wanner of \"The Seattle Times\" appreciated the novel for its writing.\nThe novel won the Scotiabank Giller Prize in 2005 while being nominated along with \"Luck\" (by Joan Barfoot), \"Sweetness in the Belly\" (by Camilla Gibb), \"Alligator\" (by Lisa Moore), and \"A Wall of Light\" (by Edeet Ravel). The judges Warren Cariou, Elizabeth Hay, and Richard B. Wright noted \"\"The Time in Between\" explores our need to understand the relationship between love and duty...[] This is a subtle and elegantly written novel by an author in complete command of his talent\". It also won the McNally Robinson Book of the Year Award in 2005. Bergen had earlier won the award in 1996 for \"A Year of Lesser\" and later again won in 2009 for \"The Retreat\". Dan Zigmond of \"SFGate\" reviews the novel as \"a rich and rewarding novel\"."}
{"id": "9433", "revid": "10289486", "url": "https://en.wikipedia.org/wiki?curid=9433", "title": "Spain in Flames", "text": "Spain in Flames is a 1937 compilation film made by Helen van Dongen during the Spanish Civil War. Hal Erickson has written that the film \"... is remarkable in its willingness to offer both sides of the conflict -- though its sympathies are firmly with the Loyalists.\" The film consists of two parts. The first, \"The Fight for Freedom\", was based on film footage from a Spanish government documentary \"Spain and the Fight for Freedom\". A foreword by the then Spanish Ambassador to the United States, Fernando de los R\u00edos, began one of the film's screenings in New York in 1937. \nThe second part, \"They Shalt Not Pass\", was based on a short film \"No Pasaran!\" done by the Artkino Film Company of the Soviet Union, where van Dongen was working at the time the film was made. John Dos Passos narrated parts of the film, and the commentary was written by Dos Passos, Ernest Hemingway, Archibald MacLeish, and Prudencio de Pareda. Erickson writes that, \"The horrendous images of battlefield carnage, not to mention the close-ups of suffering and dying Spanish children, still pack a wallop when seen today.\"\nLater, Hemingway, Dos Passos, Lillian Hellman and others founded the company Contemporary Historians, which produced another film called \"The Spanish Earth\" (1937), directed by Joris Ivens and edited by van Dongen.\n\"Spain in Flames\" was banned in New Brunswick, New Jersey and Waterbury, Connecticut. A screening of the film, accompanied by a speech from Granville Hicks, was also banned in Provincetown, Massachusetts. "}
{"id": "9434", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9434", "title": "Ernest Hemingway/For Whom the Bell Tolls", "text": ""}
{"id": "9435", "revid": "39761822", "url": "https://en.wikipedia.org/wiki?curid=9435", "title": "Frederic Henry", "text": ""}
{"id": "9436", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9436", "title": "Ernest Hemingway/Robert Jordan", "text": ""}
{"id": "9437", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9437", "title": "Famous at Twenty-Five Thirty a Master", "text": ""}
{"id": "9438", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9438", "title": "From Boy to Man Hemingways First World War", "text": ""}
{"id": "9439", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9439", "title": "From Reality to Fiction A Farewell to Arms", "text": ""}
{"id": "9440", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9440", "title": "Sure Shots The Second World War", "text": ""}
{"id": "9441", "revid": "41849504", "url": "https://en.wikipedia.org/wiki?curid=9441", "title": "The Downward Spiral", "text": "The Downward Spiral is the second studio album by American industrial rock band Nine Inch Nails, released on March 8, 1994, by Nothing Records and Interscope Records in the United States and by Island Records in Europe. It is a concept album detailing the destruction of a man from the beginning of his \"downward spiral\" to his death by suicide. \"The Downward Spiral\" features elements of industrial rock, techno and heavy metal, in contrast to the band's synth-pop-influenced debut album \"Pretty Hate Machine\" (1989), and was produced by Nine Inch Nails frontman Trent Reznor and Flood.\nIn 1992, Reznor moved to 10050 Cielo Drive in Benedict Canyon, Los Angeles, where actress Sharon Tate was murdered by members of the Manson Family. It was used as a studio called \"Le Pig\" for recording \"Broken\" (1992) and \"The Downward Spiral\" with collaborations from other musicians. The album was influenced by late-1970s rock music albums such as David Bowie's \"Low\" and Pink Floyd's \"The Wall\" in particular, and focused on texture and space. The album spawned two singles, \"March of the Pigs\" and \"Closer\", in addition to the promotional singles \"Piggy\" and \"Hurt\". \"March of the Pigs\" and \"Closer\" were accompanied by music videos, with the former shot twice and the latter's heavily censored.\n\"The Downward Spiral\" was a commercial success, and established Nine Inch Nails as a reputable force in the 1990s music scene, with its sound being widely imitated and Reznor receiving media attention and multiple honors, while descending into drug abuse and depression. It has been regarded by music critics and audiences as one of the most important albums of the 1990s, and was praised for its abrasive and eclectic nature and dark themes, although it was scrutinized by social conservatives for some of its lyrics. A remix album titled \"Further Down the Spiral\" was released in 1995.\nWriting and recording.\n\"The Downward Spiral\" was conceived after the Lollapalooza festival tour as Trent Reznor thought of a \"negative vibe\" felt by the band when they were in a European hotel. Nine Inch Nails live performances were known for its aggressive on-stage dynamic, in which band members act angry, injure themselves, and destroy instruments. Reznor had a feud with TVT Records that resulted in him co-founding Nothing Records with his former manager John Malm, Jr. and signing with Interscope. He wanted to explore a fictional character whose life is psychologically wounded and developed a concept about the album's themes; he later used the concept as lyrics. The concept was based on Reznor's social issues at the time: he had personal conflicts with band member Richard Patrick and was known for enjoying alcohol. When developing \"The Downward Spiral\", Reznor struggled with drug addiction and was depressed as he wrote songs related to personal issues. His friends suggested that he could take Prozac (fluoxetine), an antidepressant, but this choice did not appeal to him. He wanted the album's sound to diverge from \"Broken\", emphasizing mood, texture, restraint and subtlety, although he was not sure about its musical direction. The album was made with \"full range\" and focused on texture and space, avoiding explicit usage of guitars or synthesizers.\nReznor searched for and moved to 10050 Cielo Drive in 1992 for recording \"Broken\" and \"The Downward Spiral\", a decision made against his initial choice to record the album in New Orleans. 10050 Cielo Drive is referred to as the \"Tate House\" since Sharon Tate was murdered by members of the Manson Family in 1969; Reznor named the studio \"Le Pig\" after the message that was scrawled on the front door with Tate's blood by her murderers, and stayed there with Malm for 18 months. He called his first night in 10050 Cielo Drive \"terrifying\" because he already knew it and read books related to the incident. Reznor chose the Tate house to calibrate his engineering skills and the band bought a large console and two Studer machines as resources, a move that he believed was cheaper than renting. The studio was also used for the recording of Marilyn Manson's debut album \"Portrait of an American Family\", which Reznor co-produced. Marilyn Manson accepted Reznor's offer of signing a contract with Nothing Records.\nReznor collaborated with former Jane's Addiction and Porno for Pyros drummer Stephen Perkins, progressive rock guitarist Adrian Belew, and Nine Inch Nails drummer Chris Vrenna. Belew's first visit to the studio involved playing the guitar parts in \"Mr. Self-Destruct\", and he was told to play freely, think on reacting to melodies, concentrate on rhythm, and use noise. This approach improved Reznor's confidence in the instrument: he found it to be more expressive than the keyboard due to the interface. Belew praised Reznor for his \"command of technology,\" and commented that the music of Nine Inch Nails made innovations \"that are in [his] realm.\" Vrenna and Perkins played drum parts recorded live in the studio; the tracks were rendered into looped samples. Reznor took a similar approach to recording guitar parts: he would tape 20- to 25-minute-long sessions of himself playing guitars on a hard disc recorder with the Studio Vision sequencer.\nMost of the music was recorded into a Macintosh computer using a board and manipulated with music editor programs on the computer. Unique effects such as analyzing and inverting the frequency were applied to the tracks to create original sounds. The band would \"get an arrangement together\" and convert it into analog tape. Reznor sampled excerpts from guitar tracks and processed them to the point of randomness and expression. Digidesign's TurboSynth and Zoom 9030 effects unit were used extensively to process guitar tracks, often in conjunction with a Marshall JMP-1 preamp; Zoom 9030 was also used to distort vocals. Acoustic drums in various settings, as well as Roland's TR-808 and R-70 drum machines were sampled through multiple Akai S1000s and a Kurzweil K2000. Additionally, Vrenna had compiled various movie samples on Digital Audio Tapes for Reznor to sample. Other equipments and software Reznor used for recording the album include Oberheim OB-Mx, Minimoog, Prophet VS keyboard, Eventide H3000 Harmonizer, Pro Tools and various Jackson and Gibson guitars.\nIn December 1993, Reznor was confronted by Patti Tate, who asked if he was exploiting Sharon Tate's death in the house. Reznor responded that he was interested in the house as her death happened there. He later made a statement about this encounter during a 1997 interview with \"Rolling Stone\":\nFlood, known for engineering and producing U2 and Depeche Mode albums, was employed as co-producer on \"The Downward Spiral\". It became his last collaboration with Nine Inch Nails due to creative differences. A \"very dangerously self-destructive,\" humorous short song written for the album, \"Just Do It\", was not included in the final version and criticized by Flood in that Reznor had \"gone too far.\" Reznor completed the last song written for the album, \"Big Man with a Gun\", in late 1993. After the album's recording, Reznor moved out and the house was demolished shortly thereafter. \"The Downward Spiral\" entered its mixing and mastering processes, done at Record Plant Studios and A&amp;M Studios with Alan Moulder, who subsequently took on more extensive production duties for future album releases.\nMusic and lyrics.\nNumerous layers of metaphors are present throughout \"The Downward Spiral\", leaving it open to wide interpretation. The album relays nihilism and is defined by a prominent theme of self-abuse and self-control. It is a semi-autobiographical concept album, in which the overarching plot follows the protagonist's descent into madness in his own inner solipsistic world through a metaphorical \"downward spiral\", dealing with religion, dehumanization, violence, disease, society, drugs, sex, and finally, suicide. Reznor described the concept as consisting of \"someone who sheds everything around them to a potential nothingness, but through career, religion, relationship, belief and so on.\" Media journalists like \"The New York Times\" writer Jon Pareles noted the album's theme of angst had already been used by grunge bands like Nirvana, and that Nine Inch Nails' depiction was more generalized.\nUsing elements of genres such as techno, dance, electronic, heavy metal, and hard rock, \"The Downward Spiral\" is considered industrial rock, industrial, alternative rock and industrial metal. Reznor regularly uses noise and distortion in his song arrangements that do not follow verse\u2013chorus form, and incorporates dissonance with chromatic melody or harmony (or both). The treatment of metal guitars in \"Broken\" is carried over to \"The Downward Spiral\", which includes innovative techniques such as expanded song structures and unconventional time signatures. The album features a wide range of textures and moods to illustrate the mental progress of the central protagonist. Reznor's singing follows a similar pattern from beginning to end, frequently moving from whispers to screams. These techniques are all used in the song \"Hurt\", which features a highly dissonant tritone played on guitar during the verses, a B5#11, emphasized when Reznor sings the eleventh note on the word \"I\" every time the B/E# dyad is played.\n\"Mr. Self Destruct\", a song about a powerful person, follows a build-up sampled from the 1971 film \"THX 1138\" with an \"industrial roar\" and is accompanied by an audio loop of a pinion rotating. \"The Becoming\" expresses the state of being dead and the protagonist's transformation into a non-human organism. \"Closer\" concludes with a chromatic piano motif: The melody is introduced during the second verse of \"Piggy\" on organ, then reappears in power chords at drop D tuning throughout the chorus of \"Heresy\", and recurs for the final time on \"The Downward Spiral\". The album was chiefly inspired by David Bowie's \"Low\", an experimental rock album which Reznor related to on songwriting, mood, and structures, as well as progressive rock group Pink Floyd's \"The Wall\", a concept album featuring themes of abuse, isolation, and mental instability.\nPackaging.\n\"Committere\", an installation featuring artwork and sketches for \"The Downward Spiral\", \"Closer\" and \"March of the Pigs\" by Russell Mills was displayed at the Glasgow School of Art. Mills explained the ideas and materials that made up the painting (titled \"Wound\") that was used for the album's cover art:\nPromotion.\nSingles.\n\"March of the Pigs\" and \"Closer\" were released as singles; two other songs, \"Hurt\" and \"Piggy\", were issued to radio without a commercial single release. \"March of the Pigs\" has an unusual meter, alternating three bars of 7/8 time with one of 8/8. The song's music video was directed by Peter Christopherson and was shot twice; the first version scrapped due to Reznor's involvement, and the released second version being a live performance.\n\"Closer\" features a heavily modified bass drum sample from the Iggy Pop song \"Nightclubbing\" from his album \"The Idiot\". Lyrically, it is a meditation on self-hatred and obsession, but to Reznor's dismay, the song was widely misinterpreted as a lust anthem due to its chorus, which included the line \"I wanna fuck you like an animal\". The music video for \"Closer\" was directed by Mark Romanek and received frequent rotation on MTV, though the network heavily censored the original version, which they perceived to be too graphic. The video shows events in a laboratory dealing with religion, sexuality, animal cruelty, politics, and terror; controversial imagery included a nude bald woman with a crucifix mask, a monkey tied to a cross, a pig's head spinning on a machine, a diagram of a vulva, Reznor wearing an S&amp;M mask while swinging in shackles, and of him wearing a ball gag. A radio edit that partially censored the song's explicit lyrics also received extensive airtime. The video has since been made part of the permanent collection of the Museum of Modern Art in New York City.\n\"Piggy\" uses \"nothing can stop me now\", a line that recurs in \"Ruiner\" and \"Big Man with a Gun\". The frantic drumming on the song's outro is Reznor's only attempt at performing drums on the record, and one of the few \"live\" drum performances on the album. He had stated that the recording was from him testing the microphone setup in studio, but he liked the sound too much not to include it. It was released as a promotional single in December 1994 and reached the Top 20 on the \"Billboard\" Modern Rock Tracks chart.\nReleased in 1995, \"Hurt\" clearly includes references to self-harm and heroin addiction.\nTour.\nThe Nine Inch Nails live band embarked on the Self Destruct tour in support of \"The Downward Spiral\". Chris Vrenna and James Woolley performed drums and keyboards respectively, Robin Finck replaced Richard Patrick on guitar and bassist Danny Lohner was added to the line-up. The stage set-up consisted of dirty curtains which would be pulled down and up for visuals shown during songs such as \"Hurt\". The back of the stage was littered with darker and standing lights, along with very few actual ones. The tour debuted the band's grungy and messy image in which they would come out in ragged clothes slathered in corn starch. The concerts were violent and chaotic, with band members often injuring themselves. They would frequently destroy their instruments at the end of concerts, attack each other, and stage-dive into the crowd.\nThe tour included a set at Woodstock '94 broadcast on pay-per-view and seen in as many as 24\u00a0million homes. The band being covered in mud was a result of pre-concert backstage play, contrary to the belief that it was an attention-grabbing ploy, thus making it difficult for Reznor to navigate the stage: Reznor pushed Lohner into the mud pit as the concert began and saw mud from his hair entering his eyes while performing. Nine Inch Nails was widely proclaimed to have \"stolen the show\" from its popular contemporaries, mostly classic rock bands, and its fan base expanded. The band received considerable mainstream success thereafter, performing with significantly higher production values and the addition of various theatrical visual elements. Its performance of \"Happiness in Slavery\" from the Woodstock concert earned the group a Grammy Award for Best Metal Performance in 1995. \"Entertainment Weekly\" commented about the band's Woodstock '94 performance: \"Reznor unstrings rock to its horrifying, melodramatic core\u2014an experience as draining as it is exhilarating\". Despite this acclaim, Reznor attributed his dislike of the concert to its technical difficulties.\nThe main leg of the tour featured Marilyn Manson as the supporting act, who featured bassist Jeordie White (then playing under the pseudonym \"Twiggy Ramirez\"); White later played bass with Nine Inch Nails from 2005 to 2007. After another tour leg supporting the remix album \"Further Down the Spiral\", Nine Inch Nails contributed to the Alternative Nation Festival in Australia and subsequently embarked on the Dissonance Tour, which included 26 separate performances with co-headliner David Bowie. Nine Inch Nails was the opening act for the tour, and its set transitioned into Bowie's set with joint performances of both bands' songs. However, the crowds reportedly did not respond positively to the pairing due to their creative differences.\nThe tour concluded with \"Nights of Nothing\", a three-night showcase of performances from Nothing Records bands Marilyn Manson, Prick, Meat Beat Manifesto, and Pop Will Eat Itself, which ended with an 80-minute set from Nine Inch Nails. \"Kerrang!\" described the Nine Inch Nails set during the Nights of Nothing showcase as \"tight, brash and dramatic\", but was disappointed at the lack of new material. On the second of the three nights, Richard Patrick was briefly reunited with the band and contributed guitar to a performance of \"Head Like a Hole\". After the Self Destruct tour, Chris Vrenna, member of the live band since 1988 and frequent contributor to Nine Inch Nails studio recordings, left the act permanently to pursue a career in producing and to form Tweaker.\nRelease and reception.\n\"The Downward Spiral\"s release date was delayed at various times to slow down Reznor's intended pace of the album's recording. The first delay caused the process of setting up Le Pig to take longer than he expected, and its release was postponed again as he was educating himself different ways to write songs that did not resemble those on \"Broken\" and \"Pretty Hate Machine\". He considered delivering the album to Interscope in early 1993, only to experience a writer's block as he was unable to produce any satisfactory material. Interscope grew impatient and concerned with this progress, but Reznor was not forced by their demands of expediency despite crediting the label for giving him creative freedom. He told rock music producer Rick Rubin that his motivation for creating the album was to get it finished, thus Rubin responded that Reznor might not do so until he makes music that is allowed to be heard. Reznor realized that he was in the most fortunate situation he imagined when the album was recorded with a normal budget, \"cool\" equipment, and a studio to work at.\nReleased on March 8, 1994, to instant success, \"The Downward Spiral\" debuted at number two on the US \"Billboard\" 200, selling nearly 119,000 copies in its first week. On October 28, 1998, the Recording Industry Association of America (RIAA) certified the album quadruple platinum, and by December 2011, it had sold 3.7\u00a0million copies in the United States. The album peaked at number nine on the UK Albums Chart, and on July 22, 2013, it was certified gold by the British Phonographic Industry (BPI), denoting shipments in excess of 100,000 copies in the United Kingdom. It reached number 13 on the Canadian \"RPM\" albums chart and received a triple platinum certification from the Canadian Recording Industry Association (CRIA) for shipping 200,000 copies in Canada. A group of early listeners of the album viewed it as \"commercial suicide\", but Reznor did not make it for profit as his goal was to slightly broaden Nine Inch Nails' scope. Reznor felt that the finished product he delivered to Interscope was complete and faithful to his vision and thought its commercial potential was limited, but after its release he was surprised by the success and received questions about a follow-up single with a music video to be shown on MTV. The album has since sold over four million copies worldwide.\nMany music critics and audiences praised \"The Downward Spiral\" for its abrasive, eclectic nature and dark themes and commented on the concept of a destruction of a man. \"The New York Times\" writer Jon Pareles' review of the album found the music to be highly abrasive. Pareles asserted that unlike other electro-industrial groups like Ministry and Nitzer Ebb, \"Reznor writes full-fledged tunes\" with stronger use of melodies than riffs. He noticed criticisms of Nine Inch Nails from industrial purists for popularizing the genre and the album's transgression. \"Village Voice\" critic Robert Christgau gave it an \"honorable mention\" in his capsule review column and summed the record up as, \"musically, Hieronymus Bosch as postindustrial atheist; lyrically, Transformers as kiddie porn.\" Jonathan Gold, writing for \"Rolling Stone\", likened the album to cyberpunk fiction. \"Entertainment Weekly\" reviewer Tom Sinclair commented: \"Reznor's pet topics (sex, power, S&amp;M, hatred, transcendence) are all here, wrapped in hooks that hit your psyche with the force of a blowtorch.\"\nAccolades.\n\"The Downward Spiral\" has been listed on several publications' best album lists. In 2003, the album was ranked number 201 on \"Rolling Stone\" magazine's list of The 500 Greatest Albums of All Time maintaining the rating in a 2012 revised list. The \"Rolling Stone\" staff wrote: \"Holing up in the one-time home of Manson-family victim Sharon Tate, Trent Reznor made an overpowering meditation on NIN's central theme: control.\" It moved up to 122 on the magazine's revised list in 2020. The album was placed 10th on \"Spin\"s \"125 Best Albums of the Past 25 Years\" list; the \"Spin\" staff quoted Ann Powers' review that appreciated its bleak, aggressive style. It was ranked number 488 in the book \"The Top 500 Heavy Metal Albums of All Time\" by heavy metal music critic Martin Popoff. In 2001, \"Q\" named \"The Downward Spiral\" as one of the \"50 Heaviest Albums of All Time\"; in 2010, the album was ranked number 102 on their \"250 Best Albums of Q's Lifetime (1986\u20132011)\" list. \"The Downward Spiral\" was featured in Robert Dimery's book \"1001 Albums You Must Hear Before You Die\". In May 2014, \"Loudwire\" placed \"The Downward Spiral\" at number two on its \"10 Best Hard Rock Albums of 1994\" list. In July 2014, \"Guitar World\" placed \"The Downward Spiral\" at number 43 in their \"Superunknown: 50 Iconic Albums That Defined 1994\" list.\nLegacy.\nThe immediate success of \"The Downward Spiral\" established Nine Inch Nails as a reputable force in the 1990s. The band's image and musical style became so recognizable that a Gatorade commercial featured a remix of \"Down in It\" without their involvement. Reznor felt uncomfortable with the media hype and success the band earned, received false reports of his death, depression, and was falsely reported to have had a relationship with serial killer Jeffrey Dahmer, and was depicted as a sex icon due to his visual appearance. Nine Inch Nails received several honors, including Grammy Award nominations for Best Alternative Performance for \"The Downward Spiral\" and Best Rock Song for \"Hurt\". After the release of \"The Downward Spiral\", many bands such as Gravity Kills, Stabbing Westward, Filter, and M\u00f6tley Cr\u00fce made albums that imitated the sound of Nine Inch Nails.\nReznor interpreted \"The Downward Spiral\" as an extension of himself that \"became the truth fulfilling itself,\" as he experienced personal and social issues presented in the album after its release. He had already struggled with social anxiety disorder and depression and started his abuse of narcotics including cocaine while he went on an alcohol binge. Around this time, his studio perfectionism, struggles with addiction, and bouts of writer's block prolonged the production of \"The Fragile\", and Reznor completed rehabilitation from drugs in 2001.\nOne year after \"The Downward Spiral\"\u2019s release, the band released an accompanying remix album titled \"Further Down the Spiral\". It features contributions from Coil with Danny Hyde, J. G. Thirlwell, electronic musician Aphex Twin, producer Rick Rubin, and Jane's Addiction guitarist Dave Navarro. The album peaked at number 23 on the \"Billboard\" 200 and received mixed reviews. \"Recoiled\", a remix EP of \"Gave Up\", \"Closer\", \"The Downward Spiral\", and \"Eraser\" by Coil, was released on February 24, 2014, via British record label Cold Spring.\nRetrospective reviews regard \"The Downward Spiral\" as one of the most important albums of the 1990s and Reznor's greatest work. The 2004 edition of \"The New Rolling Stone Album Guide\" gave the album five out of five stars and called it \"a powerful statement, and one of the landmark albums of the Nineties.\" Writing for \"Entertainment Weekly\", Kyle Anderson remembered watching the music video of \"Closer\" on MTV as an adolescent and expressed that the album changed his perception of popular music from that of songs heard on the radio to albums with cover art. \"Stereogum\"s Tom Breihan remains favorable toward the album since it is \"the one that most fully inhabits\" Nine Inch Nails' characteristics and influenced youth culture, with teenagers wearing ripped fish nets on their arms. The album was also included in the book \"1001 Albums You Must Hear Before You Die\". According to Acclaimed Music, it is the 165th most acclaimed album, based on appearances in critics' all-time lists.\nControversies.\n\"Big Man with a Gun\" lyrics.\n\"The Downward Spiral\"s emphasis on transgressive themes drew criticism from American social conservatives. Senator Bob Dole, then the head of the Republican Party, sharply denounced Time Warner, the former owner of Interscope's former parent company Warner Music Group, after a meeting between Michael J. Fuchs (head of WMG), William Bennett, and C. Delores Tucker. During the meeting, Tucker and Bennett demanded that Fuchs recite lyrics from \"Big Man with a Gun\". Interscope had previously been blamed for releasing gangsta rap albums by rappers such as Dr. Dre, Tupac Shakur, and Snoop Dogg that were deemed objectionable. Reznor called Tucker (who erroneously referred to Nine Inch Nails as a gangsta rap act) \"such a fucking idiot\", and claimed that the song was actually a satire of the gangsta rap genre as a whole and was originally about madness. Reznor conceded \"The Downward Spiral\" could be \"harmful, through implying and subliminally suggesting things\", whereas hardcore hip hop could be \"cartoonish\". Robert Bork also repeatedly referenced \"Big Man with a Gun\" in his book \"Slouching Toward Gomorrah\" as evidence of a cultural decline. The book also incorrectly states that it is a rap song.\nAlleged contribution to the Columbine shooting.\nBefore the Columbine High School massacre, perpetrator Dylan Klebold referenced lyrics from Nine Inch Nails songs multiple times in his journal. Klebold heavily identified with the protagonist of \"The Downward Spiral\" as a symbol of his own depression. On May 4, 1999, a hearing on the marketing and distribution practices of violent content to minors by the television, music, film, and video game industries was conducted before the United States Senate Committee on Commerce, Science and Transportation. The committee heard testimony from cultural observers, professors, and mental health professionals, that included conservative William Bennett and the Archbishop of Denver, Reverend Charles J. Chaput. Participants criticized the album, Nine Inch Nails' label-mate Marilyn Manson, and the 1999 film \"The Matrix\" for their alleged contribution to the environment that made incidents like Columbine possible. The committee requested that the Federal Trade Commission and the United States Department of Justice investigate the entertainment industry's marketing practices to minors.\niPhone application refusal.\nIn 2009, Apple rejected a proposal for a Nine Inch Nails iPhone application, citing objectionable content in the title track. Days later, Apple reversed the decision, but refused to explain its reasoning.\nTrack listing.\nOriginal release.\nNotes\nDeluxe edition (Halo 8 DE).\nTo mark the album's tenth anniversary, \"The Downward Spiral\" was re-released on November 23, 2004, in high-resolution SACD and DualDisc formats. Disc one of the album's deluxe edition re-release is nearly identical to the original version; track anomalies such as sounds from previous tracks creeping up on start of tracks are fixed, and it includes a stereo and multi-channel SACD layer. The second bonus disc is a collection of remixes and B-sides and also includes a stereo SACD layer in addition to the Redbook CD layer. The last three tracks on the bonus disc are previously unreleased demo recordings from the original album.\n\"DualDisc\" (Halo 8 DVD-A)\nThe DualDisc edition of \"The Downward Spiral\" contains the same CD content on Side A as the Deluxe Edition, with a DVD-Audio layer on Side B. When played on DVD-Video players a Dolby Digital 5.1 multi-channel or Dolby Digital 2.0 stereo mix of \"The Downward Spiral\" can be selected, along with videos of \"March of the Pigs\", \"Hurt\" and an uncensored video of \"Closer\". There is also an interactive discography and an image gallery. High resolution 24-bit/48\u00a0kHz 5.1 Surround sound and stereo versions of \"The Downward Spiral\" can be played on a DVD-Audio player, allowing the user a similar high fidelity experience as the SACD layer of the Deluxe Edition. The DualDisc release does not contain the additional B-sides and demo tracks.\nPersonnel.\nCredits adapted from the liner notes of \"The Downward Spiral\"."}
{"id": "9442", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9442", "title": "Violence and Redemption", "text": ""}
{"id": "9443", "revid": "122", "url": "https://en.wikipedia.org/wiki?curid=9443", "title": "Why It Went Wrong", "text": ""}
{"id": "9444", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9444", "title": "Ernest Hemingway/Bibliography", "text": ""}
{"id": "9447", "revid": "4967956", "url": "https://en.wikipedia.org/wiki?curid=9447", "title": "Egyptian Lover", "text": "Gregory Broussard (born August 31, 1963 in Los Angeles, California), better known by his stage name Egyptian Lover, is an American musician, vocalist, producer and DJ, and was a part of the L.A. dance music and rap scene in the early 1980s.\nHistory.\nThe Egyptian Lover started out as a DJ in Los Angeles with Uncle Jamm's Army, DJing dances as large as the L.A. Sports Arena with 10,000 people. He began recording around Los Angeles in 1982 as a member of the Radio Crew, as well as Uncle Jamm's Army.\nMost of the Egyptian Lover's successful recordings were 12\" singles. He eventually released some of the earliest rap LPs, but they were less popular than his singles. On the strength of an alternate mix of his most popular single \"Egypt, Egypt\", 1984's \"On the Nile\" was moderately successful. After a break in the early 1990s, Egyptian Lover returned in 1994 with \"Back from the Tomb\", his first full-length album in over ten years.\nThe Egyptian Lover also established his own record company, Egyptian Empire Records, which included artists such as Rodney O &amp; Joe Cooley 2 Oclock &amp; Te &amp; Joezee.\nHis 2015 release, \"1984\", continues his tradition of using all analog equipment, including the Roland TR-808, along with much of the same gear used on his recordings of the 1980s. The name \"1984\" refers to his earlier albums. The album was recorded at Skip Saylor, Encore Studios, and at RUSK Studios, the same studio where \"On The Nile\" was recorded in 1984. It is widely available on double gatefold LP, CD and cassette tape.\nTouring.\nThe Egyptian Lover began touring again in 2004 throughout Europe, Asia, and North America. His performances often begin with mixing records on turntables before segueing into his original compositions.\nIn 2008, he supported M.I.A. in her People vs. Money Tour."}
{"id": "9448", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9448", "title": "Exhaust pipe", "text": ""}
{"id": "9449", "revid": "571203446", "url": "https://en.wikipedia.org/wiki?curid=9449", "title": "Electro funk", "text": ""}
{"id": "9450", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=9450", "title": "Electrical telegraph", "text": "An electrical telegraph is a point-to-point text messaging system, primarily used from the 1840s until the mid 20th century when it was slowly replaced by other telecommunication systems. It used coded pulses of electric current through dedicated wires to transmit information over long distances. It was the first electrical telecommunications system, the most widely used of a number of early messaging systems called \"telegraphs\", devised to send text messages more rapidly than written messages could be sent. This system allowed for communication to occur without the necessity of physical transportation. Prior to the electric telegraph, semaphore systems were used, including beacons, smoke signals, flag semaphore, and optical telegraphs for visual signals to communicate over distances of land.\nAn electrical telegraph consisted of two or more geographically separated stations (often called telegraph offices) connected by wires, usually supported overhead on utility poles. There were many different electrical telegraph systems invented, but the ones that became widespread fit into two broad categories. The first category consists of needle telegraphs in which a needle pointer is made to move electromagnetically with a pulse of electric current from a battery or dynamo down the telegraph line. Early systems used multiple needles requiring multiple wires. The first commercial system, and the most widely used needle telegraph, was the Cooke and Wheatstone telegraph, invented in 1837. Early equipment sets used five needles to point to the letter being transmitted, but the cost of installing wires was more economically significant than the cost of training operators so a single-needle system with a code that had to be learned became the norm.\nThe second category consists of armature systems in which the pulse activates a telegraph sounder which makes a click. The archetype of this category was the Morse system, invented by Samuel Morse in 1838, using a single wire. At the sending station, an operator would tap on a switch called a telegraph key, spelling out text messages in Morse code. Originally, the armature was intended to make marks on paper tape, but operators learned to interpret the clicks and it was more efficient to write down the message directly. In 1865, the Morse system became the standard for international communication with a modified code developed for German railways. However, some countries continued to use established national systems internally for some time afterwards.\nIn the 1840s, the electrical telegraph superseded optical telegraph systems (except in France), becoming the standard way to send urgent messages. By the latter half of the century, most developed nations had created commercial telegraph networks with local telegraph offices in most cities and towns, allowing the public to send messages called telegrams addressed to any person in the country, for a fee. Beginning in 1854, submarine telegraph cables allowed for the first rapid communication between continents. Electrical telegraph networks permitted people and commerce to transmit messages across both continents and oceans almost instantly, with widespread social and economic impacts. In the early 20th century the telegraph was slowly replaced by teletype networks.\nHistory.\nEarly work.\nFrom early studies of electricity, electrical phenomena were known to travel with great speed, and many experimenters worked on the application of electricity to communications at a distance. All the known effects of electricity\u2014such as sparks, electrostatic attraction, chemical changes, electric shocks, and later electromagnetism\u2014were applied to the problems of detecting controlled transmissions of electricity at various distances.\nIn 1753, an anonymous writer in the \"Scots Magazine\" suggested an electrostatic telegraph. Using one wire for each letter of the alphabet, a message could be transmitted by connecting the wire terminals in turn to an electrostatic machine, and observing the deflection of pith balls at the far end. The writer has never been positively identified, but the letter was signed C.M. and posted from Renfrew leading to a Charles Marshall of Renfrew being suggested. Telegraphs employing electrostatic attraction were the basis of early experiments in electrical telegraphy in Europe, but were abandoned as being impractical and were never developed into a useful communication system.\nIn 1774, Georges-Louis Le Sage realised an early electric telegraph. The telegraph had a separate wire for each of the 26 letters of the alphabet and its range was only between two rooms of his home.\nIn 1800, Alessandro Volta invented the voltaic pile, allowing for a continuous current of electricity for experimentation. This became a source of a low-voltage current that could be used to produce more distinct effects, and which was far less limited than the momentary discharge of an electrostatic machine, which with Leyden jars were the only previously known man-made sources of electricity.\nAnother very early experiment in electrical telegraphy was an \"electrochemical telegraph\" created by the German physician, anatomist and inventor Samuel Thomas von S\u00f6mmering in 1809, based on an earlier, less robust design of 1804 by Spanish polymath and scientist Francisco Salva Campillo. Both their designs employed multiple wires (up to 35) to represent almost all Latin letters and numerals. Thus, messages could be conveyed electrically up to a few kilometers (in von S\u00f6mmering's design), with each of the telegraph receiver's wires immersed in a separate glass tube of acid. An electric current was sequentially applied by the sender through the various wires representing each letter of a message; at the recipient's end, the currents electrolysed the acid in the tubes in sequence, releasing streams of hydrogen bubbles next to each associated letter or numeral. The telegraph receiver's operator would watch the bubbles and could then record the transmitted message. This is in contrast to later telegraphs that used a single wire (with ground return).\nHans Christian \u00d8rsted discovered in 1820 that an electric current produces a magnetic field that will deflect a compass needle. In the same year Johann Schweigger invented the galvanometer, with a coil of wire around a compass, which could be used as a sensitive indicator for an electric current. Also that year, Andr\u00e9-Marie Amp\u00e8re suggested that telegraphy could be achieved by placing small magnets under the ends of a set of wires, one pair of wires for each letter of the alphabet. He was apparently unaware of Schweigger's invention at the time, which would have made his system much more sensitive. In 1825, Peter Barlow tried Amp\u00e8re's idea but only got it to work over and declared it impractical. In 1830 William Ritchie improved on Amp\u00e8re's design by placing the magnetic needles inside a coil of wire connected to each pair of conductors. He successfully demonstrated it, showing the feasibility of the electromagnetic telegraph, but only within a lecture hall.\nIn 1825, William Sturgeon invented the electromagnet, with a single winding of uninsulated wire on a piece of varnished iron, which increased the magnetic force produced by electric current. Joseph Henry improved it in 1828 by placing several windings of insulated wire around the bar, creating a much more powerful electromagnet which could operate a telegraph through the high resistance of long telegraph wires. During his tenure at The Albany Academy from 1826 to 1832, Henry first demonstrated the theory of the 'magnetic telegraph' by ringing a bell through of wire strung around the room in 1831.\nIn 1835, Joseph Henry and Edward Davy independently invented the mercury dipping electrical relay, in which a magnetic needle is dipped into a pot of mercury when an electric current passes through the surrounding coil. In 1837, Davy invented the much more practical metallic make-and-break relay which became the relay of choice in telegraph systems and a key component allowing weak signals to be periodically renewed. Davy demonstrated his telegraph system in Regent's Park in 1837 and was granted a patent on 4 July 1838. Davy also invented a printing telegraph which used the electric current from the telegraph signal to mark a ribbon of calico infused with potassium iodide and calcium hypochlorite.\nFirst working systems.\nThe first working telegraph was built by the English inventor Francis Ronalds in 1816 and used static electricity. At the family home on Hammersmith Mall, he set up a complete subterranean system in a long trench as well as an long overhead telegraph. The lines were connected at both ends to revolving dials marked with the letters of the alphabet and electrical impulses sent along the wire were used to transmit messages. Offering his invention to the Admiralty in July 1816, it was rejected as \"wholly unnecessary\". His account of the scheme and the possibilities of rapid global communication in \"Descriptions of an Electrical Telegraph and of some other Electrical Apparatus\" was the first published work on electric telegraphy and even described the risk of signal retardation due to induction. Elements of Ronalds' design were utilised in the subsequent commercialisation of the telegraph over 20 years later.\nPioneering work in Russia.\nThe Schilling telegraph, invented by Baron Schilling von Canstatt in 1832, was an early needle telegraph. It had a transmitting device that consisted of a keyboard with 16 black-and-white keys. These served for switching the electric current. The receiving instrument consisted of six galvanometers with magnetic needles, suspended from silk threads. The two stations of Schilling's telegraph were connected by eight wires; six were connected with the galvanometers, one served for the return current and one for a signal bell. When at the starting station the operator pressed a key, the corresponding pointer was deflected at the receiving station. Different positions of black and white flags on different disks gave combinations which corresponded to the letters or numbers. Pavel Schilling subsequently improved its apparatus by reducing the number of connecting wires from eight to two.\nOn 21 October 1832, Schilling managed a short-distance transmission of signals between two telegraphs in different rooms of his apartment. In 1836, the British government attempted to buy the design but Schilling instead accepted overtures from Nicholas\u00a0I of Russia. Schilling's telegraph was tested on a experimental underground and underwater cable, laid around the building of the main Admiralty in Saint Petersburg and was approved for a telegraph between the imperial palace at Peterhof and the naval base at Kronstadt. However, the project was cancelled following Schilling's death in 1837. Schilling was also one of the first to put into practice the idea of the binary system of signal transmission.\nHis work was taken over and developed by Moritz von Jacobi. He invented telegraph equipment which was used by Tsar Alexander III to connect the Imperial palace at Tsarskoye Selo and Kronstadt Naval Base.\nIn 1833, Carl Friedrich Gauss, together with the physics professor Wilhelm Weber in G\u00f6ttingen installed a wire above the town's roofs. Gauss combined the Poggendorff-Schweigger multiplicator with his magnetometer to build a more sensitive device, the galvanometer. To change the direction of the electric current, he constructed a commutator of his own. As a result, he was able to make the distant needle move in the direction set by the commutator on the other end of the line.\nAt first, Gauss and Weber used the telegraph to coordinate time, but soon they developed other signals and finally, their own alphabet. The alphabet was encoded in a binary code that was transmitted by positive or negative voltage pulses which were generated by means of moving an induction coil up and down over a permanent magnet and connecting the coil with the transmission wires by means of the commutator. The page of Gauss' laboratory notebook containing both his code and the first message transmitted, as well as a replica of the telegraph made in the 1850s under the instructions of Weber are kept in the faculty of physics at the University of G\u00f6ttingen, in Germany.\nGauss was convinced that this communication would be a help to his kingdom's towns. Later in the same year, instead of a Voltaic pile, Gauss used an induction pulse, enabling him to transmit seven letters a minute instead of two. The inventors and university did not have the funds to develop the telegraph on their own, but they received funding from Alexander von Humboldt. Carl August Steinheil in Munich was able to build a telegraph network within the city in 1835\u20131836. He installed a telegraph line along the first German railroad in 1835. Steinheil built a telegraph along the Nuremberg - F\u00fcrth railway line in 1838, the first earth-return telegraph put into service.\nBy 1837, William Fothergill Cooke and Charles Wheatstone had co-developed a telegraph system which used a number of needles on a board that could be moved to point to letters of the alphabet. Any number of needles could be used, depending on the number of characters it was required to code. In May 1837 they patented their system. The patent recommended five needles, which coded twenty of the alphabet's 26 letters.\nSamuel Morse independently developed and patented a recording electric telegraph in 1837. Morse's assistant Alfred Vail developed an instrument that was called the register for recording the received messages. It embossed dots and dashes on a moving paper tape by a stylus which was operated by an electromagnet. Morse and Vail developed the Morse code signalling alphabet. The first telegram in the United States was sent by Morse on 11 January 1838, across of wire at Speedwell Ironworks near Morristown, New Jersey, although it was only later, in 1844, that he sent the message \"WHAT HATH GOD WROUGHT\" over the from the Capitol in Washington to the old Mt. Clare Depot in Baltimore.\nCommercial telegraphy.\nCooke and Wheatstone system.\nThe first commercial electrical telegraph was the Cooke and Wheatstone system. A demonstration four-needle system was installed on the Euston to Camden Town section of Robert Stephenson's London and Birmingham Railway in 1837 for signalling rope-hauling of locomotives. It was rejected in favour of pneumatic whistles. Cooke and Wheatstone had their first commercial success with a system installed on the Great Western Railway over the from Paddington station to West Drayton in 1838. This was a five-needle, six-wire system. This system suffered from failing insulation on the underground cables. When the line was extended to Slough in 1843, the telegraph was converted to a one-needle, two-wire system with uninsulated wires on poles. The one-needle telegraph proved highly successful on British railways, and 15,000 sets were still in use at the end of the nineteenth century. Some remained in service in the 1930s. The Electric Telegraph Company, the world's first public telegraphy company was formed in 1845 by financier John Lewis Ricardo and Cooke.\nWheatstone ABC telegraph.\nWheatstone developed a practical alphabetical system in 1840 called the A.B.C. System, used mostly on private wires. This consisted of a \"communicator\" at the sending end and an \"indicator\" at the receiving end. The communicator consisted of a circular dial with a pointer and the 26 letters of the alphabet (and four punctuation marks) around its circumference. Against each letter was a key that could be pressed. A transmission would begin with the pointers on the dials at both ends set to the start position. The transmitting operator would then press down the key corresponding to the letter to be transmitted. In the base of the communicator was a magneto actuated by a handle on the front. This would be turned to apply an alternating voltage to the line. Each half cycle of the current would move the pointers at both ends on by one position. When the pointer reached the position of the depressed key, it would stop and the magneto would be disconnected from the line. The communicator's pointer was geared to the magneto mechanism. The indicator's pointer was moved by a polarised electromagnet whose armature was coupled to it through an escapement. Thus the alternating line voltage moved the indicator's pointer on to the position of the depressed key on the communicator. Pressing another key would then release the pointer and the previous key, and re-connect the magneto to the line. These machines were very robust and simple to operate, and they stayed in use in Britain until well into the 20th century.\nMorse system.\nIn 1851, a conference in Vienna of countries in the German-Austrian Telegraph Union (which included many central European countries) adopted the Morse telegraph as the system for international communications. The code adopted was considerably modified from the original Morse code, and was based on a code used on Hamburg railways (Gerke, 1848). A common code was a necessary step to allow direct telegraph connection between countries. With different codes, additional operators were required to translate and retransmit the message. In 1865, a conference in Paris adopted Gerke's code as the International Morse code and was henceforth the international standard. The US, however, continued to use American Morse code internally for some time, hence international messages required retransmission in both directions.\nIn the United States, the Morse/Vail telegraph was quickly deployed in the two decades following the first demonstration in 1844. The overland telegraph connected the west coast of the continent to the east coast by 24 October 1861, bringing an end to the Pony Express.\nFrance.\nFrance was slow to adopt the electrical telegraph, because of the extensive optical telegraph system built during the Napoleonic era. There was also serious concern that an electrical telegraph could be quickly put out of action by enemy saboteurs, something that was much more difficult to do with optical telegraphs which had no exposed hardware between stations. The Foy-Breguet telegraph was eventually adopted. This was a two-needle system using two signal wires but displayed in a uniquely different way to other needle telegraphs. The needles made symbols similar to the Chappe optical system symbols, making it more familiar to the telegraph operators. The optical system was decommissioned starting in 1846, but not completely until 1855. In that year the Foy-Breguet system was replaced with the Morse system.\nExpansion.\nAs well as the rapid expansion of the use of the telegraphs along the railways, they soon spread into the field of mass communication with the instruments being installed in post offices. The era of mass personal communication had begun. Telegraph networks were expensive to build, but financing was readily available, especially from London bankers. By 1852, National systems were in operation in major countries: \nThe New York and Mississippi Valley Printing Telegraph Company, for example, was created in 1852 in Rochester, New York and eventually became the Western Union Telegraph Company. Although many countries had telegraph networks, there was no \"worldwide\" interconnection. Message by post was still the primary means of communication to countries outside Europe.\nTelegraphic improvements.\nA continuing goal in telegraphy was to reduce the cost per message by reducing hand-work, or increasing the sending and receiving rate. There were many experiments with moving pointers, and various electrical encodings. However, most systems were too complicated and unreliable. A successful expedient to reduce the cost per message was the development of telegraphese.\nThe first system that did not require skilled technicians to operate was Charles Wheatstone's ABC system in 1840 in which the letters of the alphabet were arranged around a clock-face, and the signal caused a needle to indicate the letter. This early system required the receiver to be present in real time to record the message and it reached speeds of up to 15 words a minute.\nIn 1846, Alexander Bain patented a chemical telegraph in Edinburgh. The signal current moved an iron pen across a moving paper tape soaked in a mixture of ammonium nitrate and potassium ferrocyanide, decomposing the chemical and producing readable blue marks in Morse code. The speed of the printing telegraph was 16 and a half words per minute, but messages still required translation into English by live copyists. Chemical telegraphy came to an end in the US in 1851, when the Morse group defeated the Bain patent in the US District Court.\nFor a brief period, starting with the New York\u2013Boston line in 1848, some telegraph networks began to employ sound operators, who were trained to understand Morse code aurally. Gradually, the use of sound operators eliminated the need for telegraph receivers to include register and tape. Instead, the receiving instrument was developed into a \"sounder\", an electromagnet that was energized by a current and attracted a small iron lever. When the sounding key was opened or closed, the sounder lever struck an anvil. The Morse operator distinguished a dot and a dash by the short or long interval between the two clicks. The message was then written out in long-hand.\nRoyal Earl House developed and patented a letter-printing telegraph system in 1846 which employed an alphabetic keyboard for the transmitter and automatically printed the letters on paper at the receiver, and followed this up with a steam-powered version in 1852. Advocates of printing telegraphy said it would eliminate Morse operators' errors. The House machine was used on four main American telegraph lines by 1852. The speed of the House machine was announced as 2600 words an hour.\nDavid Edward Hughes invented the printing telegraph in 1855; it used a keyboard of 26 keys for the alphabet and a spinning type wheel that determined the letter being transmitted by the length of time that had elapsed since the previous transmission. The system allowed for automatic recording on the receiving end. The system was very stable and accurate and became accepted around the world.\nThe next improvement was the Baudot code of 1874. French engineer \u00c9mile Baudot patented a printing telegraph in which the signals were translated automatically into typographic characters. Each character was assigned a five-bit code, mechanically interpreted from the state of five on/off switches. Operators had to maintain a steady rhythm, and the usual speed of operation was 30 words per minute.\nBy this point, reception had been automated, but the speed and accuracy of the transmission were still limited to the skill of the human operator. The first practical automated system was patented by Charles Wheatstone. The message (in Morse code) was typed onto a piece of perforated tape using a keyboard-like device called the 'Stick Punch'. The transmitter automatically ran the tape through and transmitted the message at the then exceptionally high speed of 70 words per minute.\nTeleprinters.\nAn early successful teleprinter was invented by Frederick G. Creed. In Glasgow he created his first keyboard perforator, which used compressed air to punch the holes. He also created a reperforator (receiving perforator) and a printer. The reperforator punched incoming Morse signals onto paper tape and the printer decoded this tape to produce alphanumeric characters on plain paper. This was the origin of the Creed High Speed Automatic Printing System, which could run at an unprecedented 200 words per minute. His system was adopted by the \"Daily Mail\" for daily transmission of the newspaper contents.\nWith the invention of the teletypewriter, telegraphic encoding became fully automated. Early teletypewriters used the ITA-1 Baudot code, a five-bit code. This yielded only thirty-two codes, so it was over-defined into two \"shifts\", \"letters\" and \"figures\". An explicit, unshared shift code prefaced each set of letters and figures. In 1901, Baudot's code was modified by Donald Murray.\nIn the 1930s, teleprinters were produced by Teletype in the US, Creed in Britain and Siemens in Germany.\nBy 1935, message routing was the last great barrier to full automation. Large telegraphy providers began to develop systems that used telephone-like rotary dialling to connect teletypewriters. These resulting systems were called \"Telex\" (TELegraph EXchange). Telex machines first performed rotary-telephone-style pulse dialling for circuit switching, and then sent data by ITA2. This \"type A\" Telex routing functionally automated message routing.\nThe first wide-coverage Telex network was implemented in Germany during the 1930s as a network used to communicate within the government.\nAt the rate of 45.45 (\u00b10.5%) baud \u2013 considered speedy at the time \u2013 up to 25 telex channels could share a single long-distance telephone channel by using \"voice frequency telegraphy multiplexing\", making telex the least expensive method of reliable long-distance communication.\nAutomatic teleprinter exchange service was introduced into Canada by CPR Telegraphs and CN Telegraph in July 1957 and in 1958, Western Union started to build a Telex network in the United States.\nThe harmonic telegraph.\nThe most expensive aspect of a telegraph system was the installation \u2013 the laying of the wire, which was often very long. The costs would be better covered by finding a way to send more than one message at a time through the single wire, thus increasing revenue per wire. Early devices included the duplex and the quadruplex which allowed, respectively, one or two telegraph transmissions in each direction. However, an even greater number of channels was desired on the busiest lines. In the latter half of the 1800s, several inventors worked towards creating a method for doing just that, including Charles Bourseul, Thomas Edison, Elisha Gray, and Alexander Graham Bell.\nOne approach was to have resonators of several different frequencies act as carriers of a modulated on-off signal. This was the harmonic telegraph, a form of frequency-division multiplexing. These various frequencies, referred to as harmonics, could then be combined into one complex signal and sent down the single wire. On the receiving end, the frequencies would be separated with a matching set of resonators.\nWith a set of frequencies being carried down a single wire, it was realized that the human voice itself could be transmitted electrically through the wire. This effort led to the invention of the telephone. (While the work toward packing multiple telegraph signals onto one wire led to telephony, later advances would pack multiple voice signals onto one wire by increasing the bandwidth by modulating frequencies much higher than human hearing. Eventually, the bandwidth was widened much further by using laser light signals sent through fiber optic cables. Fiber optic transmission can carry 25,000 telephone signals simultaneously down a single fiber.)\nOceanic telegraph cables.\nSoon after the first successful telegraph systems were operational, the possibility of transmitting messages across the sea by way of submarine communications cables was first proposed. One of the primary technical challenges was to sufficiently insulate the submarine cable to prevent the electric current from leaking out into the water. In 1842, a Scottish surgeon William Montgomerie introduced gutta-percha, the adhesive juice of the \"Palaquium gutta\" tree, to Europe. Michael Faraday and Wheatstone soon discovered the merits of gutta-percha as an insulator, and in 1845, the latter suggested that it should be employed to cover the wire which was proposed to be laid from Dover to Calais. Gutta-percha was used as insulation on a wire laid across the Rhine between Deutz and Cologne. In 1849, C. V. Walker, electrician to the South Eastern Railway, submerged a wire coated with gutta-percha off the coast from Folkestone, which was tested successfully.\nJohn Watkins Brett, an engineer from Bristol, sought and obtained permission from Louis-Philippe in 1847 to establish telegraphic communication between France and England. The first undersea cable was laid in 1850, connecting the two countries and was followed by connections to Ireland and the Low Countries.\nThe Atlantic Telegraph Company was formed in London in 1856 to undertake to construct a commercial telegraph cable across the Atlantic Ocean. It was successfully completed on 18 July 1866 by the ship SS \"Great Eastern\", captained by Sir James Anderson after many mishaps along the away. John Pender, one of the men on the Great Eastern, later founded several telecommunications companies primarily laying cables between Britain and Southeast Asia. Earlier transatlantic submarine cables installations were attempted in 1857, 1858 and 1865. The 1857 cable only operated intermittently for a few days or weeks before it failed. The study of underwater telegraph cables accelerated interest in mathematical analysis of very long transmission lines. The telegraph lines from Britain to India were connected in 1870. (Those several companies combined to form the \"Eastern Telegraph Company\" in 1872.) The HMS \"Challenger\" expedition in 1873\u20131876 mapped the ocean floor for future underwater telegraph cables.\nAustralia was first linked to the rest of the world in October 1872 by a submarine telegraph cable at Darwin. This brought news reports from the rest of the world. The telegraph across the Pacific was completed in 1902, finally encircling the world.\nFrom the 1850s until well into the 20th century, British submarine cable systems dominated the world system. This was set out as a formal strategic goal, which became known as the All Red Line. In 1896, there were thirty cable laying ships in the world and twenty-four of them were owned by British companies. In 1892, British companies owned and operated two-thirds of the world's cables and by 1923, their share was still 42.7 percent.\nCable and Wireless Company.\nCable &amp; Wireless was a British telecommunications company that traced its origins back to the 1860s, with Sir John Pender as the founder, although the name was only adopted in 1934. It was formed from successive mergers including: \nTelegraphy and longitude.\nMain article \u00a7 Section: .\nThe telegraph was very important for sending time signals to determine longitude, providing greater accuracy than previously available. Longitude was measured by comparing local time (for example local noon occurs when the sun is at its highest above the horizon) with absolute time (a time that is the same for an observer anywhere on earth). If the local times of two places differ by one hour, the difference in longitude between them is 15\u00b0 (360\u00b0/24h). Before telegraphy, absolute time could be obtained from astronomical events, such as eclipses, occultations or lunar distances, or by transporting an accurate clock (a chronometer) from one location to the other.\nThe idea of using the telegraph to transmit a time signal for longitude determination was suggested by Fran\u00e7ois Arago to Samuel Morse in 1837, and the first test of this idea was made by Capt. Wilkes of the U.S. Navy in 1844, over Morse's line between Washington and Baltimore. The method was soon in practical use for longitude determination, in particular by the U.S. Coast Survey, and over longer and longer distances as the telegraph network spread across North America and the world, and as technical developments improved accuracy and productivity\nThe \"telegraphic longitude net\" soon became worldwide. Transatlantic links between Europe and North America were established in 1866 and 1870. The US Navy extended observations into the West Indies and Central and South America with an additional transatlantic link from South America to Lisbon between 1874 and 1890. British, Russian and US observations created a chain from Europe through Suez, Aden, Madras, Singapore, China and Japan, to Vladivostok, thence to Saint Petersburg and back to Western Europe. Australia was connected to Singapore via Java in 1871 and the web circled the globe in 1902 with the connection of Australia and New Zealand to Canada via the All Red Line. The double determination of longitudes from east and west agreed within one second of arc (1/15 second of time, less than 30 metres).\nTelegraphy in war.\nThe ability to send telegrams brought obvious advantages to those conducting war. Secret messages were encoded, so interception alone would not be sufficient for the opposing side to gain an advantage. There were geographical constraints on intercepting the telegraph cables, but once radio was used, interception could be much more widespread.\nCrimean War.\nThe Crimean War was one of the first conflicts to use telegraphs and was one of the first to be documented extensively. In 1854, the government in London created a military Telegraph Detachment for the Army commanded by an officer of the Royal Engineers. It was to comprise twenty-five men from the Royal Corps of Sappers &amp; Miners trained by the Electric Telegraph Company to construct and work the first field electric telegraph.\nJournalistic recording of the war was provided by William Howard Russell (writing for \"The Times\" newspaper) with photographs by Roger Fenton. News from war correspondents kept the public of the nations involved in the war informed of the day-to-day events in a way that had not been possible in any previous war. After the French extended the telegraph to the coast of the Black Sea in late 1854, the news reached London in two days. When the British laid an underwater cable to the Crimean peninsula in April 1855, news reached London in a few hours. The daily news reports energised public opinion, which brought down the government and led to Lord Palmerston becoming prime minister.\nAmerican Civil War.\nDuring the American Civil War the telegraph proved its value as a tactical, operational, and strategic communication medium and an important contributor to Union victory. By contrast the Confederacy failed to make effective use of the South's much smaller telegraph network. Prior to the War the telegraph systems were primarily used in the commercial sector. Government buildings were not inter-connected with telegraph lines, but relied on runners to carry messages back and forth. Before the war the Government saw no need to connect lines within city limits, however, they did see the use in connections between cities. Washington D.C. being the hub of government, it had the most connections, but there were only a few lines running north and south out of the city. It wasn't until the Civil War that the government saw the true potential of the telegraph system. Soon after the shelling of Fort Sumter, the South cut telegraph lines running into D.C., which put the city in a state of panic because they feared an immediate Southern invasion.\nWithin 6 months of the start of the war, the U.S. Military Telegraph Corps (USMT) had laid approximately of line. By war's end they had laid approximately of line, 8,000 for military and 5,000 for commercial use, and had handled approximately 6.5\u00a0million messages. The telegraph was not only important for communication within the armed forces, but also in the civilian sector, helping political leaders to maintain control over their districts.\nEven before the war, the American Telegraph Company censored suspect messages informally to block aid to the secession movement. During the war, Secretary of War Simon Cameron, and later Edwin Stanton, wanted control over the telegraph lines to maintain the flow of information. Early in the war, one of Stanton's first acts as Secretary of War was to move telegraph lines from ending at McClellan's headquarters to terminating at the War Department. Stanton himself said \"[telegraphy] is my right arm\". Telegraphy assisted Northern victories, including the Battle of Antietam (1862), the Battle of Chickamauga (1863), and Sherman's March to the Sea (1864).\nThe telegraph system still had its flaws. The USMT, while the main source of telegraphers and cable, was still a civilian agency. Most operators were first hired by the telegraph companies and then contracted out to the War Department. This created tension between Generals and their operators. One source of irritation was that USMT operators did not have to follow military authority. Usually they performed without hesitation, but they were not required to, so Albert Myer created a U.S. Army Signal Corps in February 1863. As the new head of the Signal Corps, Myer tried to get all telegraph and flag signaling under his command, and therefore subject to military discipline. After creating the Signal Corps, Myer pushed to further develop new telegraph systems. While the USMT relied primarily on civilian lines and operators, the Signal Corp's new field telegraph could be deployed and dismantled faster than USMT's system.\nFirst World War.\nDuring World War I, Britain's telegraph communications were almost completely uninterrupted, while it was able to quickly cut Germany's cables worldwide. The British government censored telegraph cable companies in an effort to root out espionage and restrict financial transactions with Central Powers nations. British access to transatlantic cables and its codebreaking expertise led to the Zimmermann Telegram incident that contributed to the US joining the war. Despite British acquisition of German colonies and expansion into the Middle East, debt from the war led to Britain's control over telegraph cables to weaken while US control grew.\nSecond World War.\nWorld War II revived the 'cable war' of 1914\u20131918. In 1939, German-owned cables across the Atlantic were cut once again, and, in 1940, Italian cables to South America and Spain were cut in retaliation for Italian action against two of the five British cables linking Gibraltar and Malta. Electra House, Cable &amp; Wireless's head office and central cable station, was damaged by German bombing in 1941.\nResistance movements in occupied Europe sabotaged communications facilities such as telegraph lines, forcing the Germans to use wireless telegraphy, which could then be intercepted by Britain. The Germans developed a highly complex teleprinter attachment (German: \"Schl\u00fcssel-Zusatz\", \"cipher attachment\") that was used for enciphering telegrams, using the Lorenz cipher, between German High Command (OKW) and the army groups in the field. These contained situation reports, battle plans, and discussions of strategy and tactics. Britain intercepted these signals, diagnosed how the encrypting machine worked, and decrypted a large amount of teleprinter traffic.\nEnd of the telegraph era.\nIn America, the end of the telegraph era can be associated with the fall of the Western Union Telegraph Company. Western Union was the leading telegraph provider for America and was seen as the best competition for the National Bell Telephone Company. Western Union and Bell were both invested in telegraphy and telephone technology. Western Union's decision to allow Bell to gain the advantage in telephone technology was the result of Western Union's upper management's failure to foresee the surpassing of the telephone over the, at the time, dominant telegraph system. Western Union soon lost the legal battle for the rights to their telephone copyrights. This led to Western Union agreeing to a lesser position in the telephone competition, which in turn led to the lessening of the telegraph.\nWhile the telegraph was not the focus of the legal battles that occurred around 1878, the companies that were affected by the effects of the battle were the main powers of telegraphy at the time. Western Union thought that the agreement of 1878 would solidify telegraphy as the long-range communication of choice. However, due to the underestimates of telegraph's future and poor contracts, Western Union found itself declining. AT&amp;T acquired working control of Western Union in 1909 but relinquished it in 1914 under threat of antitrust action. AT&amp;T bought Western Union's electronic mail and Telex businesses in 1990.\nAlthough commercial \"telegraph\" services are still available in many countries, transmission is usually done by some form of data transmission other than traditional telegraphy."}
{"id": "9451", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=9451", "title": "Event", "text": "Event may refer to:"}
{"id": "9452", "revid": "8066546", "url": "https://en.wikipedia.org/wiki?curid=9452", "title": "Estruscan alphabet", "text": ""}
{"id": "9454", "revid": "41511959", "url": "https://en.wikipedia.org/wiki?curid=9454", "title": "Establishing shot", "text": "An establishing shot in filmmaking and television production sets up, or establishes, the context for a scene by showing the relationship between its important figures and objects. It is generally a long or extreme-long shot at the beginning of a scene indicating where, and sometimes when, the remainder of the scene takes place.\nEstablishing shots were more common during the classical era of filmmaking than they are now. Today's filmmakers tend to skip the establishing shot in order to move the scene along more quickly, or merely mention the setting in on-screen text (as is done in the \"Law &amp; Order\" franchise). In addition, the expositional nature of the shot (as described above) may be unsuitable to scenes in mysteries, where details are intentionally obscured or left out."}
{"id": "9455", "revid": "1021891052", "url": "https://en.wikipedia.org/wiki?curid=9455", "title": "Etruscan language", "text": "Etruscan () was the language of the Etruscan civilization, in Italy, in the ancient region of Etruria (modern Tuscany plus western Umbria and Emilia-Romagna, Veneto, Lombardy and Campania). Etruscan influenced Latin but eventually was completely superseded by it. The Etruscans left around 13,000 inscriptions that have been found so far, only a small minority of which are of significant length; some bilingual inscriptions with texts also in Latin, Greek, or Phoenician; and a few dozen loanwords. Attested from 700 BC to AD 50, the relation of Etruscan to other languages has been a source of long-running speculation and study, with its being referred to at times as an isolate, one of the Tyrsenian languages, and a number of other less well-known theories.\nThe consensus among linguists and Etruscologists is that Etruscan was a pre\u2013Indo-European language, and is closely related to the Raetic language, spoken in the Alps, and to the Lemnian language, attested in a few inscriptions on Lemnos.\nGrammatically, the language is agglutinating, with nouns and verbs showing suffixed inflectional endings and ablaut in some cases. Nouns show five cases, singular and plural numbers, with a gender distinction between masculine and feminine in pronouns.\nEtruscan appears to have had a cross-linguistically common phonological system, with four phonemic vowels and an apparent contrast between aspirated and unaspirated stops. The records of the language suggest that phonetic change took place over time, with the loss and then re-establishment of word-internal vowels, possibly due to the effect of Etruscan's word-initial stress.\nEtruscan religion influenced that of the Romans, and many of the few surviving Etruscan language artifacts are of votive or religious significance. Etruscan was written in an alphabet derived from the Greek alphabet; this alphabet was the source of the Latin alphabet. The Etruscan language is also believed to be the source of certain important cultural words of Western Europe such as 'military' and 'person', which do not have obvious Indo-European roots.\nHistory of Etruscan literacy.\nEtruscan literacy was widespread over the Mediterranean shores, as evidenced by about 13,000 inscriptions (dedications, epitaphs, etc.), most fairly short, but some of considerable length. They date from about 700 BC.\nThe Etruscans had a rich literature, as noted by Latin authors. Livy and Cicero were both aware that highly specialized Etruscan religious rites were codified in several sets of books written in Etruscan under the generic Latin title \"Etrusca Disciplina\". The \"Libri Haruspicini\" dealt with divination by reading entrails from a sacrificed animal, while the \"Libri Fulgurales\" expounded the art of divination by observing lightning. A third set, the \"Libri Rituales\", might have provided a key to Etruscan civilization: its wider scope embraced Etruscan standards of social and political life, as well as ritual practices. According to the 4th century Latin writer Maurus Servius Honoratus, a fourth set of Etruscan books existed; dealing with animal gods, but it is unlikely that any scholar living in that era could have read Etruscan. However, only one book (as opposed to inscription), the \"Liber Linteus\", survived, and only because the linen on which it was written was used as mummy wrappings.\nIn 30 BC, Livy noted that Etruscan was once widely taught to Roman boys, but had since become replaced by the teaching of only Greek, while Varro noted that works of theatre had once been composed in Etruscan.\nDemise.\nThe date of extinction for Etruscan is held by scholarship to have been either in the late first century BC, or the early first century AD. Freeman's analysis of inscriptional evidence would appear to imply that Etruscan was still flourishing in the 2nd century BC, still alive in the first century BC, and surviving in at least one location in the beginning of the first century AD; however, the replacement of Etruscan by Latin likely occurred earlier in southern regions closer to Rome.\nIn Southern Etruria, the first Etruscan site to be Latinized was Veii, when it was destroyed and repopulated by Romans in 396 BC. Caere (Cerveteri), another southern Etruscan town on the coast 45 kilometers from Rome, appears to have shifted to Latin in the late 2nd century BC. In Tarquinia and Vulci, Latin inscriptions coexisted with Etruscan inscriptions in wall paintings and grave markers for centuries, from the 3rd century BC until the early 1st century BC, after which Etruscan is replaced by exclusive use of Latin.\nIn Northern Etruria, Etruscan inscriptions continue after they disappear in Southern Etruria. At Clusium (Chiusi), tomb markings show mixed Latin and Etruscan in the first half of the 1st century BC, with cases where two subsequent generations are inscribed in Latin and then the third, youngest generation, surprisingly, is transcribed in Etruscan. At Perugia, monolingual monumental inscriptions in Etruscan are still seen in the first half of the 1st century BC, while the period of bilingual inscriptions appears to have stretched from the 3rd century to the late 1st century BC. The isolated last bilinguals are found at three northern sites. Inscriptions in Arezzo include one dated to 40 BC followed by two with slightly later dates, while in Volterra there is one dated to just after 40 BC and a final one dated to 10\u201320 AD; coins with written Etruscan near Saena have also been dated to 15 BC. Freeman notes that in rural areas the language may have survived a bit longer, and that a survival into the late 1st century AD and beyond \"cannot wholly be dismissed\", especially given the revelation of Oscan writing in Pompeii's walls.\nDespite the apparent extinction of Etruscan, it appears that Etruscan religious rites continued much later, continuing to use the Etruscan names of deities and possibly with some liturgical usage of the language. In late Republican and early Augustan times, various Latin sources including Cicero noted the esteemed reputation of Etruscan soothsayers. An episode where lightning struck an inscription with the name Caesar, turning it into Aesar, was interpreted to have been a premonition of the deification of Caesar because of the resemblance to Etruscan , meaning \"gods\", although this indicates knowledge of a single word and not the language. Centuries later and long after Etruscan is thought to have died out, Ammianus Marcellinus reports that Julian the Apostate, the last pagan Emperor, apparently had Etruscan soothsayers accompany him on his military campaigns with books on war, lightning and celestial events, but the language of these books is unknown. According to Zosimus, when Rome was faced with destruction by Alaric in 408 AD, the protection of nearby Etruscan towns was attributed to Etruscan pagan priests who claimed to have summoned a raging thunderstorm, and they offered their services \"in the ancestral manner\" to Rome as well, but the devout Christians of Rome refused the offer, preferring death to help by pagans. Freeman notes that these events may indicate that a limited theological knowledge of Etruscan may have survived among the priestly caste much longer. One 19th-century writer argued in 1892 that Etruscan deities retained an influence on early modern Tuscan folklore.\nAround 180, the Latin author Aulus Gellius mentions Etruscan alongside the Gaulish language in an anecdote. Freeman notes that although Gaulish was clearly still alive during Gellius' time, his testimony may not indicate that Etruscan was still alive because the phrase could indicate a meaning of the sort of \"it's all Greek (incomprehensible) to me\".\nAt the time of its extinction, only a few educated Romans with antiquarian interests, such as Marcus Terentius Varro, could read Etruscan. The Roman emperor Claudius (10\u00a0BC \u2013 AD\u00a054) is considered to have possibly been able to read Etruscan, and authored a treatise on Etruscan history; a separate dedication made by Claudius implies a knowledge from \"diverse Etruscan sources\", but it is unclear if any were fluent speakers of Etruscan. Plautia Urgulanilla, the emperor's first wife, was Etruscan.\nEtruscan had some influence on Latin, as a few dozen Etruscan words and names were borrowed by the Romans, some of which remain in modern languages, among which are possibly \"columna\" \"column\", \"voltur\" \"vulture\", \"tuba\" \"trumpet\", \"vagina\" \"sheath\", \"populus\" \"people\".\nGeographic distribution.\nInscriptions have been found in north-west and west-central Italy, in the region that even now bears the name of the Etruscan civilization, Tuscany (from Latin \"tusc\u012b\" \"Etruscans\"), as well as in modern Latium north of Rome, in today's Umbria west of the Tiber, in Campania and in the Po Valley to the north of Etruria. This range may indicate a maximum Italian homeland where the language was at one time spoken.\nOutside mainland Italy, inscriptions have been found in Corsica, Elba, Gallia Narbonensis, Greece, the Balkans, the Black Sea. But by far, the greatest concentration is in Italy.\nClassification.\nThe classification of Etruscan is uncertain, due to poverty of data, but is increasingly believed to be related to a few obscure ancient languages. It is generally accepted that Etruscan does not belong to any living language family, though there have been repeated (unsuccessful) attempts to demonstrate that it is Indo-European. \nTyrsenian family hypothesis.\nIn 1998, Helmut Rix put forward the view that Etruscan is related to other members of what he called the \"Tyrsenian language family\". Rix's Tyrsenian family of languages\u2014composed of Raetic, spoken in ancient times in the eastern Alps, and Lemnian, together with Etruscan\u2014has gained acceptance among scholars. Rix's Tyrsenian family has been confirmed by Stefan Schumacher, Norbert Oettinger, Carlo De Simone, and Simona Marchesini. Common features between Etruscan, Raetic, and Lemnian have been found in morphology, phonology, and syntax. On the other hand, few lexical correspondences are documented, at least partly due to the scant number of Raetic and Lemnian texts. The Tyrsenian family, or Common Tyrrhenic, in this case is often considered to be Paleo-European and to predate the arrival of Indo-European languages in southern Europe. Several scholars believe that the Lemnian language could have arrived in the Aegean Sea during the Late Bronze Age, when Mycenaean rulers recruited groups of mercenaries from Sicily, Sardinia and various parts of the Italian peninsula. Scholars such as Norbert Oettinger, Michel Gras and Carlo De Simone think that Lemnian is the testimony of an Etruscan piratesque or commercial settlement on the island that took place before 700 BC, not related to the Sea Peoples.\nSome scholars think that the Camunic language, an extinct language spoken in the Central Alps of Northern Italy, may be also related to Etruscan and to Raetic.\nIsolate hypothesis.\nEtruscan has long been thought to be a language isolate. In the first century BC, the Greek historian Dionysius of Halicarnassus stated that the Etruscan language was unlike any other. Giuliano Bonfante, a leading scholar in the field, argued in 1990 that \"it resembles no other language in Europe or elsewhere\".\nOther hypotheses.\nOver the centuries many hypotheses on the Etruscan language have been developed, many of which have not been accepted or have been considered highly speculative. The interest in Etruscan antiquities and the Etruscan language found its modern origin in a book by a Renaissance Dominican friar, Annio da Viterbo, a cabalist and orientalist now remembered mainly for literary forgeries. In 1498, Annio published his antiquarian miscellany titled \"Antiquitatum variarum\" (in 17 volumes) where he put together a theory in which both the Hebrew and Etruscan languages were said to originate from a single source, the \"Aramaic\" spoken by Noah and his descendants, founders of the Etruscan city Viterbo. Annio also started to excavate Etruscan tombs, unearthing sarcophagi and inscriptions, and made a bold attempt at deciphering the Etruscan language.\nThe 19th century saw numerous attempts to reclassify Etruscan. Ideas of Semitic origins found supporters until this time. In 1858, the last attempt was made by Johann Gustav Stickel, Jena University in his \"Das Etruskische [...] als semitische Sprache erwiesen\". A reviewer concluded that Stickel brought forward every possible argument which would speak for that hypothesis, but he proved the opposite of what he had attempted to do. In 1861, Robert Ellis proposed that Etruscan was related to Armenian, which is nowadays acknowledged as an Indo-European language. Exactly 100 years later, a relationship with Albanian was to be advanced by Zecharia Mayani, but Albanian is also known to be an Indo-European language.\nSeveral theories from the late 19th and early 20th centuries connected Etruscan to Uralic or even Altaic languages. In 1874, the British scholar Isaac Taylor brought up the idea of a genetic relationship between Etruscan and Hungarian, of which also Jules Martha would approve in his exhaustive study \"La langue \u00e9trusque\" (1913). In 1911, the French orientalist Baron Carra de Vaux suggested a connection between Etruscan and the Altaic languages. The Hungarian connection was revived by Mario Alinei, Emeritus Professor of Italian Languages at the University of Utrecht. Alinei's proposal has been rejected by Etruscan experts such as Giulio M. Facchetti, Finno-Ugric experts such as Angela Marcantonio, and by Hungarian historical linguists such as Bela Brogyanyi.\nThe idea of a relation between the language of the Minoan Linear A scripts was taken into consideration as the main hypothesis by Michael Ventris before he discovered that, in fact, the language behind the later Linear B script was Mycenean, a Greek dialect. It has been proposed to possibly be part of a wider Paleo-European \"Aegean\" language family, which would also include Minoan, Eteocretan (possibly descended from Minoan) and Eteocypriot. This has been proposed by Giulio Mauro Facchetti, a researcher who has dealt with both Etruscan and Minoan, and supported by S. Yatsemirsky, referring to some similarities between Etruscan and Lemnian on one hand, and Minoan and Eteocretan on the other. It has also been proposed that this language family is related to the pre-Indo-European languages of Anatolia, based upon place name analysis.\nOthers have suggested that Tyrsenian languages may yet be distantly related to early Indo-European languages, such as those of the Anatolian branch. More recently, Robert S. P. Beekes argued in 2002 that the people later known as the Lydians and Etruscans had originally lived in northwest Anatolia, with a coastline to the Sea of Marmara, whence they were driven by the Phrygians \"circa\" 1200 BC, leaving a remnant known in antiquity as the Tyrsenoi. A segment of this people moved south-west to Lydia, becoming known as the Lydians, while others sailed away to take refuge in Italy, where they became known as Etruscans. This account draws on the well-known story by Herodotus (I, 94) of the Lydian origin of the Etruscans or Tyrrhenians, famously rejected by Dionysius of Halicarnassus (book I), partly on the authority of Xanthus, a Lydian historian, who had no knowledge of the story, and partly on what he judged to be the different languages, laws, and religions of the two peoples.\nIn 2006, Frederik Woudhuizen went further on Herodotus' traces, suggesting that Etruscan belongs to the Anatolian branch of the Indo-European family, specifically to Luwian. Woudhuizen revived a conjecture to the effect that the Tyrsenians came from Anatolia, including Lydia, whence they were driven by the Cimmerians in the early Iron Age, 750\u2013675 BC, leaving some colonists on Lemnos. He makes a number of comparisons of Etruscan to Luwian and asserts that Etruscan is modified Luwian. He accounts for the non-Luwian features as a Mysian influence: \"deviations from Luwian [...] may plausibly be ascribed to the dialect of the indigenous population of Mysia.\" According to Woudhuizen, the Etruscans were initially colonizing the Latins, bringing the alphabet from Anatolia.\nAnother proposal, pursued mainly by a few linguists from the former Soviet Union, suggested a relationship with Northeast Caucasian (or Nakh-Daghestanian) languages.\nWriting system.\nAlphabet.\nThe Latin script owes its existence to the Etruscan alphabet, which was adapted for Latin in the form of the Old Italic script. The Etruscan alphabet employs a Euboean variant of the Greek alphabet using the letter digamma and was in all probability transmitted through Pithecusae and Cumae, two Euboean settlements in southern Italy. This system is ultimately derived from West Semitic scripts.\nThe Etruscans recognized a 26-letter alphabet, which makes an early appearance incised for decoration on a small bucchero terracotta lidded vase in the shape of a cockerel at the Metropolitan Museum of Art, ca 650\u2013600 BC. The full complement of 26 has been termed the model alphabet. The Etruscans did not use four letters of it, mainly because Etruscan did not have the voiced stops \"b\", \"d\" and \"g\"; the \"o\" was also not used. They innovated one letter for \"f\".\nText.\nWriting was from right to left except in archaic inscriptions, which occasionally used boustrophedon. An example found at Cerveteri used left to right. In the earliest inscriptions, the words are continuous. From the sixth century BC, they are separated by a dot or a colon, which symbol might also be used to separate syllables. Writing was phonetic; the letters represented the sounds and not conventional spellings. On the other hand, many inscriptions are highly abbreviated and often casually formed, so the identification of individual letters is sometimes difficult. Spelling might vary from city to city, probably reflecting differences of pronunciation.\nComplex consonant clusters.\nSpeech featured a heavy stress on the first syllable of a word, causing syncopation by weakening of the remaining vowels, which then were not represented in writing: \"Alcsntre\" for \"Alexandros\", \"Rasna\" for \"Rasena\". This speech habit is one explanation of the Etruscan \"impossible consonant clusters\". The resonants, however, may have been syllabic, accounting for some of the clusters (see below under Consonants). In other cases, the scribe sometimes inserted a vowel: Greek \"H\u0113rakl\u0113s\" became \"Hercle\" by syncopation and then was expanded to \"Herecele\". Pallottino regarded this variation in vowels as \"instability in the quality of vowels\" and accounted for the second phase (e.g. \"Herecele\") as \"vowel harmony, i.e., of the assimilation of vowels in neighboring syllables\".\nPhases.\nThe writing system had two historical phases: the archaic from the seventh to fifth centuries BC, which used the early Greek alphabet, and the later from the fourth to first centuries BC, which modified some of the letters. In the later period, syncopation increased.\nThe alphabet went on in modified form after the language disappeared. In addition to being the source of the Roman alphabet, it has been suggested that it passed northward into Veneto and from there through Raetia into the Germanic lands, where it became the Elder Futhark alphabet, the oldest form of the runes.\nCorpus.\nThe Etruscan corpus is edited in the \"Corpus Inscriptionum Etruscarum\" (CIE) and \"Thesaurus Linguae Etruscae\" (TLE).\nBilingual text.\nThe Pyrgi Tablets are a bilingual text in Etruscan and Phoenician engraved on three gold leaves, one for the Phoenician and two for the Etruscan. The Etruscan language portion has 16 lines and 37 words. The date is roughly 500 BC.\nThe tablets were found in 1964 by Massimo Pallottino during an excavation at the ancient Etruscan port of Pyrgi, now Santa Severa. The only new Etruscan word that could be extracted from close analysis of the tablets was the word for \"three\", \"ci\".\nLonger texts.\nAccording to Rix and his collaborators, only two unified (though fragmentary) texts are available in Etruscan:\nSome additional longer texts are:\nInscriptions on monuments.\nThe main material repository of Etruscan civilization, from the modern perspective, is its tombs. All other public and private buildings having been dismantled and the stone reused centuries ago. The tombs are the main source of Etruscan portables, provenance unknown, in collections throughout the world. Their incalculable value has created a brisk black market in Etruscan \"objets d'art\" \u2013 and equally brisk law enforcement effort, as it is illegal to remove any objects from Etruscan tombs without authorization from the Italian government.\nThe magnitude of the task involved in cataloguing them means that the total number of tombs is unknown. They are of many types. Especially plentiful are the hypogeal or \"underground\" chambers or system of chambers cut into tuff and covered by a tumulus. The interior of these tombs represents a habitation of the living stocked with furniture and favorite objects. The walls may display painted murals, the predecessor of wallpaper. Tombs identified as Etruscan date from the Villanovan period to about 100 BC, when presumably the cemeteries were abandoned in favor of Roman ones. Some of the major cemeteries are as follows:\nInscriptions on portable objects.\nVotives.\n\"See\" Votive gifts.\nSpecula.\nA speculum is a circular or oval hand-mirror used predominantly by Etruscan women. \"Speculum\" is Latin; the Etruscan word is or . Specula were cast in bronze as one piece or with a tang into which a wooden, bone, or ivory handle fitted. The reflecting surface was created by polishing the flat side. A higher percentage of tin in the mirror improved its ability to reflect. The other side was convex and featured intaglio or cameo scenes from mythology. The piece was generally ornate.\nAbout 2,300 specula are known from collections all over the world. As they were popular plunderables, the provenance of only a minority is known. An estimated time window is 530\u2013100 BC. Most probably came from tombs.\nMany bear inscriptions naming the persons depicted in the scenes, so they are often called picture bilinguals. In 1979, Massimo Pallottino, then president of the \"Istituto di Studi Etruschi ed Italici\" initiated the Committee of the \"Corpus Speculorum Etruscanorum\", which resolved to publish all the specula and set editorial standards for doing so.\nSince then, the committee has grown, acquiring local committees and representatives from most institutions owning Etruscan mirror collections. Each collection is published in its own fascicle by diverse Etruscan scholars.\nCistae.\nA cista is a bronze container of circular, ovoid, or more rarely rectangular shape used by women for the storage of sundries. They are ornate, often with feet and lids to which figurines may be attached. The internal and external surfaces bear carefully crafted scenes usually from mythology, usually intaglio, or rarely part intaglio, part cameo.\nCistae date from the Roman Republic of the fourth and third centuries BC in Etruscan contexts. They may bear various short inscriptions concerning the manufacturer or owner or subject matter. The writing may be Latin, Etruscan, or both. Excavations at Praeneste, an Etruscan city which became Roman, turned up about 118 cistae, one of which has been termed \"the Praeneste cista\" or \"the Ficoroni cista\" by art analysts, with special reference to the one manufactured by Novios Plutius and given by Dindia Macolnia to her daughter, as the archaic Latin inscription says. All of them are more accurately termed \"the Praenestine cistae\".\nRings and ringstones.\nAmong the most plunderable portables from the Etruscan tombs of Etruria are the finely engraved gemstones set in patterned gold to form circular or ovoid pieces intended to go on finger rings. Around one centimeter in size, they are dated to the Etruscan apogee from the second half of the sixth to the first centuries BC. The two main theories of manufacture are native Etruscan and Greek. The materials are mainly dark red carnelian, with agate and sard entering usage from the third to the first centuries BC, along with purely gold finger rings with a hollow engraved bezel setting. The engravings, mainly cameo, but sometimes intaglio, depict scarabs at first and then scenes from Greek mythology, often with heroic personages called out in Etruscan. The gold setting of the bezel bears a border design, such as cabling.\nCoins.\nEtruscan-minted coins can be dated between 5th and 3rd centuries BC. Use of the 'Chalcidian' standard, based on the silver unit of 5.8\u00a0grams, indicates that this custom, like the alphabet, came from Greece. Roman coinage later supplanted Etruscan, but the basic Roman coin, the \"sesterce\", is believed to have been based on the 2.5-denomination Etruscan coin. Etruscan coins have turned up in caches or individually in tombs and in excavations seemingly at random, and concentrated, of course, in Etruria.\nEtruscan coins were in gold, silver, and bronze, the gold and silver usually having been struck on one side only. The coins often bore a denomination, sometimes a minting authority name, and a cameo motif. Gold denominations were in units of silver; silver, in units of bronze. Full or abbreviated names are mainly Pupluna (Populonia), Vatl or Veltuna (Vetulonia), Velathri (Volaterrae), Velzu or Velznani (Volsinii) and Cha for Chamars (Camars). Insignia are mainly heads of mythological characters or depictions of mythological beasts arranged in a symbolic motif: Apollo, Zeus, Culsans, Athena, Hermes, griffin, gorgon, male sphinx, hippocamp, bull, snake, eagle, or other creatures which had symbolic significance.\nPhonology.\nIn the tables below, conventional letters used for transliterating Etruscan are accompanied by likely pronunciation in symbols within the square brackets, followed by examples of the early Etruscan alphabet which would have corresponded to these sounds:\nVowels.\nThe Etruscan vowel system consisted of four distinct vowels. Vowels \"o\" and \"u\" appear to have not been phonetically distinguished based on the nature of the writing system, as only one symbol is used to cover both in loans from Greek (e.g. Greek &gt; Etruscan \"pitcher\"). \nBefore the front vowels &lt;c&gt; is used, while &lt;k&gt; and &lt;q&gt; are used before respectively unrounded and rounded back vowels.\nConsonants.\nTable of consonants.\nEtruscan also might have had consonants \u02a7 and \u02a7\u02b0, as they might be represented in the writing by using two letters, like in the word pruma\u03b8\u015b (great-nephew or great-grandson). However, this theory is not widely accepted.\nVoiced stops missing.\nThe Etruscan consonant system primarily distinguished between aspirated and non-aspirated stops. There were no voiced stops and loanwords with them were typically devoiced, e.g. Greek \"thriambos\" was borrowed by Etruscan, becoming \"triumpus\" and \"triumphus\" in Latin.\nSyllabic theory.\nBased on standard spellings by Etruscan scribes of words without vowels or with unlikely consonant clusters (e.g. \"cl\" 'of this (gen.)' and 'freeman'), it is likely that were sometimes syllabic sonorants (cf. English \"little\", \"button\"). Thus \"cl\" and .\nRix postulates several syllabic consonants, namely and palatal as well as a labiovelar spirant and some scholars such as Mauro Cristofani also view the aspirates as palatal rather than aspirated but these views are not shared by most Etruscologists. Rix supports his theories by means of variant spellings such as am\u03c6are/am\u03c6iare, lar\u03b8al/lar\u03b8ial, aran\u03b8/aran\u03b8iia.\nMorphology.\nEtruscan was inflected, varying the endings of nouns, pronouns and verbs. It also had adjectives, adverbs, and conjunctions, which were uninflected.\nNouns.\nEtruscan substantives had five cases\u2014nominative, accusative, genitive, dative, and locative\u2014and two numbers: singular and a plural. Not all five cases are attested for every word. Nouns merge the nominative and accusative; pronouns do not generally merge these. Gender appears in personal names (masculine and feminine) and in pronouns (animate and inanimate); otherwise, it is not marked.\nUnlike the Indo-European languages, Etruscan noun endings were more agglutinative, with some nouns bearing two or three agglutinated suffixes. For example, where Latin would have distinct nominative plural and dative plural endings, Etruscan would suffix the case ending to a plural marker: Latin nominative singular \"fili-us\", \"son\", plural \"fili-i\", dative plural \"fili-is\", but Etruscan \"clan, clen-ar\" and \"clen-ar-a\u015bi\". Moreover, Etruscan nouns could bear multiple suffixes from the case paradigm alone: that is, Etruscan exhibited \"Suffixaufnahme\". Pallottino calls this phenomenon \"morphological redetermination\", which he defines as \"the typical tendency ... to redetermine the syntactical function of the form by the superposition of suffixes.\" His example is\" Uni-al-\u03b8i\", \"in the sanctuary of Juno\", where\" -al\" is a genitive ending and \"-\u03b8i\" a locative.\nSteinbauer says of Etruscan, \"there can be more than one marker ... to design a case, and ... the same marker can occur for more than one case.\"\nPronouns.\nPersonal pronouns refer to persons; demonstrative pronouns point out: English this, that, there.\nPersonal.\nThe first-person personal pronoun has a nominative \"mi\" (\"I\") and an accusative \"mini\" (\"me\"). The third person has a personal form \"an\" (\"he\" or \"she\") and an inanimate \"in\" (\"it\"). The second person is uncertain, but some, like the Bonfantes, have claimed a dative singular \"une\" (\"to thee\") and an accusative singular \"un\" (\"thee\").\nDemonstrative.\nThe demonstratives, \"ca\" and \"ta\", are used without distinction. The nominative\u2013accusative singular forms are: \"ica, eca, ca, ita, ta\"; the plural: \"cei, tei\". There is a genitive singular: \"cla, tla, cal\" and plural \"clal\". The accusative singular: \"can, cen, cn, ecn, etan, tn\"; plural \"cnl\". Locative singular: ; plural .\nAdjectives.\nThough uninflected, adjectives fall into a number of types formed from nouns with a suffix:\nAdverbs.\nAdverbs are unmarked: \"etnam\", \"again\"; \"\u03b8ui\", \"now\"; \"\u03b8uni\", \"at first.\" Most Indo-European adverbs are formed from the oblique cases, which become unproductive and descend to fixed forms. Cases such as the ablative are therefore called \"adverbial\". If there is any such system in Etruscan, it is not obvious from the relatively few surviving adverbs.\nVerbs.\nVerbs had an indicative mood and an imperative mood. Tenses were present and past. The past tense had an active voice and a passive voice.\nPresent active.\nEtruscan used a verbal root with a zero suffix or -a without distinction to number or person: \"ar, ar-a\", \"he, she, we, you, they make\".\nPast or preterite active.\nAdding the suffix to the verb root produces a third-person singular active, which has been called variously a \"past\", a \"preterite\", a \"perfect\" or an \"aorist\". In contrast to Indo-European, this form is not marked for person. Examples: \"tur/tur-ce\", \"gives/gave\"; \"sval/sval-ce\", \"lives/lived.\"\nPast passive.\nThe third-person past passive is formed with -che: \"mena/mena-ce/mena-che\", \"offers/offered/was offered\".\nVocabulary.\nBorrowings from Etruscan.\nOnly a few hundred words of the Etruscan vocabulary are understood with some certainty. The exact count depends on whether the different forms and the expressions are included. Below is a table of some of the words grouped by topic.\nSome words with corresponding Latin or other Indo-European forms are likely loanwords to or from Etruscan. For example, \"neft\u015b\" \"nephew\", is probably from Latin (Latin \"nep\u014ds, nep\u014dtis\"; this is a cognate of German \"Neffe\", Old Norse \"nefi\"). A number of words and names for which Etruscan origin has been proposed survive in Latin.\nAt least one Etruscan word has an apparent Semitic/Aramaic origin: \"talitha\" \"girl\", that could have been transmitted by Phoenicians or by the Greeks (Greek: \u03c4\u03b1\u03bb\u03b9\u03b8\u03b1). The word \"pera\" \"house\" is a false cognate to the Coptic \"per\" \"house\".\nIn addition to words believed to have been borrowed into Etruscan from Indo-European or elsewhere, there is a corpus of words such as \"familia\" which seem to have been borrowed into Latin from the older Etruscan civilization as a superstrate influence. Some of these words still have widespread currency in English and Latin-influenced languages. Other words believed to have a possible Etruscan origin include:\nEtruscan vocabulary.\nNumerals.\nMuch debate has been carried out about a possible Indo-European origin of the Etruscan cardinals. In the words of Larissa Bonfante (1990), \"What these numerals show, beyond any shadow of a doubt, is the non-Indo-European nature of the Etruscan language\". Conversely, other scholars, including Francisco R. Adrados, Albert Carnoy, Marcello Durante, Vladimir Georgiev, Alessandro Morandi and Massimo Pittau, have proposed a close phonetic proximity of the first ten Etruscan numerals to the corresponding numerals in other Indo-European languages. Italian linguist Massimo Pittau has argued that \"all the first ten Etruscan numerals have a congruent phonetic matching in as many Indo-European languages\" and \"perfectly fit within the Indo-European series\", supporting the idea that the Etruscan language was of Indo-European origins.\nThe lower Etruscan numerals are (G. Bonfante 2002:96):\nIt is unclear which of \"\u015ba\" and \"hu\u03b8\" meant \"four\" and \"six\". \"\u015aar\" may also mean \"twelve\", with \"hal\u03c7\" for \"ten\"."}
{"id": "9457", "revid": "27823944", "url": "https://en.wikipedia.org/wiki?curid=9457", "title": "Election", "text": "An election is a formal group decision-making process by which a population chooses an individual or multiple individuals to hold public office.\nElections have been the usual mechanism by which modern representative democracy has operated since the 17th century. Elections may fill offices in the legislature, sometimes in the executive and judiciary, and for regional and local government. This process is also used in many other private and business organizations, from clubs to voluntary associations and corporations.\nThe universal use of elections as a tool for selecting representatives in modern representative democracies is in contrast with the practice in the democratic archetype, ancient Athens, where the Elections were not used were considered an oligarchic institution and most political offices were filled using sortition, also known as allotment, by which officeholders were chosen by lot.\nElectoral reform describes the process of introducing fair electoral systems where they are not in place, or improving the fairness or effectiveness of existing systems. Psephology is the study of results and other statistics relating to elections (especially with a view to predicting future results). Election is the fact of electing, or being elected.\nTo \"elect\" means \"to select or make a decision\", and so sometimes other forms of ballot such as referendums are referred to as elections, especially in the United States.\nHistory.\nElections were used as early in history as ancient Greece and ancient Rome, and throughout the Medieval period to select rulers such as the Holy Roman Emperor (see imperial election) and the pope (see papal election).\nIn Vedic period of India, the \"Raja\" (chiefs) of a \"ga\u1e47a\" (a tribal organization) was apparently elected by the \"gana\". The \"Raja\" always belonged to the Kshatriya varna (warrior class), and was typically a son of the previous \"Raja\". However, the \"gana\" members had the final say in his elections. Even during the Sangam Period people elected their representatives by casting their votes and the ballot boxes (Usually a pot) were tied by rope and sealed. After the election the votes were taken out and counted. The Pala King Gopala (ruled c. 750s\u2013770s CE) in early medieval Bengal was elected by a group of feudal chieftains. Such elections were quite common in contemporary societies of the region. In the Chola Empire, around 920 CE, in Uthiramerur (in present-day Tamil Nadu), palm leaves were used for selecting the village committee members. The leaves, with candidate names written on them, were put inside a mud pot. To select the committee members, a young boy was asked to take out as many leaves as the number of positions available. This was known as the \"Kudavolai\" system.\nThe first recorded popular elections of officials to public office, by majority vote, where all citizens were eligible both to vote and to hold public office, date back to the Ephors of Sparta in 754 B.C., under the mixed government of the Spartan Constitution. Athenian democratic elections, where all citizens could hold public office, were not introduced for another 247 years, until the reforms of Cleisthenes. Under the earlier Solonian Constitution (circa 574 B.C.), all Athenian citizens were eligible to vote in the popular assemblies, on matters of law and policy, and as jurors, but only the three highest classes of citizens could vote in elections. Nor were the lowest of the four classes of Athenian citizens (as defined by the extent of their wealth and property, rather than by birth) eligible to hold public office, through the reforms of Solon. The Spartan election of the Ephors, therefore, also predates the reforms of Solon in Athens by approximately 180 years.\nQuestions of suffrage, especially suffrage for minority groups, have dominated the history of elections. Males, the dominant cultural group in North America and Europe, often dominated the and continue to do so in many countries. Early elections in countries such as the United Kingdom and the United States were dominated by landed or ruling class males. However, by 1920 all Western European and North American democracies had universal adult male suffrage (except Switzerland) and many countries began to consider women's suffrage. Despite legally mandated universal suffrage for adult males, political barriers were sometimes erected to prevent fair access to elections (see civil rights movement).\nCharacteristic.\nSuffrage.\nThe question of who may vote is a central issue in elections. The electorate does not generally include the entire population; for example, many countries prohibit those who are under the age of majority from voting, all jurisdictions require a minimum age for voting.\nIn Australia, Aboriginal people were not given the right to vote until 1962 (see 1967 referendum entry) and in 2010 the federal government removed the rights of prisoners serving for 3 years or more to vote (a large proportion of which were Aboriginal Australians).\nSuffrage is typically only for citizens of the country, though further limits may be imposed.\nHowever, in the European Union, one can vote in municipal elections if one lives in the municipality and is an EU citizen; the nationality of the country of residence is not required. \nIn some countries, voting is required by law; if an eligible voter does not cast a vote, he or she may be subject to punitive measures such as a fine. In Western Australia, the penalty for a first time offender failing to vote is a $20.00 fine, which increases to $50.00 if the offender refused to vote prior.\nElectorate.\nHistorically the size of eligible voters, the electorate, was small having the size of groups or communities of privileged men like aristocrats and men of a city (citizens).\nWith the growth of the number of people with bourgeois citizen rights outside of cities, expanding the term citizen, the electorates grew to numbers beyond the thousands.\nElections with an electorate in the hundred thousands appeared in the final decades of the Roman Republic, by extending voting rights to citizens outside of Rome with the Lex Julia of 90 BC, reaching an electorate of 910,000 and estimated voter turnout of maximum 10% in 70 BC, only again comparable in size to the first elections of the United States. At the same time the Kingdom of Great Britain had in 1780 about 214,000 eligible voters, 3% of the whole population.\nNomination of candidate.\nA representative democracy requires a procedure to govern nomination for political office. In many cases, nomination for office is mediated through preselection processes in organized political parties.\nNon-partisan systems tend to be different from partisan systems as concerns nominations. In a direct democracy, one type of non-partisan democracy, any eligible person can be nominated. Although elections were used in ancient Athens, in Rome, and in the selection of popes and Holy Roman emperors, the origins of elections in the contemporary world lie in the gradual emergence of representative government in Europe and North America beginning in the 17th century. In some systems no nominations take place at all, with voters free to choose any person at the time of voting\u2014with some possible exceptions such as through a minimum age requirement\u2014in the jurisdiction. In such cases, it is not required (or even possible) that the members of the electorate be familiar with all of the eligible persons, though such systems may involve indirect elections at larger geographic levels to ensure that some first-hand familiarity among potential electees can exist at these levels (i.e., among the elected delegates).\nAs far as partisan systems, in some countries, only members of a particular party can be nominated (see one-party state). Or, any eligible person can be nominated through a process; thus allowing him or her to be listed.\nElectoral systems.\nElectoral systems are the detailed constitutional arrangements and voting systems that convert the vote into a political decision. The first step is to tally the votes, for which various vote counting systems and ballot types are used. Voting systems then determine the result on the basis of the tally. Most systems can be categorized as either proportional or majoritarian. Among the former are party-list proportional representation and additional member system. Among the latter are First Past the Post electoral system (relative majority) and absolute majority. Many countries have growing electoral reform movements, which advocate systems such as approval voting, single transferable vote, instant runoff voting or a Condorcet method; these methods are also gaining popularity for lesser elections in some countries where more important elections still use more traditional counting methods.\nWhile openness and accountability are usually considered cornerstones of a democratic system, the act of casting a vote and the content of a voter's ballot are usually an important exception. The secret ballot is a relatively modern development, but it is now considered crucial in most free and fair elections, as it limits the effectiveness of intimidation.\nScheduling.\nThe nature of democracy is that elected officials are accountable to the people, and they must return to the voters at prescribed intervals to seek their mandate to continue in office. For that reason most democratic constitutions provide that elections are held at fixed regular intervals. In the United States, elections for public offices are typically held between every two and six years in most states and at the federal level, with exceptions for elected judicial positions that may have longer terms of office. There is a variety of schedules, for example presidents: the President of Ireland is elected every seven years, the President of Russia and the President of Finland every six years, the President of France every five years, President of the United States every four years.\nPre-decided or fixed election dates have the advantage of fairness and predictability. However, they tend to greatly lengthen campaigns, and make dissolving the legislature (parliamentary system) more problematic if the date should happen to fall at time when dissolution is inconvenient (e.g. when war breaks out). Other states (e.g., the United Kingdom) only set maximum time in office, and the executive decides exactly when within that limit it will actually go to the polls. In practice, this means the government remains in power for close to its full term, and choose an election date it calculates to be in its best interests (unless something special happens, such as a motion of no-confidence). This calculation depends on a number of variables, such as its performance in opinion polls and the size of its majority.\nElection campaigns.\nWhen elections are called, politicians and their supporters attempt to influence policy by competing directly for the votes of constituents in what are called campaigns. Supporters for a campaign can be either formally organized or loosely affiliated, and frequently utilize campaign advertising. It is common for political scientists to attempt to predict elections via Political Forecasting methods.\nThe most expensive election campaign included US$7 billion spent on the 2012 United States presidential election and is followed by the US$5 billion spent on the 2014 Indian general election.\nDifficulties with elections.\nIn many of the countries with weak rule of law, the most common reason why elections do not meet international standards of being \"free and fair\" is interference from the incumbent government. Dictators may use the powers of the executive (police, martial law, censorship, physical implementation of the election mechanism, etc.) to remain in power despite popular opinion in favor of removal. Members of a particular faction in a legislature may use the power of the majority or supermajority (passing criminal laws, defining the electoral mechanisms including eligibility and district boundaries) to prevent the balance of power in the body from shifting to a rival faction due to an election.\nNon-governmental entities can also interfere with elections, through physical force, verbal intimidation, or fraud, which can result in improper casting or counting of votes. Monitoring for and minimizing electoral fraud is also an ongoing task in countries with strong traditions of free and fair elections. Problems that prevent an election from being \"free and fair\" take various forms.\nLack of open political debate or an informed electorate.\nThe electorate may be poorly informed about issues or candidates due to lack of freedom of the press, lack of objectivity in the press due to state or corporate control, and/or lack of access to news and political media. Freedom of speech may be curtailed by the state, favoring certain viewpoints or state propaganda.\nUnfair rules.\nGerrymandering, exclusion of opposition candidates from eligibility for office, needlessly high restrictions on who may be a candidate, like ballot access rules, and manipulating thresholds for electoral success are some of the ways the structure of an election can be changed to favor a specific faction or candidate.\nInterference with campaigns.\nThose in power may arrest or assassinate candidates, suppress or even criminalize campaigning, close campaign headquarters, harass or beat campaign workers, or intimidate voters with violence. Foreign electoral intervention can also occur, with the United States interfering between 1946 and 2000 in 81 elections and Russia/USSR in 36.\nIn 2018 the most intense interventions, by means of false information, were by China in Taiwan and by Russia in Latvia; the next highest levels were in Bahrain, Qatar and Hungary.\nTampering with the election mechanism.\nThis can include falsifying voter instructions,\nviolation of the secret ballot, ballot stuffing, tampering with voting machines,\ndestruction of legitimately cast ballots,\nvoter suppression, voter registration fraud, failure to validate voter residency, fraudulent tabulation of results, and use of physical force or verbal intimation at polling places. Other examples include persuading candidates not to run, such as through blackmailing, bribery, intimidation or physical violence.\nSham election.\nA sham election, or show election, is an election that is held purely for show; that is, without any significant political choice or real impact on results of election.\nSham elections are a common event in dictatorial regimes that feel the need to feign the appearance of public legitimacy. Published results usually show nearly 100% voter turnout and high support (typically at least 80%, and close to 100% in many cases) for the prescribed or for the referendum choice that favors the political party in power. Dictatorial regimes can also organize sham elections with results simulating those that might be achieved in democratic countries.\nSometimes, only one government approved candidate is allowed to run in sham elections with no opposition candidates allowed, or opposition candidates are arrested on false charges (or even without any charges) before the election to prevent them from running.\nBallots may contain only one \"yes\" option, or in the case of a simple \"yes or no\" question, security forces often persecute people who pick \"no\", thus encouraging them to pick the \"yes\" option. In other cases, those who vote receive stamps in their passport for doing so, while those who did not vote (and thus do not receive stamps) are persecuted as enemies of the people.\nIn some cases, sham elections can backfire against the party in power, especially if the regime believes they are popular enough to win without coercion or fraud. The most famous example of this was the 1990 Myanmar general election, in which the government-sponsored National Unity Party suffered a landslide defeat to the opposition National League for Democracy and consequently the results were annulled.\nExamples.\nExamples of sham elections are the 1929 and 1934 elections in Fascist Italy, the 1942 general election in Imperial Japan, elections in Nazi Germany, the 1940 elections of the People's Parliaments in Estonia, Latvia and Lithuania, the 1928, 1935, 1942, 1949, 1951 and 1958 elections in Portugal, the 1991 Kazakh presidential election, those in North Korea, and the 1995 and 2002 presidential referendums in Saddam Hussein's Iraq.\nIn Mexico, all of the presidential elections from 1929 to 1982 are considered to be sham elections, as the Institutional Revolutionary Party (PRI) and its predecessors governed the country in a \"de facto\" single-party system without serious opposition, and won all of the presidential elections in that period with percentages of votes well over 70%. The first actually competitive presidential election in modern Mexican history was that of 1988, in which for the first time the PRI candidate faced two strong opposition candidates, though the opposition would not win until 2000.\nA predetermined conclusion is always established by the regime through suppression of the opposition, coercion of voters, vote rigging, reporting a number of votes received greater than the number of voters, outright lying, or some combination of these.\nIn an extreme example, Charles D. B. King of Liberia was reported to have won by 234,000 votes in the 1927 general election, a \"majority\" that was over fifteen times larger than the number of eligible voters."}
{"id": "9458", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9458", "title": "Executive power", "text": ""}
{"id": "9459", "revid": "2278355", "url": "https://en.wikipedia.org/wiki?curid=9459", "title": "Enniskillen", "text": "Enniskillen (, from , 'Ceithlenn's island') is a town and civil parish in County Fermanagh, Northern Ireland. It is almost exactly in the centre of the county, between the Upper and Lower sections of Lough Erne. It had a population of 13,823 at the 2011 Census. It was the seat of local government for the former Fermanagh District Council, and is the county town of Fermanagh as well as its largest town. Enniskillen was named as one of the best places to live in the UK in 2019 by the Times of London; the area comprising Hollyhill, Chanterhill Road and Cooper Crescent was described as 'the best address' for having the 'finest properties' and due to its close proximity to the centre of town.\nToponymy.\nThe town's name comes from the . This refers to Cethlenn, a figure in Irish mythology who may have been a goddess. Local legend has it that Cethlenn was wounded in battle by an arrow and attempted to swim across the River Erne, which surrounds the island, but she never reached the other side, so the island was named in reference to her. It has been anglicised many ways over the centuries \u2013 \"Iniskellen\", \"Iniskellin\", \"Iniskillin\", \"Iniskillen\", \"Inishkellen\", \"Inishkellin\", \"Inishkillin\", \"Inishkillen\" and so on.\nHistory.\nThe town's oldest building is Enniskillen Castle, built by Hugh (Maguire) the Hospitable who died in 1428. An earthwork, the Skonce on the shore of Lough Erne, may be the remains of an earlier motte. The castle was the stronghold of the junior branch of the Maguires. The first watergate was built around 1580 by C\u00fa Chonnacht Maguire, though subsequent lowering of the level of the lough has left it without water. The strategic position of the castle made its capture important for the English in 1593, to support their plans for the control of Ulster. The castle was besieged three times in 1594\u201395. The English, led by a Captain Dowdall, captured it in February 1594. Maguire then laid siege to it, and defeated a relieving force at the Battle of the Ford of the Biscuits at Drumane Bridge on the Arney River. Although the defenders were relieved, Maguire gained possession of the castle from 1595 to 1598 and it was not finally captured by the English until 1607.\nThis was part of a wider campaign to bring the province of Ulster under English control; the final capture of Enniskillen Castle in 1607 was followed by the Plantation of Ulster, during which the lands of the native Irish were seized and handed over to planters loyal to the English Crown. The Maguires were supplanted by William Cole, originally from Devon, who was appointed by James I to build an English settlement there.\nCaptain Cole was installed as Constable and strengthened the castle wall and built a \"fair house\" on the old foundation as the centre point of the county town. The first Protestant parish church was erected on the hilltop in 1627. The Royal Free School of Fermanagh was moved onto the island in 1643. The first bridges were drawbridges; permanent bridges were not installed before 1688.\nBy 1689 the town had grown significantly. During the conflict which resulted from the ousting of King James II by his Protestant rival, William III, Enniskillen and Derry were the focus of Williamite resistance in Ireland, including the nearby Battle of Newtownbutler.\nEnniskillen and Derry were the two garrisons in Ulster that were not wholly loyal to James II, and it was the last town to fall before the siege of Derry. As a direct result of this conflict, Enniskillen developed not only as a market town but also as a garrison, which became home to two regiments.\nThe current site of Fermanagh College (now part of the South West College) was the former Enniskillen Gaol. Many people were tried and hanged in the square during the times of public execution. Part of the old Gaol is still used by the college. Enniskillen Town Hall was designed by William Scott and completed in 1901.\nMilitary history.\nEnniskillen is the site of the foundation of two British Army regiments:\nThe town's name (with the archaic spelling) continues to form part of the title to The Royal Irish Regiment (27th (Inniskilling) 83rd and 87th and Ulster Defence Regiment). Enniskillen Castle features on the cap badge of both regiments.\nThe Troubles.\nEnniskillen was the site of several events during The Troubles, the most notable being the Remembrance Day bombing in which 11 people were killed. Bill Clinton opened the Clinton centre in 2002 on the site of the bombing. The Provisional Irish Republican Army claimed responsibility for the attack.\nAlleged sexual abuse and assault.\nIn 2019, at least nine men reported to the police and the press and said in public forums that, in the 1980s and 90s, when they were children, they were repeatedly molested and raped by a paedophile ring of at least 20 men in the Enniskillen area. Investigations are continuing.\nDemography.\nOn Census day (27 March 2011) there were 13,823 people living in Enniskillen (5,733 households), accounting for 0.76% of the NI total and representing an increase of 1.6% on the Census 2001 population of 13,599. Of these:\nClimate.\nEnniskillen has a maritime climate with a narrow range of temperatures and rainfall. The nearest official Met Office weather station for which online records are available is at Lough Navar Forest, about northwest of Enniskillen. Data has also more recently been collected from Enniskillen/St Angelo Airport, under north of the town centre, which should in time give a more accurate representation of the climate of the Enniskillen area.\nThe absolute maximum temperature is , recorded during July 2006. In an 'average' year, the warmest day is and only 2.4 days a year should rise to or above. The respective absolute maximum for St Angelo is \nThe absolute minimum temperature is , recorded during January 1984. In an 'average' year, the coldest night should fall to . Lough Navar is a frosty location, with some 76 air frosts recorded in a typical year. It is likely that Enniskillen town centre is significantly less frosty than this. The absolute minimum at St Angelo is , reported during the record cold month of December 2010.\nThe warmest month on record at St Angelo was August 1995 with a mean temperature of (mean maximum , mean minimum , while the coldest month was December 2010, with a mean temperature of (mean maximum , mean minimum .\nRainfall is high, averaging over 1500\u00a0mm. 212 days of the year report at least 1\u00a0mm of precipitation, ranging from 15 days during April, May and June, to 20 days in October, November, December, January and March.\nThe K\u00f6ppen climate classification subtype for this climate is \"\" (Marine West Coast Climate/Oceanic climate).\nSports.\nAssociation football.\nThe town has two association football teams called Enniskillen Rangers and Enniskillen Town United F.C.\nEnniskillen Rangers are the current holders of the Irish Junior Cup, defeating Hill Street 5\u20131 on Monday, 1 May 2017. The match was played at the National Football Stadium at Windsor Park in Belfast. They play their home games at the Ball Range.\nEnniskillen Rangers have several notable former players including Sandy Fulton and Jim Cleary.\nEnniskillen Town United F.C. currently play in the Fermanagh &amp; Western 1st Division. Their most notable former player is Michael McGovern who currently plays for Norwich City F.C. At the moment, Enniskillen Town play their home games at The Lakeland Forum playing fields in Enniskillen.\nRugby.\nEnniskillen Rugby Football Club was founded in 1925 and plays their home games at Mullaghmeen. The club currently fields 4 senior men's teams, a senior ladies teams, a range of male and female youth teams, a vibrant mini section and a disability tag team called The Enniskillen Elks. Enniskillen XV won the Ulster Towns Cup in the 2018/19 season, defeating Ballyclare 19\u20130. The team currently play in Kukri Ulster Rugby Championship Division 1.\nThe rugby club was formed on 28 August 1925, when 37 attended a meeting in Enniskillen Town Hall. The name Enniskillen Rugby Club was agreed and the club adopted the rules of Dublin University. The first match was played on 30 September 1925 against Ballyshannon in County Donegal.\nGaelic football.\nEnniskillen Gaels are a Gaelic Athletic Association club founded in 1927. They play their home games at Brewster Park, Enniskillen.\nInternational events.\nEnniskillen was the venue of the 39th G8 summit which was held on 17 and 18 June 2013. It was held at the Lough Erne Resort, a five-star hotel and golf resort on the shore of Lough Erne. The gathering was the biggest international diplomatic gathering ever held in Northern Ireland. Among the G8 leaders who attended were British Prime Minister David Cameron, United States President Barack Obama, German Chancellor Angela Merkel, and Russian President Vladimir Putin.\nIn the past, Enniskillen has hosted an array of international events, most notably stages of the World Waterski World Cup, annually from 2005 to 2007 at the Broadmeadow. Despite its success, Enniskillen was not chosen as a World Cup Stop for 2008.\nIn January 2009, Enniskillen hosted the ceremonial start of Rally Ireland 2009, the first stage of the WRC FIA World Rally Championship 2009 Calendar.\nEnniskillen has hosted the Happy Days arts festival since 2012, which celebrates \"the work and influence of Nobel Prize-winning writer Samuel Beckett\" and is the \"first annual, international, multi-arts festival to be held in Northern Ireland since the launch of the Ulster Bank Belfast Festival at Queen\u2019s in 1962\".\nEducation.\nThere are numerous schools and colleges in and around the Enniskillen area, from primary level to secondary level, including some further education colleges such as the technical college.\nTransport.\nRail \u2013 historic.\nRailway lines from Enniskillen railway station linked the town with Derry from 1854, Dundalk from 1861, Bundoran from 1868 and Sligo from 1882. By 1883 the Great Northern Railway (Ireland) absorbed all the lines except the Sligo, Leitrim and Northern Counties Railway, which remained independent throughout its existence. In October 1957 the Government of Northern Ireland closed the GNR line, which made it impossible for the SL&amp;NCR continue and forced it also to close.\nRail \u2013 current.\nThe nearest railway station to Enniskillen is Sligo station which is served by trains to Dublin Connolly and is operated by Iarnr\u00f3d \u00c9ireann. The Dublin-Sligo railway line has a two-hourly service run by Iarnr\u00f3d \u00c9ireann Official site \u2013 Timetables, bookings and operations\nThe connecting bus from Sligo via Manorhamilton to Enniskillen is route 66 operated by Bus \u00c9ireann.\nBus.\nBus service to Enniskillen is provided by both Ulsterbus and Bus \u00c9ireann, from Enniskillen bus station. Number 261, 261b and X261 Goldline buses run from Belfast to Enniskillen. Bus \u00c9ireann Route 30 runs from Donegal to Dublin Airport/Dublin City via Enniskillen.\nAir.\nEnniskillen has a World War II-era airport, Enniskillen/St Angelo Airport. The airport had scheduled flights in the past but now serves mainly private traffic.\nRoad.\nThe town is on the main A4/N16 route linking Belfast and Sligo, and on the main Dublin to Ballyshannon route, the N3/A46/A509.\nTwinning.\nEnniskillen was originally twinned with Brackwede \u2013 a Bielefeld suburb \u2013 where the Inniskilling Dragoon Guards were stationed in the late 1950s when the twinning was initiated; however, this suburb was incorporated into Stadt Bielefeld in 1973, the city with which Enniskillen is now officially twinned.\nThough the twinning arrangements are still operational, at a meeting of the Regeneration and Community Committee, in February 2018, it was agreed that the twinning arrangements would be formally terminated at the end of the Council term in June 2018. However, Fermanagh and Omagh District Council still have plans to send representatives to Brackwede for the 60th anniversary celebrations of the twinning. Therefore, the future of the twinning is now somewhat unclear."}
{"id": "9461", "revid": "1588193", "url": "https://en.wikipedia.org/wiki?curid=9461", "title": "Eric Raymond (disambiguation)", "text": "Eric S. Raymond (born 1957) is an American computer programmer and author.\nEric Raymond may also refer to:"}
{"id": "9463", "revid": "11292982", "url": "https://en.wikipedia.org/wiki?curid=9463", "title": "English language/British English", "text": ""}
{"id": "9464", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9464", "title": "Non-standard adjectives in the English language", "text": ""}
{"id": "9465", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=9465", "title": "English language/American English", "text": ""}
{"id": "9467", "revid": "613915", "url": "https://en.wikipedia.org/wiki?curid=9467", "title": "Longest word in English", "text": "The identity of the longest word in English depends upon the definition of what constitutes a word in the English language, as well as how length should be compared. \nWords may be derived naturally from the language's roots or formed by coinage and construction. Additionally, comparisons are complicated because place names may be considered words, technical terms may be arbitrarily long, and the addition of suffixes and prefixes may extend the length of words to create grammatically correct but unused or novel words. \nThe \"length\" of a word may also be understood in multiple ways. Most commonly, length is based on orthography (conventional spelling rules) and counting the number of written letters. Alternate, but less common, approaches include phonology (the spoken language) and the number of phonemes (sounds). \nMajor dictionaries.\nThe longest word in any of the major English language dictionaries is \"pneumonoultramicroscopicsilicovolcanoconiosis\", a word that refers to a lung disease contracted from the inhalation of very fine silica particles, specifically from a volcano; medically, it is the same as silicosis. The word was deliberately coined to be the longest word in English, and has since been used in a close approximation of its originally intended meaning, lending at least some degree of validity to its claim.\nThe \"Oxford English Dictionary\" contains \"pseudopseudohypoparathyroidism\" (30 letters).\n\"Merriam-Webster's Collegiate Dictionary\" does not contain \"antidisestablishmentarianism\" (28 letters), as the editors found no widespread, sustained usage of the word in its original meaning. The longest word in that dictionary is \"electroencephalographically\" (27 letters).\nThe longest non-technical word in major dictionaries is \"floccinaucinihilipilification\" at 29 letters. Consisting of a series of Latin words meaning \"nothing\" and defined as \"the act of estimating something as worthless\"; its usage has been recorded as far back as 1741.\nRoss Eckler has noted that most of the longest English words are not likely to occur in general text, meaning non-technical present-day text seen by casual readers, in which the author did not specifically intend to use an unusually long word. According to Eckler, the longest words likely to be encountered in general text are \"deinstitutionalization\" and \"counterrevolutionaries\", with 22 letters each.\nA computer study of over a million samples of normal English prose found that the longest word one is likely to encounter on an everyday basis is \"uncharacteristically\", at 20 letters.\nThe word \"internationalization\" is abbreviated \"i18n\", the embedded number representing the number of letters between the first and the last.\nCreations of long words.\nCoinages.\nIn his play \"Assemblywomen\" (\"Ecclesiazousae\"), the ancient Greek comedic playwright Aristophanes created a word of 171 letters (183 in the transliteration below), which describes a dish by stringing together its ingredients:\nHenry Carey's farce \"Chrononhotonthologos\" (1743) holds the opening line: \"Aldiborontiphoscophornio! Where left you Chrononhotonthologos?\"\nThomas Love Peacock put these creations into the mouth of the phrenologist Mr. Cranium in his 1816 romp \"Headlong Hall\": \"osteosarchaematosplanchnochondroneuromuelous\" (44 characters) and \"osseocarnisanguineoviscericartilaginonervomedullary\" (51 characters).\nJames Joyce made up nine 100-letter words plus one 101-letter word in his novel \"Finnegans Wake\", the most famous of which is Bababadalgharaghtakamminarronnkonnbronntonnerronntuonnthunntrovarrhounawnskawntoohoohoordenenthurnuk. Appearing on the first page, it allegedly represents the symbolic thunderclap associated with the fall of Adam and Eve. As it appears nowhere else except in reference to this passage, it is generally not accepted as a real word. Sylvia Plath made mention of it in her semi-autobiographical novel \"The Bell Jar\", when the protagonist was reading \"Finnegans Wake\".\n\"Supercalifragilisticexpialidocious\", the 34-letter title of a song from the movie \"Mary Poppins\", does appear in several dictionaries, but only as a proper noun defined in reference to the song title. The attributed meaning is \"a word that you say when you don't know what to say.\" The idea and invention of the word is credited to songwriters Robert and Richard Sherman.\nAgglutinative constructions.\nThe English language permits the legitimate extension of existing words to serve new purposes by the addition of prefixes and suffixes. This is sometimes referred to as agglutinative construction. This process can create arbitrarily long words: for example, the prefixes \"pseudo\" (false, spurious) and \"anti\" (against, opposed to) can be added as many times as desired. More familiarly, the addition of numerous \"great\"s to a relative, such as \"great-great-great-great-grandparent\", can produce words of arbitrary length. In musical notation, an 8192nd note may be called a \"\".\n\"Antidisestablishmentarianism\" is the longest common example of a word formed by agglutinative construction.\nTechnical terms.\nA number of scientific naming schemes can be used to generate arbitrarily long words.\nThe IUPAC nomenclature for organic chemical compounds is open-ended, giving rise to the 189,819-letter chemical name \"Methionylthreonylthreonyl...isoleucine\" for the protein also known as titin, which is involved in striated muscle formation. In nature, DNA molecules can be much bigger than protein molecules and therefore potentially be referred to with much longer chemical names. For example, the wheat chromosome 3B contains almost 1 billion base pairs, so the sequence of one of its strands, if written out in full like \"Adenilyladenilylguanilylcystidylthymidyl...\", would be about 8 billion letters long. The longest published word, \"Acetylseryltyrosylseryliso...serine\", referring to the coat protein of a certain strain of tobacco mosaic virus (), is 1,185 letters long, and appeared in the American Chemical Society's Chemical Abstracts Service in 1964 and 1966. In 1965, the Chemical Abstracts Service overhauled its naming system and started discouraging excessively long names. In 2011, a dictionary broke this record with a 1909-letter word describing the \"trpA\" protein ().\nJohn Horton Conway and Landon Curt Noll developed an open-ended system for naming powers of 10, in which one \", coming from the Latin name for 6560, is the name for 103(6560+1) = 1019683. Under the long number scale, it would be 106(6560) = 1039360.\n\" is sometimes cited as the longest binomial name\u2014it is a kind of amphipod. However, this name, proposed by B. Dybowski, was invalidated by the International Code of Zoological Nomenclature in 1929 after being petitioned by Mary J. Rathbun to take up the case.\n\"Myxococcus llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogochensis\" is the longest accepted binomial name for an organism. It is a bacterium found in soil collected at Llanfairpwllgwyngyll (discussed below). \"Parastratiosphecomyia stratiosphecomyioides\" is the longest accepted binomial name for any animal, or any organism visible with the naked eye. It is a species of soldier fly. The genus name \"Parapropalaehoplophorus\" (a fossil glyptodont, an extinct family of mammals related to armadillos) is two letters longer, but does not contain a similarly long species name.\n\"\", at 52 letters, describing the spa waters at Bath, England, is attributed to Dr. Edward Strother (1675\u20131737). The word is composed of the following elements:\nNotable long words.\nPlace names.\nThe longest officially recognized place name in an English-speaking country is\n (57 letters), which is a hill in New Zealand. The name is in the M\u0101ori language. A longer and widely recognised version of the name is Taumatawhakatangihangakoauauotamateaturipukakapikimaungahoronukupokaiwhenuakitanatahu (85 letters), which appears on the signpost at the location (see the photo on this page). In M\u0101ori, the digraphs \"ng\" and \"wh\" are each treated as single letters.\nIn Canada, the longest place name is \"Dysart, Dudley, Harcourt, Guilford, Harburn, Bruton, Havelock, Eyre and Clyde\", a township in Ontario, at 61 letters or 68 non-space characters.\nThe 58-letter name \"Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch\" is the name of a town on Anglesey, an island of Wales. In terms of the traditional Welsh alphabet, the name is only 51 letters long, as certain digraphs in Welsh are considered as single letters, for instance \"ll\", \"ng\" and \"ch\". It is generally agreed, however, that this invented name, adopted in the mid-19th century, was contrived solely to be the longest name of any town in Britain. The official name of the place is \"Llanfairpwllgwyngyll\", commonly abbreviated to \"Llanfairpwll\" or \"Llanfair PG\".\nThe longest non-contrived place name in the United Kingdom which is a single non-hyphenated word is Cottonshopeburnfoot (19 letters) and the longest which is hyphenated is Sutton-under-Whitestonecliffe (29 characters).\nThe longest place name in the United States (45 letters) is \"\", a lake in Webster, Massachusetts. It means \"Fishing Place at the Boundaries \u2013 Neutral Meeting Grounds\" and is sometimes facetiously translated as \"you fish your side of the water, I fish my side of the water, nobody fishes the middle\". The lake is also known as Webster Lake. The longest hyphenated names in the U.S. are \"Winchester-on-the-Severn\", a town in Maryland, and \"Washington-on-the-Brazos\", a notable place in Texas history.\nThe longest official geographical name in Australia is . It has 26 letters and is a Pitjantjatjara word meaning \"where the Devil urinates\".\nIn Ireland, the longest English place name at 19 letters is Newtownmountkennedy in County Wicklow.\nPersonal names.\n\"Guinness World Records\" formerly contained a category for longest personal name used.\nLong birth names are often coined in protest of naming laws or for other personal reasons."}
{"id": "9469", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=9469", "title": "Eric S. Raymond", "text": "Eric Steven Raymond (born December 4, 1957), often referred to as ESR, is an American software developer, open-source software advocate, and author of the 1997 essay and 1999 book \"The Cathedral and the Bazaar\". He wrote a guidebook for the Roguelike game \"NetHack\". In the 1990s, he edited and updated the Jargon File, currently in print as \"The New Hacker's Dictionary\".\nEarly life.\nRaymond was born in Boston, Massachusetts, in 1957 and lived in Venezuela as a child. His family moved to Pennsylvania in 1971. He developed cerebral palsy at birth; his weakened physical condition motivated him to go into computing.\nCareer.\nRaymond began his programming career writing proprietary software, between 1980 and 1985. In 1990, noting that the Jargon File had not been maintained since about 1983, he adopted it. Paul Dourish maintains an archived original version of the Jargon File, because, he says, Raymond's updates \"essentially destroyed what held it together.\"\nIn 1996 Raymond took over development of the open-source email software \"popclient\", renaming it to Fetchmail. Soon after this experience, in 1997, he wrote the essay \"The Cathedral and the Bazaar\", detailing his thoughts on open-source software development and why it should be done as openly as possible (the \"bazaar\" approach). The essay was based in part on his experience in developing Fetchmail. He first presented his thesis at the annual Linux Kongress on May 27, 1997. He later expanded the essay into a book, \"The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary\", in 1999. The essay has been widely cited. The internal white paper by Frank Hecker that led to the release of the Mozilla (then Netscape) source code in 1998 cited \"The Cathedral and the Bazaar\" as \"independent validation\" of ideas proposed by Eric Hahn and Jamie Zawinski. Hahn would later describe the 1999 book as \"clearly influential\".\nFrom the late 1990s onward, due in part to the popularity of his essay, Raymond became a prominent voice in the open source movement. He co-founded the Open Source Initiative (OSI) in 1998, taking on the self-appointed role of ambassador of open source to the press, business and public. He remains active in OSI, but stepped down as president of the initiative in February 2005. In early March 2020, he was removed from two Open Source Initiative mailing lists due to posts that violated the OSI's Code of Conduct.\nIn 1998 Raymond received and published a Microsoft document expressing worry about the quality of rival open-source software. He named this document, together with others subsequently leaked, \"The Halloween Documents\".\nIn 2000\u20132002 he created Configuration Menu Language 2 (CML2), a source code configuration system; while originally intended for the Linux operating system, it was rejected by kernel developers. (Raymond attributed this rejection to \"kernel list politics\", but Linus Torvalds said in a 2007 mailing list post that as a matter of policy, the development team preferred more incremental changes.) Raymond's 2003 book \"The Art of Unix Programming\" discusses user tools for programming and other tasks.\nSome versions of \"NetHack\" still include Raymond's guide. He has also contributed code and content to the free software video game \"The Battle for Wesnoth\".\nRaymond is the main developer of NTPSec, a \"secure, hardened replacement\" for the Unix utility NTP.\nViews on open source.\nRaymond coined an aphorism he dubbed Linus's law, inspired by Linus Torvalds: \"Given enough eyeballs, all bugs are shallow\". It first appeared in his book \"The Cathedral and the Bazaar\".\nRaymond has refused to speculate on whether the \"bazaar\" development model could be applied to works such as books and music, saying that he does not want to \"weaken the winning argument for open-sourcing software by tying it to a potential loser\".\nRaymond has had a number of public disputes with other figures in the free software movement. As head of the Open Source Initiative, he argued that advocates should focus on the potential for better products. The \"very seductive\" moral and ethical rhetoric of Richard Stallman and the Free Software Foundation fails, he said, \"not because his principles are wrong, but because that kind of language ... simply does not persuade anybody\".\nIn a 2008 essay he defended programmers' right to issue work under proprietary licenses: \"I think that if a programmer wants to write a program and sell it, it's neither my business nor anyone else's but his customer's what the terms of sale are.\" In the same essay he said that the \"logic of the system\" puts developers into \"dysfunctional roles\", with bad code the result.\nPolitical beliefs and activism.\nRaymond is a member of the Libertarian Party. He is a gun rights advocate. He has endorsed the open source firearms organization Defense Distributed, calling them \"friends of freedom\" and writing \"I approve of any development that makes it more difficult for governments and criminals to monopolize the use of force. As 3D printers become less expensive and more ubiquitous, this could be a major step in the right direction.\"\nIn 2015 Raymond accused the Ada Initiative and other women in tech groups of attempting to entrap male open source leaders and accuse them of rape, saying \"Try to avoid even being alone, ever, because there is a chance that a 'women in tech' advocacy group is going to try to collect your scalp.\"\nRaymond has claimed that \"Gays experimented with unfettered promiscuity in the 1970s and got AIDS as a consequence\", and that \"Police who react to a random black male behaving suspiciously who might be in the critical age range as though he is an near-imminent lethal threat, are being rational, not racist.\" Progressive campaign The Great Slate was successful in raising funds for candidates in part by asking for contributions from tech workers in return for not posting similar quotes by Raymond. Matasano Security employee and Great Slate fundraiser Thomas Ptacek said, \"I\u2019ve been torturing Twitter with lurid Eric S. Raymond quotes for years. Every time I do, 20 people beg me to stop.\" It is estimated that as of March 2018 over $30,000 has been raised in this way.\nReligious beliefs.\nRaymond describes himself as neo-pagan."}
{"id": "9471", "revid": "6046894", "url": "https://en.wikipedia.org/wiki?curid=9471", "title": "Externalization", "text": "In Freudian psychology, externalization (or externalisation) is an unconscious defense mechanism by which an individual \"projects\" their own internal characteristics onto the outside world, particularly onto other people. For example, a patient who is overly argumentative might instead perceive others as argumentative and themselves as blameless.\nLike other defense mechanisms, externalization is a protection against anxiety and is, therefore, part of a healthy, normally functioning mind. However, if taken to excess, it can lead to the development of a neurosis.\nThe term \"externalization\" is also used with regards to corporations. A corporation that externalizes its costs onto society and the environment is not taking full responsibility and ownership of these costs. An example might be the discharge of untreated toxic waste into a river where people wash and fish."}
{"id": "9472", "revid": "613571", "url": "https://en.wikipedia.org/wiki?curid=9472", "title": "Euro", "text": "The euro (symbol: \u20ac; code: EUR) is the official currency of 19 of the member states of the European Union. This group of states is known as the eurozone or euro area and includes about 343\u00a0million citizens . The euro, which is divided into 100 cents, is the second-largest and second-most traded currency in the foreign exchange market after the United States dollar.\nThe currency is also used officially by the institutions of the European Union, by four European microstates that are not EU members, the British Overseas Territory of Akrotiri and Dhekelia, as well as unilaterally by Montenegro and Kosovo. Outside Europe, a number of special territories of EU members also use the euro as their currency. Additionally, over 200\u00a0million people worldwide use currencies pegged to the euro.\nThe euro is the second-largest reserve currency as well as the second-most traded currency in the world after the United States dollar.\n, with more than \u20ac1.3\u00a0trillion in circulation, the euro has one of the highest combined values of banknotes and coins in circulation in the world.\nThe name \"euro\" was officially adopted on 16 December 1995 in Madrid. The euro was introduced to world financial markets as an accounting currency on 1 January 1999, replacing the former European Currency Unit (ECU) at a ratio of 1:1 (US$1.1743). Physical euro coins and banknotes entered into circulation on 1 January 2002, making it the day-to-day operating currency of its original members, and by March 2002 it had completely replaced the former currencies. While the euro dropped subsequently to US$0.83 within two years (26 October 2000), it has traded above the U.S. dollar since the end of 2002, peaking at US$1.60 on 18 July 2008 and since then returning near to its original issue rate. In late 2009, the euro became immersed in the European sovereign-debt crisis, which led to the creation of the European Financial Stability Facility as well as other reforms aimed at stabilising and strengthening the currency.\nAdministration.\nThe euro is managed and administered by the Frankfurt-based European Central Bank (ECB) and the Eurosystem (composed of the central banks of the eurozone countries). As an independent central bank, the ECB has sole authority to set monetary policy. The Eurosystem participates in the printing, minting and distribution of notes and coins in all member states, and the operation of the eurozone payment systems.\nThe 1992 Maastricht Treaty obliges most EU member states to adopt the euro upon meeting certain monetary and budgetary convergence criteria, although not all states have done so. Denmark has negotiated exemptions, while Sweden (which joined the EU in 1995, after the Maastricht Treaty was signed) turned down the euro in a non-binding referendum in 2003, and has circumvented the obligation to adopt the euro by not meeting the monetary and budgetary requirements. All nations that have joined the EU since 1993 have pledged to adopt the euro in due course. The Maastricht Treaty was later amended by the Treaty of Nice, which closed the gaps and loopholes in the Maastricht and Rome Treaties.\nIssuing modalities for banknotes.\nSince 1 January 2002, the national central banks (NCBs) and the ECB have issued euro banknotes on a joint basis. Eurosystem NCBs are required to accept euro banknotes put into circulation by other Eurosystem members and these banknotes are not repatriated. The ECB issues 8% of the total value of banknotes issued by the Eurosystem. In practice, the ECB's banknotes are put into circulation by the NCBs, thereby incurring matching liabilities vis-\u00e0-vis the ECB. These liabilities carry interest at the main refinancing rate of the ECB. The other 92% of euro banknotes are issued by the NCBs in proportion to their respective shares of the ECB capital key, calculated using national share of European Union (EU) population and national share of EU GDP, equally weighted.\nCharacteristics.\nCoins and banknotes.\nThe euro is divided into 100 cents (also referred to as \"euro cents\", especially when distinguishing them from other currencies, and referred to as such on the common side of all cent coins). In Community legislative acts the plural forms of \"euro\" and \"cent\" are spelled without the \"s\", notwithstanding normal English usage. Otherwise, normal English plurals are used, with many local variations such as \"centime\" in France.\nAll circulating coins have a \"common side\" showing the denomination or value, and a map in the background. Due to the linguistic plurality in the European Union, the Latin alphabet version of \"euro\" is used (as opposed to the less common Greek or Cyrillic) and Arabic numerals (other text is used on national sides in national languages, but other text on the common side is avoided). For the denominations except the 1-, 2- and 5-cent coins, the map only showed the 15 member states which were members when the euro was introduced. Beginning in 2007 or 2008 (depending on the country), the old map was replaced by a map of Europe also showing countries outside the EU like Norway, Ukraine, Belarus, Russia and Turkey. The 1-, 2- and 5-cent coins, however, keep their old design, showing a geographical map of Europe with the 15 member states of 2002 raised somewhat above the rest of the map. All common sides were designed by Luc Luycx. The coins also have a \"national side\" showing an image specifically chosen by the country that issued the coin. Euro coins from any member state may be freely used in any nation that has adopted the euro.\nThe coins are issued in denominations of \u20ac2, \u20ac1, 50c, 20c, 10c, 5c, 2c, and 1c. To avoid the use of the two smallest coins, some cash transactions are rounded to the nearest five cents in the Netherlands and Ireland (by voluntary agreement) and in Finland (by law). This practice is discouraged by the commission, as is the practice of certain shops of refusing to accept high-value euro notes.\nCommemorative coins with \u20ac2 face value have been issued with changes to the design of the national side of the coin. These include both commonly issued coins, such as the \u20ac2 commemorative coin for the fiftieth anniversary of the signing of the Treaty of Rome, and nationally issued coins, such as the coin to commemorate the 2004 Summer Olympics issued by Greece. These coins are legal tender throughout the eurozone. Collector coins with various other denominations have been issued as well, but these are not intended for general circulation, and they are legal tender only in the member state that issued them.\nThe design for the euro banknotes has common designs on both sides. The design was created by the Austrian designer Robert Kalina. Notes are issued in \u20ac500, \u20ac200, \u20ac100, \u20ac50, \u20ac20, \u20ac10, \u20ac5. Each banknote has its own colour and is dedicated to an artistic period of European architecture. The front of the note features windows or gateways while the back has bridges, symbolising links between states in the union and with the future. While the designs are supposed to be devoid of any identifiable characteristics, the initial designs by Robert Kalina were of specific bridges, including the Rialto and the Pont de Neuilly, and were subsequently rendered more generic; the final designs still bear very close similarities to their specific prototypes; thus they are not truly generic. The monuments looked similar enough to different national monuments to please everyone.\nThe Europa series, or second series, consists of six denominations and no longer includes the \u20ac500 with issuance discontinued as of 27 April 2019. However, both the first and the second series of euro banknotes, including the \u20ac500, remain legal tender throughout the euro area.\nPayments clearing, electronic funds transfer.\nCapital within the EU may be transferred in any amount from one state to another. All intra-Union transfers in euro are treated as domestic transactions and bear the corresponding domestic transfer costs. This includes all member states of the EU, even those outside the eurozone providing the transactions are carried out in euro. Credit/debit card charging and ATM withdrawals within the eurozone are also treated as domestic transactions; however paper-based payment orders, like cheques, have not been standardised so these are still domestic-based. The ECB has also set up a clearing system, TARGET, for large euro transactions.\nCurrency sign.\nA special euro currency sign (\u20ac) was designed after a public survey had narrowed the original ten proposals down to two. The European Commission then chose the design created by the Belgian Alain Billiet. Of the symbol, the Commission stated\nThe European Commission also specified a euro logo with exact proportions and foreground and background colour tones. Placement of the currency sign relative to the numeric amount varies from state to state, but for texts in English the symbol (or the ISO-standard \"EUR\") should precede the amount.\nHistory.\nIntroduction.\nThe euro was established by the provisions in the 1992 Maastricht Treaty. To participate in the currency, member states are meant to meet strict criteria, such as a budget deficit of less than 3% of their GDP, a debt ratio of less than 60% of GDP (both of which were ultimately widely flouted after introduction), low inflation, and interest rates close to the EU average. In the Maastricht Treaty, the United Kingdom and Denmark were granted exemptions per their request from moving to the stage of monetary union which resulted in the introduction of the euro. (For macroeconomic theory, see below.)\nThe name \"euro\" was officially adopted in Madrid on 16 December 1995. Belgian Esperantist Germain Pirlot, a former teacher of French and history is credited with naming the new currency by sending a letter to then President of the European Commission, Jacques Santer, suggesting the name \"euro\" on 4 August 1995.\nDue to differences in national conventions for rounding and significant digits, all conversion between the national currencies had to be carried out using the process of triangulation via the euro. The \"definitive\" values of one euro in terms of the exchange rates at which the currency entered the euro are shown on the right.\nThe rates were determined by the Council of the European Union, based on a recommendation from the European Commission based on the market rates on 31 December 1998. They were set so that one European Currency Unit (ECU) would equal one euro. The European Currency Unit was an accounting unit used by the EU, based on the currencies of the member states; it was not a currency in its own right. They could not be set earlier, because the ECU depended on the closing exchange rate of the non-euro currencies (principally the pound sterling) that day.\nThe procedure used to fix the conversion rate between the Greek drachma and the euro was different since the euro by then was already two years old. While the conversion rates for the initial eleven currencies were determined only hours before the euro was introduced, the conversion rate for the Greek drachma was fixed several months beforehand.\nThe currency was introduced in non-physical form (traveller's cheques, electronic transfers, banking, etc.) at midnight on 1 January 1999, when the national currencies of participating countries (the eurozone) ceased to exist independently. Their exchange rates were locked at fixed rates against each other. The euro thus became the successor to the European Currency Unit (ECU). The notes and coins for the old currencies, however, continued to be used as legal tender until new euro notes and coins were introduced on 1 January 2002.\nThe changeover period during which the former currencies' notes and coins were exchanged for those of the euro lasted about two months, until 28 February 2002. The official date on which the national currencies ceased to be legal tender varied from member state to member state. The earliest date was in Germany, where the mark officially ceased to be legal tender on 31 December 2001, though the exchange period lasted for two months more. Even after the old currencies ceased to be legal tender, they continued to be accepted by national central banks for periods ranging from several years to indefinitely (the latter for Austria, Germany, Ireland, Estonia and Latvia in banknotes and coins, and for Belgium, Luxembourg, Slovenia and Slovakia in banknotes only). The earliest coins to become non-convertible were the Portuguese escudos, which ceased to have monetary value after 31 December 2002, although banknotes remain exchangeable until 2022.\nEurozone crisis.\nFollowing the U.S. financial crisis in 2008, fears of a sovereign debt crisis developed in 2009 among investors concerning some European states, with the situation becoming particularly tense in early 2010. Greece was most acutely affected, but fellow Eurozone members Cyprus, Ireland, Italy, Portugal, and Spain were also significantly affected. All these countries utilized EU funds except Italy, which is a major donor to the EFSF. To be included in the eurozone, countries had to fulfil certain convergence criteria, but the meaningfulness of such criteria was diminished by the fact it was not enforced with the same level of strictness among countries.\nAccording to the Economist Intelligence Unit in 2011, \"[I]f the [euro area] is treated as a single entity, its [economic and fiscal] position looks no worse and in some respects, rather better than that of the US or the UK\" and the budget deficit for the euro area as a whole is much lower and the euro area's government debt/GDP ratio of 86% in 2010 was about the same level as that of the United States. \"Moreover\", they write, \"private-sector indebtedness across the euro area as a whole is markedly lower than in the highly leveraged Anglo-Saxon economies\". The authors conclude that the crisis \"is as much political as economic\" and the result of the fact that the euro area lacks the support of \"institutional paraphernalia (and mutual bonds of solidarity) of a state\".\nThe crisis continued with S&amp;P downgrading the credit rating of nine euro-area countries, including France, then downgrading the entire European Financial Stability Facility (EFSF) fund.\nA historical parallel\u00a0\u2013 to 1931 when Germany was burdened with debt, unemployment and austerity while France and the United States were relatively strong creditors\u00a0\u2013 gained attention in summer 2012 even as Germany received a debt-rating warning of its own. In the enduring of this scenario the euro serves as a mean of quantitative primitive accumulation.\nDirect and indirect usage.\nDirect usage.\nThe euro is the sole currency of 19 EU member states: Austria, Belgium, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal, Slovakia, Slovenia, and Spain. These countries constitute the \"eurozone\", some 343\u00a0million people in total .\nWith all but one (Denmark) EU members obliged to join when economic conditions permit, together with future members of the EU, the enlargement of the eurozone is set to continue. Outside the EU, the euro is also the sole currency of Montenegro and Kosovo and several European microstates (Andorra, Monaco, San Marino and the Vatican City) as well as in three overseas territories of France that are not themselves part of the EU, namely (Saint Barth\u00e9lemy, Saint Pierre and Miquelon, and the French Southern and Antarctic Lands. Together this direct usage of the euro outside the EU affects nearly 3\u00a0million people.\nThe euro has been used as a trading currency in Cuba since 1998, Syria since 2006, and Venezuela since 2018. There are also various currencies pegged to the euro (see below). In 2009, Zimbabwe abandoned its local currency and used major currencies instead, including the euro and the United States dollar.\nUse as reserve currency.\nSince its introduction, the euro has been the second most widely held international reserve currency after the U.S. dollar. The share of the euro as a reserve currency increased from 18% in 1999 to 27% in 2008. Over this period, the share held in U.S. dollar fell from 71% to 64% and that held in RMB fell from 6.4% to 3.3%. The euro inherited and built on the status of the Deutsche Mark as the second most important reserve currency. The euro remains underweight as a reserve currency in advanced economies while overweight in emerging and developing economies: according to the International Monetary Fund the total of euros held as a reserve in the world at the end of 2008 was equal to $1.1\u00a0trillion or \u20ac850\u00a0billion, with a share of 22% of all currency reserves in advanced economies, but a total of 31% of all currency reserves in emerging and developing economies.\nThe possibility of the euro becoming the first international reserve currency has been debated among economists. Former Federal Reserve Chairman Alan Greenspan gave his opinion in September 2007 that it was \"absolutely conceivable that the euro will replace the US dollar as reserve currency, or will be traded as an equally important reserve currency\". In contrast to Greenspan's 2007 assessment, the euro's increase in the share of the worldwide currency reserve basket has slowed considerably since 2007 and since the beginning of the worldwide credit crunch related recession and European sovereign-debt crisis.\nCurrencies pegged to the euro.\nOutside the eurozone, a total of 22 countries and territories that do not belong to the EU have currencies that are directly pegged to the euro including 14 countries in mainland Africa (CFA franc), two African island countries (Comorian franc and Cape Verdean escudo), three French Pacific territories (CFP franc) and three Balkan countries, Bosnia and Herzegovina (Bosnia and Herzegovina convertible mark), Bulgaria (Bulgarian lev) and North Macedonia (Macedonian denar). On 28 July 2009, S\u00e3o Tom\u00e9 and Pr\u00edncipe signed an agreement with Portugal which will eventually tie its currency to the euro. Additionally, the Moroccan dirham is tied to a basket of currencies, including the euro and the US dollar, with the euro given the highest weighting.\nWith the exception of Bosnia, Bulgaria, North Macedonia (which had pegged their currencies against the Deutsche Mark) and Cape Verde (formerly pegged to the Portuguese escudo), all of these non-EU countries had a currency peg to the French Franc before pegging their currencies to the euro. Pegging a country's currency to a major currency is regarded as a safety measure, especially for currencies of areas with weak economies, as the euro is seen as a stable currency, prevents runaway inflation and encourages foreign investment due to its stability.\nWithin the EU several currencies are pegged to the euro, mostly as a precondition to joining the eurozone. The Danish krone, Croatian kuna and Bulgarian lev are pegged due to their participation in the ERM II.\nIn total, , 182\u00a0million people in Africa use a currency pegged to the euro, 27\u00a0million people outside the eurozone in Europe, and another 545,000 people on Pacific islands.\nSince 2005, stamps issued by the Sovereign Military Order of Malta have been denominated in euros, although the Order's official currency remains the Maltese scudo. The Maltese scudo itself is pegged to the euro and is only recognised as legal tender within the Order.\nEconomics.\nOptimal currency area.\nIn economics, an optimum currency area, or region (OCA or OCR), is a geographical region in which it would maximise economic efficiency to have the entire region share a single currency. There are two models, both proposed by Robert Mundell: the stationary expectations model and the international risk sharing model. Mundell himself advocates the international risk sharing model and thus concludes in favour of the euro. However, even before the creation of the single currency, there were concerns over diverging economies. Before the late-2000s recession it was considered unlikely that a state would leave the euro or the whole zone would collapse. However the Greek government-debt crisis led to former British Foreign Secretary Jack Straw claiming the eurozone could not last in its current form. Part of the problem seems to be the rules that were created when the euro was set up. John Lanchester, writing for \"The New Yorker\", explains it: \nTransaction costs and risks.\nThe most obvious benefit of adopting a single currency is to remove the cost of exchanging currency, theoretically allowing businesses and individuals to consummate previously unprofitable trades. For consumers, banks in the eurozone must charge the same for intra-member cross-border transactions as purely domestic transactions for electronic payments (e.g., credit cards, debit cards and cash machine withdrawals).\nFinancial markets on the continent are expected to be far more liquid and flexible than they were in the past. The reduction in cross-border transaction costs will allow larger banking firms to provide a wider array of banking services that can compete across and beyond the eurozone. However, although transaction costs were reduced, some studies have shown that risk aversion has increased during the last 40 years in the Eurozone.\nPrice parity.\nAnother effect of the common European currency is that differences in prices\u2014in particular in price levels\u2014should decrease because of the law of one price. Differences in prices can trigger arbitrage, i.e., speculative trade in a commodity across borders purely to exploit the price differential. Therefore, prices on commonly traded goods are likely to converge, causing inflation in some regions and deflation in others during the transition. Some evidence of this has been observed in specific eurozone markets.\nMacroeconomic stability.\nBefore the introduction of the euro, some countries had successfully contained inflation, which was then seen as a major economic problem, by establishing largely independent central banks. One such bank was the Bundesbank in Germany; the European Central Bank was modelled on the Bundesbank.\nThe euro has come under criticism due to its regulation, lack of flexibility and rigidity towards sharing member States on issues such as nominal interest rates.\nMany national and corporate bonds denominated in euro are significantly more liquid and have lower interest rates than was historically the case when denominated in national currencies. While increased liquidity may lower the nominal interest rate on the bond, denominating the bond in a currency with low levels of inflation arguably plays a much larger role. A credible commitment to low levels of inflation and a stable debt reduces the risk that the value of the debt will be eroded by higher levels of inflation or default in the future, allowing debt to be issued at a lower nominal interest rate.\nUnfortunately, there is also a cost in structurally keeping inflation lower than in the United States, UK, and China. The result is that seen from those countries, the euro has become expensive, making European products increasingly expensive for its largest importers; hence export from the eurozone becomes more difficult.\nIn general, those in Europe who own large amounts of euros are served by high stability and low inflation.\nA monetary union means states in that union lose the main mechanism of recovery of their international competitiveness by weakening (depreciating) their currency. When wages become too high compared to productivity in exports sector then these exports become more expensive and they are crowded out from the market within a country and abroad. This drive fall of employment and output in the exports sector and fall of trade and current account balances. Fall of output and employment in tradable goods sector may be offset by the growth of non-exports sectors, especially in construction and services. Increased purchases abroad and negative current account balance can be financed without a problem as long as credit is cheap. The need to finance trade deficit weakens currency making exports automatically more attractive in a country and abroad. A state in a monetary union cannot use weakening of currency to recover its international competitiveness. To achieve this a state has to reduce prices, including wages (deflation). This could result in high unemployment and lower incomes as it was during European sovereign-debt crisis.\nTrade.\nA 2009 consensus from the studies of the introduction of the euro concluded that it has increased trade within the eurozone by 5% to 10%, although one study suggested an increase of only 3% while another estimated 9 to 14%. However, a meta-analysis of all available studies suggests that the prevalence of positive estimates is caused by publication bias and that the underlying effect may be negligible. Although a more recent meta-analysis shows that publication bias decreases over time and that there are positive trade effects from the introduction of the euro, as long as results from before 2010 are taken into account. This may be because of the inclusion of the Financial crisis of 2007\u20132008 and ongoing integration within the EU. Furthermore, older studies accounting for time trend reflecting general cohesion policies in Europe that started before, and continue after implementing the common currency find no effect on trade. These results suggest that other policies aimed at European integration might be the source of observed increase in trade.\nInvestment.\nPhysical investment seems to have increased by 5% in the eurozone due to the introduction. Regarding foreign direct investment, a study found that the intra-eurozone FDI stocks have increased by about 20% during the first four years of the EMU. Concerning the effect on corporate investment, there is evidence that the introduction of the euro has resulted in an increase in investment rates and that it has made it easier for firms to access financing in Europe. The euro has most specifically stimulated investment in companies that come from countries that previously had weak currencies. A study found that the introduction of the euro accounts for 22% of the investment rate after 1998 in countries that previously had a weak currency.\nInflation.\nThe introduction of the euro has led to extensive discussion about its possible effect on inflation. In the short term, there was a widespread impression in the population of the eurozone that the introduction of the euro had led to an increase in prices, but this impression was not confirmed by general indices of inflation and other studies. A study of this paradox found that this was due to an asymmetric effect of the introduction of the euro on prices: while it had no effect on most goods, it had an effect on cheap goods which have seen their price round up after the introduction of the euro. The study found that consumers based their beliefs on inflation of those cheap goods which are frequently purchased. It has also been suggested that the jump in small prices may be because prior to the introduction, retailers made fewer upward adjustments and waited for the introduction of the euro to do so.\nExchange rate risk.\nOne of the advantages of the adoption of a common currency is the reduction of the risk associated with changes in currency exchange rates. It has been found that the introduction of the euro created \"significant reductions in market risk exposures for nonfinancial firms both in and outside Europe\". These reductions in market risk \"were concentrated in firms domiciled in the eurozone and in non-euro firms with a high fraction of foreign sales or assets in Europe\".\nFinancial integration.\nThe introduction of the euro seems to have had a strong effect on European financial integration. According to a study on this question, it has \"significantly reshaped the European financial system, especially with respect to the securities markets [...] However, the real and policy barriers to integration in the retail and corporate banking sectors remain significant, even if the wholesale end of banking has been largely integrated.\" Specifically, the euro has significantly decreased the cost of trade in bonds, equity, and banking assets within the eurozone. On a global level, there is evidence that the introduction of the euro has led to an integration in terms of investment in bond portfolios, with eurozone countries lending and borrowing more between each other than with other countries.\nEffect on interest rates.\nAs of January 2014, and since the introduction of the euro, interest rates of most member countries (particularly those with a weak currency) have decreased. Some of these countries had the most serious sovereign financing problems.\nThe effect of declining interest rates, combined with excess liquidity continually provided by the ECB, made it easier for banks within the countries in which interest rates fell the most, and their linked sovereigns, to borrow significant amounts (above the 3% of GDP budget deficit imposed on the eurozone initially) and significantly inflate their public and private debt levels. Following the financial crisis of 2007\u20132008, governments in these countries found it necessary to bail out or nationalise their privately held banks to prevent systemic failure of the banking system when underlying hard or financial asset values were found to be grossly inflated and sometimes so near worthless there was no liquid market for them. This further increased the already high levels of public debt to a level the markets began to consider unsustainable, via increasing government bond interest rates, producing the ongoing European sovereign-debt crisis.\nPrice convergence.\nThe evidence on the convergence of prices in the eurozone with the introduction of the euro is mixed. Several studies failed to find any evidence of convergence following the introduction of the euro after a phase of convergence in the early 1990s. Other studies have found evidence of price convergence, in particular for cars. A possible reason for the divergence between the different studies is that the processes of convergence may not have been linear, slowing down substantially between 2000 and 2003, and resurfacing after 2003 as suggested by a recent study (2009).\nTourism.\nA study suggests that the introduction of the euro has had a positive effect on the amount of tourist travel within the EMU, with an increase of 6.5%.\nExchange rates.\nFlexible exchange rates.\nThe ECB targets interest rates rather than exchange rates and in general, does not intervene on the foreign exchange rate markets. This is because of the implications of the Mundell\u2013Fleming model, which implies a central bank cannot (without capital controls) maintain interest rate and exchange rate targets simultaneously, because increasing the money supply results in a depreciation of the currency. In the years following the Single European Act, the EU has liberalised its capital markets and, as the ECB has inflation targeting as its monetary policy, the exchange-rate regime of the euro is floating.\nAgainst other major currencies.\nThe euro is the second-most widely held reserve currency after the U.S. dollar. After its introduction on 4 January 1999 its exchange rate against the other major currencies fell reaching its lowest exchange rates in 2000 (3 May vs Pound sterling, 25 October vs the U.S. dollar, 26 October vs Japanese yen). Afterwards it regained and its exchange rate reached its historical highest point in 2008 (15 July vs U.S. dollar, 23 July vs Japanese yen, 29 December vs Pound sterling). With the advent of the global financial crisis the euro initially fell, to regain later. Despite pressure due to the European sovereign-debt crisis the euro remained stable. In November 2011 the euro's exchange rate index\u00a0\u2013 measured against currencies of the bloc's major trading partners\u00a0\u2013 was trading almost two percent higher on the year, approximately at the same level as it was before the crisis kicked off in 2007.\nPolitical considerations.\nBesides the economic motivations to the introduction of the euro, its creation was also partly justified as a way to foster a closer sense of joint identity between European citizens. Statements about this goal were for instance made by Wim Duisenberg, European Central Bank Governor, in 1998, Laurent Fabius, French Finance Minister, in 2000, and Romano Prodi, President of the European Commission, in 2002. However, 15 years after the introduction of the euro, a study found no evidence that it has had a positive influence on a shared sense of European identity (and no evidence that it had a negative effect either).\nLinguistic issues.\nThe formal titles of the currency are \"euro\" for the major unit and \"cent\" for the minor (one-hundredth) unit and for official use in most eurozone languages; according to the ECB, all languages should use the same spelling for the nominative singular. This may contradict normal rules for word formation in some languages, e.g., those in which there is no \"eu\" diphthong. Bulgaria has negotiated an exception; \"euro\" in the Bulgarian Cyrillic alphabet is spelled as e\u0432\u0440\u043e (\"evro\") and not e\u0443\u0440\u043e (\"euro\") in all official documents. In the Greek script the term \u03b5\u03c5\u03c1\u03ce (evr\u00f3) is used; the Greek \"cent\" coins are denominated in \u03bb\u03b5\u03c0\u03c4\u03cc/\u03ac (lept\u00f3/\u00e1). Official practice for English-language EU legislation is to use the words euro and cent as both singular and plural, although the European Commission's Directorate-General for Translation states that the plural forms \"euros\" and \"cents\" should be used in English."}
{"id": "9474", "revid": "1023642291", "url": "https://en.wikipedia.org/wiki?curid=9474", "title": "European Central Bank", "text": "The European Central Bank (ECB) is the central bank of the Eurozone, a monetary union of 19 EU member states which employ the euro. Established by the Treaty of Amsterdam, the ECB is one of the world's most important central banks and serves as one of seven institutions of the European Union, being enshrined in the Treaty on European Union (TEU). The bank's capital stock is owned by all 27 central banks of each EU member state. The current President of the ECB is Christine Lagarde. Headquartered in Frankfurt, Germany, the bank formerly occupied the Eurotower prior to the construction of its new seat.\nThe primary objective of the ECB, mandated in Article 2 of the Statute of the ECB, is to maintain price stability within the Eurozone. Its basic tasks, set out in Article 3 of the Statute, are to set and implement the monetary policy for the Eurozone, to conduct foreign exchange operations, to take care of the foreign reserves of the European System of Central Banks and operation of the financial market infrastructure under the TARGET2 payments system and the technical platform (currently being developed) for settlement of securities in Europe (TARGET2 Securities). The ECB has, under Article 16 of its Statute, the exclusive right to authorise the issuance of euro banknotes. Member states can issue euro coins, but the amount must be authorised by the ECB beforehand. \nOn 1 December 2009, the Treaty of Lisbon entered into force, ECB according to the article 13 of TEU, gained official status of an EU institution.\nThe ECB is governed by European law directly, but its set-up resembles that of a corporation in the sense that the ECB has shareholders and stock capital. Its capital is \u20ac11 billion held by the national central banks of the member states as shareholders. The initial capital allocation key was determined in 1998 on the basis of the states' population and GDP, but the capital key has been adjusted. Shares in the ECB are not transferable and cannot be used as collateral.\nWhen the ECB was created, it covered a Eurozone of eleven members. Since then, Greece joined in January 2001, Slovenia in January 2007, Cyprus and Malta in January 2008, Slovakia in January 2009, Estonia in January 2011, Latvia in January 2014 and Lithuania in January 2015.\nHistory.\nEarly years of the ECB (1998-2007).\nThe European Central Bank is the \"de facto\" successor of the European Monetary Institute (EMI). The EMI was established at the start of the second stage of the EU's Economic and Monetary Union (EMU) to handle the transitional issues of states adopting the euro and prepare for the creation of the ECB and European System of Central Banks (ESCB). The EMI itself took over from the earlier European Monetary Co-operation Fund (EMCF).\nThe ECB formally replaced the EMI on 1 June 1998 by virtue of the Treaty on European Union (TEU, Treaty of Maastricht), however it did not exercise its full powers until the introduction of the euro on 1 January 1999, signalling the third stage of EMU. The bank was the final institution needed for EMU, as outlined by the EMU reports of Pierre Werner and President Jacques Delors. It was established on 1 June 1219 The first President of the Bank was Wim Duisenberg, the former president of the Dutch central bank and the European Monetary Institute. While Duisenberg had been the head of the EMI (taking over from Alexandre Lamfalussy of Belgium) just before the ECB came into existence, the French government wanted Jean-Claude Trichet, former head of the French central bank, to be the ECB's first president. The French argued that since the ECB was to be located in Germany, its president should be French. This was opposed by the German, Dutch and Belgian governments who saw Duisenberg as a guarantor of a strong euro. Tensions were abated by a gentleman's agreement in which Duisenberg would stand down before the end of his mandate, to be replaced by Trichet.\nTrichet replaced Duisenberg as President in November 2003. Until 2007, the ECB had very successfully managed to maintain inflation close but below 2%.\nThe ECB's response to the financial crises (2008-2014).\nThe European Central Bank underwent through a deep internal transformation as it faced the global financial crisis and the Eurozone debt crisis. \nEarly response to the Eurozone debt crisis.\nThe so-called \"European debt crisis\" began after Greece's new elected government uncovered the real level indebtedness and budget deficit and warned EU institutions of the imminent danger of a Greek sovereign default.\nForeseeing a possible sovereign default in the eurozone, the general public, international and European institutions, and the financial community reassessed the economic situation and creditworthiness of some Eurozone member states, in particular Southern countries. Consequently, sovereign bonds yields of several Eurozone countries started to rise sharply. This provoked a self-fulfilling panic on financial markets: the more Greek bonds yields rose, the more likely a default became possible, the more bond yields increased in turn.\nTrichet's reluctance to intervene.\nThis panic was also aggravated because of the inability of the ECB to react and intervene on sovereign bonds markets for two reasons. First, because the ECB's legal framework normally forbids the purchase of sovereign bonds (Article 123. TFEU), This prevented the ECB from implementing quantitative easing like the Federal Reserve and the Bank of England did as soon as 2008, which played an important role in stabilizing markets. \nSecondly, a decision by the ECB made in 2005 introduced a minimum credit rating (BBB-) for all Eurozone sovereign bonds to be eligible as collateral to the ECB's open market operations. This meant that if a private rating agencies were to downgrade a sovereign bond below that threshold, many banks would suddenly become illiquid because they would lose access to ECB refinancing operations. According to former member of the governing council of the ECB Athanasios Orphanides, this change in the ECB's collateral framework \"planted the seed\" of the euro crisis.\nFaced with those regulatory constraints, the ECB led by Jean-Claude Trichet in 2010 was reluctant to intervene to calm down financial markets. Up until 6 May 2010, Trichet formally denied at several press conferences the possibility of the ECB to embark into sovereign bonds purchases, even though Greece, Portugal, Spain and Italy faced waves of credit rating downgrades and increasing interest rate spreads.\nECB's market interventions (2010-2011).\nIn a remarkable u-turn, the ECB announced on 10 May 2010, the launch of a \"Securities Market Programme\" (SMP) which involved the discretionary purchase of sovereign bonds in secondary markets. Extraordinarily, the decision was taken by the Governing Council during a teleconference call only three days after the ECB's usual meeting of 6 May (when Trichet still denied the possibility of purchasing sovereign bonds). The ECB justified this decision by the necessity to \"address severe tensions in financial markets.\" The decision also coincided with the EU leaders decision of 10 May to establish the European Financial Stabilisation mechanism, which would serve as a crisis fighting fund to safeguard the euro area from future sovereign debt crisis.\nThe ECB's bond buying focused primarily on Spanish and Italian debt. They were intended to dampen international speculation against those countries, and thus avoid a contagion of the Greek crisis towards other Eurozone countries. The assumption is that speculative activity will decrease over time and the value of the assets increase.\nAlthough SMP did involve an injection of new money into financial markets, all ECB injections were \"sterilized\" through weekly liquidity absorption. So the operation was neutral for the overall money supply.\nIn September 2011, ECB's Board member J\u00fcrgen Stark, resigned in protest against the \"Securities Market Programme\" which involved the purchase of sovereign bonds from Southern member states, a move that he considered as equivalent to monetary financing, which is prohibited by the EU Treaty. The \"Financial Times Deutschland\" referred to this episode as \"the end of the ECB as we know it\", referring to its hitherto perceived \"hawkish\" stance on inflation and its historical Deutsche Bundesbank influence.\nAs of 18 June 2012, the ECB in total had spent \u20ac212.1bn (equal to 2.2% of the Eurozone GDP) for bond purchases covering outright debt, as part of the Securities Markets Programme. Controversially, the ECB made substantial profits out of SMP, which were largely redistributed to Eurozone countries. In 2013, the Eurogroup decided to refund those profits to Greece, however the payments were suspended over 2014 until 2017 over the conflict between Yanis Varoufakis and ministers of the Eurogroup. In 2018, profits refunds were reinstalled by the Eurogroup. However, several NGOs complained that a substantial part of the ECB profits would never be refunded to Greece.\nRole in the Troika (2010-2015).\nThe ECB played a controversial role in the \"Troika\" by rejecting all forms of debt restructuring of public and private debts, forcing governments to adopt bailout programmes and structural reforms through secret letters to Italian, Spanish, Greek and Irish governments. It has further been accused of interfering in the Greek referendum of July 2015 by constraining liquidity to Greek commercial banks.\nIn November 2010, it became clear that Ireland would not be able to afford to bail out its failing banks, and Anglo Irish Bank in particular which needed around 30 billion euros, a sum the government obviously could not borrow from financial markets when its bond yields were soaring to comparable levels with the Greek bonds. Instead, the government issued a 31bn EUR \"promissory note\" (an IOU) to Anglo \u2013 which it had nationalized. In turn, the bank supplied the promissory note as collateral to the Central Bank of Ireland, so it could access emergency liquidity assistance (ELA). This way, Anglo was able to repay its bondholders. The operation became very controversial, as it basically shifted Anglo's private debts onto the government's balance sheet.\nIt became clear later that the ECB played a key role in making sure the Irish government did not let Anglo default on its debts, in order to avoid a financial instability risks. On 15 October and 6 November 2010, the ECB President Jean-Claude Trichet sent two secret letters to the Irish finance Minister which essentially informed the Irish government of the possible suspension of ELA's credit lines, unless the government requested a financial assistance programme to the Eurogroup under condition of further reforms and fiscal consolidation. \nOver 2012 and 2013, the ECB repeatedly insisted that the promissory note should be repaid in full, and refused the Government's proposal to swap the notes with a long-term (and less costly) bond until February 2013. In addition, the ECB insisted that no debt restructuring (or bail-in) should be applied to the nationalized banks' bondholders, a measure which could have saved Ireland 8 billion euros.\nIn April 2011, the ECB raised interest rates for the first time since 2008 from 1% to 1.25%, with a further increase to 1.50% in July 2011. However, in 2012\u20132013 the ECB sharply lowered interest rates to encourage economic growth, reaching the historically low 0.25% in November 2013. Soon after the rates were cut to 0.15%, then on 4 September 2014 the central bank reduced the rates by two thirds from 0.15% to 0.05%. Recently, the interest rates were further reduced reaching 0.00%, the lowest rates on record.\nIn a report adopted on 13 March 2014, the European Parliament criticized the \"potential conflict of interest between the current role of the ECB in the Troika as \u2018technical advisor\u2019 and its position as creditor of the four Member States, as well as its mandate under the Treaty\". The report was led by Austrian right-wing MEP Othmar Karas and French Socialist MEP Liem Hoang Ngoc.\nThe ECB's response under Mario Draghi (2012-2015).\nOn 1 November 2011, Mario Draghi replaced Jean-Claude Trichet as President of the ECB. This change in leadership also marks the start of a new era under which the ECB will become more and more interventionist and eventually ended the Eurozone sovereign debt crisis.\nDraghi's presidency started with the impressive launch of a new round of 1% interest loans with a term of three years (36 months) \u2013 the Long-term Refinancing operations (LTRO). Under this programme, 523 Banks tapped as much as \u20ac489.2 bn (US$640 bn). Observers were surprised by the volume of the loans made when it was implemented. By far biggest amount of was tapped by banks in Greece, Ireland, Italy and Spain. Although those LTROs loans did not directly benefit EU governments, it effectively allowed banks to do a carry trade, by lending off the LTROs loans to governments with an interest margin. The operation also facilitated the rollover of of maturing bank debts in the first three months of 2012. \n\"Whatever it takes\" (26 July 2012).\nFacing renewed fears about sovereigns in the eurozone continued Mario Draghi made a decisive speech London, by declaring that the ECB \"...is ready to do whatever it takes to preserve the Euro. And believe me, it will be enough.\" In light of slow political progress on solving the eurozone crisis, Draghi's statement has been seen as a key turning point in the eurozone crisis, as it was immediately welcomed by European leaders, and led to a steady decline in bond yields for eurozone countries, in particular Spain, Italy and France.\nFollowing up on Draghi's speech, on 6 September 2012 the ECB announced the Outright Monetary Transactions programme (OMT). Unlike the previous SMP programme, OMT has no ex-ante time or size limit. However, the activation of the purchases remains conditioned to the adherence by the benefitting country to an adjustment programme to the ESM. The program was adopted with near unanimity, the Bundesbank president Jens Weidmann being the sole member of the ECB's Governing Council to vote against.\nEven if OMT was never actually implemented until today, it made the \"Whatever it takes\" pledge credible and significantly contributed in stabilizing financial markets and ended the sovereign debt crisis. According to various sources, the OMT programme and \"whatever it takes\" speeches were made possible because EU leaders previously agreed to build the banking union.\nLow inflation and quantitative easing (2015-2019).\nIn November 2014, the bank moved into its new premises, while the Eurotower building was dedicated to host the newly established supervisory activities of the ECB under the Single Supervisory Mechanism.\nAlthough the sovereign debt crisis was almost solved by 2014, the ECB started to face a repeated decline in the Eurozone inflation rate, indicating that the economy was going towards a deflation. Responding to this threat, the ECB announced on 4 September 2014 the launch of two bond buying purchases programmes: the Covered Bond Purchasing Programme (CBPP3) and Asset-Backed Securities Programme (ABSPP).\nOn 22 January 2015, the ECB announced an extension of those programmes within a full-fledge \"quantitative easing\" programme which also included sovereign bonds, to the tune of 60 billion euros per month up until at least September 2016. The programme was started on 9 March 2015.\nOn 8 June 2016, the ECB added corporate bonds to its asset purchases portfolio with the launch of the corporate sector purchase programme (CSPP). Under this programme, it conducted net purchase of corporate bonds until January 2019 to reach about \u20ac177 billion. While the programme was halted for 11 months in January 2019, the ECB restarted net purchases in November 2019.\nAs of 2021, the size of the ECB's quantitative easing programme had reached 2947 billion euros.\nChristine Lagarde's era (2019- ).\nIn July 2019, EU leaders nominated Christine Lagarde to replace Mario Draghi as ECB President. Lagarde resigned from her position as Managing Director of the International Monetary Fund in July 2019 and formally took over the ECB's Presidency on 1 November 2019. \nLagarde immediately signaled a change of style in the ECB's leadership. She embarked the ECB's into a strategic review of the ECB's monetary policy strategy, an exercise the ECB had not done for 17 years. As part of this exercise, Lagarde committed the ECB to look into how monetary policy could contribute to address climate change, and promised that \"no stone would be left unturned.\" The ECB president also adopted a change of communication style, in particular in her use of social media to promote gender equality, and by opening dialogue with civil society stakeholders.\nResponse to the COVID-19 crisis.\nHowever, Lagarde's ambitions were quickly slowed down with the outbreak of the COVID-19 pandemic crisis. \nIn March 2020, the ECB responded quickly and boldly by launching a package of measures including a new asset purchase programme: the \u20ac1350 billion Pandemic Emergency Purchase Programme (PEPP) which aimed to lower borrowing costs and increase lending in the euro area. The PEPP was extended to cover an additional \u20ac500 billion in December 2020. The ECB also re-launched more TLTROs loans to banks at historically low levels and record-high take-up (EUR 1.3 trillion in June 2020). Lending by banks to SMEs was also facilitated by collateral easing measures, and other supervisory relaxations. The ECB also reactivated currency swap lines and enhanced existing swap lines with central banks across the globe\nStrategy Review.\nAs a consequence of the Covid19 crisis, the ECB extended the duration of the strategy review until September 2021.\nMandate and inflation target.\nUnlike many other central banks, the ECB does not have a \"dual mandate\" where it has to pursue two equally important objectives such as price stability and full employment (like the US Federal Reserve System). The ECB has only one primary objective \u2013 price stability \u2013 subject to which it may pursue secondary objectives.\nPrimary mandate.\nThe primary objective of the European Central Bank, set out in Article 127(1) of the Treaty on the Functioning of the European Union, is to maintain price stability within the Eurozone. However the EU Treaties do not specify exactly how the ECB should pursue this objective. The European Central Bank has ample discretion over the way it purses its price stability objective, as it can self-decide on the inflation target, and may also influence the way inflation is being measured.\nThe Governing Council in October 1998 defined price stability as inflation of under 2%, \u201ca year-on-year increase in the Harmonised Index of Consumer Prices (HICP) for the euro area of below 2%\u201d and added that price stability \u201dwas to be maintained over the medium term\u201d. In May 2003, following a thorough review of the ECB's monetary policy strategy, the Governing Council clarified that \u201cin the pursuit of price stability, it aims to maintain inflation rates below, but close to, 2% over the medium term\u201d.\nSince 2016, the European Central Bank's President has further adjusted its communication, by introducing the notion of \"symmetry\" in its definition of its target, thus making it clear that the ECB should respond both to inflationary pressure to deflationary pressures. As Draghi once said \"symmetry meant not only that we would not accept persistently low inflation, but also that there was no cap on inflation at 2%.\"\nSecondary mandate.\nWithout prejudice to the objective of price stability, the Treaty (127 TFEU) also provides room for the ECB to pursue other objectives:\"Without prejudice to the objective of price stability, the ESCB shall support the general economic policies in the Union with a view to contributing to the achievement of the objectives of the Union as laid down in Article 3 of the Treaty on European Union.\"This legal provision is often considered to provide a \"secondary mandate\" to the ECB, and offers ample justifications for the ECB to also prioritize other considerations such as full employment or environmental protection, which are mentioned in the Article 3 of the Treaty on the European Union. At the same time, economists and commentators are often divided on whether and how the ECB should pursue those secondary objectives, in particular the environmental impact. ECB official have also frequently pointed out the possible contradictions between those secondary objectives. To better guide the ECB's action on its secondary objectives, it has been suggested that closer consultation with the European Parliament would be warranted.\nTasks.\nTo carry out its main mission, the ECB's tasks include:\nMonetary policy tools.\nThe principal monetary policy tool of the European central bank is collateralised borrowing or repo agreements. These tools are also used by the United States Federal Reserve Bank, but the Fed does more direct purchasing of financial assets than its European counterpart. The collateral used by the ECB is typically high quality public and private sector debt.\nAll lending to credit institutions must be collateralised as required by Article 18 of the Statute of the ESCB.\nThe criteria for determining \"high quality\" for public debt have been preconditions for membership in the European Union: total debt must not be too large in relation to gross domestic product, for example, and deficits in any given year must not become too large. Though these criteria are fairly simple, a number of accounting techniques may hide the underlying reality of fiscal solvency\u2014or the lack of same.\nDifference with US Federal Reserve.\nIn the United States Federal Reserve Bank, the Federal Reserve buys assets: typically, bonds issued by the Federal government. There is no limit on the bonds that it can buy and one of the tools at its disposal in a financial crisis is to take such extraordinary measures as the purchase of large amounts of assets such as commercial paper. The purpose of such operations is to ensure that adequate liquidity is available for functioning of the financial system.\nThe Eurosystem, on the other hand, uses collateralized lending as a default instrument. There are about 1,500 eligible banks which may bid for short-term repo contracts. The difference is that banks in effect borrow cash from the ECB and must pay it back; the short durations allow interest rates to be adjusted continually. When the repo notes come due the participating banks bid again. An increase in the quantity of notes offered at auction allows an increase in liquidity in the economy. A decrease has the contrary effect. The contracts are carried on the asset side of the European Central Bank's balance sheet and the resulting deposits in member banks are carried as a liability. In layman terms, the liability of the central bank is money, and an increase in deposits in member banks, carried as a liability by the central bank, means that more money has been put into the economy.\nTo qualify for participation in the auctions, banks must be able to offer proof of appropriate collateral in the form of loans to other entities. These can be the public debt of member states, but a fairly wide range of private banking securities are also accepted. The fairly stringent membership requirements for the European Union, especially with regard to sovereign debt as a percentage of each member state's gross domestic product, are designed to ensure that assets offered to the bank as collateral are, at least in theory, all equally good, and all equally protected from the risk of inflation.\nOrganization.\nThe ECB has four decision-making bodies, that take all the decisions with the objective of fulfilling the ECB's mandate:\nDecision-making bodies.\nExecutive Board.\nThe Executive Board is responsible for the implementation of monetary policy (defined by the Governing Council) and the day-to-day running of the bank. It can issue decisions to national central banks and may also exercise powers delegated to it by the Governing Council. Executive Board members are assigned a portfolio of responsibilities by the President of the ECB. The Executive Board normally meets every Tuesday.\nIt is composed of the President of the Bank (currently Christine Lagarde), the Vice-President (currently Luis de Guindos) and four other members. They are all appointed by the European Council for non-renewable terms of eight years. Member of the Executive Board of the ECB are appointed \"from among persons of recognised standing and professional experience in monetary or banking matters by common accord of the governments of the Member States at the level of Heads of State or Government, on a recommendation from the Council, after it has consulted the European Parliament and the Governing Council of the ECB\".\nJos\u00e9 Manuel Gonz\u00e1lez-P\u00e1ramo, a Spanish member of the Executive Board since June 2004, was due to leave the board in early June 2012, but no replacement had been named as of late May. The Spanish had nominated Barcelona-born Antonio S\u00e1inz de Vicu\u00f1a \u2013 an ECB veteran who heads its legal department \u2013 as Gonz\u00e1lez-P\u00e1ramo's replacement as early as January 2012, but alternatives from Luxembourg, Finland, and Slovenia were put forward and no decision made by May. After a long political battle and delays due to the European Parliament's protest over the lack of gender balance at the ECB, Luxembourg's Yves Mersch was appointed as Gonz\u00e1lez-P\u00e1ramo's replacement.\nIn December 2020, Frank Elderson succeeded to Yves Mersch at the ECB's board.\nGoverning Council.\nThe Governing Council is the main decision-making body of the Eurosystem. It comprises the members of the Executive Board (six in total) and the governors of the National Central Banks of the euro area countries (19 as of 2015).\nSince January 2015, the ECB has published on its website a summary of the Governing Council deliberations (\"accounts\"). These publications came as a partial response to recurring criticism against the ECB's opacity. However, in contrast to other central banks, the ECB still does not disclose individual voting records of the governors seating in its Council.\nGeneral Council.\nThe General Council is a body dealing with transitional issues of euro adoption, for example, fixing the exchange rates of currencies being replaced by the euro (continuing the tasks of the former EMI). It will continue to exist until all EU member states adopt the euro, at which point it will be dissolved. It is composed of the President and vice-president together with the governors of all of the EU's national central banks.\nSupervisory Board.\nThe Supervisory Board meets twice a month to discuss, plan and carry out the ECB's supervisory tasks. It proposes draft decisions to the Governing Council under the non-objection procedure. It is composed of Chair (appointed for a non-renewable term of five years), Vice-Chair (chosen from among the members of the ECB's Executive Board) four ECB representatives and representatives of national supervisors. If the national supervisory authority designated by a Member State is not a national central bank (NCB), the representative of the competent authority can be accompanied by a representative from their NCB. In such cases, the representatives are together considered as one member for the purposes of the voting procedure.\nIt also includes the Steering Committee, which supports the activities of the Supervisory Board and prepares the Board's meetings. It is composed by the Chair of the Supervisory Board, Vice-Chair of the Supervisory Board, one ECB representative and five representatives of national supervisors. The five representatives of national supervisors are appointed by the Supervisory Board for one year based on a rotation system that ensures a fair representation of countries.\nCapital subscription.\nThe ECB is governed by European law directly, but its set-up resembles that of a corporation in the sense that the ECB has shareholders and stock capital. Its initial capital was supposed to be \u20ac5 billion and the initial capital allocation key was determined in 1998 on the basis of the member states' populations and GDP, but the key is adjustable. The euro area NCBs were required to pay their respective subscriptions to the ECB's capital in full. The NCBs of the non-participating countries have had to pay 7% of their respective subscriptions to the ECB's capital as a contribution to the operational costs of the ECB. As a result, the ECB was endowed with an initial capital of just under \u20ac4\u00a0billion. The capital is held by the national central banks of the member states as shareholders. Shares in the ECB are not transferable and cannot be used as collateral. The NCBs are the sole subscribers to and holders of the capital of the ECB.\nToday, ECB capital is about \u20ac11 billion, which is held by the national central banks of the member states as shareholders. The NCBs\u2019 shares in this capital are calculated using a capital key which reflects the respective member's share in the total population and gross domestic product of the EU. The ECB adjusts the shares every five years and whenever the number of contributing NCBs changes. The adjustment is made on the basis of data provided by the European Commission.\nAll national central banks (NCBs) that own a share of the ECB capital stock as of 1 February 2020 are listed below. Non-Euro area NCBs are required to pay up only a very small percentage of their subscribed capital, which accounts for the different magnitudes of Euro area and Non-Euro area total paid-up capital.\nReserves.\nIn addition to capital subscriptions, the NCBs of the member states participating in the euro area provided the ECB with foreign reserve assets equivalent to around \u20ac40\u00a0billion. The contributions of each NCB is in proportion to its share in the ECB's subscribed capital, while in return each NCB is credited by the ECB with a claim in euro equivalent to its contribution. 15% of the contributions was made in gold, and the remaining 85% in US dollars and UK pound Sterlings.\nLanguages.\nThe internal working language of the ECB is generally English, and press conferences are usually held in English. External communications are handled flexibly: English is preferred (though not exclusively) for communication within the ESCB (i.e. with other central banks) and with financial markets; communication with other national bodies and with EU citizens is normally in their respective language, but the ECB website is predominantly English; official documents such as the Annual Report are in the official languages of the EU.\nIndependence.\nThe European Central Bank (and by extension, the Eurosystem) is often considered as the \"most independent central bank in the world\". In general terms, this means that the Eurosystem tasks and policies can be discussed, designed, decided and implemented in full autonomy, without pressure or need for instructions from any external body. The main justification for the ECB's independence is that such an institutional setup assists the maintenance of price stability.\nIn practice, the ECB's independence is pinned by four key principles:\nDemocratic accountability.\nIn return to its high degree of independence and discretion, the ECB is accountable to the European Parliament (and to a lesser extent to the European Court of Auditors, the European Ombudsman and the Court of Justice of the EU (CJEU)). Although no interinstitutional agreement exists between the European Parliament and the ECB to regulate the ECB's accountability framework, it has been inspired by a resolution of the European Parliament adopted in 1998 which was then informally agreed with the ECB and incorporated into the Parliament's rule of procedure.\nThe accountability framework involves five main mechanisms:\nIn 2013, an interinstitutional agreement was reached between the ECB and the European Parliament in the context of the establishment of the ECB's Banking Supervision. This agreement sets broader powers to the European Parliament than the established practice on the monetary policy side of the ECB's activities. For example, under the agreement, the Parliament can veto the appointment of the Chair and Vice-Chair of the ECB's supervisory board, and may approve removals if requested by the ECB.\nTransparency.\nIn addition to its independence, the ECB is subject to limited transparency obligations in contrast to EU Institutions standards and other major central banks. Indeed, as pointed out by Transparency International, \"The Treaties establish transparency and openness as principles of the EU and its institutions. They do, however, grant the ECB a partial exemption from these principles. According to Art. 15(3) TFEU, the ECB is bound by the EU\u2019s transparency principles \u201conly when exercising [its] administrative tasks\u201d (the exemption \u2013 which leaves the term \u201cadministrative tasks\u201d undefined \u2013 equally applies to the Court of Justice of the European Union and to the European Investment Bank).\"\nIn practice, there are several concrete examples where the ECB is less transparent than other institutions:\nLocation.\nThe bank is based in Ostend (East End), Frankfurt am Main. The city is the largest financial centre in the Eurozone and the bank's location in it is fixed by the Amsterdam Treaty. The bank moved to a new purpose-built headquarters in 2014, designed by a Vienna-based architectural office, Coop Himmelbau. The building is approximately tall and is to be accompanied by other secondary buildings on a landscaped site on the site of the former wholesale market in the eastern part of Frankfurt am Main. The main construction on a 120,000 m\u00b2 total site area began in October 2008, and it was expected that the building would become an architectural symbol for Europe. While it was designed to accommodate double the number of staff who operated in the former Eurotower, that building has been retained by the ECB, owing to more space being required since it took responsibility for banking supervision.\nDebates surrounding the ECB.\nDebates on ECB independence.\nThe arguments in favour of this independence.\nThe debate on the independence of the ECB has its origins in the preparatory stages of the construction of the EMU. The German government agreed to go ahead if certain crucial guarantees were respected, such as a European Central Bank independent of national governments and shielded from political pressure along the lines of the German central bank. The French government, for its part, feared that this independence would mean that politicians would no longer have any room for manoeuvre in the process. A compromise was then reached by establishing a regular dialogue between the ECB and the Council of Finance Ministers of the euro area, the Eurogroupe.\nThe founding model of the ECB, as advocated by the German government, is explained in an article published in 1983 by two economists, Robert Barro and David Gordon. According to them, the best way to combat the inflationary bias is for central banks to be credible. This credibility would be all the more important if the central banks were independent, so that decisions are not \"contaminated\" by politics. For economists, central banks should then have only one objective: to maintain a low inflation rate. For this system to work, it would then be necessary to assume that a monetary policy conducted in this way would have no effect on the real economy.\nSince that publication, it has often been accepted that an independent institution to manage monetary policy can help to limit chronic inflation. This model was generalised in various variations at the national levels before being adopted at the European level.\nThe original European project, as intended by the founding fathers, did not attract the passions and favours of the European peoples. And rightly so. This project is thought out openly on purely technical subjects that are of little or no interest to public opinion. As a result, the founding fathers hoped that economic and ethical rationality could be exercised in all its fullness without political, ideological or historical obstacles. It is this rational messianism that the radical left has always fought against. Moreover, this project is presented as heir to the Enlightenment and Reason, the reign of human rights, a modernist and voluntarist project stemming from the tradition of the 18th century. In this order of things, the independence of the ECB allowing a rational management of monetary questionnaires outside the political game is a blessing for the supporters of this doctrine. It is difficult, if not impossible, for them to conceive of a democratisation of the ECB by attaching to it a share of political control in its operation without distorting the \"European Project\", this bible, this unique political reason which has guided professionals in Europe for generations.\nIn this same idea, we can find in the \"European Project\" the Kantian tradition with a model of successful subordination of political power to the law, leading to what Habermas calls \"the civilising force of democratic legalification\". This Habermatian theory leads us once again to isolate supranational institutions from political games. Indeed, for Habermas, European politics, like national politics for that matter, finds it impossible to define ONE uniform people, but at best a pluriform people in constant opposition, each component against the other. For this author, popular sovereignty is illusory, as is the concept of \"government by the people\". He prefers the search for a broad consensus legitimized by the majority of democratically elected representatives of the people. This explains his attachment to deflecting the influence of popular emotions from technical institutions, such as the ECB.\nThe arguments against too much independence.\nAn independence that would be the source of a democratic deficit..\nDemystify the independence of central bankers :According to Christopher Adolph (2009), the alleged neutrality of central bankers is only a legal fa\u00e7ade and not an indisputable fact . To achieve this, the author analyses the professional careers of central bankers and mirrors them with their respective monetary decision-making. To explain the results of his analysis, he utilizes he uses the \"\"principal-agent\" theory. To explain that in order to create a new entity, one needs a delegator or \"principal\" (in this case the heads of state or government of the euro area) and a delegate or \"agent\" (in this case the ECB). In his illustration, he describes the financial community as a \"shadow principale\"\" \u00a0which influences the choice of central bankers thus indicating that the central banks indeed act as interfaces between the financial world and the States. It is therefore not surprising, still according to the author, to regain their influence and preferences in the appointment of central bankers, presumed conservative, neutral and impartial according to the model of the Independent Central Bank (ICB), which eliminates this famous \"temporal inconsistency\". Central bankers had a professional life before joining the central bank and their careers will most likely continue after their tenure. They are ultimately human beings. Therefore, for the author, central bankers have interests of their own, based on their past careers and their expectations after joining the ECB, and try to send messages to their future potential employers.\nThe crisis: an opportunity to impose its will and extend its powers :\n\u2013 \"Its participation in the troika\" : Thanks to its three factors which explains its independence, the ECB took advantage of this crisis to implement, through its participation in the troika, the famous structural reforms in the Member States aimed at making, more flexible the various markets, particularly the labour market, which are still considered too rigid under the ordoliberal concept.\n- \"Macro-prudential supervision\" : At the same time, taking advantage of the reform of the financial supervision system, the Frankfurt Bank has acquired new responsibilities, such as macro-prudential supervision, in other words, supervision of the provision of financial services.\n-\"Take liberties with its mandate to save the Euro\" : Paradoxically, the crisis undermined the ECB's ordoliberal discourse \"because some of its instruments, which it had to implement, deviated significantly from its principles. It then interpreted the paradigm with enough flexibly to adapt its original reputation to these new economic conditions. It was forced to do so as a last resort to save its one and only raison d'\u00eatre: the euro. This Independent was thus obliged to be pragmatic by departing from the spirit of its statutes, which is unacceptable to the hardest supporters of ordoliberalism, which will lead to the resignation of the two German leaders present within the ECB: the governor of the Bundesbank, Jens WEIDMANN and the member of the Executive Board of the ECB, J\u00fcrgen STARK.\n\u2013 \"Regulation of the financial system\" :\u00a0 The delegation of this new function to the ECB was carried out with great simplicity and with the consent of European leaders, because neither the Commission nor the Member States really wanted to obtain the monitoring of financial abuses throughout the area. In other words, in the event of a new financial crisis, the ECB would be the perfect scapegoat.\n- \"Capturing exchange rate policy\" : The event that will most mark the definitive politicization of the ECB is, of course, the operation launched in January 2015: the quantitative easing (QE) operation. Indeed, the Euro is an overvalued currency on the world markets against the dollar and the Euro zone is at risk of deflation. In addition, Member States find themselves heavily indebted, partly due to the rescue of their national banks. The ECB, as the guardian of the stability of the euro zone, is deciding to gradually buy back more than EUR 1 100 billion Member States' public debt. In this way, money is injected back into the economy, the euro depreciates significantly, prices rise, the risk of deflation is removed, and Member States reduce their debts. However, the ECB has just given itself the right to direct the exchange rate policy of the euro zone without this being granted by the Treaties or with the approval of European leaders, and without public opinion or the public arena being aware of this.\nIn conclusion, for those in favour of a framework for ECB independence, there is a clear concentration of powers. In the light of these facts, it is clear that the ECB is no longer the simple guardian of monetary stability in the euro area, but has become, over the course of the crisis, a \"multi-competent economic player, at ease in this role that no one, especially not the agnostic governments of the euro Member States, seems to have the idea of challenging\". This new political super-actor, having captured many spheres of competence and a very strong influence in the economic field in the broad sense (economy, finance, budget...).\u00a0 This new political super-actor can no longer act alone and refuse a counter-power, consubstantial to our liberal democracies. Indeed, the status of independence which the ECB enjoys by essence should not exempt it from a real responsibility regarding the democratic process.\nThe arguments in favour of a counter power.\nIn the aftermath of the euro area crisis, several proposals for a countervailing power were put forward, to deal with criticisms of a democratic deficit. For the German economist German Issing (2001) the ECB as a democratic responsibility and should be more transparent. According to him, this transparence could bring several advantages as the improvement of the efficiency and of the credibility by giving to the public adequate information. Others think that the ECB should have a closer relationship with the European Parliament which could play a major role in the evaluation of the democratic responsibility of the ECB. The development of new institutions or the creation of a minister is another solution proposed:\nA minister for the Eurozone ?\nThe idea of a eurozone finance minister is regularly raised and supported by certain political figures, including Emmanuel Macron, as well as German Chancellor Angela Merkel, former President of the ECB Jean-Claude Trichet and former European Commissioner Pierre Moscovici. For the latter, this position would bring \"\"more democratic legitimacy\" and \"more efficiency\"\" to European politics. In his view, it is a question of merging the powers of Commissioner for the Economy and Finance with those of the President of the Eurogroup.\nThe main task of this minister would be to \"represent a strong political authority protecting the economic and budgetary interests of the euro area as a whole, and not the interests of individual Member States\". According to the Jacques Delors Institute, its competences could be as follows:\nFor Jean-Claude Trichet, this minister could also rely on the Eurogroup working group for the preparation and follow-up of meetings in euro zone format, and on the Economic and Financial Committee for meetings concerning all Member States. He would also have under his authority a General Secretariat of the Treasury of the euro area, whose tasks would be determined by the objectives of the budgetary union currently being set up \nThis proposal was nevertheless rejected in 2017 by the Eurogroup, its President, Jeroen Dijsselbloem, spoke of the importance of this institution in relation to the European Commission.\nTowards democratic institutions ?\nThe absence of democratic institutions such as a Parliament or a real government is a regular criticism of the ECB in its management of the euro area, and many proposals have been made in this respect, particularly after the economic crisis, which would have shown the need to improve the governance of the euro area. For Mo\u00efse Sidiropoulos, a professor in economy: \u201cThe crisis in the euro zone came as no surprise, because the euro remains an unfinished currency, a stateless currency with a fragile political legitimacy\u201d.\nFrench economist Thomas Piketty wrote on his blog in 2017 that it was essential to equip the euro zone with democratic institutions. An economic government could for example enable it to have a common budget, common taxes and borrowing and investment capacities. Such a government would then make the euro area more democratic and transparent by avoiding the opacity of a council such as the Eurogroup.\nNevertheless, according to him \"there is no point in talking about a government of the euro zone if we do not say to which democratic body this government will be accountable\", a real parliament of the euro zone to which a finance minister would be accountable seems to be the real priority for the economist, who also denounces the lack of action in this area.\nThe creation of a sub-committee within the current European Parliament was also mentioned, on the model of the Eurogroup, which is currently an under-formation of the ECOFIN Committee. This would require a simple amendment to the rules of procedure and would avoid a competitive situation between two separate parliamentary assemblies. The former President of the European Commission had, moreover, stated on this subject that he had \"no sympathy for the idea of a specific Eurozone Parliament\"."}
{"id": "9476", "revid": "1267919", "url": "https://en.wikipedia.org/wiki?curid=9476", "title": "Electron", "text": "The electron is a subatomic particle, symbol or , whose electric charge is negative one elementary charge. Electrons belong to the first generation of the lepton particle family, and are generally thought to be elementary particles because they have no known components or substructure. The electron has a mass that is approximately 1/1836 that of the proton. Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value, expressed in units of the reduced Planck constant, \"\u0127\". Being fermions, no two electrons can occupy the same quantum state, in accordance with the Pauli exclusion principle. Like all elementary particles, electrons exhibit properties of both particles and waves: they can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a longer de Broglie wavelength for a given energy.\nElectrons play an essential role in numerous physical phenomena, such as electricity, magnetism, chemistry and thermal conductivity, and they also participate in gravitational, electromagnetic and weak interactions. Since an electron has charge, it has a surrounding electric field, and if that electron is moving relative to an observer, said observer will observe it to generate a magnetic field. Electromagnetic fields produced from other sources will affect the motion of an electron according to the Lorentz force law. Electrons radiate or absorb energy in the form of photons when they are accelerated. Laboratory instruments are capable of trapping individual electrons as well as electron plasma by the use of electromagnetic fields. Special telescopes can detect electron plasma in outer space. Electrons are involved in many applications such as electronics, welding, cathode ray tubes, electron microscopes, radiation therapy, lasers, gaseous ionization detectors and particle accelerators.\nInteractions involving electrons with other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between the positive protons within atomic nuclei and the negative electrons without, allows the composition of the two known as atoms. Ionization or differences in the proportions of negative electrons versus positive nuclei changes the binding energy of an atomic system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding. In 1838, British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms. Irish physicist George Johnstone Stoney named this charge 'electron' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897 during the cathode ray tube experiment. Electrons can also participate in nuclear reactions, such as nucleosynthesis in stars, where they are known as beta particles. Electrons can be created through beta decay of radioactive isotopes and in high-energy collisions, for instance when cosmic rays enter the atmosphere. The antiparticle of the electron is called the positron; it is identical to the electron except that it carries electrical charge of the opposite sign. When an electron collides with a positron, both particles can be annihilated, producing gamma ray photons.\nHistory.\nDiscovery of effect of electric force.\nThe ancient Greeks noticed that amber attracted small objects when rubbed with fur. Along with lightning, this phenomenon is one of humanity's earliest recorded experiences with electricity. In his 1600 treatise , the English scientist William Gilbert coined the New Latin term , to refer to those substances with property similar to that of amber which attract small objects after being rubbed. Both \"electric\" and \"electricity\" are derived from the Latin ' (also the root of the alloy of the same name), which came from the Greek word for amber, (').\nDiscovery of two kinds of charges.\nIn the early 1700s, French chemist Charles Fran\u00e7ois du Fay found that if a charged gold-leaf is repulsed by glass rubbed with silk, then the same charged gold-leaf is attracted by amber rubbed with wool. From this and other results of similar types of experiments, du Fay concluded that electricity consists of two electrical fluids, \"vitreous\" fluid from glass rubbed with silk and \"resinous\" fluid from amber rubbed with wool. These two fluids can neutralize each other when combined. American scientist Ebenezer Kinnersley later also independently reached the same conclusion. A decade later Benjamin Franklin proposed that electricity was not from different types of electrical fluid, but a single electrical fluid showing an excess (+) or deficit (\u2212). He gave them the modern charge nomenclature of positive and negative respectively. Franklin thought of the charge carrier as being positive, but he did not correctly identify which situation was a surplus of the charge carrier, and which situation was a deficit.\nBetween 1838 and 1851, British natural philosopher Richard Laming developed the idea that an atom is composed of a core of matter surrounded by subatomic particles that had unit electric charges. Beginning in 1846, German physicist William Weber theorized that electricity was composed of positively and negatively charged fluids, and their interaction was governed by the inverse square law. After studying the phenomenon of electrolysis in 1874, Irish physicist George Johnstone Stoney suggested that there existed a \"single definite quantity of electricity\", the charge of a monovalent ion. He was able to estimate the value of this elementary charge \"e\" by means of Faraday's laws of electrolysis. However, Stoney believed these charges were permanently attached to atoms and could not be removed. In 1881, German physicist Hermann von Helmholtz argued that both positive and negative charges were divided into elementary parts, each of which \"behaves like atoms of electricity\".\nStoney initially coined the term \"electrolion\" in 1881. Ten years later, he switched to \"electron\" to describe these elementary charges, writing in 1894: \"... an estimate was made of the actual amount of this most remarkable fundamental unit of electricity, for which I have since ventured to suggest the name \"electron\"\". A 1906 proposal to change to \"electrion\" failed because Hendrik Lorentz preferred to keep \"electron\". The word \"electron\" is a combination of the words \"electric\" and \"ion\". The suffix -\"on\" which is now used to designate other subatomic particles, such as a proton or neutron, is in turn derived from electron.\nDiscovery of free electrons outside matter.\nWhile studying electrical conductivity in rarefied gases in 1859, the German physicist Julius Pl\u00fccker observed that the phosphorescent light, which was caused by radiation emitted from the cathode, appeared at the tube wall near the cathode, and the region of the phosphorescent light could be moved by application of a magnetic field. In 1869, Plucker's student Johann Wilhelm Hittorf found that a solid body placed in between the cathode and the phosphorescence would cast a shadow upon the phosphorescent region of the tube. Hittorf inferred that there are straight rays emitted from the cathode and that the phosphorescence was caused by the rays striking the tube walls. In 1876, the German physicist Eugen Goldstein showed that the rays were emitted perpendicular to the cathode surface, which distinguished between the rays that were emitted from the cathode and the incandescent light. Goldstein dubbed the rays cathode rays. Decades of experimental and theoretical research involving cathode rays were important in J. J. Thomson's eventual discovery of electrons. \nDuring the 1870s, the English chemist and physicist Sir William Crookes developed the first cathode ray tube to have a high vacuum inside. He then showed in 1874 that the cathode rays can turn a small paddle wheel when placed in their path. Therefore, he concluded that the rays carried momentum. Furthermore, by applying a magnetic field, he was able to deflect the rays, thereby demonstrating that the beam behaved as though it were negatively charged. In 1879, he proposed that these properties could be explained by regarding cathode rays as composed of negatively charged gaseous molecules in fourth state of matter in which the mean free path of the particles is so long that collisions may be ignored.\nThe German-born British physicist Arthur Schuster expanded upon Crookes's experiments by placing metal plates parallel to the cathode rays and applying an electric potential between the plates. The field deflected the rays toward the positively charged plate, providing further evidence that the rays carried negative charge. By measuring the amount of deflection for a given level of current, in 1890 Schuster was able to estimate the charge-to-mass ratio of the ray components. However, this produced a value that was more than a thousand times greater than what was expected, so little credence was given to his calculations at the time.\nIn 1892 Hendrik Lorentz suggested that the mass of these particles (electrons) could be a consequence of their electric charge.\nWhile studying naturally fluorescing minerals in 1896, the French physicist Henri Becquerel discovered that they emitted radiation without any exposure to an external energy source. These radioactive materials became the subject of much interest by scientists, including the New Zealand physicist Ernest Rutherford who discovered they emitted particles. He designated these particles alpha and beta, on the basis of their ability to penetrate matter. In 1900, Becquerel showed that the beta rays emitted by radium could be deflected by an electric field, and that their mass-to-charge ratio was the same as for cathode rays. This evidence strengthened the view that electrons existed as components of atoms.\nIn 1897, the British physicist J. J. Thomson, with his colleagues John S. Townsend and H. A. Wilson, performed experiments indicating that cathode rays really were unique particles, rather than waves, atoms or molecules as was believed earlier. Thomson made good estimates of both the charge \"e\" and the mass \"m\", finding that cathode ray particles, which he called \"corpuscles\", had perhaps one thousandth of the mass of the least massive ion known: hydrogen. He showed that their charge-to-mass ratio, \"e\"/\"m\", was independent of cathode material. He further showed that the negatively charged particles produced by radioactive materials, by heated materials and by illuminated materials were universal. The name electron was adopted for these particles by the scientific community, mainly due to the advocation by G. F. FitzGerald, J. Larmor, and H. A. Lorentz.\nThe electron's charge was more carefully measured by the American physicists Robert Millikan and Harvey Fletcher in their oil-drop experiment of 1909, the results of which were published in 1911. This experiment used an electric field to prevent a charged droplet of oil from falling as a result of gravity. This device could measure the electric charge from as few as 1\u2013150 ions with an error margin of less than 0.3%. Comparable experiments had been done earlier by Thomson's team, using clouds of charged water droplets generated by electrolysis, and in 1911 by Abram Ioffe, who independently obtained the same result as Millikan using charged microparticles of metals, then published his results in 1913. However, oil drops were more stable than water drops because of their slower evaporation rate, and thus more suited to precise experimentation over longer periods of time.\nAround the beginning of the twentieth century, it was found that under certain conditions a fast-moving charged particle caused a condensation of supersaturated water vapor along its path. In 1911, Charles Wilson used this principle to devise his cloud chamber so he could photograph the tracks of charged particles, such as fast-moving electrons.\nAtomic theory.\nBy 1914, experiments by physicists Ernest Rutherford, Henry Moseley, James Franck and Gustav Hertz had largely established the structure of an atom as a dense nucleus of positive charge surrounded by lower-mass electrons. In 1913, Danish physicist Niels Bohr postulated that electrons resided in quantized energy states, with their energies determined by the angular momentum of the electron's orbit about the nucleus. The electrons could move between those states, or orbits, by the emission or absorption of photons of specific frequencies. By means of these quantized orbits, he accurately explained the spectral lines of the hydrogen atom. However, Bohr's model failed to account for the relative intensities of the spectral lines and it was unsuccessful in explaining the spectra of more complex atoms.\nChemical bonds between atoms were explained by Gilbert Newton Lewis, who in 1916 proposed that a covalent bond between two atoms is maintained by a pair of electrons shared between them. Later, in 1927, Walter Heitler and Fritz London gave the full explanation of the electron-pair formation and chemical bonding in terms of quantum mechanics. In 1919, the American chemist Irving Langmuir elaborated on the Lewis's static model of the atom and suggested that all electrons were distributed in successive \"concentric (nearly) spherical shells, all of equal thickness\". In turn, he divided the shells into a number of cells each of which contained one pair of electrons. With this model Langmuir was able to qualitatively explain the chemical properties of all elements in the periodic table, which were known to largely repeat themselves according to the periodic law.\nIn 1924, Austrian physicist Wolfgang Pauli observed that the shell-like structure of the atom could be explained by a set of four parameters that defined every quantum energy state, as long as each state was occupied by no more than a single electron. This prohibition against more than one electron occupying the same quantum energy state became known as the Pauli exclusion principle. The physical mechanism to explain the fourth parameter, which had two distinct possible values, was provided by the Dutch physicists Samuel Goudsmit and George Uhlenbeck. In 1925, they suggested that an electron, in addition to the angular momentum of its orbit, possesses an intrinsic angular momentum and magnetic dipole moment. This is analogous to the rotation of the Earth on its axis as it orbits the Sun. The intrinsic angular momentum became known as spin, and explained the previously mysterious splitting of spectral lines observed with a high-resolution spectrograph; this phenomenon is known as fine structure splitting.\nQuantum mechanics.\nIn his 1924 dissertation \"\" (Research on Quantum Theory), French physicist Louis de Broglie hypothesized that all matter can be represented as a de Broglie wave in the manner of light. That is, under the appropriate conditions, electrons and other matter would show properties of either particles or waves. The corpuscular properties of a particle are demonstrated when it is shown to have a localized position in space along its trajectory at any given moment. The wave-like nature of light is displayed, for example, when a beam of light is passed through parallel slits thereby creating interference patterns. In 1927, George Paget Thomson discovered the interference effect was produced when a beam of electrons was passed through thin metal foils and by American physicists Clinton Davisson and Lester Germer by the reflection of electrons from a crystal of nickel.\nDe Broglie's prediction of a wave nature for electrons led Erwin Schr\u00f6dinger to postulate a wave equation for electrons moving under the influence of the nucleus in the atom. In 1926, this equation, the Schr\u00f6dinger equation, successfully described how electron waves propagated. Rather than yielding a solution that determined the location of an electron over time, this wave equation also could be used to predict the probability of finding an electron near a position, especially a position near where the electron was bound in space, for which the electron wave equations did not change in time. This approach led to a second formulation of quantum mechanics (the first by Heisenberg in 1925), and solutions of Schr\u00f6dinger's equation, like Heisenberg's, provided derivations of the energy states of an electron in a hydrogen atom that were equivalent to those that had been derived first by Bohr in 1913, and that were known to reproduce the hydrogen spectrum. Once spin and the interaction between multiple electrons were describable, quantum mechanics made it possible to predict the configuration of electrons in atoms with atomic numbers greater than hydrogen.\nIn 1928, building on Wolfgang Pauli's work, Paul Dirac produced a model of the electron\u00a0\u2013 the Dirac equation, consistent with relativity theory, by applying relativistic and symmetry considerations to the hamiltonian formulation of the quantum mechanics of the electro-magnetic field. In order to resolve some problems within his relativistic equation, Dirac developed in 1930 a model of the vacuum as an infinite sea of particles with negative energy, later dubbed the Dirac sea. This led him to predict the existence of a positron, the antimatter counterpart of the electron. This particle was discovered in 1932 by Carl Anderson, who proposed calling standard electrons \"negatons\" and using \"electron\" as a generic term to describe both the positively and negatively charged variants.\nIn 1947, Willis Lamb, working in collaboration with graduate student Robert Retherford, found that certain quantum states of the hydrogen atom, which should have the same energy, were shifted in relation to each other; the difference came to be called the Lamb shift. About the same time, Polykarp Kusch, working with Henry M. Foley, discovered the magnetic moment of the electron is slightly larger than predicted by Dirac's theory. This small difference was later called anomalous magnetic dipole moment of the electron. This difference was later explained by the theory of quantum electrodynamics, developed by Sin-Itiro Tomonaga, Julian Schwinger and\nRichard Feynman in the late 1940s.\nParticle accelerators.\nWith the development of the particle accelerator during the first half of the twentieth century, physicists began to delve deeper into the properties of subatomic particles. The first successful attempt to accelerate electrons using electromagnetic induction was made in 1942 by Donald Kerst. His initial betatron reached energies of 2.3\u00a0MeV, while subsequent betatrons achieved 300\u00a0MeV. In 1947, synchrotron radiation was discovered with a 70\u00a0MeV electron synchrotron at General Electric. This radiation was caused by the acceleration of electrons through a magnetic field as they moved near the speed of light.\nWith a beam energy of 1.5\u00a0GeV, the first high-energy\nparticle collider was ADONE, which began operations in 1968. This device accelerated electrons and positrons in opposite directions, effectively doubling the energy of their collision when compared to striking a static target with an electron. The Large Electron\u2013Positron Collider (LEP) at CERN, which was operational from 1989 to 2000, achieved collision energies of 209\u00a0GeV and made important measurements for the Standard Model of particle physics.\nConfinement of individual electrons.\nIndividual electrons can now be easily confined in ultra small (, ) CMOS transistors operated at cryogenic temperature over a range of \u2212269\u00a0\u00b0C (4\u00a0K) to about \u2212258\u00a0\u00b0C (15\u00a0K). The electron wavefunction spreads in a semiconductor lattice and negligibly interacts with the valence band electrons, so it can be treated in the single particle formalism, by replacing its mass with the effective mass tensor.\nCharacteristics.\nClassification.\nIn the Standard Model of particle physics, electrons belong to the group of subatomic particles called leptons, which are believed to be fundamental or elementary particles. Electrons have the lowest mass of any charged lepton (or electrically charged particle of any type) and belong to the first-generation of fundamental particles. The second and third generation contain charged leptons, the muon and the tau, which are identical to the electron in charge, spin and interactions, but are more massive. Leptons differ from the other basic constituent of matter, the quarks, by their lack of strong interaction. All members of the lepton group are fermions, because they all have half-odd integer spin; the electron has spin .\nFundamental properties.\nThe invariant mass of an electron is approximately \u00a0kilograms, or \u00a0atomic mass units. On the basis of Einstein's principle of mass\u2013energy equivalence, this mass corresponds to a rest energy of 0.511\u00a0MeV. The ratio between the mass of a proton and that of an electron is about 1836. Astronomical measurements show that the proton-to-electron mass ratio has held the same value, as is predicted by the Standard Model, for at least half the age of the universe.\nElectrons have an electric charge of coulombs, which is used as a standard unit of charge for subatomic particles, and is also called the elementary charge. Within the limits of experimental accuracy, the electron charge is identical to the charge of a proton, but with the opposite sign. As the symbol \"e\" is used for the elementary charge, the electron is commonly symbolized by , where the minus sign indicates the negative charge. The positron is symbolized by because it has the same properties as the electron but with a positive rather than negative charge.\nThe electron has an intrinsic angular momentum or spin of . This property is usually stated by referring to the electron as a spin- particle. For such particles the spin magnitude is , while the result of the measurement of a projection of the spin on any axis can only be \u00b1. In addition to spin, the electron has an intrinsic magnetic moment along its spin axis. It is approximately equal to one Bohr magneton,=\\frac{e\\hbar}{2m_{\\mathrm{e}}}.&lt;/math&gt;}} which is a physical constant equal to . The orientation of the spin with respect to the momentum of the electron defines the property of elementary particles known as helicity.\nThe electron has no known substructure. Nevertheless, in condensed matter physics, spin\u2013charge separation can occur in some materials. In such cases, electrons 'split' into three independent particles, the spinon, the orbiton and the holon (or chargon). The electron can always be theoretically considered as a bound state of the three, with the spinon carrying the spin of the electron, the orbiton carrying the orbital degree of freedom and the chargon carrying the charge, but in certain conditions they can behave as independent quasiparticles.\nThe issue of the radius of the electron is a challenging problem of modern theoretical physics. The admission of the hypothesis of a finite radius of the electron is incompatible to the premises of the theory of relativity. On the other hand, a point-like electron (zero radius) generates serious mathematical difficulties due to the self-energy of the electron tending to infinity. Observation of a single electron in a Penning trap suggests the upper limit of the particle's radius to be 10\u221222\u00a0meters.\nThe upper bound of the electron radius of 10\u221218\u00a0meters can be derived using the uncertainty relation in energy. There \"is\" also a physical constant called the \"classical electron radius\", with the much larger value of , greater than the radius of the proton. However, the terminology comes from a simplistic calculation that ignores the effects of quantum mechanics; in reality, the so-called classical electron radius has little to do with the true fundamental structure of the electron.\nThere are elementary particles that spontaneously decay into less massive particles. An example is the muon, with a mean lifetime of \u00a0seconds, which decays into an electron, a muon neutrino and an electron antineutrino. The electron, on the other hand, is thought to be stable on theoretical grounds: the electron is the least massive particle with non-zero electric charge, so its decay would violate charge conservation. The experimental lower bound for the electron's mean lifetime is years, at a 90% confidence level.\nQuantum properties.\nAs with all particles, electrons can act as waves. This is called the wave\u2013particle duality and can be demonstrated using the double-slit experiment.\nThe wave-like nature of the electron allows it to pass through two parallel slits simultaneously, rather than just one slit as would be the case for a classical particle. In quantum mechanics, the wave-like property of one particle can be described mathematically as a complex-valued function, the wave function, commonly denoted by the Greek letter psi (\"\u03c8\"). When the absolute value of this function is squared, it gives the probability that a particle will be observed near a location\u2014a probability density.\nElectrons are identical particles because they cannot be distinguished from each other by their intrinsic physical properties. In quantum mechanics, this means that a pair of interacting electrons must be able to swap positions without an observable change to the state of the system. The wave function of fermions, including electrons, is antisymmetric, meaning that it changes sign when two electrons are swapped; that is, , where the variables \"r\"1 and \"r\"2 correspond to the first and second electrons, respectively. Since the absolute value is not changed by a sign swap, this corresponds to equal probabilities. Bosons, such as the photon, have symmetric wave functions instead.\nIn the case of antisymmetry, solutions of the wave equation for interacting electrons result in a zero probability that each pair will occupy the same location or state. This is responsible for the Pauli exclusion principle, which precludes any two electrons from occupying the same quantum state. This principle explains many of the properties of electrons. For example, it causes groups of bound electrons to occupy different orbitals in an atom, rather than all overlapping each other in the same orbit.\nVirtual particles.\nIn a simplified picture, which often tends to give the wrong idea but may serve to illustrate some aspects, every photon spends some time as a combination of a virtual electron plus its antiparticle, the virtual positron, which rapidly annihilate each other shortly thereafter. The combination of the energy variation needed to create these particles, and the time during which they exist, fall under the threshold of detectability expressed by the Heisenberg uncertainty relation, \u0394\"E\"\u00a0\u00b7\u00a0\u0394\"t\"\u00a0\u2265\u00a0\"\u0127\". In effect, the energy needed to create these virtual particles, \u0394\"E\", can be \"borrowed\" from the vacuum for a period of time, \u0394\"t\", so that their product is no more than the reduced Planck constant, . Thus, for a virtual electron, \u0394\"t\" is at most .\nWhile an electron\u2013positron virtual pair is in existence, the Coulomb force from the ambient electric field surrounding an electron causes a created positron to be attracted to the original electron, while a created electron experiences a repulsion. This causes what is called vacuum polarization. In effect, the vacuum behaves like a medium having a dielectric permittivity more than unity. Thus the effective charge of an electron is actually smaller than its true value, and the charge decreases with increasing distance from the electron. This polarization was confirmed experimentally in 1997 using the Japanese TRISTAN particle accelerator. Virtual particles cause a comparable shielding effect for the mass of the electron.\nThe interaction with virtual particles also explains the small (about 0.1%) deviation of the intrinsic magnetic moment of the electron from the Bohr magneton (the anomalous magnetic moment). The extraordinarily precise agreement of this predicted difference with the experimentally determined value is viewed as one of the great achievements of quantum electrodynamics.\nThe apparent paradox in classical physics of a point particle electron having intrinsic angular momentum and magnetic moment can be explained by the formation of virtual photons in the electric field generated by the electron. These photons can heuristically be thought of as causing the electron to shift about in a jittery fashion (known as zitterbewegung), which results in a net circular motion with precession. This motion produces both the spin and the magnetic moment of the electron. In atoms, this creation of virtual photons explains the Lamb shift observed in spectral lines. The Compton Wavelength shows that near elementary particles such as the electron, the uncertainty of the energy allows for the creation of virtual particles near the electron. This wavelength explains the \"static\" of virtual particles around elementary particles at a close distance.\nInteraction.\nAn electron generates an electric field that exerts an attractive force on a particle with a positive charge, such as the proton, and a repulsive force on a particle with a negative charge. The strength of this force in nonrelativistic approximation is determined by Coulomb's inverse square law. When an electron is in motion, it generates a magnetic field. The Amp\u00e8re-Maxwell law relates the magnetic field to the mass motion of electrons (the current) with respect to an observer. This property of induction supplies the magnetic field that drives an electric motor. The electromagnetic field of an arbitrary moving charged particle is expressed by the Li\u00e9nard\u2013Wiechert potentials, which are valid even when the particle's speed is close to that of light (relativistic).\nWhen an electron is moving through a magnetic field, it is subject to the Lorentz force that acts perpendicularly to the plane defined by the magnetic field and the electron velocity. This centripetal force causes the electron to follow a helical trajectory through the field at a radius called the gyroradius. The acceleration from this curving motion induces the electron to radiate energy in the form of synchrotron radiation. The energy emission in turn causes a recoil of the electron, known as the Abraham\u2013Lorentz\u2013Dirac Force, which creates a friction that slows the electron. This force is caused by a back-reaction of the electron's own field upon itself.\nPhotons mediate electromagnetic interactions between particles in quantum electrodynamics. An isolated electron at a constant velocity cannot emit or absorb a real photon; doing so would violate conservation of energy and momentum. Instead, virtual photons can transfer momentum between two charged particles. This exchange of virtual photons, for example, generates the Coulomb force. Energy emission can occur when a moving electron is deflected by a charged particle, such as a proton. The acceleration of the electron results in the emission of Bremsstrahlung radiation.\nAn inelastic collision between a photon (light) and a solitary (free) electron is called Compton scattering. This collision results in a transfer of momentum and energy between the particles, which modifies the wavelength of the photon by an amount called the Compton shift.c} (1 - \\cos \\theta),&lt;/math&gt;\nwhere \"c\" is the speed of light in a vacuum and \"m\"e is the electron mass. See Zombeck (2007). }} The maximum magnitude of this wavelength shift is \"h\"/\"m\"e\"c\", which is known as the Compton wavelength. For an electron, it has a value of . When the wavelength of the light is long (for instance, the wavelength of the visible light is 0.4\u20130.7\u00a0\u03bcm) the wavelength shift becomes negligible. Such interaction between the light and free electrons is called Thomson scattering or linear Thomson scattering.\nThe relative strength of the electromagnetic interaction between two charged particles, such as an electron and a proton, is given by the fine-structure constant. This value is a dimensionless quantity formed by the ratio of two energies: the electrostatic energy of attraction (or repulsion) at a separation of one Compton wavelength, and the rest energy of the charge. It is given by \"\u03b1\"\u00a0\u2248\u00a0, which is approximately equal to .\nWhen electrons and positrons collide, they annihilate each other, giving rise to two or more gamma ray photons. If the electron and positron have negligible momentum, a positronium atom can form before annihilation results in two or three gamma ray photons totalling 1.022\u00a0MeV. On the other hand, a high-energy photon can transform into an electron and a positron by a process called pair production, but only in the presence of a nearby charged particle, such as a nucleus.\nIn the theory of electroweak interaction, the left-handed component of electron's wavefunction forms a weak isospin doublet with the electron neutrino. This means that during weak interactions, electron neutrinos behave like electrons. Either member of this doublet can undergo a charged current interaction by emitting or absorbing a and be converted into the other member. Charge is conserved during this reaction because the W\u00a0boson also carries a charge, canceling out any net change during the transmutation. Charged current interactions are responsible for the phenomenon of beta decay in a radioactive atom. Both the electron and electron neutrino can undergo a neutral current interaction via a exchange, and this is responsible for neutrino-electron elastic scattering.\nAtoms and molecules.\nAn electron can be \"bound\" to the nucleus of an atom by the attractive Coulomb force. A system of one or more electrons bound to a nucleus is called an atom. If the number of electrons is different from the nucleus's electrical charge, such an atom is called an ion. The wave-like behavior of a bound electron is described by a function called an atomic orbital. Each orbital has its own set of quantum numbers such as energy, angular momentum and projection of angular momentum, and only a discrete set of these orbitals exist around the nucleus. According to the Pauli exclusion principle each orbital can be occupied by up to two electrons, which must differ in their spin quantum number.\nElectrons can transfer between different orbitals by the emission or absorption of photons with an energy that matches the difference in potential. Other methods of orbital transfer include collisions with particles, such as electrons, and the Auger effect. To escape the atom, the energy of the electron must be increased above its binding energy to the atom. This occurs, for example, with the photoelectric effect, where an incident photon exceeding the atom's ionization energy is absorbed by the electron.\nThe orbital angular momentum of electrons is quantized. Because the electron is charged, it produces an orbital magnetic moment that is proportional to the angular momentum. The net magnetic moment of an atom is equal to the vector sum of orbital and spin magnetic moments of all electrons and the nucleus. The magnetic moment of the nucleus is negligible compared with that of the electrons. The magnetic moments of the electrons that occupy the same orbital (so called, paired electrons) cancel each other out.\nThe chemical bond between atoms occurs as a result of electromagnetic interactions, as described by the laws of quantum mechanics. The strongest bonds are formed by the sharing or transfer of electrons between atoms, allowing the formation of molecules. Within a molecule, electrons move under the influence of several nuclei, and occupy molecular orbitals; much as they can occupy atomic orbitals in isolated atoms. A fundamental factor in these molecular structures is the existence of electron pairs. These are electrons with opposed spins, allowing them to occupy the same molecular orbital without violating the Pauli exclusion principle (much like in atoms). Different molecular orbitals have different spatial distribution of the electron density. For instance, in bonded pairs (i.e. in the pairs that actually bind atoms together) electrons can be found with the maximal probability in a relatively small volume between the nuclei. By contrast, in non-bonded pairs electrons are distributed in a large volume around nuclei.\nConductivity.\nIf a body has more or fewer electrons than are required to balance the positive charge of the nuclei, then that object has a net electric charge. When there is an excess of electrons, the object is said to be negatively charged. When there are fewer electrons than the number of protons in nuclei, the object is said to be positively charged. When the number of electrons and the number of protons are equal, their charges cancel each other and the object is said to be electrically neutral. A macroscopic body can develop an electric charge through rubbing, by the triboelectric effect.\nIndependent electrons moving in vacuum are termed \"free\" electrons. Electrons in metals also behave as if they were free. In reality the particles that are commonly termed electrons in metals and other solids are quasi-electrons\u2014quasiparticles, which have the same electrical charge, spin, and magnetic moment as real electrons but might have a different mass. When free electrons\u2014both in vacuum and metals\u2014move, they produce a net flow of charge called an electric current, which generates a magnetic field. Likewise a current can be created by a changing magnetic field. These interactions are described mathematically by Maxwell's equations.\nAt a given temperature, each material has an electrical conductivity that determines the value of electric current when an electric potential is applied. Examples of good conductors include metals such as copper and gold, whereas glass and Teflon are poor conductors. In any dielectric material, the electrons remain bound to their respective atoms and the material behaves as an insulator. Most semiconductors have a variable level of conductivity that lies between the extremes of conduction and insulation. On the other hand, metals have an electronic band structure containing partially filled electronic bands. The presence of such bands allows electrons in metals to behave as if they were free or delocalized electrons. These electrons are not associated with specific atoms, so when an electric field is applied, they are free to move like a gas (called Fermi gas) through the material much like free electrons.\nBecause of collisions between electrons and atoms, the drift velocity of electrons in a conductor is on the order of millimeters per second. However, the speed at which a change of current at one point in the material causes changes in currents in other parts of the material, the velocity of propagation, is typically about 75% of light speed. This occurs because electrical signals propagate as a wave, with the velocity dependent on the dielectric constant of the material.\nMetals make relatively good conductors of heat, primarily because the delocalized electrons are free to transport thermal energy between atoms. However, unlike electrical conductivity, the thermal conductivity of a metal is nearly independent of temperature. This is expressed mathematically by the Wiedemann\u2013Franz law, which states that the ratio of thermal conductivity to the electrical conductivity is proportional to the temperature. The thermal disorder in the metallic lattice increases the electrical resistivity of the material, producing a temperature dependence for electric current.\nWhen cooled below a point called the critical temperature, materials can undergo a phase transition in which they lose all resistivity to electric current, in a process known as superconductivity. In BCS theory, pairs of electrons called Cooper pairs have their motion coupled to nearby matter via lattice vibrations called phonons, thereby avoiding the collisions with atoms that normally create electrical resistance. (Cooper pairs have a radius of roughly 100\u00a0nm, so they can overlap each other.) However, the mechanism by which higher temperature superconductors operate remains uncertain.\nElectrons inside conducting solids, which are quasi-particles themselves, when tightly confined at temperatures close to absolute zero, behave as though they had split into three other quasiparticles: spinons, orbitons and holons. The former carries spin and magnetic moment, the next carries its orbital location while the latter electrical charge.\nMotion and energy.\nAccording to Einstein's theory of special relativity, as an electron's speed approaches the speed of light, from an observer's point of view its relativistic mass increases, thereby making it more and more difficult to accelerate it from within the observer's frame of reference. The speed of an electron can approach, but never reach, the speed of light in a vacuum, \"c\". However, when relativistic electrons\u2014that is, electrons moving at a speed close to \"c\"\u2014are injected into a dielectric medium such as water, where the local speed of light is significantly less than \"c\", the electrons temporarily travel faster than light in the medium. As they interact with the medium, they generate a faint light called Cherenkov radiation.\nThe effects of special relativity are based on a quantity known as the Lorentz factor, defined as formula_1 where \"v\" is the speed of the particle. The kinetic energy \"K\"e of an electron moving with velocity \"v\" is:\nwhere \"m\"e is the mass of electron. For example, the Stanford linear accelerator can accelerate an electron to roughly 51\u00a0GeV.\nSince an electron behaves as a wave, at a given velocity it has a characteristic de Broglie wavelength. This is given by \"\u03bb\"e\u00a0=\u00a0\"h\"/\"p\" where \"h\" is the Planck constant and \"p\" is the momentum. For the 51\u00a0GeV electron above, the wavelength is about , small enough to explore structures well below the size of an atomic nucleus.\nFormation.\nThe Big Bang theory is the most widely accepted scientific theory to explain the early stages in the evolution of the Universe. For the first millisecond of the Big Bang, the temperatures were over 10\u00a0billion\u00a0kelvins and photons had mean energies over a million electronvolts. These photons were sufficiently energetic that they could react with each other to form pairs of electrons and positrons. Likewise, positron-electron pairs annihilated each other and emitted energetic photons:\nAn equilibrium between electrons, positrons and photons was maintained during this phase of the evolution of the Universe. After 15 seconds had passed, however, the temperature of the universe dropped below the threshold where electron-positron formation could occur. Most of the surviving electrons and positrons annihilated each other, releasing gamma radiation that briefly reheated the universe.\nFor reasons that remain uncertain, during the annihilation process there was an excess in the number of particles over antiparticles. Hence, about one electron for every billion electron-positron pairs survived. This excess matched the excess of protons over antiprotons, in a condition known as baryon asymmetry, resulting in a net charge of zero for the universe. The surviving protons and neutrons began to participate in reactions with each other\u2014in the process known as nucleosynthesis, forming isotopes of hydrogen and helium, with trace amounts of lithium. This process peaked after about five minutes. Any leftover neutrons underwent negative beta decay with a half-life of about a thousand seconds, releasing a proton and electron in the process,\nFor about the next \u2013, the excess electrons remained too energetic to bind with atomic nuclei. What followed is a period known as recombination, when neutral atoms were formed and the expanding universe became transparent to radiation.\nRoughly one million years after the big bang, the first generation of stars began to form. Within a star, stellar nucleosynthesis results in the production of positrons from the fusion of atomic nuclei. These antimatter particles immediately annihilate with electrons, releasing gamma rays. The net result is a steady reduction in the number of electrons, and a matching increase in the number of neutrons. However, the process of stellar evolution can result in the synthesis of radioactive isotopes. Selected isotopes can subsequently undergo negative beta decay, emitting an electron and antineutrino from the nucleus. An example is the cobalt-60 (60Co) isotope, which decays to form nickel-60 ().\nAt the end of its lifetime, a star with more than about 20 solar masses can undergo gravitational collapse to form a black hole. According to classical physics, these massive stellar objects exert a gravitational attraction that is strong enough to prevent anything, even electromagnetic radiation, from escaping past the Schwarzschild radius. However, quantum mechanical effects are believed to potentially allow the emission of Hawking radiation at this distance. Electrons (and positrons) are thought to be created at the event horizon of these stellar remnants.\nWhen a pair of virtual particles (such as an electron and positron) is created in the vicinity of the event horizon, random spatial positioning might result in one of them to appear on the exterior; this process is called quantum tunnelling. The gravitational potential of the black hole can then supply the energy that transforms this virtual particle into a real particle, allowing it to radiate away into space. In exchange, the other member of the pair is given negative energy, which results in a net loss of mass-energy by the black hole. The rate of Hawking radiation increases with decreasing mass, eventually causing the black hole to evaporate away until, finally, it explodes.\nCosmic rays are particles traveling through space with high energies. Energy events as high as have been recorded. When these particles collide with nucleons in the Earth's atmosphere, a shower of particles is generated, including pions. More than half of the cosmic radiation observed from the Earth's surface consists of muons. The particle called a muon is a lepton produced in the upper atmosphere by the decay of a pion.\nA muon, in turn, can decay to form an electron or positron.\nObservation.\nRemote observation of electrons requires detection of their radiated energy. For example, in high-energy environments such as the corona of a star, free electrons form a plasma that radiates energy due to Bremsstrahlung radiation. Electron gas can undergo plasma oscillation, which is waves caused by synchronized variations in electron density, and these produce energy emissions that can be detected by using radio telescopes.\nThe frequency of a photon is proportional to its energy. As a bound electron transitions between different energy levels of an atom, it absorbs or emits photons at characteristic frequencies. For instance, when atoms are irradiated by a source with a broad spectrum, distinct dark lines appear in the spectrum of transmitted radiation in places where the corresponding frequency is absorbed by the atom's electrons. Each element or molecule displays a characteristic set of spectral lines, such as the hydrogen spectral series. When detected, spectroscopic measurements of the strength and width of these lines allow the composition and physical properties of a substance to be determined.\nIn laboratory conditions, the interactions of individual electrons can be observed by means of particle detectors, which allow measurement of specific properties such as energy, spin and charge. The development of the Paul trap and Penning trap allows charged particles to be contained within a small region for long durations. This enables precise measurements of the particle properties. For example, in one instance a Penning trap was used to contain a single electron for a period of 10 months. The magnetic moment of the electron was measured to a precision of eleven digits, which, in 1980, was a greater accuracy than for any other physical constant.\nThe first video images of an electron's energy distribution were captured by a team at Lund University in Sweden, February 2008. The scientists used extremely short flashes of light, called attosecond pulses, which allowed an electron's motion to be observed for the first time.\nThe distribution of the electrons in solid materials can be visualized by angle-resolved photoemission spectroscopy (ARPES). This technique employs the photoelectric effect to measure the reciprocal space\u2014a mathematical representation of periodic structures that is used to infer the original structure. ARPES can be used to determine the direction, speed and scattering of electrons within the material.\nPlasma applications.\nParticle beams.\nElectron beams are used in welding. They allow energy densities up to across a narrow focus diameter of and usually require no filler material. This welding technique must be performed in a vacuum to prevent the electrons from interacting with the gas before reaching their target, and it can be used to join conductive materials that would otherwise be considered unsuitable for welding.\nElectron-beam lithography (EBL) is a method of etching semiconductors at resolutions smaller than a micrometer. This technique is limited by high costs, slow performance, the need to operate the beam in the vacuum and the tendency of the electrons to scatter in solids. The last problem limits the resolution to about 10\u00a0nm. For this reason, EBL is primarily used for the production of small numbers of specialized integrated circuits.\nElectron beam processing is used to irradiate materials in order to change their physical properties or sterilize medical and food products. Electron beams fluidise or quasi-melt glasses without significant increase of temperature on intensive irradiation: e.g. intensive electron radiation causes a many orders of magnitude decrease of viscosity and stepwise decrease of its activation energy.\nLinear particle accelerators generate electron beams for treatment of superficial tumors in radiation therapy. Electron therapy can treat such skin lesions as basal-cell carcinomas because an electron beam only penetrates to a limited depth before being absorbed, typically up to 5\u00a0cm for electron energies in the range 5\u201320\u00a0MeV. An electron beam can be used to supplement the treatment of areas that have been irradiated by X-rays.\nParticle accelerators use electric fields to propel electrons and their antiparticles to high energies. These particles emit synchrotron radiation as they pass through magnetic fields. The dependency of the intensity of this radiation upon spin polarizes the electron beam\u2014a process known as the Sokolov\u2013Ternov effect. Polarized electron beams can be useful for various experiments. Synchrotron radiation can also cool the electron beams to reduce the momentum spread of the particles. Electron and positron beams are collided upon the particles' accelerating to the required energies; particle detectors observe the resulting energy emissions, which particle physics studies .\nImaging.\nLow-energy electron diffraction (LEED) is a method of bombarding a crystalline material with a collimated beam of electrons and then observing the resulting diffraction patterns to determine the structure of the material. The required energy of the electrons is typically in the range 20\u2013200\u00a0eV. The reflection high-energy electron diffraction (RHEED) technique uses the reflection of a beam of electrons fired at various low angles to characterize the surface of crystalline materials. The beam energy is typically in the range 8\u201320\u00a0keV and the angle of incidence is 1\u20134\u00b0.\nThe electron microscope directs a focused beam of electrons at a specimen. Some electrons change their properties, such as movement direction, angle, and relative phase and energy as the beam interacts with the material. Microscopists can record these changes in the electron beam to produce atomically resolved images of the material. In blue light, conventional optical microscopes have a diffraction-limited resolution of about 200\u00a0nm. By comparison, electron microscopes are limited by the de Broglie wavelength of the electron. This wavelength, for example, is equal to 0.0037\u00a0nm for electrons accelerated across a 100,000-volt potential. The Transmission Electron Aberration-Corrected Microscope is capable of sub-0.05\u00a0nm resolution, which is more than enough to resolve individual atoms. This capability makes the electron microscope a useful laboratory instrument for high resolution imaging. However, electron microscopes are expensive instruments that are costly to maintain.\nTwo main types of electron microscopes exist: transmission and scanning. Transmission electron microscopes function like overhead projectors, with a beam of electrons passing through a slice of material then being projected by lenses on a photographic slide or a charge-coupled device. Scanning electron microscopes rasteri a finely focused electron beam, as in a TV set, across the studied sample to produce the image. Magnifications range from 100\u00d7 to 1,000,000\u00d7 or higher for both microscope types. The scanning tunneling microscope uses quantum tunneling of electrons from a sharp metal tip into the studied material and can produce atomically resolved images of its surface.\nOther applications.\nIn the free-electron laser (FEL), a relativistic electron beam passes through a pair of undulators that contain arrays of dipole magnets whose fields point in alternating directions. The electrons emit synchrotron radiation that coherently interacts with the same electrons to strongly amplify the radiation field at the resonance frequency. FEL can emit a coherent high-brilliance electromagnetic radiation with a wide range of frequencies, from microwaves to soft X-rays. These devices are used in manufacturing, communication, and in medical applications, such as soft tissue surgery.\nElectrons are important in cathode ray tubes, which have been extensively used as display devices in laboratory instruments, computer monitors and television sets. In a photomultiplier tube, every photon striking the photocathode initiates an avalanche of electrons that produces a detectable current pulse. Vacuum tubes use the flow of electrons to manipulate electrical signals, and they played a critical role in the development of electronics technology. However, they have been largely supplanted by solid-state devices such as the transistor."}
{"id": "9477", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=9477", "title": "Europium", "text": "Europium is a chemical element with the symbol Eu and atomic number 63. Europium is the most reactive lanthanide by far, having to be stored under an inert fluid to protect it from atmospheric oxygen or moisture. Europium is also the softest lanthanide, as it can be dented with a fingernail and easily cut with a knife. When oxidation is removed a shiny-white metal is visible. Europium was isolated in 1901 and is named after the continent of Europe. Being a typical member of the lanthanide series, europium usually assumes the oxidation state +3, but the oxidation state +2 is also common. All europium compounds with oxidation state +2 are slightly reducing. Europium has no significant biological role and is relatively non-toxic compared to other heavy metals. Most applications of europium exploit the phosphorescence of europium compounds. Europium is one of the rarest of the rare-earth elements on Earth.\nCharacteristics.\nPhysical properties.\nEuropium is a ductile metal with a hardness similar to that of lead. It crystallizes in a body-centered cubic lattice. Some properties of europium are strongly influenced by its half-filled electron shell. Europium has the second lowest melting point and the lowest density of all lanthanides.\nEuropium has been claimed to become a superconductor when it is cooled below 1.8 K and compressed to above 80 GPa. However the experimental evidence on which this claim is based\nhas been challenged. If it becomes a superconductor this is believed to occur because europium is divalent in the metallic state, and is converted into the trivalent state by the applied pressure. In the divalent state, the strong local magnetic moment (J = 7/2) suppresses the superconductivity, which is induced by eliminating this local moment (J = 0 in Eu3+).\nChemical properties.\nEuropium is the most reactive rare-earth element. It rapidly oxidizes in air, so that bulk oxidation of a centimeter-sized sample occurs within several days. Its reactivity with water is comparable to that of calcium, and the reaction is\nBecause of the high reactivity, samples of solid europium rarely have the shiny appearance of the fresh metal, even when coated with a protective layer of mineral oil. Europium ignites in air at 150 to 180\u00a0\u00b0C to form europium(III) oxide:\nEuropium dissolves readily in dilute sulfuric acid to form pale pink solutions of the hydrated Eu(III), which exist as a nonahydrate:\nEu(II) vs. Eu(III).\nAlthough usually trivalent, europium readily forms divalent compounds. This behavior is unusual for most lanthanides, which almost exclusively form compounds with an oxidation state of +3. The +2 state has an electron configuration 4\"f\"7 because the half-filled \"f\"-shell provides more stability. In terms of size and coordination number, europium(II) and barium(II) are similar. The sulfates of both barium and europium(II) are also highly insoluble in water. Divalent europium is a mild reducing agent, oxidizing in air to form Eu(III) compounds. In anaerobic, and particularly geothermal conditions, the divalent form is sufficiently stable that it tends to be incorporated into minerals of calcium and the other alkaline earths. This ion-exchange process is the basis of the \"negative europium anomaly\", the low europium content in many lanthanide minerals such as monazite, relative to the chondritic abundance. Bastn\u00e4site tends to show less of a negative europium anomaly than does monazite, and hence is the major source of europium today. The development of easy methods to separate divalent europium from the other (trivalent) lanthanides made europium accessible even when present in low concentration, as it usually is.\nIsotopes.\nNaturally occurring europium is composed of 2 isotopes, 151Eu and 153Eu, which occur in almost equal proportions; 153Eu is slightly more abundant (52.2% natural abundance). While 153Eu is stable, 151Eu was found to be unstable to alpha decay with a half-life of in 2007, giving about 1 alpha decay per two minutes in every kilogram of natural europium. This value is in reasonable agreement with theoretical predictions. Besides the natural radioisotope 151Eu, 35 artificial radioisotopes have been characterized, the most stable being 150Eu with a half-life of 36.9 years, 152Eu with a half-life of 13.516 years, and 154Eu with a half-life of 8.593 years. All the remaining radioactive isotopes have half-lives shorter than 4.7612 years, and the majority of these have half-lives shorter than 12.2 seconds. This element also has 8 meta states, with the most stable being 150mEu (\"t\"1/2=12.8 hours), 152m1Eu (\"t\"1/2=9.3116 hours) and 152m2Eu (\"t\"1/2=96 minutes).\nThe primary decay mode for isotopes lighter than 153Eu is electron capture, and the primary mode for heavier isotopes is beta minus decay. The primary decay products before 153Eu are isotopes of samarium (Sm) and the primary products after are isotopes of gadolinium (Gd).\nEuropium as a nuclear fission product.\nEuropium is produced by nuclear fission, but the fission product yields of europium isotopes are low near the top of the mass range for fission products.\nAs with other lanthanides, many isotopes of europium, especially those that have odd mass numbers or are neutron-poor like 152Eu, have high cross sections for neutron capture, often high enough to be neutron poisons.\n151Eu is the beta decay product of samarium-151, but since this has a long decay half-life and short mean time to neutron absorption, most 151Sm instead ends up as 152Sm.\n152Eu (half-life 13.516 years) and 154Eu (half-life 8.593 years) cannot be beta decay products because 152Sm and 154Sm are non-radioactive, but 154Eu is the only long-lived \"shielded\" nuclide, other than 134Cs, to have a fission yield of more than 2.5 parts per million fissions. A larger amount of 154Eu is produced by neutron activation of a significant portion of the non-radioactive 153Eu; however, much of this is further converted to 155Eu.\n155Eu (half-life 4.7612 years) has a fission yield of 330 parts per million (ppm) for uranium-235 and thermal neutrons; most of it is transmuted to non-radioactive and nonabsorptive gadolinium-156 by the end of fuel burnup.\nOverall, europium is overshadowed by caesium-137 and strontium-90 as a radiation hazard, and by samarium and others as a neutron poison.\nOccurrence.\nEuropium is not found in nature as a free element. Many minerals contain europium, with the most important sources being bastn\u00e4site, monazite, xenotime and loparite-(Ce). No europium-dominant minerals are known yet, despite a single find of a tiny possible Eu\u2013O or Eu\u2013O\u2013C system phase in the Moon's regolith.\nDepletion or enrichment of europium in minerals relative to other rare-earth elements is known as the europium anomaly. Europium is commonly included in trace element studies in geochemistry and petrology to understand the processes that form igneous rocks (rocks that cooled from magma or lava). The nature of the europium anomaly found helps reconstruct the relationships within a suite of igneous rocks. The average crustal abundance of europium is 2\u20132.2 ppm.\nDivalent europium (Eu2+) in small amounts is the activator of the bright blue fluorescence of some samples of the mineral fluorite (CaF2). The reduction from Eu3+ to Eu2+ is induced by irradiation with energetic particles. The most outstanding examples of this originated around Weardale and adjacent parts of northern England; it was the fluorite found here that fluorescence was named after in 1852, although it was not until much later that europium was determined to be the cause.\nIn astrophysics, the signature of europium in stellar spectra can be used to classify stars and inform theories of how or where a particular star was born. For instance, astronomers in 2019 identified higher-than-expected levels of europium within the star J1124+4535, hypothesizing that this star originated in a dwarf galaxy that collided with the Milky Way billions of years ago.\nProduction.\nEuropium is associated with the other rare-earth elements and is, therefore, mined together with them. Separation of the rare-earth elements occurs during later processing. Rare-earth elements are found in the minerals bastn\u00e4site, loparite-(Ce), xenotime, and monazite in mineable quantities. Bastn\u00e4site is a group of related fluorocarbonates, Ln(CO3)(F,OH). Monazite is a group of related of orthophosphate minerals (Ln denotes a mixture of all the lanthanides except promethium), loparite-(Ce) is an oxide, and xenotime is an orthophosphate (Y,Yb,Er...)PO4. Monazite also contains thorium and yttrium, which complicates handling because thorium and its decay products are radioactive. For the extraction from the ore and the isolation of individual lanthanides, several methods have been developed. The choice of method is based on the concentration and composition of the ore and on the distribution of the individual lanthanides in the resulting concentrate. Roasting the ore, followed by acidic and basic leaching, is used mostly to produce a concentrate of lanthanides. If cerium is the dominant lanthanide, then it is converted from cerium(III) to cerium(IV) and then precipitated. Further separation by solvent extractions or ion exchange chromatography yields a fraction which is enriched in europium. This fraction is reduced with zinc, zinc/amalgam, electrolysis or other methods converting the europium(III) to europium(II). Europium(II) reacts in a way similar to that of alkaline earth metals and therefore it can be precipitated as a carbonate or co-precipitated with barium sulfate. Europium metal is available through the electrolysis of a mixture of molten EuCl3 and NaCl (or CaCl2) in a graphite cell, which serves as cathode, using graphite as anode. The other product is chlorine gas.\nA few large deposits produce or produced a significant amount of the world production. The Bayan Obo iron ore deposit in Inner Mongolia contains significant amounts of bastn\u00e4site and monazite and is, with an estimated 36 million tonnes of rare-earth element oxides, the largest known deposit. The mining operations at the Bayan Obo deposit made China the largest supplier of rare-earth elements in the 1990s. Only 0.2% of the rare-earth element content is europium. The second large source for rare-earth elements between 1965 and its closure in the late 1990s was the Mountain Pass rare earth mine in California. The bastn\u00e4site mined there is especially rich in the light rare-earth elements (La-Gd, Sc, and Y) and contains only 0.1% of europium. Another large source for rare-earth elements is the loparite found on the Kola peninsula. It contains besides niobium, tantalum and titanium up to 30% rare-earth elements and is the largest source for these elements in Russia.\nCompounds.\nEuropium compounds tend to exist trivalent oxidation state under most conditions. Commonly these compounds feature Eu(III) bound by 6\u20139 oxygenic ligands, typically water. These compounds, the chlorides, sulfates, nitrates, are soluble in water or polar organic solvent. Lipophilic europium complexes often feature acetylacetonate-like ligands, e.g., Eufod.\nHalides.\nEuropium metal reacts with all the halogens:\nThis route gives white europium(III) fluoride (EuF3), yellow europium(III) chloride (EuCl3), gray europium(III) bromide (EuBr3), and colorless europium(III) iodide (EuI3). Europium also forms the corresponding dihalides: yellow-green europium(II) fluoride (EuF2), colorless europium(II) chloride (EuCl2), colorless europium(II) bromide (EuBr2), and green europium(II) iodide (EuI2).\nChalcogenides and pnictides.\nEuropium forms stable compounds with all of the chalcogens, but the heavier chalcogens (S, Se, and Te) stabilize the lower oxidation state. Three oxides are known: europium(II) oxide (EuO), europium(III) oxide (Eu2O3), and the mixed-valence oxide Eu3O4, consisting of both Eu(II) and Eu(III).\nOtherwise, the main chalcogenides are europium(II) sulfide (EuS), europium(II) selenide (EuSe) and europium(II) telluride (EuTe): all three of these are black solids. EuS is prepared by sulfiding the oxide at temperatures sufficiently high to decompose the Eu2O3:\nThe main nitride is europium(III) nitride (EuN).\nHistory.\nAlthough europium is present in most of the minerals containing the other rare elements, due to the difficulties in separating the elements it was not until the late 1800s that the element was isolated. William Crookes observed the phosphorescent spectra of the rare elements including those eventually assigned to europium.\nEuropium was first found in 1892 by Paul \u00c9mile Lecoq de Boisbaudran, who obtained basic fractions from samarium-gadolinium concentrates which had spectral lines not accounted for by samarium or gadolinium. However, the discovery of europium is generally credited to French chemist Eug\u00e8ne-Anatole Demar\u00e7ay, who suspected samples of the recently discovered element samarium were contaminated with an unknown element in 1896 and who was able to isolate it in 1901; he then named it \"europium\".\nWhen the europium-doped yttrium orthovanadate red phosphor was discovered in the early 1960s, and understood to be about to cause a revolution in the color television industry, there was a scramble for the limited supply of europium on hand among the monazite processors, as the typical europium content in monazite is about 0.05%. However, the Molycorp bastn\u00e4site deposit at the Mountain Pass rare earth mine, California, whose lanthanides had an unusually high europium content of 0.1%, was about to come on-line and provide sufficient europium to sustain the industry. Prior to europium, the color-TV red phosphor was very weak, and the other phosphor colors had to be muted, to maintain color balance. With the brilliant red europium phosphor, it was no longer necessary to mute the other colors, and a much brighter color TV picture was the result. Europium has continued to be in use in the TV industry ever since as well as in computer monitors. Californian bastn\u00e4site now faces stiff competition from Bayan Obo, China, with an even \"richer\" europium content of 0.2%.\nFrank Spedding, celebrated for his development of the ion-exchange technology that revolutionized the rare-earth industry in the mid-1950s, once related the story of how he was lecturing on the rare earths in the 1930s, when an elderly gentleman approached him with an offer of a gift of several pounds of europium oxide. This was an unheard-of quantity at the time, and Spedding did not take the man seriously. However, a package duly arrived in the mail, containing several pounds of genuine europium oxide. The elderly gentleman had turned out to be Herbert Newby McCoy, who had developed a famous method of europium purification involving redox chemistry.\nApplications.\nRelative to most other elements, commercial applications for europium are few and rather specialized. Almost invariably, its phosphorescence is exploited, either in the +2 or +3 oxidation state.\nIt is a dopant in some types of glass in lasers and other optoelectronic devices. Europium oxide (Eu2O3) is widely used as a red phosphor in television sets and fluorescent lamps, and as an activator for yttrium-based phosphors. Color TV screens contain between 0.5 and 1\u00a0g of europium oxide. Whereas trivalent europium gives red phosphors, the luminescence of divalent europium depends strongly on the composition of the host structure. UV to deep red luminescence can be achieved. The two classes of europium-based phosphor (red and blue), combined with the yellow/green terbium phosphors give \"white\" light, the color temperature of which can be varied by altering the proportion or specific composition of the individual phosphors. This phosphor system is typically encountered in helical fluorescent light bulbs. Combining the same three classes is one way to make trichromatic systems in TV and computer screens, but as an additive, it can be particularly effective in improving the intensity of red phosphor. Europium is also used in the manufacture of fluorescent glass, increasing the general efficiency of fluorescent lamps. One of the more common persistent after-glow phosphors besides copper-doped zinc sulfide is europium-doped strontium aluminate. Europium fluorescence is used to interrogate biomolecular interactions in drug-discovery screens. It is also used in the anti-counterfeiting phosphors in euro banknotes.\nAn application that has almost fallen out of use with the introduction of affordable superconducting magnets is the use of europium complexes, such as Eu(fod)3, as shift reagents in NMR spectroscopy. Chiral shift reagents, such as Eu(hfc)3, are still used to determine enantiomeric purity.\nA recent (2015) application of europium is in quantum memory chips which can reliably store information for days at a time; these could allow sensitive quantum data to be stored to a hard disk-like device and shipped around.\nA theorized application of europium is its use in stopping thermonuclear threats. Due to its high neutron capture cross-section and neutron poison chain it is preferred for neutron poison based anti-thermonuclear missiles.\nPrecautions.\nThere are no clear indications that europium is particularly toxic compared to other heavy metals. Europium chloride, nitrate and oxide have been tested for toxicity: europium chloride shows an acute intraperitoneal LD50 toxicity of 550\u00a0mg/kg and the acute oral LD50 toxicity is 5000\u00a0mg/kg. Europium nitrate shows a slightly higher intraperitoneal LD50 toxicity of 320\u00a0mg/kg, while the oral toxicity is above 5000\u00a0mg/kg. The metal dust presents a fire and explosion hazard."}
{"id": "9478", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=9478", "title": "Erbium", "text": "Erbium is a chemical element with the symbol Er and atomic number 68. A silvery-white solid metal when artificially isolated, natural erbium is always found in chemical combination with other elements. It is a lanthanide, a rare earth element, originally found in the gadolinite mine in Ytterby in Sweden, from which it got its name.\nErbium's principal uses involve its pink-colored Er3+ ions, which have optical fluorescent properties particularly useful in certain laser applications. Erbium-doped glasses or crystals can be used as optical amplification media, where Er3+ ions are optically pumped at around 980 or and then radiate light at in stimulated emission. This process results in an unusually mechanically simple laser optical amplifier for signals transmitted by fiber optics. The wavelength is especially important for optical communications because standard single mode optical fibers have minimal loss at this particular wavelength.\nIn addition to optical fiber amplifier-lasers, a large variety of medical applications (i.e. dermatology, dentistry) rely on the erbium ion's emission (see ) when lit at another wavelength, which is highly absorbed in water in tissues, making its effect very superficial. Such shallow tissue deposition of laser energy is helpful in laser surgery, and for the efficient production of steam which produces enamel ablation by common types of dental laser.\nCharacteristics.\nPhysical properties.\nA trivalent element, pure erbium metal is malleable (or easily shaped), soft yet stable in air, and does not oxidize as quickly as some other rare-earth metals. Its salts are rose-colored, and the element has characteristic sharp absorption spectra bands in visible light, ultraviolet, and near infrared. Otherwise it looks much like the other rare earths. Its sesquioxide is called erbia. Erbium's properties are to a degree dictated by the kind and amount of impurities present. Erbium does not play any known biological role, but is thought to be able to stimulate metabolism.\nErbium is ferromagnetic below 19\u00a0K, antiferromagnetic between 19 and 80 K and paramagnetic above 80\u00a0K.\nErbium can form propeller-shaped atomic clusters Er3N, where the distance between the erbium atoms is 0.35\u00a0nm. Those clusters can be isolated by encapsulating them into fullerene molecules, as confirmed by transmission electron microscopy.\nChemical properties.\nErbium metal retains its luster in dry air, however will tarnish slowly in moist air and burns readily to form erbium(III) oxide:\nErbium is quite electropositive and reacts slowly with cold water and quite quickly with hot water to form erbium hydroxide:\nErbium metal reacts with all the halogens:\nErbium dissolves readily in dilute sulfuric acid to form solutions containing hydrated Er(III) ions, which exist as rose red [Er(OH2)9]3+ hydration complexes:\nIsotopes.\nNaturally occurring erbium is composed of 6 stable isotopes, , , , , , and , with being the most abundant (33.503% natural abundance). 29 radioisotopes have been characterized, with the most stable being with a half-life of , with a half-life of , with a half-life of , with a half-life of , and with a half-life of . All of the remaining radioactive isotopes have half-lives that are less than , and the majority of these have half-lives that are less than 4 minutes. This element also has 13 meta states, with the most stable being with a half-life of .\nThe isotopes of erbium range in atomic weight from () to (). The primary decay mode before the most abundant stable isotope, , is electron capture, and the primary mode after is beta decay. The primary decay products before are element 67 (holmium) isotopes, and the primary products after are element 69 (thulium) isotopes.\nHistory.\nErbium (for Ytterby, a village in Sweden) was discovered by Carl Gustaf Mosander in 1843. Mosander was working with a sample of what was thought to be the single metal oxide yttria, derived from the mineral gadolinite. He discovered that the sample contained at least two metal oxides in addition to pure yttria, which he named \"erbia\" and \"terbia\" after the village of Ytterby where the gadolinite had been found. Mosander was not certain of the purity of the oxides and later tests confirmed his uncertainty. Not only did the \"yttria\" contain yttrium, erbium, and terbium; in the ensuing years, chemists, geologists and spectroscopists discovered five additional elements: ytterbium, scandium, thulium, holmium, and gadolinium.\nErbia and terbia, however, were confused at this time. A spectroscopist mistakenly switched the names of the two elements during spectroscopy. After 1860, terbia was renamed erbia and after 1877 what had been known as erbia was renamed terbia. Fairly pure Er2O3 was independently isolated in 1905 by Georges Urbain and Charles James. Reasonably pure erbium metal was not produced until 1934 when Wilhelm Klemm and Heinrich Bommer reduced the anhydrous chloride with potassium vapor. It was only in the 1990s that the price for Chinese-derived erbium oxide became low enough for erbium to be considered for use as a colorant in art glass.\nOccurrence.\nThe concentration of erbium in the Earth crust is about 2.8\u00a0mg/kg and in the sea water 0.9\u00a0ng/L. This concentration is enough to make erbium about 45th in elemental abundance in the Earth's crust.\nLike other rare earths, this element is never found as a free element in nature but is found bound in monazite sand ores. It has historically been very difficult and expensive to separate rare earths from each other in their ores but ion-exchange chromatography methods developed in the late 20th century have greatly brought down the cost of production of all rare-earth metals and their chemical compounds.\nThe principal commercial sources of erbium are from the minerals xenotime and euxenite, and most recently, the ion adsorption clays of southern China; in consequence, China has now become the principal global supplier of this element. In the high-yttrium versions of these ore concentrates, yttrium is about two-thirds of the total by weight, and erbia is about 4\u20135%. When the concentrate is dissolved in acid, the erbia liberates enough erbium ion to impart a distinct and characteristic pink color to the solution. This color behavior is similar to what Mosander and the other early workers in the lanthanides would have seen in their extracts from the gadolinite minerals of Ytterby.\nProduction.\nCrushed minerals are attacked by hydrochloric or sulfuric acid that transforms insoluble rare-earth oxides into soluble chlorides or sulfates. The acidic filtrates are partially neutralized with caustic soda (sodium hydroxide) to pH 3\u20134. Thorium precipitates out of solution as hydroxide and is removed. After that the solution is treated with ammonium oxalate to convert rare earths into their insoluble oxalates. The oxalates are converted to oxides by annealing. The oxides are dissolved in nitric acid that excludes one of the main components, cerium, whose oxide is insoluble in HNO3. The solution is treated with magnesium nitrate to produce a crystallized mixture of double salts of rare-earth metals. The salts are separated by ion exchange. In this process, rare-earth ions are sorbed onto suitable ion-exchange resin by exchange with hydrogen, ammonium or cupric ions present in the resin. The rare earth ions are then selectively washed out by suitable complexing agent. Erbium metal is obtained from its oxide or salts by heating with calcium at under argon atmosphere.\nApplications.\nErbium's everyday uses are varied. It is commonly used as a photographic filter, and because of its resilience it is useful as a metallurgical additive.\nLasers and optics.\nA large variety of medical applications (i.e. dermatology, dentistry) utilize erbium ion's emission (see ), which is highly absorbed in water (absorption coefficient about ). Such shallow tissue deposition of laser energy is necessary for laser surgery, and the efficient production of steam for laser enamel ablation in dentistry.\nErbium-doped optical silica-glass fibers are the active element in erbium-doped fiber amplifiers (EDFAs), which are widely used in optical communications. The same fibers can be used to create fiber lasers. In order to work efficiently, erbium-doped fiber is usually co-doped with glass modifiers/homogenizers, often aluminum or phosphorus. These dopants help prevent clustering of Er ions and transfer the energy more efficiently between excitation light (also known as optical pump) and the signal. Co-doping of optical fiber with Er and Yb is used in high-power Er/Yb fiber lasers. Erbium can also be used in erbium-doped waveguide amplifiers.\nMetallurgy.\nWhen added to vanadium as an alloy, erbium lowers hardness and improves workability. An erbium-nickel alloy Er3Ni has an unusually high specific heat capacity at liquid-helium temperatures and is used in cryocoolers; a mixture of 65% Er3Co and 35% Er0.9Yb0.1Ni by volume improves the specific heat capacity even more.\nColoring.\nErbium oxide has a pink color, and is sometimes used as a colorant for glass, cubic zirconia and porcelain. The glass is then often used in sunglasses and cheap jewelry.\nOthers.\nErbium is used in nuclear technology in neutron-absorbing control rods.\nBiological role.\nErbium does not have a biological role, but erbium salts can stimulate metabolism. Humans consume 1 milligram of erbium a year on average. The highest concentration of erbium in humans is in the bones, but there is also erbium in the human kidneys and liver.\nToxicity.\nErbium is slightly toxic if ingested, but erbium compounds are not toxic. Metallic erbium in dust form presents a fire and explosion hazard."}
{"id": "9479", "revid": "1019849469", "url": "https://en.wikipedia.org/wiki?curid=9479", "title": "Einsteinium", "text": "Einsteinium is a synthetic element with the symbol Es and atomic number 99. Einsteinium is a member of the actinide series and it is the seventh transuranic element. It is named to honor Albert Einstein.\nEinsteinium was discovered as a component of the debris of the first hydrogen bomb explosion in 1952. Its most common isotope einsteinium-253 (half-life 20.47 days) is produced artificially from decay of californium-253 in a few dedicated high-power nuclear reactors with a total yield on the order of one milligram per year. The reactor synthesis is followed by a complex process of separating einsteinium-253 from other actinides and products of their decay. Other isotopes are synthesized in various laboratories, but in much smaller amounts, by bombarding heavy actinide elements with light ions. Owing to the small amounts of produced einsteinium and the short half-life of its most easily produced isotope, there are currently almost no practical applications for it outside basic scientific research. In particular, einsteinium was used to synthesize, for the first time, 17 atoms of the new element mendelevium in 1955.\nEinsteinium is a soft, silvery, paramagnetic metal. Its chemistry is typical of the late actinides, with a preponderance of the +3 oxidation state; the +2 oxidation state is also accessible, especially in solids. The high radioactivity of einsteinium-253 produces a visible glow and rapidly damages its crystalline metal lattice, with released heat of about 1000 watts per gram. Difficulty in studying its properties is due to einsteinium-253's decay to berkelium-249 and then californium-249 at a rate of about 3% per day. The isotope of einsteinium with the longest half-life, einsteinium-252 (half-life 471.7 days) would be more suitable for investigation of physical properties, but it has proven far more difficult to produce and is available only in minute quantities, and not in bulk. Einsteinium is the element with the highest atomic number which has been observed in macroscopic quantities in its pure form, and this was the common short-lived isotope einsteinium-253.\nLike all synthetic transuranic elements, isotopes of einsteinium are very radioactive and are considered highly dangerous to health on ingestion.\nHistory.\nEinsteinium was first identified in December 1952 by Albert Ghiorso and co-workers at the University of California, Berkeley in collaboration with the Argonne and Los Alamos National Laboratories, in the fallout from the \"Ivy Mike\" nuclear test. The test was carried out on November 1, 1952, at Enewetak Atoll in the Pacific Ocean and was the first successful test of a hydrogen bomb. Initial examination of the debris from the explosion had shown the production of a new isotope of plutonium, , which could only have formed by the absorption of six neutrons by a uranium-238 nucleus followed by two beta decays.\nAt the time, the multiple neutron absorption was thought to be an extremely rare process, but the identification of indicated that still more neutrons could have been captured by the uranium nuclei, thereby producing new elements heavier than californium.\nGhiorso and co-workers analyzed filter papers which had been flown through the explosion cloud on airplanes (the same sampling technique that had been used to discover ). Larger amounts of radioactive material were later isolated from coral debris of the atoll, which were delivered to the U.S. The separation of suspected new elements was carried out in the presence of a citric acid/ammonium buffer solution in a weakly acidic medium (pH \u2248 3.5), using ion exchange at elevated temperatures; fewer than 200 atoms of einsteinium were recovered in the end. Nevertheless, element 99 (einsteinium), namely its 253Es isotope, could be detected via its characteristic high-energy alpha decay at 6.6\u00a0MeV. It was produced by the capture of 15 neutrons by uranium-238 nuclei followed by seven beta-decays, and had a half-life of 20.5 days. Such multiple neutron absorption was made possible by the high neutron flux density during the detonation, so that newly generated heavy isotopes had plenty of available neutrons to absorb before they could disintegrate into lighter elements. Neutron capture initially raised the mass number without changing the atomic number of the nuclide, and the concomitant beta-decays resulted in a gradual increase in the atomic number:\n^{238}_{92}U -&gt;[\\ce{+15n}][6 \\beta^-] ^{253}_{98}Cf -&gt;[\\beta^-] ^{253}_{99}Es\n&lt;/chem&gt;\nSome 238U atoms, however, could absorb two additional neutrons (for a total of 17), resulting in 255Es, as well as in the 255Fm isotope of another new element, fermium. The discovery of the new elements and the associated new data on multiple neutron capture were initially kept secret on the orders of the U.S.\u00a0military until 1955 due to Cold War tensions and competition with Soviet Union in nuclear technologies. However, the rapid capture of so many neutrons would provide needed direct experimental confirmation of the so-called r-process multiple neutron absorption needed to explain the cosmic nucleosynthesis (production) of certain heavy chemical elements (heavier than nickel) in supernova explosions, before beta decay. Such a process is needed to explain the existence of many stable elements in the universe.\nMeanwhile, isotopes of element 99 (as well as of new element 100, fermium) were produced in the Berkeley and Argonee laboratories, in a nuclear reaction between nitrogen-14 and uranium-238, and later by intense neutron irradiation of plutonium or californium:\nThese results were published in several articles in 1954 with the disclaimer that these were not the first studies that had been carried out on the elements. The Berkeley team also reported some results on the chemical properties of einsteinium and fermium. The \"Ivy Mike\" results were declassified and published in 1955.\nIn their discovery of the elements 99 and 100, the American teams had competed with a group at the Nobel Institute for Physics, Stockholm, Sweden. In late 1953 \u2013 early 1954, the Swedish group succeeded in the synthesis of light isotopes of element 100, in particular 250Fm, by bombarding uranium with oxygen nuclei. These results were also published in 1954. Nevertheless, the priority of the Berkeley team was generally recognized, as its publications preceded the Swedish article, and they were based on the previously undisclosed results of the 1952 thermonuclear explosion; thus the Berkeley team was given the privilege to name the new elements. As the effort which had led to the design of \"Ivy Mike\" was codenamed Project PANDA, element 99 had been jokingly nicknamed \"Pandemonium\" but the official names suggested by the Berkeley group derived from two prominent scientists, Albert Einstein and Enrico Fermi: \"We suggest for the name for the element with the atomic number 99, einsteinium (symbol E) after Albert Einstein and for the name for the element with atomic number 100, fermium (symbol Fm), after Enrico Fermi.\" Both Einstein and Fermi died between the time the names were originally proposed and when they were announced. The discovery of these new elements was announced by Albert Ghiorso at the first Geneva Atomic Conference held on 8\u201320 August 1955. The symbol for einsteinium was first given as \"E\" and later changed to \"Es\" by IUPAC.\nCharacteristics.\nPhysical.\nEinsteinium is a synthetic, silvery-white, radioactive metal. In the periodic table, it is located to the right of the actinide californium, to the left of the actinide fermium and below the lanthanide holmium with which it shares many similarities in physical and chemical properties. Its density of 8.84\u00a0g/cm3 is lower than that of californium (15.1\u00a0g/cm3) and is nearly the same as that of holmium (8.79\u00a0g/cm3), despite atomic einsteinium being much heavier than holmium. The melting point of einsteinium (860\u00a0\u00b0C) is also relatively low \u2013 below californium (900\u00a0\u00b0C), fermium (1527\u00a0\u00b0C) and holmium (1461\u00a0\u00b0C). Einsteinium is a soft metal, with the bulk modulus of only 15 GPa, which value is one of the lowest among non-alkali metals.\nContrary to the lighter actinides californium, berkelium, curium and americium which crystallize in a double hexagonal structure at ambient conditions, einsteinium is believed to have a face-centered cubic (\"fcc\") symmetry with the space group \"Fm\"\"m\" and the lattice constant \"a\" = 575 pm. However, there is a report of room-temperature hexagonal einsteinium metal with \"a\" = 398 pm and \"c\" = 650 pm, which converted to the \"fcc\" phase upon heating to 300\u00a0\u00b0C.\nThe self-damage induced by the radioactivity of einsteinium is so strong that it rapidly destroys the crystal lattice, and the energy release during this process, 1000 watts per gram of 253Es, induces a visible glow. These processes may contribute to the relatively low density and melting point of einsteinium. Further, owing to the small size of the available samples, the melting point of einsteinium was often deduced by observing the sample being heated inside an electron microscope. Thus, the surface effects in small samples could reduce the melting point value.\nThe metal is trivalent and has a noticeably high volatility. In order to reduce the self-radiation damage, most measurements of solid einsteinium and its compounds are performed right after thermal annealing. Also, some compounds are studied under the atmosphere of the reductant gas, for example H2O+HCl for EsOCl so that the sample is partly regrown during its decomposition.\nApart from the self-destruction of solid einsteinium and its compounds, other intrinsic difficulties in studying this element include scarcity \u2013 the most common 253Es isotope is available only once or twice a year in sub-milligram amounts \u2013 and self-contamination due to rapid conversion of einsteinium to berkelium and then to californium at a rate of about 3.3% per day:\n^{253}_{99}Es -&gt;[\\alpha][20 \\ce{d}] ^{249}_{97}Bk -&gt;[\\beta^-][314 \\ce{d}] ^{249}_{98}Cf\n&lt;/chem&gt;\nThus, most einsteinium samples are contaminated, and their intrinsic properties are often deduced by extrapolating back experimental data accumulated over time. Other experimental techniques to circumvent the contamination problem include selective optical excitation of einsteinium ions by a tunable laser, such as in studying its luminescence properties.\nMagnetic properties have been studied for einsteinium metal, its oxide and fluoride. All three materials showed Curie\u2013Weiss paramagnetic behavior from liquid helium to room temperature. The effective magnetic moments were deduced as for Es2O3 and for the EsF3, which are the highest values among actinides, and the corresponding Curie temperatures are 53 and 37 K.\nChemical.\nLike all actinides, einsteinium is rather reactive. Its trivalent oxidation state is most stable in solids and aqueous solution where it induces a pale pink color. The existence of divalent einsteinium is firmly established, especially in the solid phase; such +2 state is not observed in many other actinides, including protactinium, uranium, neptunium, plutonium, curium and berkelium. Einsteinium(II) compounds can be obtained, for example, by reducing einsteinium(III) with samarium(II) chloride. The oxidation state +4 was postulated from vapor studies and is as yet uncertain.\nIsotopes.\nNineteen isotopes and three nuclear isomers are known for einsteinium, with mass numbers ranging from 240 to 257. All are radioactive and the most stable nuclide, 252Es, has a half-life of 471.7 days. The next most stable isotopes are 254Es (half-life 275.7 days), 255Es (39.8 days), and 253Es (20.47 days). All of the remaining isotopes have half-lives shorter than 40 hours, and most of them decay within fewer than 30 minutes. Of the three nuclear isomers, the most stable is 254mEs with a half-life of 39.3 hours.\nNuclear fission.\nEinsteinium has a high rate of nuclear fission that results in a low critical mass for a sustained nuclear chain reaction. This mass is 9.89 kilograms for a bare sphere of 254Es isotope, and can be lowered to 2.9 kilograms by adding a 30-centimeter-thick steel neutron reflector, or even to 2.26 kilograms with a 20-cm-thick reflector made of water. However, even this small critical mass greatly exceeds the total amount of einsteinium isolated thus far, especially of the rare 254Es isotope.\nNatural occurrence.\nBecause of the short half-life of all isotopes of einsteinium, any primordial einsteinium\u2014that is, einsteinium that could possibly have been present on the Earth during its formation\u2014has long since decayed. Synthesis of einsteinium from naturally-occurring actinides uranium and thorium in the Earth's crust requires multiple neutron capture, which is an extremely unlikely event. Therefore, all terrestrial einsteinium is produced in scientific laboratories, high-power nuclear reactors, or in nuclear weapons tests, and is present only within a few years from the time of the synthesis.\nThe transuranic elements from americium to fermium, including einsteinium, occurred naturally in the natural nuclear fission reactor at Oklo, but no longer do so.\nEinsteinium was observed in Przybylski's Star in 2008.\nSynthesis and extraction.\nEinsteinium is produced in minute quantities by bombarding lighter actinides with neutrons in dedicated high-flux nuclear reactors. The world's major irradiation sources are the 85-megawatt High Flux Isotope Reactor (HFIR) at the Oak Ridge National Laboratory in Tennessee, U.S., and the SM-2 loop reactor at the Research Institute of Atomic Reactors (NIIAR) in Dimitrovgrad, Russia, which are both dedicated to the production of transcurium (\"Z\"\u00a0&gt; 96) elements. These facilities have similar power and flux levels, and are expected to have comparable production capacities for transcurium elements, although the quantities produced at NIIAR are not widely reported. In a \"typical processing campaign\" at Oak Ridge, tens of grams of curium are irradiated to produce decigram quantities of californium, milligram quantities of berkelium (249Bk) and einsteinium and picogram quantities of fermium.\nThe first microscopic sample of 253Es sample weighing about 10 nanograms was prepared in 1961 at HFIR. A special magnetic balance was designed to estimate its weight. Larger batches were produced later starting from several kilograms of plutonium with the einsteinium yields (mostly 253Es) of 0.48 milligrams in 1967\u20131970, 3.2 milligrams in 1971\u20131973, followed by steady production of about 3 milligrams per year between 1974 and 1978. These quantities however refer to the integral amount in the target right after irradiation. Subsequent separation procedures reduced the amount of isotopically pure einsteinium roughly tenfold.\nLaboratory synthesis.\nHeavy neutron irradiation of plutonium results in four major isotopes of einsteinium: 253Es (\u03b1-emitter with half-life of 20.47 days and with a spontaneous fission half-life of 7\u00d7105 years); 254\"m\"Es (\u03b2-emitter with half-life of 39.3 hours), 254Es (\u03b1-emitter with half-life of about 276 days) and 255Es (\u03b2-emitter with half-life of 39.8 days). An alternative route involves bombardment of uranium-238 with high-intensity nitrogen or oxygen ion beams.\nEinsteinium-247 (half-life 4.55 minutes) was produced by irradiating americium-241 with carbon or uranium-238 with nitrogen ions. The latter reaction was first realized in 1967 in Dubna, Russia, and the involved scientists were awarded the Lenin Komsomol Prize.\nThe isotope 248Es was produced by irradiating 249Cf with deuterium ions. It mainly decays by emission of electrons to 248Cf with a half-life of minutes, but also releases \u03b1-particles of 6.87\u00a0MeV energy, with the ratio of electrons to \u03b1-particles of about 400.\nThe heavier isotopes 249Es, 250Es, 251Es and 252Es were obtained by bombarding 249Bk with \u03b1-particles. One to four neutrons are liberated in this process making possible the formation of four different isotopes in one reaction.\nEinsteinium-253 was produced by irradiating a 0.1\u20130.2 milligram 252Cf target with a thermal neutron flux of (2\u20135)\u00d71014 neutrons\u00b7cm\u22122\u00b7s\u22121 for 500\u2013900 hours:\nIn 2020, scientists at the Oak Ridge National Laboratory were able to create 233 nanograms of 254Es, a new world record. This allowed some chemical properties of the element to be studied for the first time.\nSynthesis in nuclear explosions.\nThe analysis of the debris at the 10-megaton \"Ivy Mike\" nuclear test was a part of long-term project. One of the goals of which was studying the efficiency of production of transuranium elements in high-power nuclear explosions. The motivation for these experiments was that synthesis of such elements from uranium requires multiple neutron capture. The probability of such events increases with the neutron flux, and nuclear explosions are the most powerful man-made neutron sources, providing densities of the order 1023 neutrons/cm2 within a microsecond, or about 1029 neutrons/(cm2\u00b7s). In comparison, the flux of the HFIR reactor is 5 neutrons/(cm2\u00b7s). A dedicated laboratory was set up right at Enewetak Atoll for preliminary analysis of debris, as some isotopes could have decayed by the time the debris samples reached the mainland U.S. The laboratory was receiving samples for analysis as soon as possible, from airplanes equipped with paper filters which flew over the atoll after the tests. Whereas it was hoped to discover new chemical elements heavier than fermium, none of these were found even after a series of megaton explosions conducted between 1954 and 1956 at the atoll.\nThe atmospheric results were supplemented by the underground test data accumulated in the 1960s at the Nevada Test Site, as it was hoped that powerful explosions conducted in confined space might result in improved yields and heavier isotopes. Apart from traditional uranium charges, combinations of uranium with americium and thorium have been tried, as well as a mixed plutonium-neptunium charge, but they were less successful in terms of yield and was attributed to stronger losses of heavy isotopes due to enhanced fission rates in heavy-element charges. Product isolation was problematic as the explosions were spreading debris through melting and vaporizing the surrounding rocks at depths of 300\u2013600 meters. Drilling to such depths to extract the products was both slow and inefficient in terms of collected volumes.\nAmong the nine underground tests that were carried between 1962 and 1969, the last one was the most powerful and had the highest yield of transuranium elements. Milligrams of einsteinium that would normally take a year of irradiation in a high-power reactor, were produced within a microsecond. However, the major practical problem of the entire proposal was collecting the radioactive debris dispersed by the powerful blast. Aircraft filters adsorbed only about 4 of the total amount, and collection of tons of corals at Enewetak Atoll increased this fraction by only two orders of magnitude. Extraction of about 500 kilograms of underground rocks 60 days after the Hutch explosion recovered only about 1 of the total charge. The amount of transuranium elements in this 500-kg batch was only 30 times higher than in a 0.4\u00a0kg rock picked up 7 days after the test which demonstrated the highly non-linear dependence of the transuranium elements yield on the amount of retrieved radioactive rock. Shafts were drilled at the site before the test in order to accelerate sample collection after explosion, so that explosion would expel radioactive material from the epicenter through the shafts and to collecting volumes near the surface. This method was tried in two tests and instantly provided hundreds kilograms of material, but with actinide concentration 3 times lower than in samples obtained after drilling. Whereas such method could have been efficient in scientific studies of short-lived isotopes, it could not improve the overall collection efficiency of the produced actinides.\nAlthough no new elements (apart from einsteinium and fermium) could be detected in the nuclear test debris, and the total yields of transuranium elements were disappointingly low, these tests did provide significantly higher amounts of rare heavy isotopes than previously available in laboratories.\nSeparation.\nSeparation procedure of einsteinium depends on the synthesis method. In the case of light-ion bombardment inside a cyclotron, the heavy ion target is attached to a thin foil, and the generated einsteinium is simply washed off the foil after the irradiation. However, the produced amounts in such experiments are relatively low. The yields are much higher for reactor irradiation, but there, the product is a mixture of various actinide isotopes, as well as lanthanides produced in the nuclear fission decays. In this case, isolation of einsteinium is a tedious procedure which involves several repeating steps of cation exchange, at elevated temperature and pressure, and chromatography. Separation from berkelium is important, because the most common einsteinium isotope produced in nuclear reactors, 253Es, decays with a half-life of only 20 days to 249Bk, which is fast on the timescale of most experiments. Such separation relies on the fact that berkelium easily oxidizes to the solid +4 state and precipitates, whereas other actinides, including einsteinium, remain in their +3 state in solutions.\nSeparation of trivalent actinides from lanthanide fission products can be done by a cation-exchange resin column using a 90% water/10% ethanol solution saturated with hydrochloric acid (HCl) as eluant. It is usually followed by anion-exchange chromatography using 6 molar HCl as eluant. A cation-exchange resin column (Dowex-50 exchange column) treated with ammonium salts is then used to separate fractions containing elements 99, 100 and 101. These elements can be then identified simply based on their elution position/time, using \u03b1-hydroxyisobutyrate solution (\u03b1-HIB), for example, as eluant.\nSeparation of the 3+ actinides can also be achieved by solvent extraction chromatography, using bis-(2-ethylhexyl) phosphoric acid (abbreviated as HDEHP) as the stationary organic phase, and nitric acid as the mobile aqueous phase. The actinide elution sequence is reversed from that of the cation-exchange resin column. The einsteinium separated by this method has the advantage to be free of organic complexing agent, as compared to the separation using a resin column.\nPreparation of the metal.\nEinsteinium is highly reactive and therefore strong reducing agents are required to obtain the pure metal from its compounds. This can be achieved by reduction of einsteinium(III) fluoride with metallic lithium:\nHowever, owing to its low melting point and high rate of self-radiation damage, einsteinium has high vapor pressure, which is higher than that of lithium fluoride. This makes this reduction reaction rather inefficient. It was tried in the early preparation attempts and quickly abandoned in favor of reduction of einsteinium(III) oxide with lanthanum metal:\nChemical compounds.\nOxides.\nEinsteinium(III) oxide (Es2O3) was obtained by burning einsteinium(III) nitrate. It forms colorless cubic crystals, which were first characterized from microgram samples sized about 30 nanometers. Two other phases, monoclinic and hexagonal, are known for this oxide. The formation of a certain Es2O3 phase depends on the preparation technique and sample history, and there is no clear phase diagram. Interconversions between the three phases can occur spontaneously, as a result of self-irradiation or self-heating. The hexagonal phase is isotypic with lanthanum(III) oxide where the Es3+ ion is surrounded by a 6-coordinated group of O2\u2212 ions.\nHalides.\nEinsteinium halides are known for the oxidation states +2 and +3. The most stable state is +3 for all halides from fluoride to iodide.\nEinsteinium(III) fluoride (EsF3) can be precipitated from einsteinium(III) chloride solutions upon reaction with fluoride ions. An alternative preparation procedure is to exposure einsteinium(III) oxide to chlorine trifluoride (ClF3) or F2 gas at a pressure of 1\u20132 atmospheres and a temperature between 300 and 400\u00a0\u00b0C. The EsF3 crystal structure is hexagonal, as in californium(III) fluoride (CfF3) where the Es3+ ions are 8-fold coordinated by fluorine ions in a bicapped trigonal prism arrangement.\nEinsteinium(III) chloride (EsCl3) can be prepared by annealing einsteinium(III) oxide in the atmosphere of dry hydrogen chloride vapors at about 500\u00a0\u00b0C for some 20 minutes. It crystallizes upon cooling at about 425\u00a0\u00b0C into an orange solid with a hexagonal structure of UCl3 type, where einsteinium atoms are 9-fold coordinated by chlorine atoms in a tricapped trigonal prism geometry. Einsteinium(III) bromide (EsBr3) is a pale-yellow solid with a monoclinic structure of AlCl3 type, where the einsteinium atoms are octahedrally coordinated by bromine (coordination number 6).\nThe divalent compounds of einsteinium are obtained by reducing the trivalent halides with hydrogen:\nEinsteinium(II) chloride (EsCl2), einsteinium(II) bromide (EsBr2), and einsteinium(II) iodide (EsI2) have been produced and characterized by optical absorption, with no structural information available yet.\nKnown oxyhalides of einsteinium include EsOCl, EsOBr and EsOI. These salts are synthesized by treating a trihalide with a vapor mixture of water and the corresponding hydrogen halide: for example, EsCl3 + H2O/HCl to obtain EsOCl.\nOrganoeinsteinium compounds.\nThe high radioactivity of einsteinium has a potential use in radiation therapy, and organometallic complexes have been synthesized in order to deliver einsteinium atoms to an appropriate organ in the body. Experiments have been performed on injecting einsteinium citrate (as well as fermium compounds) to dogs. Einsteinium(III) was also incorporated into beta-diketone chelate complexes, since analogous complexes with lanthanides previously showed strongest UV-excited luminescence among metallorganic compounds. When preparing einsteinium complexes, the Es3+ ions were 1000 times diluted with Gd3+ ions. This allowed reducing the radiation damage so that the compounds did not disintegrate during the period of 20 minutes required for the measurements. The resulting luminescence from Es3+ was much too weak to be detected. This was explained by the unfavorable relative energies of the individual constituents of the compound that hindered efficient energy transfer from the chelate matrix to Es3+ ions. Similar conclusion was drawn for other actinides americium, berkelium and fermium.\nLuminescence of Es3+ ions was however observed in inorganic hydrochloric acid solutions as well as in organic solution with di(2-ethylhexyl)orthophosphoric acid. It shows a broad peak at about 1064 nanometers (half-width about 100\u00a0nm) which can be resonantly excited by green light (ca. 495\u00a0nm wavelength). The luminescence has a lifetime of several microseconds and the quantum yield below 0.1%. The relatively high, compared to lanthanides, non-radiative decay rates in Es3+ were associated with the stronger interaction of f-electrons with the inner Es3+ electrons.\nApplications.\nThere is almost no use for any isotope of einsteinium outside basic scientific research aiming at production of higher transuranic elements and transactinides.\nIn 1955, mendelevium was synthesized by irradiating a target consisting of about 109 atoms of 253Es in the 60-inch cyclotron at Berkeley Laboratory. The resulting 253Es(\u03b1,n)256Md reaction yielded 17 atoms of the new element with the atomic number of 101.\nThe rare isotope einsteinium-254 is favored for production of ultraheavy elements because of its large mass, relatively long half-life of 270 days, and availability in significant amounts of several micrograms. Hence einsteinium-254 was used as a target in the attempted synthesis of ununennium (element 119) in 1985 by bombarding it with calcium-48 ions at the superHILAC linear accelerator at Berkeley, California. No atoms were identified, setting an upper limit for the cross section of this reaction at 300 nanobarns.\nEinsteinium-254 was used as the calibration marker in the chemical analysis spectrometer (\"alpha-scattering surface analyzer\") of the Surveyor 5 lunar probe. The large mass of this isotope reduced the spectral overlap between signals from the marker and the studied lighter elements of the lunar surface.\nSafety.\nMost of the available einsteinium toxicity data originates from research on animals. Upon ingestion by rats, only about 0.01% einsteinium ends in the blood stream. From there, about 65% goes to the bones, where it would remain for about 50 years if not for its radioactive decay, not to speak of the 3-years maximum lifespan of rats, 25% to the lungs (biological half-life about 20 years, although this is again rendered irrelevant by the short half-lives of einsteinium isotopes), 0.035% to the testicles or 0.01% to the ovaries \u2013 where einsteinium stays indefinitely. About 10% of the ingested amount is excreted. The distribution of einsteinium over the bone surfaces is uniform and is similar to that of plutonium."}
{"id": "9480", "revid": "35936988", "url": "https://en.wikipedia.org/wiki?curid=9480", "title": "Edmund Stoiber", "text": "Edmund R\u00fcdiger Stoiber (born 28 September 1941) is a German politician who served as the 16th Minister President of the state of Bavaria between 1993 and 2007 and chairman of the Christian Social Union (CSU) between 1999 and 2007. In 2002, he ran for the office of Chancellor of Germany in the federal election, but in one of the narrowest elections in German history lost against Gerhard Schr\u00f6der. On 18 January 2007, he announced his decision to step down from the posts of minister-president and party chairman by 30 September, after having been under fire in his own party for weeks.\nEarly life.\nStoiber was born in Oberaudorf in the district of Rosenheim in Bavaria. Prior to entering politics in 1974 and serving in the Bavarian parliament, he was a lawyer and worked at the University of Regensburg.\nEducation and profession.\nStoiber attended the Ignaz-G\u00fcnther-Gymnasium in Rosenheim, where he received his \"Abitur\" (high school diploma) in 1961, although he had to repeat one year for failing in Latin. His military service was with the 1st Gebirgsdivision (mountain infantry division) in Mittenwald and Bad Reichenhall and was cut-short due to a knee injury. Then Stoiber studied at Ludwig Maximilians University of Munich political science and then, from fall 1962, law. In 1967, he passed the state law exam and then worked at the University of Regensburg in criminal law and Eastern European law. He was awarded a doctorate of jurisprudence, and then in 1971 passed the second state examination with distinction.\nIn 1971, Stoiber joined the Bavarian State Ministry of Development and Environment.\nPolitical career.\nIn 1978, Stoiber was elected secretary general of the CSU, a post he held until 1982/83. In this capacity, he served as campaign manager of Franz-Josef Strauss, the first Bavarian leader to run for the chancellorship, in the 1980 national elections. From 1982 to 1986 he served as deputy to the Bavarian secretary of the state and then, in the position of State Minister, led the State Chancellery from 1982 to 1988. From 1988 to 1993 he served as State Minister of the Interior.\nMinister-President of Bavaria, 1993\u20132007.\nIn May 1993, the Landtag of Bavaria, the state's parliament, elected Stoiber as Minister-President succeeding Max Streibl. He came to power amid a political crisis involving a sex scandal, surrounding a contender for the state premiership. Upon taking office, he nominated Strauss' daughter Monika Hohlmeier as State Minister for Education and Cultural Affairs.\nIn his capacity as Minister-President, Stoiber served as President of the Bundesrat in 1995/96. In 1998, he also succeeded Theo Waigel as chairman of the CSU.\nDuring Stoiber's 14 years leading Bavaria, the state solidified its position as one of Germany's richest. Already by 1998, under his leadership, the state had privatized more than $3 billion worth of state-owned businesses and used that money to invest in new infrastructure and provide venture capital for new companies. He was widely regarded a central figure in building one of Europe's most powerful regional economies, attracting thousands of hi-tech, engineering and media companies and reducing unemployment to half the national average.\nCandidate for Chancellor, 2002.\nIn 2002, Stoiber politically outmaneuvered CDU chairwoman, Angela Merkel, and was declared the CDU/CSU's candidate for the office of chancellor by practically the entire leadership of the CSU's sister party CDU, challenging Gerhard Schr\u00f6der. At that time, Merkel had generally been seen as a transitional chair and was strongly opposed by the CDU's male leaders, often called the party's \"crown princes\".\nIn the run up to the 2002 national elections, the CSU/CDU held a huge lead in the opinion polls and Stoiber famously remarked that \"...this election is like a football match where it's the second half and my team is ahead by 2\u20130.\" However, on election day things had changed. The SPD had mounted a huge comeback, and the CDU/CSU was narrowly defeated (though both the SPD and CDU/CSU had 38.5% of the vote, the SPD was ahead by a small 6,000 vote margin, winning 251 seats to the CDU/CSU's 248). The election was one of modern Germany's closest votes.\nGerhard Schr\u00f6der was re-elected as chancellor by the parliament in a coalition with the Greens, who had increased their vote share marginally. Many commentators faulted Stoiber's reaction to the floods in eastern Germany, in the run-up to the election, as a contributory factor in his party's poor electoral result and defeat. In addition, Schr\u00f6der distinguished himself from his opponent by taking an active stance against the upcoming United States-led Iraq War. His extensive campaigning on this stance was widely seen as swinging the election to the SPD in the weeks running up to the election.\nLater political career.\nStoiber subsequently led the CSU to an absolute majority in the 2003 Bavarian state elections, for the third time in a row, winning this time 60.7% of the votes and a two-thirds majority in the Landtag. This was the widest margin ever achieved by a German party in any state.\nBetween 2003 and 2004, Stoiber served as co-chair (alongside Franz M\u00fcntefering) of the First Commission on the modernization of the federal state (\"F\u00f6deralismuskommission I\"), which had been established to reform the division of powers between federal and state authorities in Germany. In February 2004, he became a candidate of Jacques Chirac and Gerhard Schr\u00f6der for the presidency of the European Commission but he decided not to run for this office.\nStoiber had ambitions to run again for the chancellorship, but Merkel secured the nomination, and in November 2005 she won the general election. He was slated to join Merkel's first grand coalition cabinet as Economics minister. However, on 1 November 2005, he announced his decision to stay in Bavaria, due to personnel changes on the SPD side of the coalition (Franz M\u00fcntefering resigned as SPD chairman) and an unsatisfactory apportionment of competences between himself and designated Science minister Annette Schavan. Stoiber also resigned his seat in the 16th Bundestag, being a member from 18 October to 8 November.\nSubsequently, criticism grew in the CSU, where other politicians had to scale back their ambitions after Stoiber's decision to stay in Bavaria. On 18 January 2007, he announced his decision to stand down from the posts of minister-president and party chairman by 30 September. G\u00fcnther Beckstein, then Bavarian state minister of the interior, succeeded him as minister-president and Erwin Huber as party chairman, defeating Horst Seehofer at a convention at 18 September 2007 with 58,1% of the votes. Both Beckstein and Huber resigned after the 2008 state elections, in which the CSU vote dropped to 43,4% and the party had to form a coalition with another party for the first time since 1966.\nLife after politics.\nStoiber was first appointed in 2007 as a special adviser to then-European Commission President Jos\u00e9 Manuel Barroso to chair the \"High level group on administrative burdens\", made up of national experts, NGOs, business and industry organizations. Quickly nicknamed the \"Stoiber Group\", it produced a report in July 2014 with several proposals on streamlining the regulatory process. Stoiber was re-appointed in December 2014 by Jean-Claude Juncker to the same role, from which he resigned after one year in late 2015.\nSince his retirement from German politics in 2007, Stoiber has worked as a lawyer and held paid and unpaid positions, including:\nStoiber was a CSU delegate to the Federal Convention for the purpose of electing the President of Germany in 2017.\nPolitical positions.\nForeign policy.\nIn his capacity as Minister-President, Stoiber made 58 foreign trips, including to China (1995, 2003), Israel (2001), Egypt (2001), India (2004, 2007) and South Korea (2007).\nIn 2002, Stoiber publicly expressed support for the United States in their policy toward Iraq. During his election campaign, he made clear his opposition to war, and his support for the introduction of weapons inspectors to Iraq without preconditions as a way of avoiding war, and he criticized Schr\u00f6der for harming the German-American alliance by not calling President George W. Bush and discussing the issue privately. He also attacked German Foreign Minister Joschka Fischer for his criticism of the U.S. position.\nStoiber is known for backing Vladimir Putin and there have been comparisons to Gerhard Schr\u00f6der. One author called Stoiber a \"Moscow's Trojan Horse\". Putin is known to have given Stoiber \"extreme forms of flattery\" and privileges such as a private dinner at Putin's residence outside Moscow.\nEuropean integration.\nStoiber has been said to be skeptical of Germany's decision to adopt the euro. In 1997, he joined the ministers-president of two other German states, Kurt Biedenkopf and Gerhard Schr\u00f6der, in making the case for a five-year delay in Europe's currency union. When the European Commission recommended that Greece be allowed to join the eurozone in 1998, he demanded that the country be barred from adopting the common currency for several years instead. He is a staunch opponent of Turkey's integration into the European Union, claiming that its non-Christian culture would dilute the Union.\nAt the same time, Stoiber has repeatedly insisted he is a \"good European\" who is keen, for instance, on forging an EU-wide foreign policy, replete with a single European army. Earlier, in 1993, he had told German newspapers: \"I want a simple confederation. That means the nation-states maintain their dominant role, at least as far as internal matters are concerned.\"\nEconomic policy.\nWhile the conservative wing of the German political spectrum, primarily formed of the CDU and CSU, enjoys considerable support, this support tends to be less extended to Stoiber. He enjoys considerably more support in his home state of Bavaria than in the rest of Germany, where CDU chairwoman Angela Merkel is more popular. This has its reasons: Merkel supports a kind of fiscal conservatism, but a more liberal social policy. Stoiber, on the other hand, favors a more conservative approach to both fiscal and social matters, and while this ensures him the religious vote, strongest in Bavaria, it has weakened his support at the national level.\nIn 2005, Stoiber successfully lobbied Novartis, the Swiss pharmaceuticals group, to move the headquarters of its Sandoz subsidiary to Munich, making it one of Europe's highest-profile corporate relocations that year as well as a significant boost to Stoiber's attempts to build up Bavaria as a pharmaceuticals and biotechnology center.\nDuring his time as Minister-President of Bavaria, Stoiber pushed for the construction of a roughly 40-kilometer high-speed magnetic-levitation link from Munich's main station to its airport, to be built by Transrapid International, a consortium including ThyssenKrupp and Munich-based Siemens. After he left office, the German federal government abandoned the plans in 2008 because of spiraling costs of as much as \u20ac3.4 billion.\nDomestic policy.\nStoiber, as a minister in the state of Bavaria, was widely known for advocating a reduction in the number of asylum seekers Germany accepts, something that prompted critics to label him xenophobic, anti-Turkish and anti-Islam. In the late 1990s, he criticized the incoming Chancellor Gerhard Schr\u00f6der for saying that he would work hard in the interest of Germans \"and\" people living in Germany. Stoiber's remarks drew heavy criticism in the press.\nWhen Germany's Federal Constitutional Court decided in 1995 that a Bavarian law requiring a crucifix to be hung in each of the state's 40,000 classrooms was unconstitutional, Stoiber said he would not order the removal of crucifixes \"for the time being\", and asserted that he was under no obligation to remove them in schools where parents unanimously opposed such action.\nDuring his 2002 election campaign, Stoiber indicated he would not ban same-sex marriages\u2014sanctioned by the Schr\u00f6der government\u2014a policy he had vehemently objected to when it was introduced.\nMedia policy.\nStoiber has been a staunch advocate of changes in German law that would give more power to owners of private TV channels. In 1995, he publicly called for the abolition of Germany's public television service ARD and a streamlining of its regional services, adding that he and Minister-President Kurt Biedenkopf of Saxony would break the contract ARD has with regional governments if reforms were not undertaken. However, when European Commissioner for Competition Karel van Miert unveiled ideas for reforming the rules governing the financing of public service broadcasters in 1998, Stoiber led the way in rejecting moves to reform established practice.\nControversies.\nComments on East Germany.\nDuring the run-up to the German general election in 2005, which was held ahead of schedule, Stoiber created controversy through a campaign speech held in the beginning of August 2005 in the federal state of Baden-W\u00fcrttemberg. He said, \"I do not accept that the East [of Germany] will again decide who will be Germany's chancellor. It cannot be allowed that the frustrated determine Germany's fate.\" People in the new federal states of Germany (the former German Democratic Republic) were offended by Stoiber's remarks. While the CSU attempted to portray them as \"misinterpreted\", Stoiber created further controversy when he claimed that \"if it was like Bavaria everywhere, there wouldn't be any problems. Unfortunately, not everyone in Germany is as intelligent as in Bavaria.\" The tone of the comments was exacerbated by a perception by some within Germany of the state of Bavaria as \"arrogant\".\nMany, including members of the CDU, attribute Stoiber's comments and behavior as a contributing factor to the CDU's losses in the 2005 general election. He was accused by many in the CDU/CSU of offering \"half-hearted\" support to Angela Merkel, with some even accusing him of being reluctant to support a female candidate from the East. (This also contrasted unfavorably with Merkel's robust support for his candidacy in the 2002 election.) He has insinuated that votes were lost because of the choice of a female candidate. He came under heavy fire for these comments from press and politicians alike, especially since he himself lost almost 10% of the Bavarian vote\u2014a dubious feat in itself as Bavarians tend to consistently vote conservatively. Nonetheless, a poll has suggested over 9% may have voted differently if the conservative candidate was a man from the West, although this does not clearly show if such a candidate would have gained or lost votes for the conservatives.\nBayernLB activities.\nWhen the Croatian National Bank turned down BayernLB's original bid to take over the local arm of Hypo Alpe-Adria-Bank International, this drew strong criticism from Stoiber, who said the decision was \"unacceptable\" and a \"severe strain\" for Bavaria's relations with Croatia. Croatia was seeking to join the European Union at the time. The central bank's board later reviewed and accepted BayernLB's offer of 1.6 billion euros. The investment in Hypo Group Alpe Adria was part of a series of ill-fated investments, which later forced BayernLB to take a 10 billion-euro bailout in the financial crisis.\nEuropean Commission job.\nIn September 2015, Emily O'Reilly, the European Ombudsman, received a complaint from two NGOs, Corporate Europe Observatory and Friends of the Earth, according to which Stoiber's appointment as special adviser on the Commission's better regulation agenda broke internal rules on appointments.\nPersonal life.\nStoiber is Roman Catholic. He is married to Karin Stoiber. They have three children: Constanze (1971), Veronica (1977), Dominic (1980) and five grandchildren: Johannes (1999), Benedikt (2001), Theresa Marie (2005), Ferdinand (2009) and another grandson (2011).\nStoiber is a keen football fan and serves as co-chairman on the advisory board of FC Bayern Munich. Before the 2002 election, FC Bayern general manager Uli Hoene\u00df expressed his support for Stoiber and the CSU. Football legend, former FC Bayern president and DFB vice president Franz Beckenbauer showed his support for Stoiber by letting him join the German national football team on their flight home from Japan after the 2002 FIFA World Cup.\nIn his youth, Stoiber played for local football side BCF Wolfratshausen.\nExternal links.\n "}
{"id": "9481", "revid": "1015722839", "url": "https://en.wikipedia.org/wiki?curid=9481", "title": "Erfurt", "text": "Erfurt ( , ; ) is the capital and largest city in the state of Thuringia, central Germany. It is located in the southern part of the Thuringian Basin, within the wide valley of the Gera river. It is located south-west of Leipzig, south-west of Berlin, north of Munich and north-east of Frankfurt. Together with a string of neighbouring cities Gotha, Weimar, Jena and others, Erfurt forms the central metropolitan corridor of Thuringia called \"Th\u00fcringer St\u00e4dtekette\" (German \"Thuringian city chain\") with over 500,000 inhabitants.\nErfurt's old town is one of the best preserved medieval city centres in Germany. Tourist attractions include the Kr\u00e4merbr\u00fccke (Merchants' bridge), the Old Synagogue, the ensemble of Erfurt Cathedral and \"Severikirche\" (St Severus's Church) and Petersberg Citadel, one of the largest and best preserved town fortresses in Europe. The city's economy is based on agriculture, horticulture and microelectronics. Its central location has led to it becoming a logistics hub for Germany and central Europe. Erfurt hosts the second-largest trade fair in eastern Germany (after Leipzig) as well as the public television children's channel KiKa.\nThe city is situated on the Via Regia, a medieval trade and pilgrims' road network. Modern day Erfurt is also a hub for ICE high speed trains and other German and European transport networks. Erfurt was first mentioned in 742, as Saint Boniface founded the diocese. Although the town did not belong to any of the Thuringian states politically, it quickly became the economic centre of the region and it was a member of the Hanseatic League. It was part of the Electorate of Mainz during the Holy Roman Empire, and later became part of the Kingdom of Prussia in 1802. From 1949 until 1990 Erfurt was part of the German Democratic Republic (East Germany).\nThe University of Erfurt was founded in 1379, making it the first university to be established within the geographic area which constitutes modern-day Germany. It closed in 1816 and was re-established in 1994, with the main modern campus on what was a teachers' training college. Martin Luther (1483\u20131546) was its most famous student, studying there from 1501 before entering St Augustine's Monastery in 1505. Other noted Erfurters include the medieval philosopher and mystic Meister Eckhart (c. 1260\u20131328), the Baroque composer Johann Pachelbel (1653\u20131706) and the sociologist Max Weber (1864\u20131920).\nHistory.\nPrehistory and antiquity.\nErfurt is an old Germanic settlement. The earliest evidence of human settlement dates from the prehistoric era; archaeological finds from the north of Erfurt revealed human traces from the paleolithic period, ca. 100,000 BCE.\nTo the west of Erfurt in Frienstedt existed, in the AD era, a big Germanic village, which was found during the construction of a highway. Where they also discovered the oldest Germanic word ever discovered in Central Germany written in runic script was found on a comb from a sacrificial shaft the word: \"kaba\". From Roman Times, however, they found 200 coins dating back to the 3rd century, plus 150 Roman ceramic fragments and more than 200 fibulae. Also 11 inhumation graves of the Ha\u00dfleben-Leuna group, which is an archeological cultural group.\nThe Melchendorf dig in the southern city part showed a settlement from the neolithic period. The Thuringii inhabited the Erfurt area ca. 480 and gave their name to Thuringia ca. 500.\nMiddle Age.\nThe town is first mentioned in 742 under the name of \"Erphesfurt\": in that year, Saint Boniface wrote to Pope Zachary to inform him that he had established three dioceses in central Germany, one of them \"in a place called Erphesfurt, which for a long time has been inhabited by pagan natives.\" All three dioceses (the other two were W\u00fcrzburg and B\u00fcraburg) were confirmed by Zachary the next year, though in 755 Erfurt was brought into the diocese of Mainz. That the place was populous already is borne out by archeological evidence, which includes 23 graves and six horse burials from the sixth and seventh centuries.\nThroughout the Middle Ages, Erfurt was an important trading town because of its location, near a ford across the Gera river. Together with the other five Thuringian woad towns of Gotha, Tennstedt, Arnstadt and Langensalza it was the centre of the German woad trade, which made those cities very wealthy. Erfurt was the junction of important trade routes: the Via Regia was one of the most used east\u2013west roads between France and Russia (via Frankfurt, Erfurt, Leipzig and Wroc\u0142aw) and another route in the north\u2013south direction was the connection between the Baltic Sea ports (e. g. L\u00fcbeck) and the potent upper Italian city-states like Venice and Milan.\nDuring the 10th and 11th centuries both the Emperor and the Electorate of Mainz held some privileges in Erfurt. The German kings had an important monastery on Petersberg hill and the Archbishops of Mainz collected taxes from the people. Around 1100, some people became free citizens by paying the annual \"\" (liberation tax), which marks a first step in becoming an independent city. During the 12th century, as a sign of more and more independence, the citizens built a city wall around Erfurt (in the area of today's ). After 1200, independence was fulfilled and a city council was founded in 1217; the town hall was built in 1275. In the following decades, the council bought a city-owned territory around Erfurt which consisted at its height of nearly 100 villages and castles and even another small town (S\u00f6mmerda). Erfurt became an important regional power between the Landgraviate of Thuringia around, the Electorate of Mainz to the west and the Electorate of Saxony to the east. Between 1306 and 1481, Erfurt was allied with the two other major Thuringian cities (M\u00fchlhausen and Nordhausen) in the Thuringian City Alliance and the three cities joined the Hanseatic League together in 1430. A peak in economic development was reached in the 15th century, when the city had a population of 20,000 making it one of the largest in Germany. Between 1432 and 1446, a second and higher city wall was established. In 1483, a first city fortress was built on Cyriaksburg hill in the southwestern part of the town.\nThe Jewish community of Erfurt was founded in the 11th century and became, together with Mainz, Worms and Speyer, one of the most influential in Germany. Their Old Synagogue is still extant and a museum today, as is the mikveh at Gera river near . In 1349, during the wave of Black Death Jewish persecutions across Europe, the Jews of Erfurt were rounded up, with more than 100 killed and the rest driven from the city. Before the persecution, a wealthy Jewish merchant buried his property in the basement of his house. In 1998, this treasure was found during construction works. The Erfurt Treasure with various gold and silver objects is shown in the exhibition in the synagogue today. Only a few years after 1349, the Jews moved back to Erfurt and founded a second community, which was disbanded by the city council in 1458.\nIn 1379, the University of Erfurt was founded. Together with the University of Cologne it was one of the first city-owned universities in Germany, while they were usually owned by the \"\". Some buildings of this old university are extant or restored in the \"Latin Quarter\" in the northern city centre (like , student dorms \"\" and others, the hospital and the church of the university). The university quickly became a hotspot of German cultural life in Renaissance humanism with scholars like Ulrich von Hutten, Helius Eobanus Hessus and Justus Jonas.\nIn the year 1184, Erfurt was the location of a notable accident called the \"Erfurter Latrinensturz\" ('Latrine fall'). King Henry VI held council in a building of the Erfurt Cathedral to negotiate peace between two of his vassals, Archbishop Konrad I of Mainz and Landgrave Ludwig III of Thuringia. The amassed weight of all the gathered men proved too heavy for the floor to bear, which collapsed. According to contemporary accounts, dozens of people fell to their death into the latrine pit below. Ludwig III, Konrad I and Henry VI survived the affair.\nEarly modern period.\nIn 1501 Martin Luther (1483 - 1546) moved to Erfurt and began his studies at the university. After 1505, he lived at St. Augustine's Monastery as a friar. In 1507 he was ordained as a priest in Erfurt Cathedral. He moved permanently to Wittenberg in 1511. Erfurt was an early adopter of the Protestant Reformation, in 1521.\nIn 1530, the city became one of the first in Europe to be officially bi-confessional with the Hammelburg Treaty. It kept that status through all the following centuries. The later 16th and the 17th century brought a slow economic decline of Erfurt. Trade shrank, the population was falling and the university lost its influence. The city's independence was endangered. In 1664, the city and surrounding area were brought under the dominion of the Electorate of Mainz and the city lost its independence. The Electorate built a huge fortress on Petersberg hill between 1665 and 1726 to control the city and instituted a governor to rule Erfurt.\nIn 1682 and 1683 Erfurt experienced the worst plague years in its history. In 1683 more than half of the population died because of the deadly disease.\nIn Erfurt witch-hunts are known from 1526 to 1705. Trial records are only incomplete. Twenty people were involved in witch trials and at least eight people died.\nDuring the late 18th century, Erfurt saw another cultural peak. Governor Karl Theodor Anton Maria von Dalberg had close relations with Johann Wolfgang von Goethe, Friedrich Schiller, Johann Gottfried Herder, Christoph Martin Wieland and Wilhelm von Humboldt, who often visited him at his court in Erfurt.\nErfurt during the Napoleonic Wars.\nErfurt became part of the Kingdom of Prussia in 1802, to compensate for territories Prussia lost to France on the Left Bank of the Rhine. In the Capitulation of Erfurt the city, its 12,000 Prussian and Saxon defenders under William VI, Prince of Orange-Nassau, 65 artillery pieces, and the Petersberg Citadel and Cyriaksburg Citadel were handed over to the French on 16 October 1806;&lt;ref name=\"Petre 1907/1993\"&gt;&lt;/ref&gt; At the time of the capitulation, Joachim Murat, Marshal of France, had about 16,000 troops near Erfurt. With the attachment of the Saxe-Weimar territory of Blankenhain, the city became part of the First French Empire in 1806 as the Principality of Erfurt, directly subordinate to Napoleon as an \"imperial state domain\" (), separate from the Confederation of the Rhine, which the surrounding Thuringian states had joined. Erfurt was administered by a civilian and military Senate (\"\") under a French governor, based in the , previously the seat of city's governor under the Electorate. Napoleon first visited the principality on 23 July 1807, inspecting the citadels and fortifications. In 1808, the Congress of Erfurt was held with Napoleon and Alexander I of Russia visiting the city.\nDuring their administration, the French introduced street lighting and a tax on foreign horses to pay for maintaining the road surface. The suffered under the French occupation, with its inventory being auctioned off to other local churches \u2013 including the organ, bells and even the tower of the chapel (\"\") \u2013 and the former monastery's library being donated to the University of Erfurt (and then to the Boineburg Library when the university closed in 1816). Similarly the Cyriaksburg Citadel was damaged by the French, with the city-side walls being partially dismantled in the hunt for imagined treasures from the convent, workers being paid from the sale of the building materials.\nIn 1811, to commemorate the birth of the Prince Imperial, a ceremonial column (') of wood and plaster was erected on the common. Similarly, the ' \u2013 a Greek-style temple topped by a winged victory with shield, sword and lance and containing a bust of Napoleon sculpted by Friedrich D\u00f6ll \u2013 was erected in the ' woods, including a grotto with fountain and flower beds, using a large pond (') from the , inaugurated with ceremony on 14 August 1811 after extravagant celebrations for Napoleon's birthday, which were repeated in 1812 with a concert in the conducted by Louis Spohr.\nWith the Sixth Coalition forming after French defeat in Russia, on 24 February 1813 Napoleon ordered the Petersburg Citadel to prepare for siege, visiting the city on 25 April to inspect the fortifications, in particular both Citadels. On 10 July 1813, Napoleon put , baron of the Empire, in charge of the defences of Erfurt. However, when the French decreed that 1000 men would be conscripted into the , the recruits were joined by other citizens in rioting on 19 July that led to 20 arrests, of whom 2 were sentenced to death by French court-martial; as a result, the French ordered the closure of all inns and alehouses.\nWithin a week of the Sixth Coalition's decisive victory at Leipzig (16\u201319 October 1813), however, Erfurt was besieged by Prussian, Austrian and Russian troops under the command of Prussian Lt Gen von Kleist. After a first capitulation signed by d'Alton on 20 December 1813 the French troops withdrew to the two fortresses of Petersberg and Cyriaksburg, allowing for the Coalition forces to march into Erfurt on 6 January 1814 to jubilant greetings; the ' ceremonial column was burned and destroyed as a symbol of the citizens' oppression under the French; similarly the ' was burned on 1 November 1813 and completely destroyed by Erfurters and their besiegers in 1814. After a call for volunteers 3 days later, 300 Erfurters joined the Coalition armies in France. Finally, in May 1814, the French capitulated fully, with 1,700 French troops vacating the Petersberg and Cyriaksburg fortresses. During the two and a half months of siege, the mortality rate rose in the city greatly; 1,564 Erfurt citizens died in 1813, around a thousand more than the previous year.\nAfter the Congress of Vienna, Erfurt was restored to Prussia on 21 June 1815, becoming the capital of one of the three districts (\"\") of the new Province of Saxony, but some southern and eastern parts of Erfurter lands joined Blankenhain in being transferred to the Grand Duchy of Saxe-Weimar-Eisenach the following September. Although enclosed by Thuringian territory in the west, south and east, the city remained part of the Prussian Province of Saxony until 1944.\nSince 1815.\nAfter the 1848 Revolution, many Germans desired to have a united national state. An attempt in this direction was the failed Erfurt Union of German states in 1850.\nThe Industrial Revolution reached Erfurt in the 1840s, when the Thuringian Railway connecting Berlin and Frankfurt was built. During the following years, many factories in different sectors were founded. One of the biggest was the \"Royal Gun Factory of Prussia\" in 1862. After the Unification of Germany in 1871, Erfurt moved from the southern border of Prussia to the centre of Germany, so the fortifications of the city were no longer needed. The demolition of the city fortifications in 1873 led to a construction boom in Erfurt, because it was now possible to build in the area formerly occupied by the city walls and beyond. Many public and private buildings emerged and the infrastructure (such as a tramway, hospitals, and schools) improved rapidly. The number of inhabitants grew from 40,000 around 1870 to 130,000 in 1914 and the city expanded in all directions.\nThe \"Erfurt Program\" was adopted by the Social Democratic Party of Germany during its congress at Erfurt in 1891.\nBetween the wars, the city kept growing. Housing shortages were fought with building programmes and social infrastructure was broadened according to the welfare policy in the Weimar Republic. The Great Depression between 1929 and 1932 led to a disaster for Erfurt, nearly one out of three became unemployed. Conflicts between far-left and far-right-oriented milieus increased and many inhabitants supported the new Nazi government and Adolf Hitler. Others, especially some communist workers, put up resistance against the new administration. In 1938, the new synagogue was destroyed during the . Jews lost their property and emigrated or were deported to Nazi concentration camps (together with many communists). In 1914, the company \"Topf and Sons\" began the manufacture of crematoria later becoming the market leader in this industry. Under the Nazis, \"JA Topf &amp; Sons\" supplied specially developed crematoria, ovens and associated plants to the Auschwitz-Birkenau, Buchenwald and Mauthausen-Gusen concentration camps. On 27 January 2011 a memorial and museum dedicated to the Holocaust victims was opened at the former company premises in Erfurt.\nDuring World War II, Erfurt experienced more than 27 British and American air raids, about 1600 civilians lost their lives. Bombed as a target of the Oil Campaign of World War II, Erfurt suffered only limited damage and was captured on 12 April 1945, by the US 80th Infantry Division. On 3 July, American troops left the city, which then became part of the Soviet Zone of Occupation and eventually of the German Democratic Republic (East Germany). In 1948, Erfurt became the capital of Thuringia, replacing Weimar. In 1952, the in the GDR were dissolved in favour of centralization under the new socialist government. Erfurt then became the capital of a new \" (district). In 1953, the of education was founded, followed by the of medicine in 1954, the first academic institutions in Erfurt since the closing of the university in 1816.\nOn 19 March 1970, the East and West German heads of government Willi Stoph and Willy Brandt met in Erfurt, the first such meeting since the division of Germany. During the 1970s and 1980s, as the economic situation in GDR worsened, many old buildings in city centre decayed, while the government fought against the housing shortage by building large settlements in the periphery. The Peaceful Revolution of 1989/1990 led to German reunification.\nWith the re-formation of the state of Thuringia in 1990, the city became the state capital. After reunification, a deep economic crisis occurred in Eastern Germany. Many factories closed and many people lost their jobs and moved to the former West Germany. At the same time, many buildings were redeveloped and the infrastructure improved massively. In 1994, the new university was opened, as was the Fachhochschule in 1991. Between 2005 and 2008, the economic situation improved as the unemployment rate decreased and new enterprises developed. In addition, the population began to increase once again.\nA school shooting occurred on 26 April 2002 at the Gutenberg-Gymnasium.\nSince the 1990s, organized crime has gained a foothold in Erfurt, with several mafia groups, including the Armenian mafia present in the city. Among other events, there has been a robbery and an arson attack targeting the gastronomy sector and in 2014 there was a shoot-out in an open street. The rocker group Hells Angels was also active in the city.\nGeography and demographics.\nTopography.\nErfurt is situated in the south of the Thuringian basin, a fertile agricultural area between the Harz mountains to the north and the Thuringian forest to the southwest. Whereas the northern parts of the city area are flat, the southern ones consist of hilly landscape up to 430 m of elevation. In this part lies the municipal forest of \" with beeches and oaks as main tree species. To the east and to the west are some non-forested hills so that the Gera river valley within the town forms a basin. North of the city are some gravel pits in operation, while others are abandoned, flooded and used as leisure areas.\nClimate.\nErfurt has a humid continental climate (Dfb) or an oceanic climate (\"Cfb\") according to the K\u00f6ppen climate classification system. Summers are warm and sometimes humid with average high temperatures of and lows of . Winters are relatively cold with average high temperatures of and lows of . The city's topography creates a microclimate caused by the location inside a basin with sometimes inversion in winter (quite cold nights under ) and inadequate air circulation in summer. Annual precipitation is only with moderate rainfall throughout the year. Light snowfall mainly occurs from December through February, but snow cover does not usually remain for long.\nAdministrative divisions.\nErfurt abuts the districts of S\u00f6mmerda (municipalities Witterda, Elxleben, Walschleben, Riethnordhausen, N\u00f6da, Alperstedt, Gro\u00dfrudestedt, Udestedt, Kleinm\u00f6lsen and Gro\u00dfm\u00f6lsen) in the north, Weimarer Land (municipalities Niederzimmern, Nohra, M\u00f6nchenholzhausen and Klettbach) in the east, Ilm-Kreis (municipalities Kirchheim, Rockhausen and Amt Wachsenburg) in the south and Gotha (municipalities Nesse-Apfelst\u00e4dt, Nottleben, Zimmernsupra and Bienst\u00e4dt) in the west.\nThe city itself is divided into 53 districts. The centre is formed by the district ' (old town) and the districts ' in the northwest, ' in the northeast, ' in the east, ' in the southeast, ' in the southwest and ' in the west. More former industrial districts are ' (incorporated in 1911), ' and ' in the north. Another group of districts is marked by Plattenbau settlements, constructed during the DDR period: ', ', ', ' and ' in the northern as well as ', ' and ' in the southern city parts.\nFinally, there are many villages with an average population of approximately 1,000 which were incorporated during the 20th century; however, they have mostly stayed rural to date:\nDemographics.\nAround the year 1500, the city had 18,000 inhabitants and was one of the largest cities in the Holy Roman Empire. The population then more or less stagnated until the 19th century. The population of Erfurt was 21,000 in 1820, and increased to 32,000 in 1847, the year of rail connection as industrialization began. In the following decades Erfurt grew up to 130,000 at the beginning of World War I and 190,000 inhabitants in 1950. A maximum was reached in 1988 with 220,000 persons. The bad economic situation in eastern Germany after the reunification resulted in a decline in population, which fell to 200,000 in 2002 before rising again to 206,000 in 2011. The average growth of population between 2009 and 2012 was approximately 0.68% p. a, whereas the population in bordering rural regions is shrinking with accelerating tendency. Suburbanization played only a small role in Erfurt. It occurred after reunification for a short time in the 1990s, but most of the suburban areas were situated within the administrative city borders.\nThe birth deficit was 200 in 2012, this is \u22121.0 per 1,000 inhabitants (Thuringian average: -4.5; national average: -2.4). The net migration rate was +8.3 per 1,000 inhabitants in 2012 (Thuringian average: -0.8; national average: +4.6). The most important regions of origin of Erfurt migrants are rural areas of Thuringia, Saxony-Anhalt and Saxony as well as foreign countries like Poland, Russia, Syria, Afghanistan and Hungary.\nLike other eastern German cities, foreigners account only for a small share of Erfurt's population: circa 3.0% are non-Germans by citizenship and overall 5.9% are migrants (according to the 2011 EU census).\nDue to the official atheism of the former GDR, most of the population is non-religious. 14.8% are members of the Evangelical Church in Central Germany and 6.8% are Catholics (according to the 2011 EU census). The Jewish Community consists of 500 members. Most of them migrated to Erfurt from Russia and Ukraine in the 1990s.\nCulture, sights and cityscape.\nResidents notable in cultural history.\nMartin Luther (1483\u20131546) studied law and philosophy at the University of Erfurt from 1501. He lived in St. Augustine's Monastery in Erfurt, as a friar from 1505 to 1511.\nThe theologian, philosopher and mystic Meister Eckhart (c. 1260\u20131328) entered the Dominican monastery in Erfurt when he was aged about 18 (around 1275). Eckhart was the Dominican Prior at Erfurt from 1294 until 1298, and Vicar of Thuringia from 1298 to 1302. After a year in Paris, he returned to Erfurt in 1303 and administered his duties as Provincial of Saxony from there until 1311.\nMax Weber (1864\u20131920) was born in Erfurt. He was a sociologist, philosopher, jurist, and political economist whose ideas have profoundly influenced modern social theory and social research.\nThe textile designer Margaretha Reichardt (1907\u20131984) was born and died in Erfurt. She studied at the Bauhaus from 1926 to 1930, and while there worked with Marcel Breuer on his innovative chair designs. Her former home and weaving workshop in Erfurt, the \"Margaretha Reichardt Haus\", is now a museum, managed by the Angermuseum Erfurt.\nJohann Pachelbel (1653\u20131706) served as organist at the Prediger church in Erfurt from June 1678 until August 1690. Pachelbel composed approximately seventy pieces for organ while in Erfurt.\nAfter 1906 the composer Richard Wetz (1875\u20131935) lived in Erfurt and became the leading person in the town's musical life. His major works were written here, including three symphonies, a Requiem and a Christmas Oratorio.\nAlexander M\u00fcller (1808\u20131863) pianist, conductor and composer, was born in Erfurt. He later moved to Z\u00fcrich, where he served as leader of the General Music Society's subscription concerts series.\nThe city is the birthplace of one of Johann Sebastian Bach's cousins, Johann Bernhard Bach, as well as Johann Sebastian Bach's father Johann Ambrosius Bach. Bach's parents were married in 1668 in a small church, the \" (Merchant's Church), that still exists on the main square, Anger.\nFamous modern musicians from Erfurt are Clueso, the Boogie Pimps and Yvonne Catterfeld.\nMuseums.\nErfurt has a great variety of museums:\nTheatre.\nSince 2003, the modern opera house is home to Theater Erfurt and its Philharmonic Orchestra. The \"grand stage\" section has 800 seats and the \"studio stage\" can hold 200 spectators. In September 2005, the opera \"Waiting for the Barbarians\" by Philip Glass premiered in the opera house. The Erfurt Theater has been a source of controversy recently. In 2005, a performance of Engelbert Humperdinck's opera \"\" stirred up the local press since the performance contained suggestions of pedophilia and incest. The opera was advertised in the program with the addition \"for adults only\".\nOn 12 April 2008, a version of Verdi's opera \" directed by Johann Kresnik opened at the Erfurt Theater. The production stirred deep controversy by featuring nude performers in Mickey Mouse masks dancing on the ruins of the World Trade Center and a female singer with a painted on Hitler toothbrush moustache performing a straight arm Nazi salute, along with sinister portrayals of American soldiers, Uncle Sam, and Elvis Presley impersonators. The director described the production as a populist critique of modern American society, aimed at showing up the disparities between rich and poor. The controversy prompted one local politician to call for locals to boycott the performances, but this was largely ignored and the premi\u00e8re was sold out.\nSport.\nThe Messe Erfurt serves as home court for the Oettinger Rockets, a professional basketball team in Germany's first division, the Basketball Bundesliga.\nNotable types of sport in Erfurt are athletics, ice skating, cycling (with the oldest velodrome in use in the world, opened in 1885), swimming, handball, volleyball, tennis and football. The city's football club is member of and based in with a capacity of 20,000. The \" was the second indoor speed skating arena in Germany.\nCityscape.\nErfurt's cityscape features a medieval core of narrow, curved alleys in the centre surrounded by a belt of \" architecture, created between 1873 and 1914. In 1873, the city's fortifications were demolished and it became possible to build houses in the area in front of the former city walls. \nIn the following years, Erfurt saw a construction boom. In the northern area (districts Andreasvorstadt, Johannesvorstadt and Ilversgehofen) tenements for the factory workers were built whilst the eastern area (Kr\u00e4mpfervorstadt and Daberstedt) featured apartments for white-collar workers and clerks and the southwestern part (L\u00f6bervorstadt and Br\u00fchlervorstadt) with its beautiful valley landscape saw the construction of villas and mansions of rich factory owners and notables.\nDuring the interwar period, some settlements in Bauhaus style were realized, often as housing cooperatives.\nAfter World War II and over the whole GDR period, housing shortages remained a problem even though the government started a big apartment construction programme. Between 1970 and 1990 large settlements with high-rise blocks on the northern (for 50,000 inhabitants) and southeastern (for 40,000 inhabitants) periphery were constructed. After reunification the renovation of old houses in city centre and the \" areas was a big issue. The federal government granted substantial subsidies, so that many houses could be restored.\nCompared to many other German cities, little of Erfurt was destroyed in World War II. This is one reason why the centre today offers a mixture of medieval, Baroque and Neoclassical architecture as well as buildings from the last 150 years.\nPublic green spaces are located along Gera river and in several parks like the ', the ' and the \"\". The largest green area is the , a horticultural exhibition park and botanic garden established in 1961.\nSights and architectural heritage.\nChurches, monasteries and synagogues.\nThe city centre has about 25 churches and monasteries, most of them in Gothic style, some also in Romanesque style or a mixture of Romanesque and Gothic elements, and a few in later styles. The various steeples characterize the medieval centre and led to one of Erfurt's nicknames as the \"Thuringian Rome\".\nSynagogues.\nThe oldest parts of Erfurt's \"Alte Synagoge\" (Old Synagogue) date to the 11th century. It was used until 1349 when the Jewish community was destroyed in a pogrom known as the Erfurt Massacre. The building had many other uses since then. It was conserved in the 1990s and in 2009 it became a museum of Jewish history.\nA rare Mikveh, a ritual bath, dating from c.1250, was discovered by archeologists in 2007. It has been accessible to visitors on guided tours since September 2011.\nIn 2015 the Old Synagogue and Mikveh were nominated as a World Heritage Site. It has been tentatively listed but a final decision has not yet been made.\nAs religious freedom was granted in the 19th century, some Jews returned to Erfurt. They built their synagogue on the banks of the Gera river and used it from 1840 until 1884. The neoclassical building is known as the \"Kleine Synagoge\" (Small Synagogue). Today it is used an events centre. It is also open to visitors.\nA larger synagogue, the \"Gro\u00dfe Synagoge\" (Great Synagogue), was opened in 1884 because the community had become larger and wealthier. This moorish style building was destroyed during nationwide Nazi riots, known as on 9\u201310 November 1938.\nIn 1947 the land which the Great Synagogue had occupied was returned to the Jewish community and they built their current place of worship, the \"Neue Synagoge\" (New Synagogue) which opened in 1952. It was the only synagogue building erected under communist rule in East Germany.\nSecular architecture.\nBesides the religious buildings there is a lot of historic secular architecture in Erfurt, mostly concentrated in the city centre, but some 19th- and 20th-century buildings are located on the outskirts. \nFortifications.\nFrom 1066 until 1873 the old town of Erfurt was encircled by a fortified wall. About 1168 this was extended to run around the western side of Petersberg hill, enclosing it within the city boundaries.\nAfter German Unification in 1871, Erfurt became part of the newly created German Empire. The threat to the city from its Saxon neighbours and from Bavaria was no longer present, so it was decided to dismantle the city walls. Only a few remnants remain today. A piece of inner wall can be found in a small park at the corner Juri-Gagarin-Ring and Johannesstra\u00dfe and another piece at the flood ditch (\"Flutgraben\") near Franckestra\u00dfe. There is also a small restored part of the wall in the Br\u00fchler Garten, behind the Catholic orphanage. Only one of the wall's fortified towers was left standing, on Boyneburgufer, but this was destroyed in an air raid in 1944.\nThe Petersberg Citadel is one of the largest and best preserved city fortresses in Europe, covering an area of 36 hectares in the north-west of the city centre. It was built from 1665 on Petersberg hill and was in military use until 1963. Since 1990, it has been significantly restored and is now open to the public as an historic site.\nThe is a smaller citadel south-west of the city centre, dating from 1480. Today, it houses the German horticulture museum.\n19th- and 20th-century architecture in the outskirts.\nBetween 1873 and 1914, a belt of ' architecture emerged around the city centre. The mansion district in the south-west around , and hosts some interesting ' and \"Art Nouveau\" buildings.\nThe \"M\u00fchlenviertel\" (\"mill quarter\"), is an area of beautiful Art Nouveau apartment buildings, cobblestone streets and street trees just to the north of the old city, in the vicinity of Nord Park, bordered by the Gera river on its east side. The Schmale Gera stream runs through the area. In the Middle Ages numerous small enterprises using the power of water mills occupied the area, hence the name \"M\u00fchlenviertel\", with street names such as Waidm\u00fchlenweg (woad, or indigo, mill way), Storchm\u00fchlenweg (stork mill way) and Papierm\u00fchlenweg (paper mill way).\nThe \"Bauhaus\" style is represented by some housing cooperative projects in the east around and and in the north around . Lutherkirke Church in (1927), is an Art Deco building.\nThe former malt factory \"Wolff\" at in the east of Erfurt is a large industrial complex built between 1880 and 1939, and in use until 2000. A new use has not been found yet, but the area is sometimes used as a location in movie productions because of its atmosphere.\nExamples of Nazi architecture include the buildings of the (Thuringian parliament) and (an event hall) in the south at . While the building (1930s) represents more the neo-Roman/fascist style, (1940s) is marked by some neo-Germanic \" style elements.\nThe Stalinist early-GDR style is manifested in the main building of the university at (1953) and the later more international modern GDR style is represented by the horticultural exhibition centre \" at , the housing complexes like Rieth or and the redevelopment of and area along in the city centre.\nThe current international glass and steel architecture is dominant among most larger new buildings like the Federal Labour Court of Germany (1999), the new opera house (2003), the new main station (2007), the university library, the Erfurt Messe (convention centre) and the ice rink.\nEconomy and infrastructure.\nDuring recent years, the economic situation of the city improved: the unemployment rate declined from 21% in 2005 to 9% in 2013. Nevertheless, some 14,000 households with 24,500 persons (12% of population) are dependent upon state social benefits (Hartz IV).\nAgriculture, industry and services.\nFarming has a great tradition in Erfurt: the cultivation of woad made the city rich during the Middle Ages. Today, horticulture and the production of flower seeds is still an important business in Erfurt. There is also growing of fruits (like apples, strawberries and sweet cherries), vegetables (e.g. cauliflowers, potatoes, cabbage and sugar beets) and grain on more than 60% of the municipal territory.\nIndustrialization in Erfurt started around 1850. Until World War I, many factories were founded in different sectors like engine building, shoes, guns, malt and later electro-technics, so that there was no industrial monoculture in the city. After 1945, the companies were nationalized by the GDR government, which led to the decline of some of them. After reunification, nearly all factories were closed, either because they failed to successfully adopt to a free market economy or because the German government sold them to west German businessmen who closed them to avoid competition to their own enterprises. However, in the early 1990s the federal government started to subsidize the foundation of new companies. It still took a long time before the economic situation stabilized around 2006. Since this time, unemployment has decreased and overall, new jobs were created. Today, there are many small and medium-sized companies in Erfurt with electro-technics, semiconductors and photovoltaics in focus. Engine production, food production, the Braugold brewery, and Born Feinkost, a producer of Thuringian mustard, remain important industries.\nErfurt is an \"\" (which means \"supra-centre\" according to Central place theory) in German regional planning. Such centres are always hubs of service businesses and public services like hospitals, universities, research, trade fairs, retail etc. Additionally, Erfurt is the capital of the federal state of Thuringia, so that there are many institutions of administration like all the Thuringian state ministries and some nationwide authorities. Typical for Erfurt are the logistic business with many distribution centres of big companies, the Erfurt Trade Fair and the media sector with KiKa and MDR as public broadcast stations. A growing industry is tourism, due to the various historical sights of Erfurt. There are 4,800 hotel beds and (in 2012) 450,000 overnight visitors spent a total of 700,000 nights in hotels. Nevertheless, most tourists are one-day visitors from Germany. The Christmas Market in December attracts some 2,000,000 visitors each year.\nTransport.\nBy rail.\nThe ICE railway network puts Erfurt 1\u00bd hours from Berlin, 2\u00bd hours from Frankfurt, 2 hours from Dresden, and 45 minutes from Leipzig. In 2017, the ICE line to Munich opened, making the trip to Erfurt main station only 2\u00bd hours.\nThere are regional trains from Erfurt to Weimar, Jena, Gotha, Eisenach, Bad Langensalza, Magdeburg, Nordhausen, G\u00f6ttingen, M\u00fchlhausen, W\u00fcrzburg, Meiningen, Ilmenau, Arnstadt, and Gera.\nIn freight transport there is an intermodal terminal in the district of Vieselbach \"()\" with connections to rail and the autobahn.\nBy road.\nThe two Autobahnen crossing each other nearby at \"Erfurter Kreuz\" are the Bundesautobahn 4 (Frankfurt\u2013Dresden) and the Bundesautobahn 71 (Schweinfurt\u2013Sangerhausen). Together with the east tangent both motorways form a circle road around the city and lead the interregional traffic around the centre. Whereas the A 4 was built in the 1930s, the A 71 came into being after the reunification in the 1990s and 2000s. In addition to both motorways there are two Bundesstra\u00dfen: the Bundesstra\u00dfe 7 connects Erfurt parallel to A 4 with Gotha in the west and Weimar in the east. The Bundesstra\u00dfe 4 is a connection between Erfurt and Nordhausen in the north. Its southern part to Coburg was annulled when A 71 was finished (in this section, the A 71 now effectively serves as B 4). Within the circle road, B 7 and B 4 are also annulled, so that the city government has to pay for maintenance instead of the German federal government. The access to the city is restricted as \" since 2012 for some vehicles. Large parts of the inner city are a pedestrian area which can not be reached by car (except for residents).\nBy light rail and bus.\nThe Erfurt public transport system is marked by the area-wide (light rail) network, established as a tram system in 1883, upgraded to a light rail (\") system in 1997, and continually expanded and upgraded through the 2000s. Today, there are six \"Stadtbahn\" lines running every ten minutes on every light rail route.\nAdditionally, Erfurt operates a bus system, which connects the sparsely populated outer districts of the region to the city center. Both systems are organized by \"SWE EVAG\", a transit company owned by the city administration. Trolleybuses were in service in Erfurt from 1948 until 1975, but are no longer in service.\nBy airplane.\nErfurt-Weimar Airport lies west of the city centre. It is linked to the central train station via Stadtbahn (tram). It was significantly extended in the 1990s, with flights mostly to Mediterranean holiday destinations and to London during the peak Christmas market tourist season. Connections to longer haul flights are easily accessible via Frankfurt Airport, which can be reached in 2 hours via a direct train from Frankfurt Airport to Erfurt, and from Leipzig/Halle Airport, which can be reached within half an hour.\nBy bike.\nBiking is becoming increasingly popular since construction of high quality cycle tracks began in the 1990s. There are cycle lanes for general commuting within Erfurt city.\nLong-distance trails, such as the \"Gera track\" and the \"\" (Thuringian cities trail), connect points of tourist interest. The former runs along the Gera river valley from the Thuringian forest to the river Unstrut; the latter follows the medieval Via Regia from Eisenach to Altenburg via Gotha, Erfurt, Weimar, and Jena.\nThe Rennsteig Cycle Way was opened in 2000. This designated high-grade hiking and bike trail runs along the ridge of the Thuringian Central Uplands. The bike trail, about long, occasionally departs from the course of the historic Rennsteig hiking trail, which dates back to the 1300s, to avoid steep inclines. It is therefore about longer than the hiking trail.\nThe Rennsteig is connected to the E3 European long distance path, which goes from the Atlantic coast of Spain to the Black Sea coast of Bulgaria, and the E6 European long distance path, running from Arctic Finland to Turkey.\nEducation.\nAfter reunification, the educational system was reorganized. The University of Erfurt, founded in 1379 and closed in 1816, was refounded in 1994 with a focus on social sciences, modern languages, humanities and teacher training. Today there are approximately 6,000 students working within four faculties, the Max Weber Center for Advanced Cultural and Social Studies, and three academic research institutes. The University has an international reputation and participates in international student exchange programmes.\nThe \"Fachhochschule Erfurt\", is a university of applied sciences, founded in 1991, which offers a combination of academic training and practical experience in subjects such as social work and social pedagogy, business studies, and engineering. There are nearly 5,000 students in six faculties, of which the faculty of landscaping and horticulture has a national reputation.\nThe International University of Applied Sciences Bad Honnef \u2013 Bonn (IUBH), is a privately run university with a focus on business and economics. It merged with the former Adam-Ries-Fachhochschule in 2013.\nThe world renowned Bauhaus design school was founded in 1919 in the city of Weimar, approximately from Erfurt, 12 minutes by train. The buildings are now part of a World Heritage Site and are today used by the Bauhaus-Universit\u00e4t Weimar, which teaches design, arts, media and technology related subjects.\nFurthermore, there are eight ', six state-owned, one Catholic and one Protestant (Evangelisches Ratsgymnasium Erfurt). One of the state-owned schools is a ', an elite boarding school for young talents in athletics, swimming, ice skating or football. Another state-owned school, \"\", offers a focus in sciences as an elite boarding school in addition to the common curriculum.\nMedia.\nThe German national public television children's channel \"KiKa\" is based in Erfurt.\nMDR, Mitteldeutscher Rundfunk, a radio and television company, has a broadcast centre and studios in Erfurt.\nThe Th\u00fcringer Allgemeine is a statewide newspaper that is headquartered in the city.\nPolitics.\nMayor and city council.\nThe first freely elected mayor after German reunification was Manfred Ruge of the Christian Democratic Union, who served from 1990 to 2006. Since 2006, Andreas Bausewein of the Social Democratic Party (SPD) has been mayor. The most recent mayoral election was held on 15 April 2018, with a runoff held on 29 April, and the results were as follows:\n! rowspan=2 colspan=2| Candidate\n! rowspan=2| Party\n! colspan=2| First round\n! colspan=2| Second round\n! Votes\n! Votes\n! colspan=3| Valid votes\n! 83,701\n! 99.3\n! 60,550\n! 98.0\n! colspan=3| Invalid votes\n! 562\n! 0.7\n! 1,240\n! 2.0\n! colspan=3| Total\n! 84,263\n! 100.0\n! 61,790\n! 100.0\n! colspan=3| Electorate/voter turnout\n! 172,908\n! 48.7\n! 172,562\n! 35.8\nThe most recent city council election was held on 26 May 2019, and the results were as follows:\n! colspan=2| Party\n! Lead candidate\n! Votes\n! +/-\n! Seats\n! colspan=3| Valid votes\n! 97,492\n! 96.8\n! \n! colspan=3| Invalid votes\n! 3,232\n! 3.2\n! \n! colspan=3| Total\n! 100,724\n! 100.0\n! 50\n! \u00b10\n! colspan=3| Electorate/voter turnout\n! 172,389\n! 58.4\n! 11.1\n! \nTwin towns \u2013 sister cities.\nErfurt is twinned with:"}
{"id": "9482", "revid": "11191612", "url": "https://en.wikipedia.org/wiki?curid=9482", "title": "Enya", "text": "Enya Patricia Brennan (Irish: \"Eithne P\u00e1draig\u00edn N\u00ed Bhraon\u00e1in\" ; born 17 May 1961), known professionally as Enya, is an Irish singer, songwriter, record producer and musician. Born into a musical family and raised in the Irish-speaking area of Gweedore in County Donegal, Enya began her music career when she joined her family's Celtic folk band Clannad in 1980 on keyboards and backing vocals. She left in 1982 with their manager and producer Nicky Ryan to pursue a solo career, with Ryan's wife Roma Ryan as her lyricist. Enya developed her sound over the following four years with multitracked vocals and keyboards with elements of new age, Celtic, classical, church, and folk music. She has sung in ten languages.\nEnya's first projects as a solo artist included soundtrack work for \"The Frog Prince\" (1984) and the 1987 BBC documentary series \"The Celts\", which was released as her debut album, \"Enya\" (1987). She signed with Warner Music UK, which granted her artistic freedom and minimal interference from the label. The commercial and critical success of \"Watermark\" (1988) propelled her to worldwide fame, helped by the international top-10 hit single \"Orinoco Flow\". This was followed by the multi-million-selling albums \"Shepherd Moons\" (1991), \"The Memory of Trees\" (1995) and \"A Day Without Rain\" (2000). Sales of the latter and its lead single, \"Only Time\", surged in the United States following its use in the media coverage of the September 11 attacks. Following \"Amarantine\" (2005) and \"And Winter Came...\" (2008), Enya took an extended break from music; she returned in 2012 and released \"Dark Sky Island\" (2015).\nShe is Ireland's best-selling solo artist and second-best-selling artist behind U2, with a discography that has sold 26.5\u00a0million certified albums in the United States and an estimated 75 million records worldwide, making her one of the best-selling music artists of all time. \"A Day Without Rain\" (2000) remains the best-selling new-age album, with an estimated 16 million copies sold worldwide. Enya has won awards including seven World Music Awards, four Grammy Awards for Best New Age Album, and an Ivor Novello Award. She was nominated for an Academy Award and a Golden Globe Award for \"May It Be\", written for \"\" (2001).\nEarly life.\nEithne P\u00e1draig\u00edn N\u00ed Bhraon\u00e1in was born on 17 May 1961 in Dore, in the parish of Gaoth Dobhair, in the northwestern county of Donegal, Ireland. It is a Gaeltacht region where Irish is the primary language. Her name is anglicised as Enya Patricia Brennan, where Enya is the phonetic spelling of how Eithne is pronounced in her native Ulster dialect of Irish; \"N\u00ed Bhraon\u00e1in\" translates to \"daughter of Brennan\". The fifth of nine children, Enya was born into a Roman Catholic family of musicians. Her father, Leo Brennan, was the leader of the Slieve Foy Band, an Irish showband, and ran Leo's Tavern in Meenaleck; her mother, M\u00e1ire Brennan (\"n\u00e9e\" Duggan), who had distant Spanish roots and whose ancestors settled on Tory Island, was an amateur musician who played in Leo's band and taught music at Gweedore Community School. Enya's maternal grandfather Aodh was the headmaster of the primary school in Dore, and her grandmother was a teacher there. Aodh was also the founder of the Gweedore Theatre company.\nEnya described her upbringing as \"very quiet and happy.\" At age three, she took part in her first singing competition at the annual Feis Ceoil music festival. She took part in pantomimes at Gweedore Theatre and sang with her siblings in her mother's choir at St Mary's church in Derrybeg. She learned English at primary school and began piano lessons at age four. \"I had to do school work and then travel to a neighbouring town for piano lessons, and then more school work. I ... remember my brothers and sisters playing outside ... and I would be inside playing the piano. This one big book of scales, practising them over and over.\" When Enya turned eleven, her grandfather paid for her education at a strict convent boarding school in Milford run by nuns of the Loreto order, where she developed a taste for classical music, art, Latin and watercolour painting. \"It was devastating to be torn away from such a large family, but it was good for my music.\" Enya left the school at 17 and studied classical music in college for one year with the aim of becoming \"a piano teacher sort of person. I never thought of myself composing or being on stage.\"\nCareer.\n1976\u20131985: Clannad and early solo career.\nIn the 1970s, several members of Enya's family formed Clannad, a Celtic band with Nicky Ryan as their manager, sound engineer and producer and his future wife Roma Ryan assisting with the tour management and administrative duties. In 1980, after her year at college, Enya decided not to study music at university and instead accepted Ryan's invitation to join the group with the aim of expanding their sound by incorporating keyboards and another backup vocalist. She toured across Europe and played an uncredited role on their sixth album, \"Crann \u00dall\" (1980), with a line-up of siblings M\u00e1ire, P\u00f3l and Ciar\u00e1n Brennan and twin uncles, Noel and P\u00e1draig Duggan. Enya became an official and credited member by the time of their next album \"Fuaim\" (1981), which features a front cover photograph of her with the band. Nicky maintains it was never his intention to make Enya a permanent member, and realised she was \"fiercely independent ... intent on playing her own music. She was just not sure of how to go about it\". This sparked discussions between the two on the idea of using Enya's voice to form a \"choir of one\", a concept based on the \"wall of sound\" technique by Phil Spector that interested them both.\nIn 1982, during a Clannad tour of Switzerland, Nicky called for a band meeting as several issues had arisen and felt they needed to be addressed. He added, \"It was short and only required a vote, I was a minority of one and lost. Roma and I were out. This left the question of what happened with Enya. I decided to stand back and say nothing\". Enya chose to leave to pursue a solo career with the Ryans, which initially caused some friction between the three and her family but she preferred being independent and disliked being confined in the group as \"somebody in the background\". Nicky then suggested to Enya that either she return to Gweedore \"with no particular definite future\", or live with him and Roma in their home, then located in the northern Dublin suburb of Artane, \"and see what happens, musically\". After their bank denied them a loan, Enya sold her saxophone and gave piano lessons and the Ryans used what they could afford from their savings to build a recording facility named Aigle Studio, named after the French word for \"eagle\", in a shed in their back garden, and rented it out to other artists to cover its costs. They formed a musical partnership in the process with Nicky as Enya's producer and arranger and Roma her lyricist, and became directors of their music company, Aigle Music. In the following two years, Enya developed her playing and composing by recording herself recite classical pieces on the piano and listening back to them. The process was repeated until she started to improvise sections and develop her own piano arrangements. Her first composition was \"An Taibhse Uaighneach\", Irish for \"The Lonely Ghost\". During this time, Enya played the synthesiser on \"Ceol Aduaidh\" (1983) by Mair\u00e9ad N\u00ed Mhaonaigh and Frankie Kennedy and performed with the duo and Mhaonaigh's brother Gear\u00f3id in their short lived group, Ragairne.\nEnya's first solo endeavour arrived in 1983 when she recorded two piano instrumentals, \"An Ghaoth \u00d3n Ghrian\", Irish for \"The Solar Wind\", and \"Miss Clare Remembers\", at Windmill Lane Studios in Dublin which were released on \"Touch Travel\" (1984), a limited release audio cassette of music from various artists on the Touch label. She is credited as \"Eithne N\u00ed Bhraon\u00e1in\" on its liner notes. After several months of preparation, Enya's debut solo performance took place on 23 September 1983 at the National Stadium in Dublin that was televised for RT\u00c9's music show \"Festival Folk\". Nial Morris, a musician who worked with her during this time, recalled she \"was so nervous she could barely get on stage, and she cowered behind the piano until the gig was over.\"\nAt the suggestion of Roma, who thought Enya's music would suit accompanying visual images, a demo tape of her compositions with Morris on additional keyboards was made and sent to various film producers. Among them was David Puttnam, who liked the tape and chose Enya to compose the soundtrack to the romantic comedy film \"The Frog Prince\" (1984), of which he served as executive producer. Enya wrote nine tracks for the film but found her songs were rearranged and orchestrated against her wishes by Richard Myhill except two tracks she sang on, \"The Frog Prince\" and \"Dreams\", with the latter's lyrics penned by Charlie McGettigan. Film editor Jim Clark later claimed the rearrangements were necessary as Enya found it difficult to compose to picture. Released in 1985 by Island Visual Arts, the album is the first commercial release that credits her as \"Enya\". The change from Eithne to Enya originated from Nicky Ryan, who thought her name would be too difficult for people outside Ireland to pronounce correctly, and suggested the phonetic spelling of her name. Enya looked back on the project as a good career move, but a disappointing one as \"we weren't part of it at the end\". She then sang on three tracks on \"Ordinary Man\" (1985) by Christy Moore.\n1985\u20131989: \"The Celts\" and \"Watermark\".\nIn 1985, producer Tony McAuley commissioned Enya to write a song for the six-part BBC2 television documentary series \"The Celts\". She already had written a Celtic-influenced song named \"The March of the Celts\" and submitted it to the project. Each episode was to feature a different composer at first, but director David Richardson liked the track so much, he selected her to compose the entire soundtrack. Enya recorded 72 minutes of music in 1986 at Aigle Studio and the BBC studios in Wood Lane, London without recording to picture, though she was required to portray certain themes and ideas that the producers wanted. Unlike \"The Frog Prince\", she worked with little interference which granted her freedom to establish her sound that she adopted throughout her career, using multi-tracked vocals, keyboards, and percussion with elements of Celtic, classical, church and folk music.\nIn March 1987, two months before the series aired on television, a 40-minute selection of the soundtrack was released as Enya's first solo album, titled \"Enya\", by BBC Records in the United Kingdom and by Atlantic Records in the United States. The latter promoted it with a new-age imprint on the packaging which Nicky later thought was \"a cowardly thing for them to do\". The album gained enough public attention to reach number 8 on the Irish Albums Chart and number 69 on the UK Albums Chart. \"I Want Tomorrow\" was released as Enya's first single. \"Boadicea\" was sampled by The Fugees on their 1996 song \"Ready or Not\"; the group neither sought permission nor gave her credit, causing Enya to threaten legal action. The group subsequently gave her credit and paid a fee worth around $3\u00a0million. Later in 1987, she appeared on Sin\u00e9ad O'Connor's debut album \"The Lion and the Cobra\", reciting Psalm 91 in Irish on the song \"Never Get Old\".\nSeveral weeks after the release of her debut album, Enya secured a recording contract with Warner Music UK after Rob Dickins, the label's chairman and a fan of Clannad, took a liking to \"Enya\" and found himself playing it \"every night before I went to bed\". He then met Enya and the Ryans at a chance meeting at the Irish Recorded Music Association award ceremony in Dublin, and learned Enya was thinking about signing with a rival label. Dickins seized the opportunity and signed her to Warner Music with a deal worth \u00a375,000, granting her wish to write and record with artistic freedom, minimal interference from the label, and without set deadlines to finish albums. Dickins said: \"Sometimes you sign an act to make money, and sometimes you sign an act to make music. This was clearly the latter ... I just wanted to be involved with this music.\" Enya then left Atlantic and signed with the Warner-led Geffen Records to handle her American distribution.\nWith the green-light to produce a new studio album, Enya recorded \"Watermark\" from June 1987 to April 1988. It was initially recorded in analogue at Aigle Studio before Dickins requested to have it re-recorded digitally at Orinoco Studios in Bermondsey, London. \"Watermark\" was released in September 1988 and became an unexpected hit, reaching number 5 in the United Kingdom and number 25 on the \"Billboard\" 200 in the United States following its release there in January 1989. Its lead single, \"Orinoco Flow\", was the last song written for the album. It was not intended to be a single at first, but Enya and the Ryans chose it after Dickins asked for a single from them several times as a joke, knowing Enya's music was not made for the Top 40 chart. Dickins and engineer Ross Cullum are referenced in the songs' lyrics. \"Orinoco Flow\" became an international top 10 hit and was number one in the United Kingdom for three weeks. The new-found success propelled Enya to international fame and she received endorsement deals and offers to use her music in television commercials. She spent one year travelling worldwide to promote the album which increased her exposure through interviews, appearances, and live performances. By 1996, \"Watermark\" had sold in excess of 1.2\u00a0million copies in the United Kingdom and 4 million in the United States.\n1989\u20131997: \"Shepherd Moons\" and \"The Memory of Trees\".\nAfter promoting \"Watermark\", Enya purchased new recording equipment and started work on her next album, \"Shepherd Moons\". She found the success of \"Watermark\" caused a considerable amount of pressure when it came to writing new songs, adding, \"I kept thinking, 'Would this have gone on \"Watermark\"? Is it as good?' Eventually I had to forget about this and start on a blank canvas and just really go with what felt right.\" Enya wrote songs based on several ideas, including entries from her diary, the Blitz in London, and her grandparents. \"Shepherd Moons\" was released in November 1991, her first album released under Warner-led Reprise Records in the United States. It became a greater commercial success than \"Watermark\", reaching number one at home for one week and number 17 in the United States. \"Caribbean Blue\", its lead single, charted at number thirteen in the United Kingdom. By 1997, the album had reached multi-platinum certification for selling in excess of 1.2\u00a0million copies in the United Kingdom and 5 million in the United States.\nIn 1991, Warner Music released a collection of five Enya music videos as \"Moonshadows\" for home video. In 1993, Enya won her first Grammy Award for Best New Age Album for \"Shepherd Moons\". Soon after, Enya and Nicky entered discussions with Industrial Light &amp; Magic, founded by George Lucas, regarding an elaborate stage lighting system for a proposed concert tour, but nothing came out of the meetings. In November 1992, Warner had obtained the rights to \"Enya\" and re-released the album as \"The Celts\" with new artwork. It surpassed its initial sale performance, reaching number 10 in the United Kingdom and reached platinum certification in the United States in 1996 for one million copies shipped.\nAfter travelling worldwide to promote \"Shepherd Moons\", Enya started to write and record her fourth album, \"The Memory of Trees\". The album was released in November 1995. It peaked at number five in the United Kingdom and number nine in the United States, where it sold over 3 million copies. Its lead single, \"Anywhere Is\", reached number seven in the United Kingdom. The second, \"On My Way Home\", reached number twenty-six in the same country. In late 1994, Enya put out an extended play of Christmas music titled \"The Christmas EP\". Enya was offered to compose the score for \"Titanic\", but declined. A recording of her singing \"O\u00edche Chi\u00fain\", an Irish-language version of \"Silent Night\", appeared on the charity album \"A Very Special Christmas 3\", released in benefit of the Special Olympics in October 1997.\nIn early 1997, Enya began to select tracks for her first compilation album, \"trying to select the obvious ones, the hits, and others.\" She chose to work on the collection following the promotional tour for \"The Memory of Trees\" as she felt it was the right time in her career, and that her contract with WEA required her to release a \"best of\" album. The set, named \"Paint the Sky with Stars: The Best of Enya\", features two new tracks, \"Paint the Sky with Stars\" and \"Only If...\". Released in November 1997, the album was a worldwide commercial success, reaching No. 4 in the UK and No. 30 in the US, where it went on to sell over 4 million copies. \"Only If...\" was released as a single in 1997. Enya described the album as \"like a musical diary ... each melody has a little story and I live through that whole story from the beginning ... your mind goes back to that day and what you were thinking.\"\n1998\u20132007: \"A Day Without Rain\" and \"Amarantine\".\nEnya started work on her fifth studio album, titled \"A Day Without Rain\", in mid-1998. In a departure from her previous albums she incorporated the use of a string section into her compositions, something that was not a conscious decision at first, but Enya and Nicky Ryan agreed it complemented the songs that were being written. The album was released in November 2000, and reached number 6 in the United Kingdom and an initial peak of number 17 in the United States. In the aftermath of the 11 September attacks, sales of the album and its lead single, \"Only Time\", surged after the song was widely used during radio and television coverage of the events, leading to its description as \"a post-September 11 anthem\". The exposure caused \"A Day Without Rain\" to outperform its original chart performance to peak at number 2 on the \"Billboard\" 200, and the release of a maxi single containing the original and a pop remix of \"Only Time\" in November 2001. Enya donated its proceeds in aid of the International Association of Firefighters. The song topped the \"Billboard\" Hot Adult Contemporary Tracks chart and went to number 10 on the Hot 100 singles, Enya's highest charting US single to date. A second single, \"Wild Child\", was released in December 2001. \"A Day Without Rain\" remains Enya's biggest seller, with 7 million copies sold in the US and the most sold new-age album of all time with an estimated 13\u00a0million copies sold worldwide.\nIn 2001, Enya agreed to write and perform on two tracks for the of \"\" (2001) at the request of director Peter Jackson. Its composer Howard Shore \"imagined her voice\" as he wrote the film's score, making an uncommon exception to include another artist in one of his soundtracks. After flying to New Zealand to observe the filming and to watch a rough cut of the film, Enya returned to Ireland and composed \"An\u00edron (Theme for Aragorn and Arwen)\" with lyrics by Roma in J. R. R. Tolkien's fictional Elvish language Sindarin, and \"May It Be\", sung in English and another Tolkien language, Quenya. Shore then based his orchestrations around Enya's recorded vocals and themes to create \"a seamless sound\". In 2002, Enya released \"May It Be\" as a single which earned her an Academy Award nomination for Best Original Song. She performed the song live at the 74th Academy Awards ceremony with an orchestra in March 2002, and later cited the moment as a career highlight.\nEnya undertook additional studio projects in 2001 and 2002. The first was work on the soundtrack to the Japanese romantic film \"Calmi Cuori Appassionati\" (2001) which was subsequently released as \"Themes from Calmi Cuori Appassionati\" (2001). The album is formed of tracks spanning her career from \"Enya\" to \"A Day Without Rain\" with two B-sides. The album went to number 2 in Japan, and became Enya's second to sell one million copies in the country. November 2002 saw the release of \"Only Time \u2013 The Collection\", a box set of 51 tracks recorded through her career which received a limited release of 200,000 copies.\nIn September 2003, Enya returned to Aigle Studio to start work on her sixth studio album, \"Amarantine\". Roma said the title means \"everlasting\". The album marks the first instance of Enya singing in Loxian, a fictional language created by Roma that came about when Enya was working on \"Water Shows the Hidden Heart\". After numerous attempts to sing the song in English, Irish and Latin, Roma suggested a new language based on some of the sounds Enya would sing along to when developing her songs. It was a success, and Enya sang \"Less Than a Pearl\" and \"The River Sings\" in the same way. Roma worked on the language further, creating a \"culture and history\" behind it surrounding the Loxian people who are of another planet, questioning the existence of life on another. \"Sumiregusa (Wild Violet)\" is sung in Japanese. \"Amarantine\" was a global success, reaching number 6 on the \"Billboard\" 200 and number 8 in the UK. It has sold over 1 million certified copies in the US, a considerable drop in sales in comparison to her previous albums. Enya dedicated the album to BBC producer Tony McAuley, who had commissioned Enya to write the soundtrack to \"The Celts\", following his death in 2003. The lead single, \"Amarantine\", was released in December 2005. A Christmas Special Edition was released in 2006, followed by a Deluxe Edition.\nIn 2006, Enya released \"\", a Christmas-themed EP released exclusively in the US following an exclusive partnership with the NBC network and the Target department store chain. It includes two new songs, \"Christmas Secrets\" and \"The Magic of the Night\".\nIn June 2007, Enya received an honorary doctorate from the National University of Ireland, Galway. A month later, she received one from the University of Ulster.\n2008\u2013present: \"And Winter Came...\" and \"Dark Sky Island\".\nEnya continued to write music with a winter and Christmas theme for her seventh studio album, \"And Winter Came...\". Initially she intended to make an album of seasonal songs and hymns set for a release in late 2007, but decided to produce a winter-themed album instead. The track \"My! My! Time Flies!\", a tribute to the late Irish guitarist Jimmy Faulkner, incorporates a guitar solo performed by Pat Farrell, the first use of a guitar on an Enya album since \"I Want Tomorrow\" from \"Enya\". Upon its release in November 2008, \"And Winter Came...\" reached No. 6 in the UK and No. 8 in the US and sold almost 3.5\u00a0million copies worldwide by 2011.\nAfter promoting \"And Winter Came...\", Enya took an extended break from writing and recording music. She spent her time resting, visiting family in Australia, and renovating her new home in the south of France. In March 2009, her first four studio albums were reissued in Japan in the Super High Material CD format with bonus tracks. Her second compilation album and DVD, \"The Very Best of Enya\", was released in November 2009 and features songs from 1987 to 2008, including a previously unreleased version of \"An\u00edron\". In 2013, \"Only Time\" was used in the \"Epic Split\" advertisement by Volvo Trucks starring Jean-Claude Van Damme who does the splits while suspended between two lorries. The video went viral, leading to numerous parodies of the commercial uploaded to YouTube also using \"Only Time\". The attention resulted in the song peaking at No. 43 on the \"Billboard\" Hot 100 singles chart.\nIn 2012, Enya returned to the studio to record her eighth album, \"Dark Sky Island\". Its name refers to the island of Sark, which became the first island to be designated a dark-sky preserve, and a series of poems on islands by Roma Ryan. The new album was promoted with the premiere in October 2015 of its lead single, \"Echoes in Rain\", on Ken Bruce's radio show and with the release in the same month of the single as a digital download. Upon its release on 20 November 2015, \"Dark Sky Island\" went to No. 4 in the UK, Enya's highest charting studio album there since \"Shepherd Moons\" went to No. 1, and to No. 8 in the US. A Deluxe Edition features three additional songs. Enya completed a promotional tour of the UK and Europe, the US and Japan. During her visit to Japan, Enya performed \"Orinoco Flow\" and \"Echoes in Rain\" at the Universal Studios Japan Christmas show in Osaka. In December 2016, Enya appeared on the Raidi\u00f3 Teilif\u00eds \u00c9ireann Christmas special \"Christmas Carols from Cork\", marking her first Irish television appearance in over seven years. She sang \"Adeste Fideles\" and \"Oiche Chi\u00fain\" as well as her own carol composition \"The Spirit of Christmas Past\".\nMusical style.\nEnya's vocal range is mezzo-soprano. She has cited her musical foundations as \"the classics\", church music, and \"Irish reels and jigs\" with a particular interest in Sergei Rachmaninoff, a favourite composer of hers. She has an autographed picture of him in her home. Since 1982, she has recorded her music with Nicky Ryan as producer and arranger and his wife Roma Ryan as lyricist. While in Clannad, Enya chose to work with Nicky as the two shared an interest in vocal harmonies, and Ryan, influenced by The Beach Boys and the \"Wall of Sound\" technique that Phil Spector pioneered, wanted to explore the idea of \"the multivocals\" for which her music became known. According to Enya, \"Angeles\" from \"Shepherd Moons\" has roughly 500 vocals recorded individually and layered. Enya performs all vocals and the majority of instruments in her songs apart from musicians to play percussion, guitar, uilleann pipes, cornet, and double bass. Her early works including \"Watermark\" feature numerous keyboards, including the Yamaha KX88 Master, Yamaha DX7, Oberheim Matrix, Akai S900, Roland D-50, and Roland Juno-60, the latter a particular favourite of hers.\nNumerous critics and reviewers classify Enya's albums as new age music and she has won four Grammy Awards in the category. However, Enya does not classify her music as part of the genre. When asked what genre she would classify her music, her reply was \"Enya\". Nicky Ryan commented on the new age comments: \"Initially it was fine, but it's really not new age. Enya plays a whole lot of instruments, not just keyboards. Her melodies are strong and she sings a lot. So I can't see a comparison.\" The music video to \"Caribbean Blue\" and the art work to \"The Memory of Trees\" feature adapted works from artist Maxfield Parrish.\nEnya has sung in ten languages in her career, including English, Irish, Latin, Welsh, Spanish, French and Japanese. She has recorded music influenced by works from fantasy author J. R. R. Tolkien, including the instrumental \"Lothl\u00f3rien\" from \"Shepherd Moons\". She sang \"May It Be\" in English and Tolkien's fictional language Quenya, and \"An\u00edron\", sang in Tolkien's other language Sindarin, for \"\". Her albums \"Amarantine\" and \"Dark Sky Island\" include songs sung in Loxian, a fictional language created by Roma, that has no official syntax. Its vocabulary was formed by Enya singing the song's notes to which Roma wrote their phonetic spelling.\nEnya adopted a composing and songwriting method that has deviated little throughout her career. At the start of the recording process for an album she enters the studio, forgetting about her previous success, fame, and songs of hers that became hits. \"If I did that\", she said, \"I'd have to call it a day\". She then develops ideas on the piano, keeping note of any arrangement that can be worked on further. During her time writing, Enya works a five-day week, takes weekends off, and does not work on her music at home. With Irish as her first language, Enya initially records her songs in Irish as she can express \"feeling much more directly\" than English. After a period of time, Enya presents her ideas to Nicky to discuss what pieces work best, while Roma works in parallel to devise a lyric to the songs. Enya considered \"Fallen Embers\" from \"A Day Without Rain\" a perfect time when the lyrics reflect as to how she felt while writing the song. In 2008, she newly discovered her tendency to write \"two or three songs\" during the winter months, work on the arrangements and lyrics the following spring and summer, and then work on the next couple of songs when autumn arrives.\nLive performances.\nEnya says that Warner Music and she \"did not see eye to eye\" initially as the label imagined her performing on stage \"with a piano ... maybe two or three synthesiser players and that's it\". Enya also explained that the time put into her studio albums causes her to \"run overtime\", leaving little time to plan for other such projects. She also expressed the difficulty in recreating her studio-oriented sound for the stage. In 1996, Ryan said Enya had received an offer worth almost \u00a3500,000 to perform a concert in Japan. In 2016, Enya spoke about the prospect of a live concert when she revealed talks with the Ryans during her three-year break after \"And Winter Came...\" (2008) to perform a show at the Metropolitan Opera House in New York City that would be simulcast to cinemas worldwide. Before such an event could happen, Nicky suggested that she enter a studio and record \"all the hits\" live with an orchestra and choir to see how they would sound.\nEnya has sung with live and lip synching vocals on various talk and music shows, events, and ceremonies throughout her career, usually during her worldwide press tours for each album. In December 1995, she performed \"Anywhere Is\" at a Christmas concert at Vatican City with Pope John Paul II in attendance, who met and thanked her for performing. In April 1996, Enya performed the same song during her surprise appearance at the fiftieth birthday celebration for Carl XVI Gustaf, the King of Sweden and a fan of Enya's. In 1997, Enya participated in a live Christmas Eve broadcast in London and flew to County Donegal afterwards to join her family for their annual midnight Mass choral performance, in which she partakes each year. In March 2002, she performed \"May It Be\" with an orchestra at the year's Academy Awards ceremony. Enya and her sisters performed as part of the local choir Cor Mhuire in July 2005 at St. Mary's church in Gweedore during the annual Earagail Arts Festival.\nPersonal life.\nIn 1997, Enya bought Manderley Castle, a Victorian Grade A listed castle home in Killiney, County Dublin for IR\u00a32.5\u00a0million at auction. Formerly known as Victoria and Ayesha Castle, she renamed the castle after the house from the book \"Rebecca\" by Daphne du Maurier. In 2009, during her three-year break from music, Enya purchased a home in southern France.\nSince the 1980s, Enya has attracted the attention of several stalkers. In 1996, an Italian man who was seen in Dublin wearing a photograph of Enya around his neck stabbed himself outside her parents' pub after being ejected from the premises. In May 2005, Enya applied to spend roughly \u00a3250,000 on security improvements, covering gaps in the castle's outer wall and installing bollards and iron railings. Despite these improvements, in October 2005, two people broke into her home; one attacked and tied up one of her housekeepers and left with several of Enya's items after she had raised the alarm in her safe room.\nEnya is known for keeping a private lifestyle, saying: \"The music is what sells. Not me, or what I stand for\u00a0... that's the way I've always wanted it\". She is not married and is a surrogate aunt to the Ryans' two daughters. In 1991, she said: \"I'm afraid of marriage because I'm afraid someone might want me because of who I am instead of because they loved me... I wouldn't go rushing into anything unexpected, but I do think a great deal about this\". A relationship she had with one man ended in 1997, around the time when she considered taking time out of music to have a family, but found she was putting pressure on herself over the matter and \"gone the route I wanted to go\". She declares herself as \"more spiritual than religious... I derive from religion what I enjoy.\"\nIn 2006, Enya ranked third in a list of the wealthiest Irish entertainers with an estimated fortune of \u00a375\u00a0million, and No. 95 in the \"Sunday Times\" Rich List of the richest 250 Irish people. The 2016 edition, which listed its top 50 \"Music Millionaires of Britain and Ireland\", she emerged as the richest female singer with a fortune of \u00a391\u00a0million for a place at No. 28.\nIn 2017 a newly discovered species of fish, \"Leporinus enyae\", found in the Orinoco River drainage area, was named after Enya.\nMinor planet 6433 Enya is named after her.\nAwards and nominations.\nBillboard Music Awards\nGrammy Awards\nJapan Gold Disc Awards\nWorld Music Awards\n!scope=\"row\" rowspan=\"3\"|1989\n!scope=\"row\"|1990\n!scope=\"row\"|1992\n!scope=\"row\" rowspan=\"3\"|1993\n!scope=\"row\" rowspan=1|1998\n!scope=\"row\"|2001\n!scope=\"row\"|2001\n!scope=\"row\"|2002\n!scope=\"row\"|2002\n!scope=\"row\" rowspan=\"3\"|2002\n!scope=\"row\" rowspan=\"1\"|2003\n!scope=\"row\" rowspan=\"3\"|2004\n!scope=\"row\"|2005\n!scope=\"row\"|2016"}
{"id": "9483", "revid": "1020727150", "url": "https://en.wikipedia.org/wiki?curid=9483", "title": "East Berlin", "text": "East Berlin was the \"de facto\" capital city of the German Democratic Republic from 1949 to 1990. Formally, it was the Soviet sector of Berlin, established in 1945. The American, British, and French sectors were known as West Berlin. From 13 August 1961 until 9 November 1989, East Berlin was separated from West Berlin by the Berlin Wall. The Western Allied powers did not recognise East Berlin as the GDR's capital, nor the GDR's authority to govern East Berlin. On 3 October 1990, the day Germany was officially reunified, East and West Berlin formally reunited as the city of Berlin.\nOverview.\nWith the London Protocol of 1944 signed on 12 September 1944, the United States, the United Kingdom and the Soviet Union decided to divide Germany into three occupation zones and to establish a special area of Berlin, which was occupied by the three Allied Forces together. In May 1945, the Soviet Union installed a city government for the whole city that was called \"Magistrate of Greater Berlin\", which existed until 1947. After the war, the Allied Forces initially administered the city together within the Allied Kommandatura, which served as the governing body of the city. However, in 1948 the Soviet representative left the Kommandatura and the common administration broke apart during the following months. In the Soviet sector, a separate city government was established, which continued to call itself \"Magistrate of Greater Berlin\".\nWhen the German Democratic Republic was established in 1949, it immediately claimed East Berlin as its capital\u2014a claim that was recognised by all communist countries. Nevertheless, its representatives to the People's Chamber were not directly elected and did not have full voting rights until 1981.\nIn June 1948, all railways and roads leading to West Berlin were blocked, and East Berliners were not allowed to emigrate. Nevertheless, more than 1,000 East Germans were escaping to West Berlin each day by 1960, caused by the strains on the East German economy from war reparations owed to the Soviet Union, massive destruction of industry, and lack of assistance from the Marshall Plan. In August 1961, the East German Government tried to stop the population exodus by enclosing West Berlin within the Berlin Wall. It was very dangerous for fleeing residents to cross because armed soldiers were trained to shoot illegal migrants.\nEast Germany was a socialist republic, but there was not complete economic equality. Privileges such as prestigious apartments and good schooling were given to members of the ruling party and their families. Eventually, Christian churches were allowed to operate without restraint after years of harassment by authorities. In the 1970s, wages of East Berliners rose and working hours fell.\nThe Soviet Union and the Communist bloc recognised East Berlin as the GDR\u2019s capital. However, Western Allies (the US, UK, and France) never formally acknowledged the authority of the East German government to govern East Berlin. Official Allied protocol recognised only the authority of the Soviet Union in East Berlin in accordance with the occupation status of Berlin as a whole. The United States Command Berlin, for example, published detailed instructions for U.S. military and civilian personnel wishing to visit East Berlin. In fact, the three Western commandants regularly protested against the presence of the East German National People's Army (NVA) in East Berlin, particularly on the occasion of military parades. Nevertheless, the three Western Allies eventually established embassies in East Berlin in the 1970s, although they never recognised it as the capital of East Germany. Treaties instead used terms such as \"seat of government.\"\nOn 3 October 1990, East and West Germany and East and West Berlin were reunited, thus formally ending the existence of East Berlin. Citywide elections in December 1990 resulted in the first \u201call Berlin\u201d mayor being elected to take office in January 1991, with the separate offices of mayors in East and West Berlin expiring at the time, and Eberhard Diepgen (a former mayor of West Berlin) became the first elected mayor of a reunited Berlin.\nEast Berlin today.\nSince reunification, the German government has spent vast amounts of money on reintegrating the two halves of the city and bringing services and infrastructure in the former East Berlin up to the standard established in West Berlin.\nAfter reunification, the East German economy suffered significantly. Under the adopted policy of privatisation of state-owned firms under the auspices of the Treuhandanstalt, many East German factories were shut down\u2014which also led to mass unemployment\u2014due to gaps in productivity with and investment compared to West German companies, as well as an inability to comply with West German pollution and safety standards in a way that was deemed cost effective. Because of this, a massive amount of West German economic aid was poured into East Germany to revitalize it. This stimulus was part-funded through a 7.5% tax on income for individuals and companies (in addition to normal income tax or company tax) known as the \"Solidarit\u00e4tszuschlaggesetz\" (SolZG) or \"solidarity surcharge\", which though only in effect for 1991-1992 (later reintroduced in 1995 at 7.5 and then dropped down to 5.5% in 1998 and continues to be levied to this day) led to a great deal of resentment toward the East Germans.\nDespite the large sums of economic aid poured into East Berlin, there still remain obvious differences between the former East and West Berlins. East Berlin has a distinct visual style; this is partly due to the greater survival of prewar fa\u00e7ades and streetscapes, with some still showing signs of wartime damage. The unique look of Stalinist architecture that was used in East Berlin (along with the rest of the former GDR) also contrasts markedly with the urban development styles employed in the former West Berlin. Additionally, the former East Berlin (along with the rest of the former GDR) retains a small number of its GDR-era street and place names commemorating German socialist heroes, such as Karl-Marx-Allee, Rosa-Luxemburg-Platz, and Karl-Liebknecht-Stra\u00dfe. Many such names, however, were deemed inappropriate (for various reasons) and, through decommunization, changed after a long process of review (so, for instance, Leninallee reverted to Landsberger Allee in 1991, and Dimitroffstra\u00dfe reverted to Danziger Stra\u00dfe in 1995).\nAnother symbolic icon of the former East Berlin (and of East Germany as a whole) is the \"Ampelm\u00e4nnchen\" (tr. \"little traffic light men\"), a stylized version of a fedora-wearing man crossing the street, which is found on traffic lights at many pedestrian crosswalks throughout the former East. Following a civic debate about whether the Ampelm\u00e4nnchen should be abolished or disseminated more widely (due to concerns of consistency), several cross walks in some parts of the former West Berlin also employ the Ampelm\u00e4nnchen.\nTwenty-five years after the two cities were reunified, the people of East and West Berlin still had noticeable differences between them, which became more apparent among the older generations. The two groups also had sometimes-derogatory slang terms to refer to each other. A former East Berliner (or East German) was known as an \"\"Ossi\" (from the German word for east, \"Ost\"), and a former West Berliner (or West German) was known as a \"Wessi\"\" (from the German word for west, \"West\"). Both sides also engaged in stereotyping the other. A stereotypical \"Ossi\" had little ambition or poor work ethic and was chronically bitter, while a stereotypical \"Wessi\" was arrogant, selfish, impatient and pushy.\nBoroughs of East Berlin.\nAt the time of German reunification, East Berlin comprised the boroughs of"}
{"id": "9485", "revid": "182", "url": "https://en.wikipedia.org/wiki?curid=9485", "title": "Electronic instruments", "text": ""}
{"id": "9486", "revid": "10913857", "url": "https://en.wikipedia.org/wiki?curid=9486", "title": "List of international environmental agreements", "text": "This is a list of international environmental agreements.\nMost of the following agreements are legally binding for countries that have formally ratified them. Some, such as the Kyoto Protocol, differentiate between types of countries and each nation's respective responsibilities under the agreement. Several hundred international environmental agreements exist but most link only a limited number of countries. These bilateral or sometimes trilateral agreements are only binding for the countries that have ratified them but are nevertheless essential in the international environmental regime. Including the major conventions listed below, more than 3,000 international environmental instruments have been identified by the IEA Database Project.\nAlphabetical order.\nCoastal Marine and Island Biodiversity Conservation Project\nTopic order.\nAtmosphere.\n&lt;section begin=air treaties /&gt;\n&lt;section end=air treaties/&gt;\nHazardous substances.\n&lt;section begin=waste treaties /&gt;\n&lt;section end=waste treaties /&gt;"}
{"id": "9487", "revid": "16849003", "url": "https://en.wikipedia.org/wiki?curid=9487", "title": "Epsilon", "text": "Epsilon (, ; uppercase ', lowercase ' or lunate ; ) is the fifth letter of the Greek alphabet, corresponding phonetically to a . In the system of Greek numerals it also has the value five. It was derived from the Phoenician letter He . Letters that arose from epsilon include the Roman E, \u00cb and \u0190, and Cyrillic \u0415, \u00c8, \u0401, \u0404 and \u042d.\nThe name of the letter was originally (), but the name was changed to (\"e psilon\" \"simple e\") in the Middle Ages to distinguish the letter from the digraph , a former diphthong that had come to be pronounced the same as epsilon.\nThe uppercase form of epsilon looks identical to Latin E but has its own code point in Unicode: . The lowercase version has two typographical variants, both inherited from medieval Greek handwriting. One, the most common in modern typography and inherited from medieval minuscule, looks like a reversed number \"3\" and is encoded . The other, also known as lunate or uncial epsilon and inherited from earlier uncial writing, looks like a semicircle crossed by a horizontal bar: it is encoded . While in normal typography these are just alternative font variants, they may have different meanings as mathematical symbols: computer systems therefore offer distinct encodings for them. In TeX, codice_1 ( formula_1 ) denotes the lunate form, while codice_2 ( formula_2 ) denotes the reversed-3 form.\nThere is also a 'Latin epsilon', or \"open e\", which looks similar to the Greek lowercase epsilon. It is encoded in Unicode as and and is used as an IPA phonetic symbol. The lunate or uncial epsilon provided inspiration for the euro sign, .\nThe lunate epsilon, , is not to be confused with the set membership symbol ; nor should the Latin uppercase epsilon, , be confused with the Greek uppercase (sigma). The symbol formula_3, first used in set theory and logic by Giuseppe Peano and now used in mathematics in general for set membership (\"belongs to\") evolved from the letter epsilon, since the symbol was originally used as an abbreviation for the Latin word \"est\". In addition, mathematicians often read the symbol as \"element of\", as in \"1 is an element of the natural numbers\" for formula_4, for example. As late as 1960, \u03b5 itself was used for set membership, while its negation \"does not belong to\" (now ) was denoted by (epsilon prime). Only gradually did a fully separate, stylized symbol take the place of epsilon in this role. In a related context, Peano also introduced the use of a backwards epsilon, , for the phrase \"such that\", although the abbreviation \"s.t.\" is occasionally used in place of \u03f6 in informal cardinals.\nHistory.\nOrigin.\nThe letter \u0395 was taken over from the Phoenician letter He () when Greeks first adopted alphabetic writing. In archaic Greek writing, its shape is often still identical to that of the Phoenician letter. Like other Greek letters, it could face either leftward or rightward (), depending on the current writing direction, but, just as in Phoenician, the horizontal bars always faced in the direction of writing. Archaic writing often preserves the Phoenician form with a vertical stem extending slightly below the lowest horizontal bar. In the classical era, through the influence of more cursive writing styles, the shape was simplified to the current E glyph.\nSound value.\nWhile the original pronunciation of the Phoenician letter \"He\" was , the earliest Greek sound value of \u0395 was determined by the vowel occurring in the Phoenician letter name, which made it a natural choice for being reinterpreted from a consonant symbol to a vowel symbol denoting an sound. Besides its classical Greek sound value, the short phoneme, it could initially also be used for other -like sounds. For instance, in early Attic before c. 500 BC, it was used also both for the long, open , and for the long close . In the former role, it was later replaced in the classic Greek alphabet by Eta (\u0397), which was taken over from eastern Ionic alphabets, while in the latter role it was replaced by the digraph spelling \u0395\u0399.\nEpichoric alphabets.\nSome dialects used yet other ways of distinguishing between various e-like sounds.\nIn Corinth, the normal function of \u0395 to denote and was taken by a glyph resembling a pointed B (), while \u0395 was used only for long close . The letter Beta, in turn, took the deviant shape .\nIn Sicyon, a variant glyph resembling an X () was used in the same function as Corinthian .\nIn Thespiai (Boeotia), a special letter form consisting of a vertical stem with a single rightward-pointing horizontal bar () was used for what was probably a raised variant of in pre-vocalic environments. This tack glyph was used elsewhere also as a form of \"Heta\", i.e. for the sound .\nGlyph variants.\nAfter the establishment of the canonical classical Ionian (Eucleidean) Greek alphabet, new glyph variants for \u0395 were introduced through handwriting. In the uncial script (used for literary papyrus manuscripts in late antiquity and then in early medieval vellum codices), the \"lunate\" shape () became predominant. In cursive handwriting, a large number of shorthand glyphs came to be used, where the cross-bar and the curved stroke were linked in various ways. Some of them resembled a modern lowercase Latin \"e\", some a \"6\" with a connecting stroke to the next letter starting from the middle, and some a combination of two small \"c\"-like curves. Several of these shapes were later taken over into minuscule book hand. Of the various minuscule letter shapes, the inverted-3 form became the basis for lower-case Epsilon in Greek typography during the modern era.\nUses.\nInternational Phonetic Alphabet.\nDespite its pronunciation as , in the International Phonetic Alphabet, the Latin epsilon represents open-mid front unrounded vowel, as in the English word \"pet\" .\nSymbol.\nThe uppercase Epsilon is not commonly used outside of the Greek language because of its similarity to the Latin letter E. However, it is commonly used in structural mechanics with Young's Modulus equations for calculating tensile, compressive and areal strain.\nThe Greek lowercase epsilon , the lunate epsilon symbol , or the Latin lowercase epsilon (see above) is used in a variety of places:\nUnicode.\nThese characters are used only as mathematical symbols. Stylized Greek text should be encoded using the normal Greek letters, with markup and formatting to indicate text style."}
{"id": "9488", "revid": "1016287216", "url": "https://en.wikipedia.org/wiki?curid=9488", "title": "Eta", "text": "Eta (uppercase ', lowercase '; \"\u0113\u0302ta\" or \"ita\" ) is the seventh letter of the Greek alphabet. Originally denoting the consonant /h/, its sound value in the classical Attic dialect of Ancient Greek was a long vowel , raised to in hellenistic Greek, a process known as iotacism.\nIn the ancient Attic number system (Herodianic or acrophonic numbers), the number 100 was represented by \"\", because it was the initial of \"\u0397\u0395\u039a\u0391\u03a4\u039f\u039d\", the ancient spelling of \"\u1f11\u03ba\u03b1\u03c4\u03cc\u03bd\" = \"one hundred\". In the latter system of (Classical) Greek numerals it has a value of 8. \nEta was derived from the Phoenician letter heth . Letters that arose from eta include the Latin H and the Cyrillic letter \u0418.\nHistory.\nConsonant h.\nThe letter shape 'H' was originally used in most Greek dialects to represent the sound /h/, a voiceless glottal fricative. In this function, it was borrowed in the 8th century BC by the Etruscan and other Old Italic alphabets, which were based on the Euboean form of the Greek alphabet. This also gave rise to the Latin alphabet with its letter H.\nOther regional variants of the Greek alphabet (epichoric alphabets), in dialects that still preserved the sound /h/, employed various glyph shapes for consonantal \"heta\" side by side with the new vocalic \"eta\" for some time. \nIn the southern Italian colonies of Heracleia and Tarentum, the letter shape was reduced to a \"half-heta\" lacking the right vertical stem (\u0370). From this sign later developed the sign for rough breathing or \"spiritus asper\", which brought back the marking of the /h/ sound into the standardized post-classical (polytonic) orthography.\nDionysius Thrax in the second century BC records that the letter name was still pronounced \"heta\" (\u1f25\u03c4\u03b1), correctly explaining this irregularity by stating \"in the old days the letter \u0397 served to stand for the rough breathing, as it still does with the Romans.\"\nLong e.\nIn the East Ionic dialect, however, the sound /h/ disappeared by the sixth century BC, and the letter was re-used initially to represent a development of a long vowel , which later merged in East Ionic with instead. In 403 BC, Athens took over the Ionian spelling system and with it the vocalic use of H (even though it still also had the /h/ sound itself at that time). This later became the standard orthography in all of Greece.\nItacism.\nDuring the time of post-classical Koin\u00e9 Greek, the sound represented by eta was raised and merged with several other formerly distinct vowels, a phenomenon called \"iotacism\" or \"itacism\", after the new pronunciation of the letter name as \"ita\" instead of \"eta\".\nItacism is continued into Modern Greek, where the letter name is pronounced and represents the sound /i/ (a close front unrounded vowel). It shares this function with several other letters (\u03b9, \u03c5) and digraphs (\u03b5\u03b9, \u03bf\u03b9), which are all pronounced alike. This phenomenon at large is called iotacism.\nCyrillic script.\nEta was also borrowed with the sound value of [i] into the Cyrillic script, where it gave rise to the Cyrillic letter \u0418.\nUses.\nLetter.\nIn Modern Greek, due to iotacism, the letter (pronounced ) represents a close front unrounded vowel, . In Classical Greek, it represented a long open-mid front unrounded vowel, .\nSymbol.\nUpper case.\nThe uppercase letter \u0397 is used as a symbol in textual criticism for the Alexandrian text-type (from Hesychius, its once-supposed editor).\nIn chemistry, the letter H as symbol of enthalpy sometimes is said to be a Greek eta, but since enthalpy comes from \u1f10\u03bd\u03b8\u03ac\u03bb\u03c0\u03bf\u03c2, which begins in a smooth breathing and epsilon, it is more likely a Latin H for 'heat'.\nIn information theory the uppercase Greek letter H is used to represent the concept of entropy of a discrete random variable.\nLower case.\nThe lowercase letter \u03b7 is used as a symbol in:\nCharacter encodings.\nMathematical Eta.\nThese characters are used only as mathematical symbols. Stylized Greek text should be encoded using the normal Greek letters, with markup and formatting to indicate text style."}
{"id": "9489", "revid": "951220526", "url": "https://en.wikipedia.org/wiki?curid=9489", "title": "Eric Arthur Blair", "text": "Residing RNA inject \u00a9 chromosomes into proper pathway patch part plan pay prop propane pause... Page engage sage stoic Ronin ruckus notus lotus potent infiltration foundation non existent\nCorner stone"}
{"id": "9491", "revid": "11361977", "url": "https://en.wikipedia.org/wiki?curid=9491", "title": "Eskimo", "text": "Eskimo ( ) or Eskimos are the indigenous circumpolar peoples who have traditionally inhabited the northern circumpolar region from eastern Siberia (Russia) to Alaska (United States), Northern Canada, Nunavik, Nunatsiavut, and Greenland. \nThe two main peoples known as Eskimo are the Inuit (including the Alaskan I\u00f1upiat, the Greenlandic Inuit, and the Inuit peoples of Canada) and the Yupik (or \"Yuit\") of eastern Siberia and Alaska. A third northern group, the Aleut, are closely related to both. They share a relatively recent common ancestor and a language group, Eskimo-Aleut. \nMany Inuit, Yupik, Aleut and other individuals consider the term \"Eskimo\" to be unacceptable. The word has no exact synonym, and stems from the Montagnais \"ayas\u0306kimew\": \"netter of snowshoes\".\nThe non-Inuit sub-branch of the Eskimo branch of the Eskimo-Aleut language family consists of four distinct Yupik languages, two used in the Russian Far East and St. Lawrence Island, and two used in western Alaska, southwestern Alaska, and the western part of Southcentral Alaska. The extinct language of the Sirenik people is sometimes argued to be related to these.\nAccording to recent genomic research, the Chukchi people of eastern Siberia are the closest living relatives of the Siberian Yupik and other the indigenous peoples of the Americas.\nThere are more than 183,000 Eskimo people alive today, of which 135,000 or more live in or near the traditional circumpolar regions. The NGO known as the Inuit Circumpolar Council claims to represent 180,000 people.\nThe governments in Canada and the United States have made moves to cease using the term \"Eskimo\" in official documents, but it has not been entirely eliminated, as the word is in some places written into tribal, and therefore national, legal terminology. Canada officially uses the term \"Inuit\" to describe the Native people living in the country's northernmost sector. The United States government legally uses \"Alaska Native\" for the Yupik, Inuit, and Aleut, but also for non-Eskimo indigenous Alaskans including the Tlingit, the Haida, the Eyak, and the Tsimshian, in addition to at least nine separate northern Athabaskan/Dene peoples. The designation \"Alaska Native\" applies to enrolled tribal members only, in contrast to individual Eskimo/Aleut persons claiming descent from the world's \"most widespread aboriginal group\".\nHistory.\nA distinct Asian lineage exists for Siberian Yupik people and the North American speakers of the Eskimo-Aleut language group, who have up to 43% of their DNA in common with an ancient people or set of ancient peoples of otherwise unknown origin. It is understood that some or all of these ancient people underwent a stream of migration from Asia to North America during the pre-neolithic era, somewhere between 5,000 and 12,600 years ago. It is believed that ancestors of the Aleut people inhabited the Aleutian Chain 10,000 years ago.\nThe earliest positively identified Paleo-Eskimo cultures (Early Paleo-Eskimo) date to 5,000 years ago. Several earlier indigenous peoples existed in the northern circumpolar regions of eastern Siberia, Alaska, and Canada (although probably not in Greenland). The Paleo-Eskimo peoples appear to have developed in Alaska from people related to the Arctic small tool tradition in eastern Asia, whose ancestors had probably migrated to Alaska at least 3,000 to 5,000 years earlier. Similar artifacts have been found in Siberia that date to perhaps 18,000 years ago.\nThe Yupik languages and cultures in Alaska evolved in place, beginning with the original pre-Dorset Indigenous culture developed in Alaska. At least 4,000 years ago, the Unangan culture of the Aleut became distinct. It is not generally considered an Eskimo culture. However, there is some possibility of an Aleutian origin of the Dorset people, who in turn are a likely ancestor of Inuit and Yupik people today.\nApproximately 1,500 to 2,000 years ago, apparently in northwestern Alaska, two other distinct variations appeared. Inuit language became distinct and, over a period of several centuries, its speakers migrated across northern Alaska, through Canada, and into Greenland. The distinct culture of the Thule people (drawing strongly from the Birnirk culture) developed in northwestern Alaska. It very quickly spread over the entire area occupied by Eskimo peoples, though it was not necessarily adopted by all of them.\nNomenclature.\nEtymology.\nThere exists a scholarly consensus that the word Eskimo etymologically derives from the Innu-aimun (Montagnais) word \"ayas\u0306kimew\" meaning \"a person who laces a snowshoe\" (an origin proposed by Ives Goddard at the Smithsonian Institution), is related to \"husky\" (a breed of dog). The word \"assime\u00b7w\" means \"she laces a snowshoe\" in Innu, and Innu language speakers refer to the neighbouring Mi'kmaq people using words that sound like \"eskimo\".\nIn 1978, Jos\u00e9 Mailhot, a Quebec anthropologist who speaks Montagnais, published a paper suggesting that Eskimo meant \"people who speak a different language\". French traders who encountered the Montagnais in the eastern areas adopted their word for the more western peoples and spelled it as \"Esquimau\" in a transliteration.\nSome people consider \"Eskimo\" offensive, because it is popularly perceived to mean \"eaters of raw meat\" in Algonquian languages common to people along the Atlantic coast. An unnamed Cree speaker suggested the original word that became corrupted to Eskimo might have been \"askamiciw\" (which means \"he eats it raw\"); the Inuit are referred to in some Cree texts as \"askipiw\" (which means \"eats something raw\"). This etymology, which some people still believe, has been discredited. Regardless, the term still carries a derogatory connotation for many Inuit and Yupik.\nOne of the first printed uses of the French word \"Esquimaux\" comes from Samuel Hearne's \"A Journey from Prince of Wales's Fort in Hudson's Bay to the Northern Ocean in the Years 1769, 1770, 1771, 1772\" first published in 1795.\nUsage.\nThe term \"Eskimo\" is still used by people to encompass the Inuit and Yupik, as well as other Indigenous Alaskan and Siberian peoples. In the 21st century, usage in North America has declined. Linguistic, ethnic, and cultural differences exist between Yupik and Inuit.\nIn Canada and Greenland, and to a certain extent in Alaska, the term \"Eskimo\" is predominantly seen as offensive and has been widely replaced by the term \"Inuit\" or terms specific to a particular group or community. This has resulted in a trend whereby some Canadians and Americans believe that they should use \"Inuit\" even for Yupik who are a non-Inuit people.\nThe Inuit of Greenland generally refer to themselves as Greenlanders (\"Kalaallit\" or \"Gr\u00f8nl\u00e6ndere\") and speak the Greenlandic language and Danish. The Inuit of Greenland belong to three groups: the Kalaallit of west Greenland, who speak Kalaallisut; the Tunumiit of Tunu (east Greenland), who speak Tunumiit oraasiat (\"East Greenlandic\"); and the Inughuit of north Greenland, who speak Inuktun.\nThe word \"Eskimo\" is a racially charged term in Canada. In Canada's Central Arctic, \"Inuinnaq\" is the preferred, and in the eastern Canadian Arctic \"Inuit\". The language is often called \"Inuktitut\", though other local designations are also used. \nSection 25 of the Canadian Charter of Rights and Freedoms and section 35 of the Canadian Constitution Act of 1982 recognized the Inuit as a distinctive group of Aboriginal peoples in Canada. Although \"Inuit\" can be applied to all of the Eskimo peoples in Canada and Greenland, that is not true in Alaska and Siberia. In Alaska, the term \"Eskimo\" is still used (has been commonly used but is decreasing in prevalence) because it includes both I\u00f1upiat (singular: I\u00f1upiaq), who are Inuit, and Yupik, who are not.\nAlaskans also use the term \"Alaska Native\", which is inclusive of (and under U.S. and Alaskan law, as well as the linguistic and cultural legacy of Alaska, refers to) all Indigenous peoples of Alaska, including not only the I\u00f1upiat (Alaskan Inuit) and the Yupik, but also groups such as the Aleut, who share a recent ancestor, as well as the largely unrelated indigenous peoples of the Pacific Northwest Coast and the Alaskan Athabaskans, such as the Eyak people. The term \"Alaska Native\" has important legal usage in Alaska and the rest of the United States as a result of the Alaska Native Claims Settlement Act of 1971. It does not apply to Inuit or Yupik originating outside the state. As a result, the term Eskimo is still in use in Alaska. Alternative terms, such as \"Inuit-Yupik\", have been proposed, but none has gained widespread acceptance. Recent (early 21st century) population estimates registered more than 135,000 individuals of Eskimo descent, with approximately 85,000 living in North America, 50,000 in Greenland, and the rest residing in Siberia.\nInuit Circumpolar Council.\nIn 1977, the Inuit Circumpolar Conference (ICC) meeting in Utqia\u0121vik, Alaska, officially adopted \"Inuit\" as a designation for all circumpolar Native peoples, regardless of their local view on an appropriate term. They voted to replace the word \"Eskimo\" with \"Inuit\". Even at that time, such a designation was not accepted by all. As a result, the Canadian government usage has replaced the term \"Eskimo\" with \"Inuit\" (\"Inuk\" in singular). \nThe ICC charter defines \"Inuit\" as including \"the Inupiat, Yupik (Alaska), Inuit, Inuvialuit (Canada), Kalaallit (Greenland) and Yupik (Russia)\". Despite the ICC's 1977 decision to adopt the term \"Inuit\", this was never accepted by the Yupik, who likened it to calling all American Indians as \"Navajo\" simply because the Navajo felt that that was what all tribes should be called.\nIn 2010, the ICC passed a resolution in which they implored scientists to use \"Inuit\" and \"Paleo-Inuit\" instead of \"Eskimo\" or \"Paleo-Eskimo\". \nAcademic response.\nIn a 2015 commentary in the journal \"Arctic\", Canadian archaeologist Max Friesen argued fellow Arctic archaeologists should follow the ICC and use \"Paleo-Inuit\" instead of \"Paleo-Eskimo\". In 2016, Lisa Hodgetts and \"Arctic\" editor Patricia Wells wrote: \"In the Canadian context, continued use of any term that incorporates \"Eskimo\" is potentially harmful to the relationships between archaeologists and the Inuit and Inuvialuit communities who are our hosts and increasingly our research partners.\"\nHodgetts and Wells suggested using more specific terms when possible (e.g., Dorset and Groswater) and agreed with Frieson in using the \"Inuit tradition\" to replace \"Neo-Eskimo\", although they noted replacement for \"Palaeoeskimo\" was still an open question and discussed \"Paleo-Inuit\", \"Arctic Small Tool Tradition\", and \"pre-Inuit\", as well as Inuktitut loanwords like \"Tuniit\" and \"Sivullirmiut\", as possibilities. \nIn 2020, Katelyn Braymer-Hayes and colleagues argued in the \"Journal of Anthropological Archaeology\" that there is a \"clear need\" to replace the terms \"Neo-Eskimo\" and \"Paleo-Eskimo\", citing the ICC resolution, but finding a consensus within the Alaskan context particularly is difficult, since Alaska Natives do not use the word \"Inuit\" to describe themselves nor is the term legally applicable only to I\u00f1upiat and Yupik in Alaska, and as such, terms used in Canada like \"Paleo Inuit\" and \"Ancestral Inuit\" would not be acceptable.\nAmerican linguist Lenore Grenoble has also explicitly deferred to the ICC resolution and used \"Inuit\u2013Yupik\" instead of \"Eskimo\" with regards to the language branch.\nLanguages.\nThe Eskimo\u2013Aleut family of languages includes two cognate branches: the Aleut (Unangan) branch and the Eskimo branch.\nThe number of cases varies, with Aleut languages having a greatly reduced case system compared to those of the Eskimo subfamily. Eskimo\u2013Aleut languages possess voiceless plosives at the bilabial, coronal, velar and uvular positions in all languages except Aleut, which has lost the bilabial stops but retained the nasal. In the Eskimo subfamily a voiceless alveolar lateral fricative is also present.\nThe Eskimo sub-family consists of the Inuit language and Yupik language sub-groups. The Sirenikski language, which is virtually extinct, is sometimes regarded as a third branch of the Eskimo language family. Other sources regard it as a group belonging to the Yupik branch.\nInuit languages comprise a dialect continuum, or dialect chain, that stretches from Unalakleet and Norton Sound in Alaska, across northern Alaska and Canada, and east to Greenland. Changes from western (I\u00f1upiaq) to eastern dialects are marked by the dropping of vestigial Yupik-related features, increasing consonant assimilation (e.g., \"kumlu\", meaning \"thumb\", changes to \"kuvlu\", changes to \"kublu\", changes to \"kulluk\", changes to \"kulluq\",) and increased consonant lengthening, and lexical change. Thus, speakers of two adjacent Inuit dialects would usually be able to understand one another, but speakers from dialects distant from each other on the dialect continuum would have difficulty understanding one another. Seward Peninsula dialects in western Alaska, where much of the I\u00f1upiat culture has been in place for perhaps less than 500 years, are greatly affected by phonological influence from the Yupik languages. Eastern Greenlandic, at the opposite end of the Inuit range, has had significant word replacement due to a unique form of ritual name avoidance.\nEthnographically, Inuit of Greenland belong to three groups: the Kalaallit of west Greenland, who speak Kalaallisut; the Tunumiit of Tunu (east Greenland), who speak Tunumiit oraasiat (\"East Greenlandic\"), and the Inughuit of north Greenland, who speak Inuktun.\nThe four Yupik languages, by contrast, including Alutiiq (Sugpiaq), Central Alaskan Yup'ik, Naukan (Naukanski), and Siberian Yupik, are distinct languages with phonological, morphological, and lexical differences. They demonstrate limited mutual intelligibility. Additionally, both Alutiiq and Central Yup'ik have considerable dialect diversity. The northernmost Yupik languages \u2013 Siberian Yupik and Naukan Yupik \u2013 are linguistically only slightly closer to Inuit than is Alutiiq, which is the southernmost of the Yupik languages. Although the grammatical structures of Yupik and Inuit languages are similar, they have pronounced differences phonologically. Differences of vocabulary between Inuit and any one of the Yupik languages are greater than between any two Yupik languages. Even the dialectal differences within Alutiiq and Central Alaskan Yup'ik sometimes are relatively great for locations that are relatively close geographically.\nDespite the relatively small population of Naukan speakers, documentation of the language dates back to 1732. While Naukan is only spoken in Siberia, the language acts as an intermediate between two Alaskan languages: Siberian Yupik Eskimo and Central Yup'ik Eskimo.\nThe Sirenikski language is sometimes regarded as a third branch of the Eskimo language family, but other sources regard it as a group belonging to the Yupik branch.\nAn overview of the Eskimo\u2013Aleut languages family is given below:\nAmerican linguist Lenore Grenoble has explicitly deferred to this resolution and used \"Inuit\u2013Yupik\" instead of \"Eskimo\" with regards to the language branch.\nInuit.\nThe Inuit inhabit the Arctic and northern Bering Sea coasts of Alaska in the United States, and Arctic coasts of the Northwest Territories, Nunavut, Quebec, and Labrador in Canada, and Greenland (associated with Denmark). Until fairly recent times, there has been a remarkable homogeneity in the culture throughout this area, which traditionally relied on fish, marine mammals, and land animals for food, heat, light, clothing, and tools. Their food sources primarily relied on seals, whales, whale blubber, walrus, and fish, all of which they hunted using harpoons on the ice. Clothing consisted of robes made of wolfskin and reindeer skin to acclimate to the low temperatures. They maintain a unique Inuit culture.\nGreenland's Inuit.\nGreenlandic Inuit make up 90% of Greenland's population. They belong to three major groups:\nCanadian Inuit.\nCanadian Inuit live primarily in Inuit Nunangat (lit. \"lands, waters and ices of the [Inuit] people\"_, their traditional homeland although some people live in southern parts of Canada. Inuit Nunangat ranges from the Yukon\u2013Alaska border in the west across the Arctic to northern Labrador.\nThe Inuvialuit live in the Inuvialuit Settlement Region, the northern part of Yukon and the Northwest Territories, which stretches to the Amundsen Gulf and the Nunavut border and includes the western Canadian Arctic Islands. The land was demarked in 1984 by the Inuvialuit Final Agreement.\nThe majority of Inuit live in Nunavut (a territory of Canada), Nunavik (the northern part of Quebec) and in Nunatsiavut (the Inuit settlement region in Labrador).\nAlaska's I\u00f1upiat.\nThe I\u00f1upiat are the Inuit of Alaska's Northwest Arctic and North Slope boroughs and the Bering Straits region, including the Seward Peninsula. Utqia\u0121vik, the northernmost city in the United States, is above the Arctic Circle and in the I\u00f1upiat region. Their language is known as I\u00f1upiaq.\nYupik.\nThe Yupik are indigenous or aboriginal peoples who live along the coast of western Alaska, especially on the Yukon-Kuskokwim delta and along the Kuskokwim River (Central Alaskan Yup'ik); in southern Alaska (the Alutiiq); and along the eastern coast of Chukotka in the Russian Far East and St. Lawrence Island in western Alaska (the Siberian Yupik). The Yupik economy has traditionally been strongly dominated by the harvest of marine mammals, especially seals, walrus, and whales.\nAlutiiq.\nThe Alutiiq, also called \"Pacific Yupik\" or \"Sugpiaq\", are a southern, coastal branch of Yupik. They are not to be confused with the Aleut, who live further to the southwest, including along the Aleutian Islands. They traditionally lived a coastal lifestyle, subsisting primarily on ocean resources such as salmon, halibut, and whales, as well as rich land resources such as berries and land mammals. Alutiiq people today live in coastal fishing communities, where they work in all aspects of the modern economy. They also maintain the cultural value of a subsistence lifestyle.\nThe Alutiiq language is relatively close to that spoken by the Yupik in the Bethel, Alaska area. But, it is considered a distinct language with two major dialects: the Koniag dialect, spoken on the Alaska Peninsula and on Kodiak Island, and the Chugach dialect, spoken on the southern Kenai Peninsula and in Prince William Sound. Residents of Nanwalek, located on southern part of the Kenai Peninsula near Seldovia, speak what they call Sugpiaq. They are able to understand those who speak Yupik in Bethel. With a population of approximately 3,000, and the number of speakers in the hundreds, Alutiiq communities are working to revitalize their language.\nCentral Alaskan Yup'ik.\n\"Yup'ik\", with an apostrophe, denotes the speakers of the Central Alaskan Yup'ik language, who live in western Alaska and southwestern Alaska from southern Norton Sound to the north side of Bristol Bay, on the Yukon\u2013Kuskokwim Delta, and on Nelson Island. The use of the apostrophe in the name \"Yup'ik\" is a written convention to denote the long pronunciation of the \"p\" sound; but it is spoken the same in other Yupik languages. Of all the Alaska Native languages, Central Alaskan Yup'ik has the most speakers, with about 10,000 of a total Yup'ik population of 21,000 still speaking the language. The five dialects of Central Alaskan Yup'ik include General Central Yup'ik, and the Egegik, Norton Sound, Hooper Bay-Chevak, and Nunivak dialects. In the latter two dialects, both the language and the people are called \"Cup'ik\".\nSiberian Yupik.\nSiberian Yupik reside along the Bering Sea coast of the Chukchi Peninsula in Siberia in the Russian Far East and in the villages of Gambell and Savoonga on St. Lawrence Island in Alaska. The Central Siberian Yupik spoken on the Chukchi Peninsula and on St. Lawrence Island is nearly identical. About 1,050 of a total Alaska population of 1,100 Siberian Yupik people in Alaska speak the language. It is the first language of the home for most St. Lawrence Island children. In Siberia, about 300 of a total of 900 Siberian Yupik people still learn and study the language, though it is no longer learned as a first language by children.\nNaukan.\nAbout 70 of 400 Naukan people still speak Naukanski. The Naukan originate on the Chukot Peninsula in Chukotka Autonomous Okrug in Siberia. Despite the relatively small population of Naukan speakers, documentation of the language dates back to 1732. While Naukan is only spoken in Siberia, the language acts as an intermediate between two Alaskan languages: Siberian Yupik Eskimo and Central Yup'ik Eskimo.\nSirenik Eskimos.\nSome speakers of Siberian Yupik languages used to speak an Eskimo variant in the past, before they underwent a language shift. These former speakers of Sirenik Eskimo language inhabited the settlements of Sireniki, Imtuk, and some small villages stretching to the west from Sireniki along south-eastern coasts of Chukchi Peninsula. They lived in neighborhoods with Siberian Yupik and Chukchi peoples.\nAs early as in 1895, Imtuk was a settlement with a mixed population of Sirenik Eskimos and Ungazigmit (the latter belonging to Siberian Yupik). Sirenik Eskimo culture has been influenced by that of Chukchi, and the language shows Chukchi language influences. Folktale motifs also show the influence of Chuckchi culture.\nThe above peculiarities of this (already extinct) Eskimo language amounted to mutual unintelligibility even with its nearest language relatives: in the past, Sirenik Eskimos had to use the unrelated Chukchi language as a lingua franca for communicating with Siberian Yupik.\nMany words are formed from entirely different roots from in Siberian Yupik, but even the grammar has several peculiarities distinct not only among Eskimo languages, but even compared to Aleut. For example, dual number is not known in Sirenik Eskimo, while most Eskimo\u2013Aleut languages have dual, including its neighboring Siberian Yupikax relatives.\nLittle is known about the origin of this diversity. The peculiarities of this language may be the result of a supposed long isolation from other Eskimo groups, and being in contact only with speakers of unrelated languages for many centuries. The influence of the Chukchi language is clear.\nBecause of all these factors, the classification of Sireniki Eskimo language is not settled yet: Sireniki language is sometimes regarded as a third branch of Eskimo (at least, its possibility is mentioned). Sometimes it is regarded rather as a group belonging to the Yupik branch."}
{"id": "9495", "revid": "11555324", "url": "https://en.wikipedia.org/wiki?curid=9495", "title": "EU", "text": ""}
{"id": "9496", "revid": "1024100661", "url": "https://en.wikipedia.org/wiki?curid=9496", "title": "Epiphenomenalism", "text": "Epiphenomenalism is a position on the mind\u2013body problem which holds that physical and biochemical events within the human body (sense organs, neural impulses, and muscle contractions, for example) are causal with respect to mental events (thought, consciousness, and cognition). According to this view, subjective mental events are completely dependent for their existence on corresponding physical and biochemical events within the human body yet themselves have no causal efficacy on physical events. The appearance that subjective mental states (such as intentions) influence physical events is merely an illusion. For instance, fear seems to make the heart beat faster, but according to epiphenomenalism the biochemical secretions of the brain and nervous system (such as adrenaline)\u2014not the experience of fear\u2014is what raises the heartbeat. Because mental events are a kind of overflow that cannot cause anything physical, yet have non-physical properties, epiphenomenalism is viewed as a form of property dualism.\nDevelopment.\nDuring the seventeenth century, Ren\u00e9 Descartes argued that animals are subject to mechanical laws of nature. He defended the idea of automatic behavior, or the performance of actions without conscious thought. Descartes questioned how the immaterial mind and the material body can interact causally. His interactionist model (1649) held that the body relates to the mind through the pineal gland. La Mettrie, Leibniz, and Spinoza all in their own way began this way of thinking. The idea that even if the animal were conscious nothing would be added to the production of behavior, even in animals of the human type, was first voiced by La Mettrie (1745), and then by Cabanis (1802), and was further explicated by Hodgson (1870) and Huxley (1874).\nThomas Henry Huxley agreed with Descartes that behavior is determined solely by physical mechanisms, but he also believed that humans enjoy an intelligent life. In 1874, Huxley argued, in the Presidential Address to the British Association for the Advancement of Science, that animals are conscious automata. Huxley proposed that psychical changes are collateral products of physical changes. He termed the stream of consciousness an \"epiphenomenon;\" like the bell of a clock that has no role in keeping the time, consciousness has no role in determining behavior.\nHuxley defended automatism by testing reflex actions, originally supported by Descartes. Huxley hypothesized that frogs that undergo lobotomy would swim when thrown into water, despite being unable to initiate actions. He argued that the ability to swim was solely dependent on the molecular change in the brain, concluding that consciousness is not necessary for reflex actions. According to epiphenomenalism, animals experience pain only as a result of neurophysiology.\nIn 1870, Huxley conducted a case study on a French soldier who had sustained a shot in the Franco-Prussian War that fractured his left parietal bone. Every few weeks the soldier would enter a trance-like state, smoking, dressing himself, and aiming his cane like a rifle all while being insensitive to pins, electric shocks, odorous substances, vinegar, noise, and certain light conditions. Huxley used this study to show that consciousness was not necessary to execute these purposeful actions, justifying the assumption that humans are insensible machines. Huxley's mechanistic attitude towards the body convinced him that the brain alone causes behavior.\nIn the early 1900s scientific behaviorists such as Ivan Pavlov, John B. Watson, and B. F. Skinner began the attempt to uncover laws describing the relationship between stimuli and responses, without reference to inner mental phenomena. Instead of adopting a form of eliminativism or mental fictionalism, positions that deny that inner mental phenomena exist, a behaviorist was able to adopt epiphenomenalism in order to allow for the existence of mind. George Santayana (1905) believed that all motion has merely physical causes. Because consciousness is accessory to life and not essential to it, natural selection is responsible for ingraining tendencies to avoid certain contingencies without any conscious achievement involved. By the 1960s, scientific behaviourism met substantial difficulties and eventually gave way to the cognitive revolution. Participants in that revolution, such as Jerry Fodor, reject epiphenomenalism and insist upon the efficacy of the mind. Fodor even speaks of \"epiphobia\"\u2014fear that one is becoming an epiphenomenalist.\nHowever, since the cognitive revolution, there have been several who have argued for a version of epiphenomenalism. In 1970, Keith Campbell proposed his \"new epiphenomenalism\", which states that the body produces a spiritual mind that does not act on the body. How the brain causes a spiritual mind, according to Campbell, is destined to remain beyond our understanding forever (see New Mysterianism). In 2001, David Chalmers and Frank Jackson argued that claims about conscious states should be deduced a priori from claims about physical states alone. They offered that epiphenomenalism bridges, but does not close, the explanatory gap between the physical and the phenomenal realms. These more recent versions maintain that only the subjective, qualitative aspects of mental states are epiphenomenal. Imagine both Pierre and a robot eating a cupcake. Unlike the robot, Pierre is conscious of eating the cupcake while the behavior is under way. This subjective experience is often called a \"quale\" (plural qualia), and it describes the private \"raw feel\" or the subjective \"what-it-is-like\" that is the inner accompaniment of many mental states. Thus, while Pierre and the robot are both doing the same thing, only Pierre has the inner conscious experience.\nFrank Jackson (1982), for example, once espoused the following view:\nAccording to epiphenomenalism, mental states like Pierre's pleasurable experience\u2014or, at any rate, their distinctive qualia\u2014are epiphenomena; they are side-effects or by-products of physical processes in the body. If Pierre takes a second bite, it is not caused by his pleasure from the first; If Pierre says, \"That was good, so I will take another bite\", his speech act is not caused by the preceding pleasure. The conscious experiences that accompany brain processes are causally impotent. The mind might simply be a byproduct of other properties such as brain size or pathway activation synchronicity, which are adaptive.\nSome thinkers draw distinctions between different varieties of epiphenomenalism. In \"Consciousness Explained\", Daniel Dennett distinguishes between a purely metaphysical sense of epiphenomenalism, in which the epiphenomenon has no causal impact at all, and Huxley's \"steam whistle\" epiphenomenalism, in which effects exist but are not functionally relevant.\nArguments for.\nA large body of neurophysiological data seems to support epiphenomenalism . Some of the oldest such data is the Bereitschaftspotential or \"readiness potential\" in which electrical activity related to voluntary actions can be recorded up to two seconds before the subject is aware of making a decision to perform the action. More recently Benjamin Libet et al. (1979) have shown that it can take 0.5 seconds before a stimulus becomes part of conscious experience even though subjects can respond to the stimulus in reaction time tests within 200 milliseconds. The methods and conclusions of this experiment have received much criticism (e.g., see the many critical commentaries in Libet's (1985) target article), including recently by neuroscientists such as Peter Tse, who claim to show that the readiness potential has nothing to do with consciousness at all. Recent research on the Event Related Potential also shows that conscious experience does not occur until the late phase of the potential (P3 or later) that occurs 300 milliseconds or more after the event. In Bregman's auditory continuity illusion, where a pure tone is followed by broadband noise and the noise is followed by the same pure tone it seems as if the tone occurs throughout the period of noise. This also suggests a delay for processing data before conscious experience occurs. Popular science author Tor N\u00f8rretranders has called the delay the \"user illusion\", implying that we only have the illusion of conscious control, most actions being controlled automatically by non-conscious parts of the brain with the conscious mind relegated to the role of spectator.\nThe scientific data seem to support the idea that conscious experience is created by non-conscious processes in the brain (i.e., there is subliminal processing that becomes conscious experience). These results have been interpreted to suggest that people are capable of action before conscious experience of the decision to act occurs. Some argue that this supports epiphenomenalism, since it shows that the feeling of making a decision to act is actually an epiphenomenon; the action happens before the decision, so the decision did not cause the action to occur.\nArguments against.\nThe most powerful argument against epiphenomenalism is that it is self-contradictory: if we have knowledge about epiphenomenalism, then our brains know about the existence of the mind, but if epiphenomenalism were correct, then our brains should not have any knowledge about the mind, because the mind does not affect anything physical.\nHowever, some philosophers do not accept this as a rigorous refutation. For example, Victor Argonov states that epiphenomenalism is a questionable, but experimentally falsifiable theory. He argues that the personal mind is not the only source of knowledge about the existence of mind in the world. A creature (even a zombie) could have knowledge about mind and the mind-body problem by virtue of some innate knowledge. The information about mind (and its problematic properties such as qualia) could have been, in principle, implicitly \"written\" in the material world since its creation. Epiphenomenalists can say that God created immaterial mind and a detailed \"program\" of material human behavior that makes it possible to speak about the mind\u2013body problem. That version of epiphenomenalism seems highly exotic, but it cannot be excluded from consideration by pure theory. However, Argonov suggests that experiments could refute epiphenomenalism. In particular, epiphenomenalism could be refuted if neural correlates of consciousness can be found in the human brain, and it is proven that human speech about consciousness is caused by them.\nSome philosophers, such as Dennett, reject both epiphenomenalism and the existence of qualia with the same charge that Gilbert Ryle leveled against a Cartesian \"ghost in the machine\", that they too are category mistakes. A quale or conscious experience would not belong to the category of objects of reference on this account, but rather to the category of ways of doing things.\nFunctionalists assert that mental states are well described by their overall role, their activity in relation to the organism as a whole. \"This doctrine is rooted in Aristotle's conception of the soul, and has antecedents in Hobbes's conception of the mind as a 'calculating machine', but it has become fully articulated (and popularly endorsed) only in the last third of the 20th century.\" In so far as it mediates stimulus and response, a mental function is analogous to a program that processes input/output in automata theory. In principle, multiple realisability would guarantee platform dependencies can be avoided, whether in terms of hardware and operating system or, \"ex hypothesi\", biology and philosophy. Because a high-level language is a practical requirement for developing the most complex programs, functionalism implies that a non-reductive physicalism would offer a similar advantage over a strictly eliminative materialism.\nEliminative materialists believe \"folk psychology\" is so unscientific that, ultimately, it will be better to eliminate primitive concepts such as \"mind,\" \"desire\" and \"belief,\" in favor of a future neuro-scientific account. A more moderate position such as J. L. Mackie's \"error theory\" suggests that false beliefs should be stripped away from a mental concept without eliminating the concept itself, the legitimate core meaning being left intact.\nBenjamin Libet's results are quoted in favor of epiphenomenalism, but he believes subjects still have a \"conscious veto\", since the readiness potential does not invariably lead to an action. In \"Freedom Evolves\", Daniel Dennett argues that a no-free-will conclusion is based on dubious assumptions about the location of consciousness, as well as questioning the accuracy and interpretation of Libet's results. Similar criticism of Libet-style research has been made by neuroscientist Adina Roskies and cognitive theorists Tim Bayne and Alfred Mele.\nOthers have argued that data such as the Bereitschaftspotential undermine epiphenomenalism for the same reason, that such experiments rely on a subject reporting the point in time at which a conscious experience and a conscious decision occurs, thus relying on the subject to be able to consciously perform an action. That ability would seem to be at odds with early epiphenomenalism, which according to Huxley is the broad claim that consciousness is \"completely without any power\u2026 as the steam-whistle which accompanies the work of a locomotive engine is without influence upon its machinery\".\nAdrian G. Guggisberg and Anna\u00efs Mottaz have also challenged those findings.\nA study by Aaron Schurger and colleagues published in PNAS challenged assumptions about the causal nature of the readiness potential itself (and the \"pre-movement buildup\" of neural activity in general), thus denying the conclusions drawn from studies such as Libet's and Fried's.\nIn favor of interactionism, Celia Green (2003) argues that epiphenomenalism does not even provide a satisfactory solution to the problem of interaction posed by substance dualism. Although it does not entail substance dualism, according to Green, epiphenomenalism implies a one-way form of interactionism that is just as hard to conceive of as the two-way form embodied in substance dualism. Green suggests the assumption that it is less of a problem may arise from the unexamined belief that physical events have some sort of primacy over mental ones.\nA number of scientists and philosophers, including William James, Karl Popper, John C. Eccles and Donald Symons, dismiss epiphenomenalism from an evolutionary perspective. They point out that the view that mind is an epiphenomenon of brain activity is not consistent with evolutionary theory, because if mind were functionless, it would have disappeared long ago, as it would not have been favoured by evolution."}
{"id": "9497", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=9497", "title": "Esperantio", "text": ""}
{"id": "9498", "revid": "93143", "url": "https://en.wikipedia.org/wiki?curid=9498", "title": "Esperantujo", "text": "Esperantujo () or Esperantio is the Esperanto community: the community of speakers of the Esperanto language and their culture, as well as the places and institutions where the language is used. The term is used \"as if it were a country.\"\nAlthough it does not occupy its own area of Earth's surface, it can be said to constitute the 120 countries which have their own national Esperanto association.\nEtymology and terminology.\nThe word is formed analogously to country names. In Esperanto, the names of countries were traditionally formed from the ethnic name of their inhabitants plus the suffix \"-ujo\", for example, \"France\" was \"Francujo\", from \"franco\" (a Frenchman).\nThe term analogous to \"Francujo\" would be \"Esperantistujo\" (Esperantist-nation). However, that would convey the idea of the physical body of people, whereas using the name of the language as the basis of the word gives it the more abstract connotation of a cultural sphere.\nCurrently, names of nation states are often formed with the suffix \"-io\" traditionally reserved for deriving country names from geographic features, so now \"Francio\", and recently the form \"Esperantio\" has been used \"i.a.\" in the Pasporta Servo and the Esperanto Citizens' Community.\nHistory.\nIn 1908, Dr. Wilhelm Molly attempted to create an Esperanto state in the Prussian-Belgian condominium of Neutral Moresnet, known as \"Amikejo\" (place of friendship). What became of it is unclear, and Neutral Moresnet was annexed to Belgium in the Treaty of Versailles, 1919.\nDuring the 1960s came a new effort of creating an Esperanto state, which this time was called Republic of Rose Island. The state island stood in the Adriatic Sea near Italy.\nIn Europe on 2 June 2001 a number of organizations (they prefer to call themselves establishments) founded the \"Esperanta Civito\", which \"aims to be a subject of international law\" and \"aims to consolidate the relations between the Esperantists who feel themselves belonging to the diaspora language group which does not belong to any country\". \"Esperanto Civito\" always uses the name Esperantujo (introduced by Hector Hodler in 1908), which itself is defined according to their interpretation of \"raumism\", and the meaning, therefore, may differ from the traditional Esperanto understanding of the word \"Esperantujo\".\nGeography.\nEsperantujo means any physical place as Esperanto meetings or virtual networks where they meet Esperanto speakers. Sometimes it is said that it is everywhere, where Esperanto speakers are yet connected.\nThere is a German city, Herzberg am Harz, which since 12 July 2006 is called \"the Esperanto city\". There are bilingual signs and pointers, in both German and Esperanto.\nJudging by the members of the World Esperanto Association, the countries with the most Esperanto speakers are (in descending order): Brazil, Germany, Japan, France, the United States, China, Italy.\nA language learning partner application called Amikumu has been launched in 2017, allowing Esperanto speakers to find each other.\nPolitics.\nAssociations.\nThere is no governmental system in Esperantujo because it is not a true state. However, there is a social hierarchy of associations:\nAlso there are thematic associations worldwide, which are concerned with spirituality, hobbies, science or that brings together Esperantists which share common interests.\nThere is also a number of global organizations, such as Sennacieca Asocio Tutmonda (SAT), or the World Esperanto Youth Organization (TEJO), which has 46 national sections.\nForeign relations.\nUniversal Esperanto Association is not a governmental system; however, the association represents Esperanto worldwide. In addition to the United Nations and UNESCO, the UEA has consultative relationships with UNICEF and the Council of Europe and general cooperative relations with the [[Organization of American States]]. UEA officially collaborates with the [[International Organization for Standardization]] (ISO) by means of an active connection to the ISO Committee on terminology (ISO/TC 37). The association is active for information on the [[European Union]] and other interstate and international organizations and conferences. UEA is a member of [[European Language Council]], a joint forum of universities and linguistic associations to promote the knowledge of languages and cultures within and outside the European Union. Moreover, on 10 May 2011, the UEA and the [[Infoterm|International Information Center for Terminology]] (Infoterm) signed an Agreement on Cooperation, its objectives are inter exchange information, support each other and help out for projects, meetings, publications in the field of terminology and by which the UEA become Associate Member of Infoterm.\nPolitical movement.\nIn 2003 there was a European political movement called [[Europe\u2013Democracy\u2013Esperanto]] created. Within it is found a European federation that brings together local associations whose statutes depends on the countries. The working language of the movement is Esperanto. The goal is \"to provide the [[European Union]] with the necessary tools to set up member rights democracy\". The [[international auxiliary language|international language]] is a tool to enable cross-border political and social dialogue and actively contribute to peace and understanding between peoples. The original idea in the first ballot was mainly to spread the existence and the use of Esperanto to the general public. However, in France voices have grown steadily: 25067 (2004) 28944 (2009) and 33115 (2014). In this country there are a number of movements which support the issue: [[France \u00c9quit\u00e9]], [[Europe-Libert\u00e9]], and [[Politicat]].\nSymbols.\n[[File:Flag of Esperanto.svg|thumb|[[Flag of Esperanto|Verda Flago]].]]\nThe [[flag of Esperanto]] is called \"Verda Flago\" (Green Flag). It consists of:\nThe anthem is called \"La Espero\" since 1891: it is a poem written by [[L. L. Zamenhof]]. The song is usually sung at the triumphal march composed by [[F\u00e9licien Menu de M\u00e9nil]] in 1909.\nThe Jubilee symbol represents the language internally, while the flag represents the Esperanto movement. It contains the Latin letter E (Esperanto) and the Cyrillic letter \u042d (\u042d\u0441\u043f\u0435\u0440\u0430\u043d\u0442\u043e) symbolizing the unification of West and East. The Jubilee symbol has been controversial, with some Esperantists derisively calling it \"the melon.\" \nIn addition, Ludwik Lejzer Zamenhof, the initiator of the language, is often used as a symbol. Sometimes he is even called \"Uncle Zam\", referring to the cartoon incarnation of American [[Uncle Sam]].\nPopulation.\nEducation.\n[[File:KER-Ekzameno Atestilo C1.JPG|thumb|right|250px|Certificate of KER-exam]]\nIn addition to textbooks, including the \"[[Fundamento de Esperanto]]\" by Zamenhof, the [[Assimil]]-methods and the video-methods such as [[Muzzy in Gondoland]] of the [[BBC]] and \"[[Pasporto al la tuta mondo]]\", there are many courses for learning online. Moreover, some universities teach Esperanto, and the [[ELTE-ITK|Higher Foreign Language training (University E\u00f6tv\u00f6s Lor\u00e1nd)]] delivers certificates in accordance with the [[Common European Framework of Reference for Languages]] (CEFR). More than 1600 people have such a certificate around the world: in 2014 around 470 at the level of B1, 510 at the level of B2 and 700 for C1. The [[International League of Esperanto Teachers]] (ILEI) is also working to publish learning materials for teachers.\nThe University of Esperanto offers video lectures in Esperanto, for specialties like Confronting War, Informational Technologies and Astronomy. Courses are also held during the [[World Esperanto Congress]] in the framework of the [[Internacia Kongresa Universitato]] (IKU). After that, [[Universal Esperanto Association|UEA]] uploads the related documents on its website.\nScience is an appropriate department for works in Esperanto. For example, the [[Conference on the Application of Esperanto in Science and Technology]] (KAEST) occurs in November every year since 1998 in the [[Czech Republic]] and [[Slovakia]]. Personal initiatives are also common: Doctor of mathematics [[Ulrich Matthias]] created a document about the foundations of Linear Algebra and the American group of [[Maine]] (USA) wrote a guidebook to learn the programming language [[Python (programming language)|Python]].\nIn general, Esperanto is used as a [[lingua franca]] in some websites aiming teaching of other languages, such as [[German language|German]], [[Slovak language|Slovak]], [[Swahili language|Swahili]], [[Wolof language|Wolof]] or [[Toki Pona]].\nMedia.\nSince 1889 when \"[[La Esperantisto]]\" appeared, and soon other magazines in Esperanto throughout many countries in the world. Some of them are information media of Esperanto associations (\"[[Esperanto (magazine)|Esperanto]]\", \"[[Sennaciulo]]\" and \"[[Kontakto]]\"). Online Esperanto magazines like \"[[Libera Folio]]\", launched in 2003, offer independent view of the Esperanto movement, aiming to soberly and critically shed light on current development. Most of the magazines deal with current events; one of such magazines is \"[[Monato]]\", which is read in more than 60 countries. Its articles are written by correspondents from 40 countries, which know the local situation very well. Other most popular Esperanto newspapers are \"[[La Ondo de Esperanto]]\", \"[[Beletra Almanako]]\", \"[[Literatura Foiro]]\", and \"[[Heroldo de Esperanto]]\". Often national associations magazines are also published in order to inform about the movement in the country, such as \"Le Monde de l'esp\u00e9ranto\" of [[Esp\u00e9ranto-France]]. There are also scientific journals, such as \"[[Scienca Revuo]]\" of [[Internacia Scienca Asocio Esperantista]] (ISAE).\n\"Muzaiko\" is a radio that has broadcast an all-day international program of songs, interviews and current events in Esperanto since 2011. The latest two can be downloaded as podcasts. Besides Muzaiko, these other stations offer an hour of Esperanto-language broadcasting of various topics: \"[[Radio Libertaire]]\", \"[[Polskie Radio]]\", \"[[Vatican Radio]]\", \"[[Varsovia Vento]], \"[[Radio Verda]] and \"[[Kern.punkto]]\".\nInternet.\nSpread of the [[Internet]] has enabled more efficient communication among Esperanto speakers and slightly replaced slower media such as [[mail]]. Many massively used websites such as [[Facebook]] or [[Google]] offer Esperanto interface. On 15 December 2009, on the occasion of the jubilee of 150th birthday of [[L. L. Zamenhof]], Google additionally made visible the Esperanto flag as a part of their [[Google Doodles]]. Media as [[Twitter]], [[Telegram (software)|Telegram]], [[Reddit]] or [[Ipernity]] also contain a significant number of people in this community. In addition, content-providers such as [[WordPress]] and [[YouTube]] also enable bloggers write in Esperanto. Esperanto versions of programs such as the office suite [[LibreOffice]] and [[Mozilla Firefox]] browser, or the educational program about programming [[Scratch (programming language)|Scratch]] are also available. Additionally, online games like [[Minecraft]] offer complete Esperanto interface.\n[[Monero (cryptocurrency)|Monero]], an anonymous [[cryptocurrency]], was named after the Esperanto word for \"coin\" and its official [[Cryptocurrency wallet|wallet]] is available in Esperanto. The same applies to Monerujo (\"Monero container\"), the only [[Open-source software|open-source]] wallet for [[Android (operating system)|Android]]. \nSport.\nAlthough Esperanto is not a country, there is an [[Esperanto football team]] , which has existed since 2014 and participates in matches during [[World Esperanto Congress]]es. The team is part of the [[N.F.-Board]] and not of [[FIFA]], and have played against the teams of Armenian-originating Argentine Community in 2014 and the team from [[Western Sahara]] in 2015.\nEsperanto speakers and Esperantists.\nInitially, Esperanto speakers learned the language as it was described by [[L. L. Zamenhof]]. In 1905 the \"[[Fundamento de Esperanto]]\" put together the first Esperanto textbook, an exercise book and a universal dictionary.\nThe [[Declaration of Boulogne|\"Declaration about the essence of Esperantism\"]] (1905) defines an \"Esperantist\" to be anyone who speaks and uses Esperanto. \"Esperantism\" was defined to be a movement to promote the widespread use of Esperanto as a supplement to [[First language|mother tongues]] in international and inter-ethnic contexts. As the word \"esperantist\" is linked with this \"esperantism\" (the [[Esperanto movement]]) and as -ists and -isms are linked with ideologies, today many people who speak Esperanto prefer to be called \"Esperanto speaker\".\nThe monthly magazine \"[[La Ondo de Esperanto]]\" every year since 1998 proclaims an 'Esperantist of the year', who remarkably contributed to the spreading of the language during the year.\nEconomy.\nBusinesses.\nPublishing and selling books, the so-called book services, is the main market and is often the first expenditure of many Esperanto associations. Some companies are already well known: for example [[Vinilkosmo]], which publishes and makes popular Esperanto music since 1990. Then there are initiatives such as the job-seeking website \"[[Eklaboru]]\", created by Chuck Smith, for job offers and candidates within Esperanto associations or Esperanto meetings.\nCurrency.\nIn 1907, [[Ren\u00e9 de Saussure]] proposed the [[spesmilo]] \u27e8\u20b7\u27e9 as an international currency. It had some use before the First World War.\nIn 1942 a currency called the \"[[stelo]]\" (\"star\"; plural, \"steloj\") was created. It was used at meetings of the \"[[Universala Ligo]]\" and in Esperanto environments such as the annual [[World Esperanto Congress|Universal Congress]]. Over the years it slowly became unusable and at the official closing of the Universala Ligo in the 1990s, the remaining \"steloj\" coins were handed over to the [[Universal Esperanto Association|UEA]]. You can buy them at the UEA's book service as souvenirs.\nThe current \"steloj\" are made of plastic, they are used in a number of meetings, especially among young people. The currency is maintained by Stelaro, which calculates the rates, keeps the stock, and opened branches in various e-meetings. Currently, there are \"stelo\"-coins of 1 \u2605, 3 \u2605 and 10 \u2605. Quotes of Stars at 31 December 2014 were [25] 1 EUR = 4.189 \u2605.\nCulture.\nArchitectural heritage.\n[[File:A\u016dstrio-Vieno-Zamenhof-monumento-2.jpg|thumb|right|L. L. Zamenhof [[bust (sculpture)|bust]] in the [[Esperantopark]] in [[Vienna]]]]\nThere exist [[Zamenhof-Esperanto object]]s (ZEOs), scattered in numerous countries around the world, which are the things named in honor of [[L. L. Zamenhof]] or Esperanto: monuments, street names, places and so on. There also exists a [[Universal Esperanto Association|UEA]]-committee for ZEOs.\nIn addition, in several countries there are also sites dedicated to Esperanto: meetup places, workshops, seminars, festivals, Esperanto houses. These places provide attractions for Esperantists. Here are two: the [[Castle of Gr\u00e9silion]] in [[France]] and the [[Department of Planned Languages and Esperanto Museum]] in [[Vienna]] ([[Austria]]).\nCultural heritage.\n[[File:2008-07-19 kd-oj en uk-ls.JPG|thumb|250px|right|Music in Esperanto]]\nEsperanto literary heritage is the richest and the most diverse of any constructed language. There are over 25,000 Esperanto books (originals and translations) as well as over a hundred regularly distributed [[List of Esperanto magazines|Esperanto magazines]].\nThere are also a [[List of Esperanto-language films|number of movies]] which have been published in Esperanto. Moreover, Esperanto itself was used in numerous movies.\nCelebrations.\nMany public holidays recognized by Esperanto speakers are celebrated international and already accepted in other countries and organizations such as [[UN]] or [[UNESCO]]. Here are the celebrations internationally proposed by the [[Universal Esperanto Association|UEA]] since 2010:\nCultural events.\n[[File:Renkontighoj en Germanio partoprenantoj.png|thumb|250px|Number of participants of Esperanto-meeting in Central Europe]]\nEvery year numerous meetings of Esperanto speakers in different topics around the world take place. They mobilize Esperanto-speakers which share the same will about a specific topic. The main example is the [[Universal Congress of Esperanto]] (UK), which annually organizes the [[Universal Esperanto Association|UEA]] every summer for a week. Other events:\nNext to these globally comprising meetings there are also local events such as [[Novjara Renkonti\u011do|New Year's Gathering]] (NR) or [[Esperanto Youth Week]] (JES), which occur during the last days of December and first days of January. These meetings seem to have been successful during the last 20 years.\nDue to the fact that there are a lot of Esperanto meetings around the globe, there are two websites which aim to list and share them. Eventoj.hu describes them with a list and dates, and contains an archive until 1996, while Esperant.io offers world map with the locations of future meetings.\nReferences.\n[[Category:Esperanto]]"}
{"id": "9499", "revid": "33089882", "url": "https://en.wikipedia.org/wiki?curid=9499", "title": "Ethernet", "text": "Ethernet () is a family of wired computer networking technologies commonly used in local area networks (LAN), metropolitan area networks (MAN) and wide area networks (WAN). It was commercially introduced in 1980 and first standardized in 1983 as IEEE 802.3. Ethernet has since been refined to support higher bit rates, a greater number of nodes, and longer link distances, but retains much backward compatibility. Over time, Ethernet has largely replaced competing wired LAN technologies such as Token Ring, FDDI and ARCNET.\nThe original 10BASE5 Ethernet uses coaxial cable as a shared medium, while the newer Ethernet variants use twisted pair and fiber optic links in conjunction with switches. Over the course of its history, Ethernet data transfer rates have been increased from the original 2.94 megabits per second (Mbit/s) to the latest 400\u00a0gigabits per second (Gbit/s). The comprise several wiring and signaling variants of the OSI physical layer in use with Ethernet.\nSystems communicating over Ethernet divide a stream of data into shorter pieces called frames. Each frame contains source and destination addresses, and error-checking data so that damaged frames can be detected and discarded; most often, higher-layer protocols trigger retransmission of lost frames. Per the OSI model, Ethernet provides services up to and including the data link layer. The 48-bit MAC address was adopted by other IEEE 802 networking standards, including IEEE 802.11 (Wi-Fi), as well as by FDDI. EtherType values are also used in Subnetwork Access Protocol (SNAP) headers.\nEthernet is widely used in homes and industry, and interworks well with wireless Wi-Fi technologies. The Internet Protocol is commonly carried over Ethernet and so it is considered one of the key technologies that make up the Internet.\nHistory.\nEthernet was developed at Xerox PARC between 1973 and 1974. It was inspired by ALOHAnet, which Robert Metcalfe had studied as part of his PhD dissertation. The idea was first documented in a memo that Metcalfe wrote on May 22, 1973, where he named it after the luminiferous aether once postulated to exist as an \"omnipresent, completely-passive medium for the propagation of electromagnetic waves.\" In 1975, Xerox filed a patent application listing Metcalfe, David Boggs, Chuck Thacker, and Butler Lampson as inventors. In 1976, after the system was deployed at PARC, Metcalfe and Boggs published a seminal paper. Yogen Dalal, Ron Crane, Bob Garner, and Roy Ogus facilitated the upgrade from the original 2.94\u00a0Mbit/s protocol to the 10\u00a0Mbit/s protocol, which was released to the market in 1980.\nMetcalfe left Xerox in June 1979 to form 3Com. He convinced Digital Equipment Corporation (DEC), Intel, and Xerox to work together to promote Ethernet as a standard. As part of that process Xerox agreed to relinquish their 'Ethernet' trademark. The first standard was published on September 30, 1980 as \"The Ethernet, A Local Area Network. Data Link Layer and Physical Layer Specifications\". This so-called DIX standard (Digital Intel Xerox) specified 10\u00a0Mbit/s Ethernet, with 48-bit destination and source addresses and a global 16-bit Ethertype-type field. Version 2 was published in November, 1982 and defines what has become known as Ethernet II. Formal standardization efforts proceeded at the same time and resulted in the publication of IEEE 802.3 on June 23, 1983.\nEthernet initially competed with Token Ring and other proprietary protocols. Ethernet was able to adapt to market needs and with 10BASE2, shift to inexpensive thin coaxial cable and from 1990, to the now-ubiquitous twisted pair with 10BASE-T. By the end of the 1980s, Ethernet was clearly the dominant network technology. In the process, 3Com became a major company. 3Com shipped its first 10\u00a0Mbit/s Ethernet 3C100 NIC in March 1981, and that year started selling adapters for PDP-11s and VAXes, as well as Multibus-based Intel and Sun Microsystems computers. This was followed quickly by DEC's Unibus to Ethernet adapter, which DEC sold and used internally to build its own corporate network, which reached over 10,000 nodes by 1986, making it one of the largest computer networks in the world at that time. An Ethernet adapter card for the IBM PC was released in 1982, and, by 1985, 3Com had sold 100,000. In the 1980s, IBM's own PC Network product competed with Ethernet for the PC, and through the 1980s, LAN hardware, in general, was not common on PCs. However, in the mid to late 1980s, PC networking did become popular in offices and schools for printer and fileserver sharing, and among the many diverse competing LAN technologies of that decade, Ethernet was one of the most popular. Parallel port based Ethernet adapters were produced for a time, with drivers for DOS and Windows. By the early 1990s, Ethernet became so prevalent that Ethernet ports began to appear on some PCs and most workstations. This process was greatly sped up with the introduction of 10BASE-T and its relatively small modular connector, at which point Ethernet ports appeared even on low-end motherboards.\nSince then, Ethernet technology has evolved to meet new bandwidth and market requirements. In addition to computers, Ethernet is now used to interconnect appliances and other personal devices. As Industrial Ethernet it is used in industrial applications and is quickly replacing legacy data transmission systems in the world's telecommunications networks. By 2010, the market for Ethernet equipment amounted to over $16\u00a0billion per year.\nStandardization.\nIn February 1980, the Institute of Electrical and Electronics Engineers (IEEE) started project 802 to standardize local area networks (LAN). The \"DIX-group\" with Gary Robinson (DEC), Phil Arst (Intel), and Bob Printis (Xerox) submitted the so-called \"Blue Book\" CSMA/CD specification as a candidate for the LAN specification. In addition to CSMA/CD, Token Ring (supported by IBM) and Token Bus (selected and henceforward supported by General Motors) were also considered as candidates for a LAN standard. Competing proposals and broad interest in the initiative led to strong disagreement over which technology to standardize. In December 1980, the group was split into three subgroups, and standardization proceeded separately for each proposal.\nDelays in the standards process put at risk the market introduction of the Xerox Star workstation and 3Com's Ethernet LAN products. With such business implications in mind, David Liddle (General Manager, Xerox Office Systems) and Metcalfe (3Com) strongly supported a proposal of Fritz R\u00f6scheisen (Siemens Private Networks) for an alliance in the emerging office communication market, including Siemens' support for the international standardization of Ethernet (April 10, 1981). Ingrid Fromm, Siemens' representative to IEEE 802, quickly achieved broader support for Ethernet beyond IEEE by the establishment of a competing Task Group \"Local Networks\" within the European standards body ECMA TC24. In March 1982, ECMA TC24 with its corporate members reached an agreement on a standard for CSMA/CD based on the IEEE 802 draft. Because the DIX proposal was most technically complete and because of the speedy action taken by ECMA which decisively contributed to the conciliation of opinions within IEEE, the IEEE 802.3 CSMA/CD standard was approved in December 1982. IEEE published the 802.3 standard as a draft in 1983 and as a standard in 1985.\nApproval of Ethernet on the international level was achieved by a similar, cross-partisan action with Fromm as the liaison officer working to integrate with International Electrotechnical Commission (IEC) Technical Committee 83 and International Organization for Standardization (ISO) Technical Committee 97 Sub Committee 6. The ISO 8802-3 standard was published in 1989.\nEvolution.\nEthernet has evolved to include higher bandwidth, improved medium access control methods, and different physical media. The coaxial cable was replaced with point-to-point links connected by Ethernet repeaters or switches.\nEthernet stations communicate by sending each other data packets: blocks of data individually sent and delivered. As with other IEEE 802 LANs, adapters come programmed with globally unique 48-bit MAC address so that each Ethernet station has a unique address. The MAC addresses are used to specify both the destination and the source of each data packet. Ethernet establishes link-level connections, which can be defined using both the destination and source addresses. On reception of a transmission, the receiver uses the destination address to determine whether the transmission is relevant to the station or should be ignored. A network interface normally does not accept packets addressed to other Ethernet stations.\nAn EtherType field in each frame is used by the operating system on the receiving station to select the appropriate protocol module (e.g., an Internet Protocol version such as IPv4). Ethernet frames are said to be \"self-identifying\", because of the EtherType field. Self-identifying frames make it possible to intermix multiple protocols on the same physical network and allow a single computer to use multiple protocols together. Despite the evolution of Ethernet technology, all generations of Ethernet (excluding early experimental versions) use the same frame formats. Mixed-speed networks can be built using Ethernet switches and repeaters supporting the desired Ethernet variants.\nDue to the ubiquity of Ethernet, and the ever-decreasing cost of the hardware needed to support it, most manufacturers now build Ethernet interfaces directly into PC motherboards, eliminating the need for a separate network card.\nEthernet was originally based on the idea of computers communicating over a shared coaxial cable acting as a broadcast transmission medium. The method used was similar to those used in radio systems, with the common cable providing the communication channel likened to the \"Luminiferous aether\" in 19th-century physics, and it was from this reference that the name \"Ethernet\" was derived.\nOriginal Ethernet's shared coaxial cable (the shared medium) traversed a building or campus to every attached machine. A scheme known as carrier sense multiple access with collision detection (CSMA/CD) governed the way the computers shared the channel. This scheme was simpler than competing Token Ring or Token Bus technologies. Computers are connected to an Attachment Unit Interface (AUI) transceiver, which is in turn connected to the cable (with thin Ethernet the transceiver is usually integrated into the network adapter). While a simple passive wire is highly reliable for small networks, it is not reliable for large extended networks, where damage to the wire in a single place, or a single bad connector, can make the whole Ethernet segment unusable.\nThrough the first half of the 1980s, Ethernet's 10BASE5 implementation used a coaxial cable in diameter, later called \"thick Ethernet\" or \"thicknet\". Its successor, 10BASE2, called \"thin Ethernet\" or \"thinnet\", used the RG-58 coaxial cable. The emphasis was on making installation of the cable easier and less costly.\nSince all communication happens on the same wire, any information sent by one computer is received by all, even if that information is intended for just one destination. The network interface card interrupts the CPU only when applicable packets are received: the card ignores information not addressed to it. Use of a single cable also means that the data bandwidth is shared, such that, for example, available data bandwidth to each device is halved when two stations are simultaneously active.\nA collision happens when two stations attempt to transmit at the same time. They corrupt transmitted data and require stations to re-transmit. The lost data and re-transmission reduces throughput. In the worst case, where multiple active hosts connected with maximum allowed cable length attempt to transmit many short frames, excessive collisions can reduce throughput dramatically. However, a Xerox report in 1980 studied performance of an existing Ethernet installation under both normal and artificially generated heavy load. The report claimed that 98% throughput on the LAN was observed. This is in contrast with token passing LANs (Token Ring, Token Bus), all of which suffer throughput degradation as each new node comes into the LAN, due to token waits. This report was controversial, as modeling showed that collision-based networks theoretically became unstable under loads as low as 37% of nominal capacity. Many early researchers failed to understand these results. Performance on real networks is significantly better.\nIn a modern Ethernet, the stations do not all share one channel through a shared cable or a simple repeater hub; instead, each station communicates with a switch, which in turn forwards that traffic to the destination station. In this topology, collisions are only possible if station and switch attempt to communicate with each other at the same time, and collisions are limited to this link. Furthermore, the 10BASE-T standard introduced a full duplex mode of operation which became common with Fast Ethernet and the de facto standard with Gigabit Ethernet. In full duplex, switch and station can send and receive simultaneously, and therefore modern Ethernets are completely collision-free.\nRepeaters and hubs.\nFor signal degradation and timing reasons, coaxial Ethernet segments have a restricted size. Somewhat larger networks can be built by using an Ethernet repeater. Early repeaters had only two ports, allowing, at most, a doubling of network size. Once repeaters with more than two ports became available, it was possible to wire the network in a star topology. Early experiments with star topologies (called \"Fibernet\") using optical fiber were published by 1978.\nShared cable Ethernet is always hard to install in offices because its bus topology is in conflict with the star topology cable plans designed into buildings for telephony. Modifying Ethernet to conform to twisted pair telephone wiring already installed in commercial buildings provided another opportunity to lower costs, expand the installed base, and leverage building design, and, thus, twisted-pair Ethernet was the next logical development in the mid-1980s.\nEthernet on unshielded twisted-pair cables (UTP) began with StarLAN at 1\u00a0Mbit/s in the mid-1980s. In 1987 SynOptics introduced the first twisted-pair Ethernet at 10\u00a0Mbit/s in a star-wired cabling topology with a central hub, later called LattisNet. These evolved into 10BASE-T, which was designed for point-to-point links only, and all termination was built into the device. This changed repeaters from a specialist device used at the center of large networks to a device that every twisted pair-based network with more than two machines had to use. The tree structure that resulted from this made Ethernet networks easier to maintain by preventing most faults with one peer or its associated cable from affecting other devices on the network.\nDespite the physical star topology and the presence of separate transmit and receive channels in the twisted pair and fiber media, repeater-based Ethernet networks still use half-duplex and CSMA/CD, with only minimal activity by the repeater, primarily generation of the jam signal in dealing with packet collisions. Every packet is sent to every other port on the repeater, so bandwidth and security problems are not addressed. The total throughput of the repeater is limited to that of a single link, and all links must operate at the same speed.\nWhile repeaters can isolate some aspects of Ethernet segments, such as cable breakages, they still forward all traffic to all Ethernet devices. The entire network is one collision domain, and all hosts have to be able to detect collisions anywhere on the network. This limits the number of repeaters between the farthest nodes and creates practical limits on how many machines can communicate on an Ethernet network. Segments joined by repeaters have to all operate at the same speed, making phased-in upgrades impossible.\nTo alleviate these problems, bridging was created to communicate at the data link layer while isolating the physical layer. With bridging, only well-formed Ethernet packets are forwarded from one Ethernet segment to another; collisions and packet errors are isolated. At initial startup, Ethernet bridges work somewhat like Ethernet repeaters, passing all traffic between segments. By observing the source addresses of incoming frames, the bridge then builds an address table associating addresses to segments. Once an address is learned, the bridge forwards network traffic destined for that address only to the associated segment, improving overall performance. Broadcast traffic is still forwarded to all network segments. Bridges also overcome the limits on total segments between two hosts and allow the mixing of speeds, both of which are critical to the incremental deployment of faster Ethernet variants.\nIn 1989, Motorola Codex introduced their 6310 EtherSpan, and Kalpana introduced their EtherSwitch; these were examples of the first commercial Ethernet switches. Early switches such as this used cut-through switching where only the header of the incoming packet is examined before it is either dropped or forwarded to another segment. This reduces the forwarding latency. One drawback of this method is that it does not readily allow a mixture of different link speeds. Another is that packets that have been corrupted are still propagated through the network. The eventual remedy for this was a return to the original store and forward approach of bridging, where the packet is read into a buffer on the switch in its entirety, its frame check sequence verified and only then the packet is forwarded. In modern network equipment, this process is typically done using application-specific integrated circuits allowing packets to be forwarded at wire speed.\nWhen a twisted pair or fiber link segment is used and neither end is connected to a repeater, full-duplex Ethernet becomes possible over that segment. In full-duplex mode, both devices can transmit and receive to and from each other at the same time, and there is no collision domain. This doubles the aggregate bandwidth of the link and is sometimes advertised as double the link speed (for example, 200\u00a0Mbit/s for Fast Ethernet). The elimination of the collision domain for these connections also means that all the link's bandwidth can be used by the two devices on that segment and that segment length is not limited by the constraints of collision detection.\nSince packets are typically delivered only to the port they are intended for, traffic on a switched Ethernet is less public than on shared-medium Ethernet. Despite this, switched Ethernet should still be regarded as an insecure network technology, because it is easy to subvert switched Ethernet systems by means such as ARP spoofing and MAC flooding.\nThe bandwidth advantages, the improved isolation of devices from each other, the ability to easily mix different speeds of devices and the elimination of the chaining limits inherent in non-switched Ethernet have made switched Ethernet the dominant network technology.\nAdvanced networking.\nSimple switched Ethernet networks, while a great improvement over repeater-based Ethernet, suffer from single points of failure, attacks that trick switches or hosts into sending data to a machine even if it is not intended for it, scalability and security issues with regard to switching loops, broadcast radiation and multicast traffic.\nAdvanced networking features in switches use shortest path bridging (SPB) or the spanning-tree protocol (STP) to maintain a loop-free, meshed network, allowing physical loops for redundancy (STP) or load-balancing (SPB). Shortest path bridging includes the use of the link-state routing protocol IS-IS to allow larger networks with shortest path routes between devices.\nAdvanced networking features also ensure port security, provide protection features such as MAC lockdown and broadcast radiation filtering, use virtual LANs to keep different classes of users separate while using the same physical infrastructure, employ multilayer switching to route between different classes, and use link aggregation to add bandwidth to overloaded links and to provide some redundancy.\nIn 2016, Ethernet replaced InfiniBand as the most popular system interconnect of TOP500 supercomputers.\nVarieties.\nThe Ethernet physical layer evolved over a considerable time span and encompasses coaxial, twisted pair and fiber-optic physical media interfaces, with speeds from to . The first introduction of twisted-pair CSMA/CD was StarLAN, standardized as 802.3 1BASE5. While 1BASE5 had little market penetration, it defined the physical apparatus (wire, plug/jack, pin-out, and wiring plan) that would be carried over to 10BASE-T through 10GBASE-T.\nThe most common forms used are 10BASE-T, 100BASE-TX, and 1000BASE-T. All three use twisted-pair cables and 8P8C modular connectors. They run at , , and , respectively.\nFiber optic variants of Ethernet (that commonly use SFP modules) are also very popular in larger networks, offering high performance, better electrical isolation and longer distance (tens of kilometers with some versions). In general, network protocol stack software will work similarly on all varieties.\nFrame structure.\nIn IEEE 802.3, a datagram is called a \"packet\" or \"frame\". \"Packet\" is used to describe the overall transmission unit and includes the preamble, start frame delimiter (SFD) and carrier extension (if present). The \"frame\" begins after the start frame delimiter with a frame header featuring source and destination MAC addresses and the EtherType field giving either the protocol type for the payload protocol or the length of the payload. The middle section of the frame consists of payload data including any headers for other protocols (for example, Internet Protocol) carried in the frame. The frame ends with a 32-bit cyclic redundancy check, which is used to detect corruption of data in transit. Notably, Ethernet packets have no time-to-live field, leading to possible problems in the presence of a switching loop.\nAutonegotiation.\nAutonegotiation is the procedure by which two connected devices choose common transmission parameters, e.g. speed and duplex mode. Autonegotiation was initially an optional feature, first introduced with 100BASE-TX, while it is also backward compatible with 10BASE-T. Autonegotiation is mandatory for 1000BASE-T and faster.\nError conditions.\nSwitching loop.\nA switching loop or bridge loop occurs in computer networks when there is more than one Layer 2 (OSI model) path between two endpoints (e.g. multiple connections between two network switches or two ports on the same switch connected to each other). The loop creates broadcast storms as broadcasts and multicasts are forwarded by switches out every port, the switch or switches will repeatedly rebroadcast the broadcast messages flooding the network. Since the Layer 2 header does not support a \"time to live\" (TTL) value, if a frame is sent into a looped topology, it can loop forever.\nA physical topology that contains switching or bridge loops is attractive for redundancy reasons, yet a switched network must not have loops. The solution is to allow physical loops, but create a loop-free logical topology using the shortest path bridging (SPB) protocol or the older spanning tree protocols (STP) on the network switches.\nJabber.\nA node that is sending longer than the maximum transmission window for an Ethernet packet is considered to be \"jabbering\". Depending on the physical topology, jabber detection and remedy differ somewhat."}
{"id": "9500", "revid": "66", "url": "https://en.wikipedia.org/wiki?curid=9500", "title": "E.P.Thompson on Luddites", "text": ""}
{"id": "9501", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=9501", "title": "E. P. Thompson on Luddites", "text": ""}
{"id": "9502", "revid": "28779459", "url": "https://en.wikipedia.org/wiki?curid=9502", "title": "List of explorations", "text": "Some of the most important explorations of State Societies, in chronological order:"}
{"id": "9505", "revid": "22066013", "url": "https://en.wikipedia.org/wiki?curid=9505", "title": "Elias Canetti", "text": "Elias Canetti (; ; 25 July 1905 \u2013 14 August 1994) was a German-language author, born in Ruse, Bulgaria to a merchant family. They moved to Manchester, England, but his father died in 1912, and his mother took her three sons back to the continent. They settled in Vienna.\nCanetti moved to England in 1938 after the Anschluss to escape Nazi persecution. He became a British citizen in 1952. He is known as a modernist novelist, playwright, memoirist, and non-fiction writer. He won the Nobel Prize in Literature in 1981, \"for writings marked by a broad outlook, a wealth of ideas and artistic power\". He is noted for his non-fiction book \"Crowds and Power\", among other works.\nLife and work.\nEarly life.\nBorn in 1905 to businessman Jacques Canetti and Mathilde \"n\u00e9e\" Arditti in Ruse, a city on the Danube in Bulgaria, Canetti was the eldest of three sons. His ancestors were Sephardi Jews. His paternal ancestors settled in Ruse from Ottoman Adrianople. The original family name was \"Ca\u00f1ete\", named after Ca\u00f1ete, Cuenca, a village in Spain.\nIn Ruse, Canetti's father and grandfather were successful merchants who operated out of a commercial building, which they had built in 1898. Canetti's mother descended from the Arditti family, one of the oldest Sephardi families in Bulgaria, who were among the founders of the Ruse Jewish colony in the late 18th century. The Ardittis can be traced to the 14th century, when they were court physicians and astronomers to the Aragonese royal court of Alfonso IV and Pedro IV. Before settling in Ruse, they had migrated into Italy and lived in Livorno in the 17th century.\nCanetti spent his childhood years, from 1905 to 1911, in Ruse until the family moved to Manchester, England, where Canetti's father joined a business established by his wife's brothers. In 1912, his father died suddenly, and his mother moved with their children first to Lausanne, then Vienna in the same year. They lived in Vienna from the time Canetti was aged seven onwards. His mother insisted that he speak German, and taught it to him. By this time Canetti already spoke Ladino (his native language), Bulgarian, English, and some French; the latter two he studied in the one year they were in Britain. Subsequently, the family moved first (from 1916 to 1921) to Z\u00fcrich and then (until 1924) to Frankfurt, where Canetti graduated from high school.\nCanetti went back to Vienna in 1924 in order to study chemistry. However, his primary interests during his years in Vienna became philosophy and literature. Introduced into the literary circles of First-Republic-Vienna, he started writing. Politically leaning towards the left, he was present at the July Revolt of 1927 \u2013 he came near to the action accidentally, was most impressed by the burning of books (recalled frequently in his writings), and left the place quickly with his bicycle. He gained a degree in chemistry from the University of Vienna in 1929, but never worked as a chemist.\nHe published two works in Vienna before escaping to Great Britain. He reflected the experiences of Nazi Germany and political chaos in his works, especially exploring mob action and group thinking in his novel \"Die Blendung\" (\"Auto-da-F\u00e9\", 1935) and non-fiction \"Crowds and Power\" (1960). He wrote several volumes of memoirs, contemplating the influence of his multi-lingual background and childhood.\nPersonal life.\nIn 1934 in Vienna he married Veza (Venetiana) Taubner-Calderon (1897\u20131963), who acted as his muse and devoted literary assistant. Canetti remained open to relationships with other women. He had a short affair with Anna Mahler. In 1938, after the \"Anschluss\" with Germany, the Canettis moved to London. He became closely involved with the painter Marie-Louise von Motesiczky, who was to remain a close companion for many years. His name has also been linked with the author Iris Murdoch (see John Bayley's \"Iris, A Memoir of Iris Murdoch\", which has several references to an author, referred to as \"the Dichter\", who was a Nobel Laureate and whose works included \"Die Blendung\" [English title \"Auto-da-F\u00e9\"]).\nAfter Veza died in 1963, Canetti married Hera Buschor (1933\u20131988), with whom he had a daughter, Johanna, in 1972. Canetti's brother Jacques Canetti settled in Paris, where he championed a revival of French chanson. Despite being a German-language writer, Canetti settled in Britain until the 1970s, receiving British citizenship in 1952. For his last 20 years, Canetti lived mostly in Z\u00fcrich.\nCareer.\nA writer in German, Canetti won the Nobel Prize in Literature in 1981, \"for writings marked by a broad outlook, a wealth of ideas and artistic power\". He is known chiefly for his celebrated trilogy of autobiographical memoirs of his childhood and of pre-Anschluss Vienna: \"Die Gerettete Zunge\" (The Tongue Set Free); \"Die Fackel im Ohr\" (The Torch in My Ear), and \"Das Augenspiel\" (The Play of the Eyes); for his modernist novel \"Auto-da-F\u00e9\" (\"Die Blendung\"); and for \"Crowds and Power\", a psychological study of crowd behaviour as it manifests itself in human activities ranging from mob violence to religious congregations.\nIn the 1970s, Canetti began to travel more frequently to Zurich, where he settled and lived for his last 20 years. He died in Z\u00fcrich in 1994."}
{"id": "9506", "revid": "39753414", "url": "https://en.wikipedia.org/wiki?curid=9506", "title": "Edward Jenner", "text": "Edward Jenner, (17 May 1749 \u2013 26 January 1823) was an English physician and scientist who pioneered the concept of vaccines including creating the smallpox vaccine, the world's first vaccine. The terms \"vaccine\" and \"vaccination\" are derived from \"Variolae vaccinae\" (smallpox of the cow), the term devised by Jenner to denote cowpox. He used it in 1798 in the long title of his \"Inquiry into the Variolae vaccinae known as the Cow Pox\", in which he described the protective effect of cowpox against smallpox.\nIn the West, Jenner is often called \"the father of immunology\", and his work is said to have \"saved more lives than the work of any other human\". In Jenner's time, smallpox killed around 10% of the population, with the number as high as 20% in towns and cities where infection spread more easily. In 1821, he was appointed physician extraordinary to King George IV, and was also made mayor of Berkeley and justice of the peace. A member of the Royal Society, in the field of zoology he was the first person to describe the brood parasitism of the cuckoo. In 2002, Jenner was named in the BBC's list of the 100 Greatest Britons.\nEarly life.\nEdward Jenner was born on 6 May 1749 (17 May New Style) in Berkeley, Gloucestershire, England as the eighth of nine children. His father, the Reverend Stephen Jenner, was the vicar of Berkeley, so Jenner received a strong basic education.\nWhen he was young, he went to school in Wotton-under-Edge at Katherine Lady Berkeley's School and in Cirencester. During this time, he was inoculated (by variolation) for smallpox, which had a lifelong effect upon his general health. At the age of 14, he was apprenticed for seven years to Daniel Ludlow, a surgeon of Chipping Sodbury, South Gloucestershire, where he gained most of the experience needed to become a surgeon himself.\nIn 1770, aged 21, Jenner became apprenticed in surgery and anatomy under surgeon John Hunter and others at St George's Hospital, London. William Osler records that Hunter gave Jenner William Harvey's advice, well known in medical circles (and characteristic of the Age of Enlightenment), \"Don't think; try.\" Hunter remained in correspondence with Jenner over natural history and proposed him for the Royal Society. Returning to his native countryside by 1773, Jenner became a successful family doctor and surgeon, practising on dedicated premises at Berkeley.\nJenner and others formed the Fleece Medical Society or Gloucestershire Medical Society, so called because it met in the parlour of the Fleece Inn, Rodborough, Gloucestershire. Members dined together and read papers on medical subjects. Jenner contributed papers on angina pectoris, ophthalmia, and cardiac valvular disease and commented on cowpox. He also belonged to a similar society which met in Alveston, near Bristol.\nHe became a master mason on 30 December 1802, in Lodge of Faith and Friendship #449. From 1812\u20131813, he served as worshipful master of Royal Berkeley Lodge of Faith and Friendship.\nZoology.\nEdward Jenner was elected fellow of the Royal Society in 1788, following his publication of a careful study of the previously misunderstood life of the nested cuckoo, a study that combined observation, experiment, and dissection.\nEdward Jenner described how the newly hatched cuckoo pushed its host's eggs and fledgling chicks out of the nest (contrary to existing belief that the adult cuckoo did it). Having observed this behaviour, Jenner demonstrated an anatomical adaptation for it\u2014the baby cuckoo has a depression in its back, not present after 12 days of life, that enables it to cup eggs and other chicks. The adult does not remain long enough in the area to perform this task. Jenner's findings were published in \"Philosophical Transactions of the Royal Society\" in 1788.\n\"The singularity of its shape is well adapted to these purposes; for, different from other newly hatched birds, its back from the scapula downwards is very broad, with a considerable depression in the middle. This depression seems formed by nature for the design of giving a more secure lodgement to the egg of the Hedge-sparrow, or its young one, when the young Cuckoo is employed in removing either of them from the nest. When it is about twelve days old, this cavity is quite filled up, and then the back assumes the shape of nestling birds in general.\" Jenner's nephew assisted in the study. He was born on 30 June 1737.\nJenner's understanding of the cuckoo's behaviour was not entirely believed until the artist Jemima Blackburn, a keen observer of birdlife, saw a blind nestling pushing out a host's egg. Her description and illustration of this were enough to convince Charles Darwin to revise a later edition of \"On the Origin of Species\".\nJenner's interest in Zoology played a large role in his first experiment with inoculation. Not only did he have a profound understanding of human anatomy due to his medical training, but he also understood animal biology and its role in human-animal trans-species boundaries in disease transmission. At the time, there was no way of knowing how important this connection would be to the history and discovery of vaccinations. We see this connection now; many present-day vaccinations include animal parts from cows, rabbits, and chicken eggs, which can be attributed to the work of Jenner and his cowpox/smallpox vaccination.\nMarriage and human medicine.\nJenner married Catherine Kingscote (died 1815 from tuberculosis) in March 1788. He might have met her while he and other fellows were experimenting with balloons. Jenner's trial balloon descended into Kingscote Park, Gloucestershire, owned by Catherine's father Anthony Kingscote. They had three children: Edward Robert (1789-1810), Robert Fitzharding (1792-1854) and Catherine (1794-1833).\nHe earned his MD from the University of St Andrews in 1792. He is credited with advancing the understanding of angina pectoris. In his correspondence with Heberden, he wrote: \"How much the heart must suffer from the coronary arteries not being able to perform their functions\".\nInvention of the vaccine.\nInoculation was already pioneered in Asian medicine and was a standard practice but involved serious risks, one of which was the fear that those inoculated would then transfer the disease to those around them due to their becoming carriers of the disease. In 1721, Lady Mary Wortley Montagu had imported variolation to Britain after having observed it in Constantinople. While Johnnie Notions had great success with his self-devised inoculation (and was reputed not to have lost a single patient), his method's practice was limited to the Shetland Isles. Voltaire wrote that at this time 60% of the population caught smallpox and 20% of the population died of it. Voltaire also states that the Circassians used the inoculation from times immemorial, and the custom may have been borrowed by the Turks from the Circassians. In 1766, Daniel Bernoulli analysed smallpox morbidity and mortality data to demonstrate the efficacy of inoculation.\nBy 1768, English physician John Fewster had realised that prior infection with cowpox rendered a person immune to smallpox. In the years following 1770, at least five investigators in England and Germany (Sevel, Jensen, Jesty 1774, Rendell, Plett 1791) successfully tested in humans a cowpox vaccine against smallpox. For example, Dorset farmer Benjamin Jesty successfully vaccinated and presumably induced immunity with cowpox in his wife and two children during a smallpox epidemic in 1774, but it was not until Jenner's work that the procedure became widely understood. Jenner may have been aware of Jesty's procedures and success. A similar observation was later made in France by Jacques Antoine Rabaut-Pommier in 1780.\nNoting the common observation that milkmaids were generally immune to smallpox, Jenner postulated that the pus in the blisters that milkmaids received from cowpox (a disease similar to smallpox, but much less virulent) protected them from smallpox.\nOn 14 May 1796, Jenner tested his hypothesis by inoculating James Phipps, an eight-year-old boy who was the son of Jenner's gardener. He scraped pus from cowpox blisters on the hands of Sarah Nelmes, a milkmaid who had caught cowpox from a cow called Blossom, whose hide now hangs on the wall of the St. George's Medical School library (now in Tooting). Phipps was the 17th case described in Jenner's first paper on vaccination.\nJenner inoculated Phipps in both arms that day, subsequently producing in Phipps a fever and some uneasiness, but no full-blown infection. Later, he injected Phipps with variolous material, the routine method of immunization at that time. No disease followed. The boy was later challenged with variolous material and again showed no sign of infection.\nDonald Hopkins has written, \"Jenner's unique contribution was not that he inoculated a few persons with cowpox, but that he then proved [by subsequent challenges] that they were immune to smallpox. Moreover, he demonstrated that the protective cowpox pus could be effectively inoculated from person to person, not just directly from cattle.\" Jenner successfully tested his hypothesis on 23 additional subjects.\nJenner continued his research and reported it to the Royal Society, which did not publish the initial paper. After revisions and further investigations, he published his findings on the 23 cases, including his 11-month-old son Robert. Some of his conclusions were correct, some erroneous; modern microbiological and microscopic methods would make his studies easier to reproduce. The medical establishment deliberated at length over his findings before accepting them. Eventually, vaccination was accepted, and in 1840, the British government banned variolationthe use of smallpox to induce immunityand provided vaccination using cowpox free of charge (\"see\" Vaccination Act).\nThe success of his discovery soon spread around Europe and was used \"en masse\" in the Spanish Balmis Expedition (1803\u20131806), a three-year-long mission to the Americas, the Philippines, Macao, China, led by Dr. Francisco Javier de Balmis with the aim of giving thousands the smallpox vaccine. The expedition was successful, and Jenner wrote: \"I don\u2019t imagine the annals of history furnish an example of philanthropy so noble, so extensive as this\". Napoleon, who at the time was at war with Britain, had all his French troops vaccinated, awarded Jenner a medal, and at the request of Jenner, he released two English prisoners of war and permitted their return home. Napoleon remarked he could not \"refuse anything to one of the greatest benefactors of mankind\".\nJenner's continuing work on vaccination prevented him from continuing his ordinary medical practice. He was supported by his colleagues and the King in petitioning Parliament, and was granted \u00a310,000 in 1802 for his work on vaccination. In 1807, he was granted another \u00a320,000 after the Royal College of Physicians confirmed the widespread efficacy of vaccination.\nLater life.\nJenner was later elected a foreign honorary member of the American Academy of Arts and Sciences in 1802, a member of the American Philosophical Society in 1804, and a foreign member of the Royal Swedish Academy of Sciences in 1806. In 1803 in London, he became president of the Jennerian Society, concerned with promoting vaccination to eradicate smallpox. The Jennerian ceased operations in 1809. Jenner became a member of the Medical and Chirurgical Society on its founding in 1805 (now the Royal Society of Medicine) and presented several papers there. In 1808, with government aid, the National Vaccine Establishment was founded, but Jenner felt dishonoured by the men selected to run it and resigned his directorship.\nReturning to London in 1811, Jenner observed a significant number of cases of smallpox after vaccination. He found that in these cases the severity of the illness was notably diminished by previous vaccination. In 1821, he was appointed physician extraordinary to King George IV, and was also made mayor of Berkeley and justice of the peace. He continued to investigate natural history, and in 1823, the last year of his life, he presented his \"Observations on the Migration of Birds\" to the Royal Society.\nDeath.\nJenner was found in a state of apoplexy on 25 January 1823, with his right side paralysed. He did not recover and died the next day of an apparent stroke, his second, on 26 January 1823, aged 73. He was buried in the family vault at the Church of St Mary, Berkeley. He was survived by his son Robert Fitzharding (1797\u20131854) and his daughter Catherine (1794\u20131833), his elder son Edward (1789\u20131810) having died of tuberculosis at age 21.\nReligious views.\nNeither fanatic nor lax, Jenner was a Christian who in his personal correspondence showed himself quite spiritual; he treasured the Bible. Some days before his death, he stated to a friend: \"I am not surprised that men are not grateful to me; but I wonder that they are not grateful to God for the good which He has made me the instrument of conveying to my fellow creatures\".\nHowever, his contemporary Rabbi Israel Lipschitz in his classic commentary on the Mishnah, the \"Tiferes Yisrael\", wrote that Jenner was one of the \"righteous of the nations\", deserving a lofty place in the World to Come, for having saved millions of people from smallpox.\nLegacy.\nIn 1980, the World Health Organization declared smallpox an eradicated disease. This was the result of coordinated public health efforts, but vaccination was an essential component. Although the disease was declared eradicated, some pus samples still remain in laboratories in Centers for Disease Control and Prevention in Atlanta in the US, and in State Research Center of Virology and Biotechnology VECTOR in Koltsovo, Novosibirsk Oblast, Russia.\nJenner's vaccine laid the foundation for contemporary discoveries in immunology. In 2002, Jenner was named in the BBC's list of the 100 Greatest Britons following a UK-wide vote. The lunar crater Jenner is named in his honour. Jenner was recognized in the TV show 'The Walking Dead'. In \"TS-19\", a CDC scientist is named Edwin Jenner."}
{"id": "9507", "revid": "191757", "url": "https://en.wikipedia.org/wiki?curid=9507", "title": "Encyclopedia Britannica", "text": ""}
{"id": "9508", "revid": "21763262", "url": "https://en.wikipedia.org/wiki?curid=9508", "title": "Encyclop\u00e6dia Britannica", "text": "The (Latin for \"British Encyclopaedia\") is a general knowledge English-language encyclopaedia which is now published exclusively as an online encyclopaedia. It was formerly published by Encyclop\u00e6dia Britannica, Inc., and other publishers (for previous editions). It was written by about 100\u00a0full-time editors and more than 4,000\u00a0contributors. The 2010 version of the 15th edition, which spans 32 volumes and 32,640 pages, was the last printed edition.\nThe \"Britannica\" was the longest running in-print encyclopaedia in the English language, being printed for 244 years. It was first published between 1768 and 1771 in the Scottish capital of Edinburgh, as three volumes. (This first edition is available in facsimile.) The encyclopaedia grew in size: the second edition was 10 volumes, and by its fourth edition (1801\u20131810) it had expanded to 20 volumes. Its rising stature as a scholarly work helped recruit eminent contributors, and the 9th (1875\u20131889) and 11th editions (1911) are landmark encyclopaedias for scholarship and literary style. Starting with the 11th edition and following its acquisition by an American firm, the \"Britannica\" shortened and simplified articles to broaden its appeal to the North American market. In 1933, the \"Britannica\" became the first encyclopaedia to adopt \"continuous revision\", in which the encyclopaedia is continually reprinted, with every article updated on a schedule. In March 2012, Encyclop\u00e6dia Britannica, Inc. announced it would no longer publish printed editions, and would focus instead on the online version.\nThe 15th edition had a three-part structure: a 12-volume of short articles (generally fewer than 750\u00a0words), a 17-volume of long articles (two to 310\u00a0pages), and a single volume to give a hierarchical outline of knowledge. The was meant for quick fact-checking and as a guide to the ; readers are advised to study the outline to understand a subject's context and to find more detailed articles. Over 70 years, the size of the \"Britannica\" has remained steady, with about 40\u00a0million words on half a million topics. Though published in the United States since 1901, the \"Britannica\" has for the most part maintained British English spelling.\nPresent status.\nPrint version.\nSince 1985, the \"Britannica\" has had four parts: the , the , the , and a two-volume index. The \"Britannica\" articles are found in the and , which encompass 12 and 17 volumes, respectively, each volume having roughly one thousand pages. The 2007 has 699 in-depth articles, ranging in length from 2 to 310 pages and having references and named contributors. In contrast, the 2007 has roughly 65,000 articles, the vast majority (about 97%) of which contain fewer than 750 words, no references, and no named contributors. The articles are intended for quick fact-checking and to help in finding more thorough information in the . The articles are meant both as authoritative, well-written articles on their subjects and as storehouses of information not covered elsewhere. The longest article (310 pages) is on the United States, and resulted from the merger of the articles on the individual states. A 2013 \"Global Edition\" of \"Britannica\" contained approximately forty thousand articles.\nInformation can be found in the \"Britannica\" by following the cross-references in the and ; however, these are sparse, averaging one cross-reference per page. Hence, readers are recommended to consult instead the alphabetical index or the , which organizes the \"Britannica\" contents by topic.\nThe core of the is its \"Outline of Knowledge\", which aims to provide a logical framework for all human knowledge. Accordingly, the Outline is consulted by the \"Britannica\" editors to decide which articles should be included in the and . The Outline is also intended to be a study guide, to put subjects in their proper perspective, and to suggest a series of \"Britannica\" articles for the student wishing to learn a topic in depth. However, libraries have found that it is scarcely used, and reviewers have recommended that it be dropped from the encyclopaedia. The also has color transparencies of human anatomy and several appendices listing the staff members, advisors, and contributors to all three parts of the \"Britannica\".\nTaken together, the and comprise roughly 40 million words and 24,000 images. The two-volume index has 2,350 pages, listing the 228,274 topics covered in the \"Britannica\", together with 474,675 subentries under those topics. The \"Britannica\" generally prefers British spelling over American; for example, it uses \"colour\" (not \"color\"), \"centre\" (not \"center\"), and \"encyclopaedia\" (not \"encyclopedia\"). However, there are exceptions to this rule, such as \"defense\" rather than \"defence\". Common alternative spellings are provided with cross-references such as \"Color: \"see\" Colour.\"\nSince 1936, the articles of the \"Britannica\" have been revised on a regular schedule, with at least 10% of them considered for revision each year. According to one Britannica website, 46% of its articles were revised over the past three years; however, according to another Britannica website, only 35% of the articles were revised.\nThe alphabetization of articles in the and follows strict rules. Diacritical marks and non-English letters are ignored, while numerical entries such as \"1812, War of\" are alphabetized as if the number had been written out (\"Eighteen-twelve, War of\"). Articles with identical names are ordered first by persons, then by places, then by things. Rulers with identical names are organized first alphabetically by country and then by chronology; thus, Charles III of France precedes Charles I of England, listed in \"Britannica\" as the ruler of Great Britain and Ireland. (That is, they are alphabetized as if their titles were \"Charles, France, 3\" and \"Charles, Great Britain and Ireland, 1\".) Similarly, places that share names are organized alphabetically by country, then by ever-smaller political divisions.\nIn March 2012, the company announced that the 2010 edition would be the last printed version. This was announced as a move by the company to adapt to the times and focus on its future using digital distribution. The peak year for the printed encyclopaedia was 1990 when 120,000 sets were sold, but it dropped to 40,000 in 1996. 12,000 sets of the 2010 edition were printed, of which 8,000 had been sold . By late April 2012, the remaining copies of the 2010 edition had sold out at Britannica's online store. , a replica of Britannica's 1768 first edition is sold on the online store.\nRelated printed material.\n\"Britannica Junior\" was first published in 1934 as 12 volumes. It was expanded to 15 volumes in 1947, and renamed \"Britannica Junior Encyclop\u00e6dia\" in 1963. It was taken off the market after the 1984 printing.\nA British \"Children's Britannica\" edited by John Armitage was issued in London in 1960. Its contents were determined largely by the eleven-plus standardized tests given in Britain. Britannica introduced the \"Children's Britannica\" to the US market in 1988, aimed at ages seven to 14.\nIn 1961, a 16 volume \"Young Children's Encyclopaedia\" was issued for children just learning to read.\n\"My First Britannica\" is aimed at children ages six to 12, and the \"Britannica Discovery Library\" is for children aged three to six (issued 1974 to 1991).\nThere have been, and are, several abridged \"Britannica\" encyclopaedias. The single-volume \"Britannica Concise Encyclop\u00e6dia\" has 28,000 short articles condensing the larger 32-volume \"Britannica\"; there are authorized translations in languages such as Chinese and Vietnamese. \"Compton's by Britannica\", first published in 2007, incorporating the former \"Compton's Encyclopedia\", is aimed at 10- to 17-year-olds and consists of 26 volumes and 11,000 pages.\nSince 1938, Encyclop\u00e6dia Britannica, Inc. has published annually a \"Book of the Year\" covering the past year's events. A given edition of the \"Book of the Year\" is named in terms of the year of its publication, though the edition actually covers the events of the previous year. Articles dating back to the 1994 edition are included online. The company also publishes several specialized reference works, such as \"Shakespeare: The Essential Guide to the Life and Works of the Bard\" (Wiley, 2006).\nOptical disc, online, and mobile versions.\nThe \"Britannica Ultimate Reference Suite 2012 DVD\" contains over 100,000 articles. This includes regular \"Britannica\" articles, as well as others drawn from the \"Britannica Student Encyclop\u00e6dia\", and the \"Britannica Elementary Encyclop\u00e6dia.\" The package includes a range of supplementary content including maps, videos, sound clips, animations and web links. It also offers study tools and dictionary and thesaurus entries from Merriam-Webster.\n\"Britannica\" Online is a website with more than 120,000 articles and is updated regularly. It has daily features, updates and links to news reports from \"The New York Times\" and the BBC. , roughly 60% of Encyclop\u00e6dia Britannica's revenue came from online operations, of which around 15% came from subscriptions to the consumer version of the websites. , subscriptions were available on a yearly, monthly or weekly basis. Special subscription plans are offered to schools, colleges and libraries; such institutional subscribers constitute an important part of Britannica's business. Beginning in early 2007, the \"Britannica\" made articles freely available if they are hyperlinked from an external site. Non-subscribers are served pop-ups and advertising.\nOn 20 February 2007, Encyclop\u00e6dia Britannica, Inc. announced that it was working with mobile phone search company AskMeNow to launch a mobile encyclopaedia. Users will be able to send a question via text message, and AskMeNow will search \"Britannica\" 28,000-article concise encyclopaedia to return an answer to the query. Daily topical features sent directly to users' mobile phones are also planned.\nOn 3 June 2008, an initiative to facilitate collaboration between online expert and amateur scholarly contributors for Britannica's online content (in the spirit of a wiki), with editorial oversight from Britannica staff, was announced. Approved contributions would be credited, though contributing automatically grants Encyclop\u00e6dia Britannica, Inc. perpetual, irrevocable license to those contributions.\nOn 22 January 2009, Britannica's president, Jorge Cauz, announced that the company would be accepting edits and additions to the online \"Britannica\" website from the public. The published edition of the encyclopaedia will not be affected by the changes. Individuals wishing to edit the \"Britannica\" website will have to register under their real name and address prior to editing or submitting their content. All edits submitted will be reviewed and checked and will have to be approved by the encyclopaedia's professional staff. Contributions from non-academic users will sit in a separate section from the expert-generated \"Britannica\" content, as will content submitted by non-\"Britannica\" scholars. Articles written by users, if vetted and approved, will also only be available in a special section of the website, separate from the professional articles. Official \"Britannica\" material would carry a \"Britannica Checked\" stamp, to distinguish it from the user-generated content.\nOn 14 September 2010, Encyclop\u00e6dia Britannica, Inc. announced a partnership with mobile phone development company Concentric Sky to launch a series of iPhone products aimed at the K-12 market. On 20 July 2011, Encyclop\u00e6dia Britannica, Inc. announced that Concentric Sky had ported the Britannica Kids product line to Intel's Intel Atom-based Netbooks and on 26 October 2011 that it had launched its encyclopedia as an iPad app. In 2010, Britannica released Britannica ImageQuest, a database of images.\nIn March 2012, it was announced that the company would cease printing the encyclopaedia set, and that it would focus more on its online version.\nOn 7 June 2018, Britannica released a Google Chrome extension, Britannica Insights, which shows snippets of information from Britannica Online in a sidebar for Google Search results. The Britannica sidebar does not replace Google's sidebar and is instead placed above Google's sidebar. Britannica Insights was also available as a Firefox extension but this was taken down due to a code review issue.\nPersonnel and management.\nContributors.\nThe 2007 print version of the \"Britannica\" has 4,411 contributors, many eminent in their fields, such as Nobel laureate economist Milton Friedman, astronomer Carl Sagan, and surgeon Michael DeBakey. Roughly a quarter of the contributors are deceased, some as long ago as 1947 (Alfred North Whitehead), while another quarter are retired or emeritus. Most (approximately 98%) contribute to only a single article; however, 64 contributed to three articles, 23 contributed to four articles, 10 contributed to five articles, and 8 contributed to more than five articles. An exceptionally prolific contributor is Christine Sutton of the University of Oxford, who contributed 24 articles on particle physics.\nWhile \"Britannica\" authors have included writers such as Albert Einstein, Marie Curie, and Leon Trotsky, as well as notable independent encyclopaedists such as Isaac Asimov, some have been criticized for lack of expertise. In 1911 the historian George L. Burr wrote:\nStaff.\n in the fifteenth edition of \"Britannica\", Dale Hoiberg, a sinologist, was listed as \"Britannica's\" Senior Vice President and editor-in-chief. Among his predecessors as editors-in-chief were Hugh Chisholm (1902\u20131924), James Louis Garvin (1926\u20131932), Franklin Henry Hooper (1932\u20131938), Walter Yust (1938\u20131960), Harry Ashmore (1960\u20131963), Warren E. Preece (1964\u20131968, 1969\u20131975), Sir William Haley (1968\u20131969), Philip W. Goetz (1979\u20131991), and Robert McHenry (1992\u20131997). Anita Wolff was listed as the Deputy Editor and Theodore Pappas as Executive Editor. Prior Executive Editors include John V. Dodge (1950\u20131964) and Philip W. Goetz.\nPaul T. Armstrong remains the longest working employee of Encyclop\u00e6dia Britannica. He began his career there in 1934, eventually earning the positions of treasurer, vice president, and chief financial officer in his 58 years with the company, before retiring in 1992.\nThe 2007 editorial staff of the \"Britannica\" included five Senior Editors and nine Associate Editors, supervised by Dale Hoiberg and four others. The editorial staff helped to write the articles of the and some sections of the . The preparation and publication of the required trained staff. According to the final page of the 2007 , the staff were organized into ten departments:\nSome of these departments were organized hierarchically. For example, the copy editors were divided into four copy editors, two senior copy editors, four supervisors, plus a coordinator and a director. Similarly, the Editorial department was headed by Dale Hoiberg and assisted by four others; they oversaw the work of five senior editors, nine associate editors, and one executive assistant.\nBritannica had 14 editors in 2019: Adam Augustyn, Patricia Bauer, Brian Duignan, Alison Eldridge, Erik Gregersen, Amy McKenna, Melissa Petruzzello, John P. Rafferty, Michael Ray, Kara Rogers, Amy Tikkanen, Jeff Wallenfeldt, Adam Zeidan, and Alicja Zelazko.\nEditorial advisors.\nThe \"Britannica\" has an editorial board of advisors, which includes 12 distinguished scholars: non-fiction author Nicholas Carr, religion scholar Wendy Doniger, political economist Benjamin M. Friedman, Council on Foreign Relations President Emeritus Leslie H. Gelb, computer scientist David Gelernter, Physics Nobel laureate Murray Gell-Mann, Carnegie Corporation of New York President Vartan Gregorian, philosopher Thomas Nagel, cognitive scientist Donald Norman, musicologist Don Michael Randel, Stewart Sutherland, Baron Sutherland of Houndwood, President of the Royal Society of Edinburgh, and cultural anthropologist Michael Wesch.\nThe \"Prop\u00e6dia\" and its \"Outline of Knowledge\" were produced by dozens of editorial advisors under the direction of Mortimer J. Adler. Roughly half of these advisors have since died, including some of the Outline's chief architects \u2013 Rene Dubos (d. 1982), Loren Eiseley (d. 1977), Harold D. Lasswell (d. 1978), Mark Van Doren (d. 1972), Peter Ritchie Calder (d. 1982) and Mortimer J. Adler (d. 2001). The also lists just under 4,000 advisors who were consulted for the unsigned articles.\nCorporate structure.\nIn January 1996, the \"Britannica\" was purchased from the Benton Foundation by billionaire Swiss financier Jacqui Safra, who serves as its current Chair of the Board. In 1997, Don Yannias, a long-time associate and investment advisor of Safra, became CEO of Encyclop\u00e6dia Britannica, Inc. In 1999, a new company, Britannica.com Inc., was created to develop digital versions of the \"Britannica\"; Yannias assumed the role of CEO in the new company, while his former position at the parent company remained vacant for two years. Yannias' tenure at Britannica.com Inc. was marked by missteps, considerable lay-offs, and financial losses. In 2001, Yannias was replaced by Ilan Yeshua, who reunited the leadership of the two companies. Yannias later returned to investment management, but remains on the \"Britannica\" Board of Directors.\nIn 2003, former management consultant Jorge Aguilar-Cauz was appointed President of Encyclop\u00e6dia Britannica, Inc. Cauz is the senior executive and reports directly to the \"Britannica's\" Board of Directors. Cauz has been pursuing alliances with other companies and extending the \"Britannica\" brand to new educational and reference products, continuing the strategy pioneered by former CEO Elkan Harrison Powell in the mid-1930s.\nUnder Safra's ownership, the company has experienced financial difficulties and has responded by reducing the price of its products and implementing drastic cost cuts. According to a 2003 report in the \"New York Post\", the \"Britannica\" management has eliminated employee 401(k) accounts and encouraged the use of free images. These changes have had negative impacts, as freelance contributors have waited up to six months for checks and the \"Britannica\" staff have gone years without pay rises.\nIn the fall of 2017, Karthik Krishnan was appointed global chief executive officer of the Encyclop\u00e6dia Britannica Group. Krishnan brought a varied perspective to the role based on several high-level positions in digital media, including RELX (Reed Elsevier, FT SE 100) and Rodale, in which he was responsible for \"driving business and cultural transformation and accelerating growth\".\nTaking the reins of the company as it was preparing to mark its 250th anniversary and define the next phase of its digital strategy for consumers and K-12 schools, Krishnan launched a series of new initiatives in his first year.\nFirst was Britannica Insights, a free, downloadable software extension to the Google Chrome browser that served up edited, fact-checked Britannica information with queries on search engines such as Google, Yahoo, and Bing. Its purpose, the company said, was to \"provide trusted, verified information\" in conjunction with search results that were thought to be increasingly unreliable in the era of misinformation and \"fake news.\"\nThe product was quickly followed by Britannica School Insights, which provided similar content for subscribers to Britannica's online classroom solutions, and a partnership with YouTube in which verified Britannica content appeared on the site as an antidote to user-generated video content that could be false or misleading. \u00a0\nKrishnan, himself an educator at New York University's Stern School of Business, believes in the \"transformative power of education\" and set steering the company toward solidifying its place among leaders in educational technology and supplemental curriculum. Krishnan aimed at providing more useful and relevant solutions to customer needs, extending and renewing Britannica's historical emphasis on \"Utility\", which had been the watchword of its first edition in 1768.\nKrishnan also is active in civic affairs, with organizations such as the Urban Enterprise Initiative and Urban Upbound, whose board he serves on.\nCompetition.\nAs the \"Britannica\" is a general encyclopaedia, it does not seek to compete with specialized encyclopaedias such as the \"Encyclopaedia of Mathematics\" or the \"Dictionary of the Middle Ages\", which can devote much more space to their chosen topics. In its first years, the \"Britannica\" main competitor was the general encyclopaedia of Ephraim Chambers and, soon thereafter, \"Rees's Cyclop\u00e6dia\" and Coleridge's \"Encyclop\u00e6dia Metropolitana\". In the 20th century, successful competitors included \"Collier's Encyclopedia\", the \"Encyclopedia Americana\", and the \"World Book Encyclopedia\". Nevertheless, from the 9th edition onwards, the \"Britannica\" was widely considered to have the greatest authority of any general English-language encyclopaedia, especially because of its broad coverage and eminent authors. The print version of the \"Britannica\" was significantly more expensive than its competitors.\nSince the early 1990s, the \"Britannica\" has faced new challenges from digital information sources. The Internet, facilitated by the development of search engines, has grown into a common source of information for many people, and provides easy access to reliable original sources and expert opinions, thanks in part to initiatives such as Google Books, MIT's release of its educational materials and the open PubMed Central library of the National Library of Medicine. In general, the Internet tends to provide more current coverage than print media, due to the ease with which material on the Internet can be updated. In rapidly changing fields such as science, technology, politics, culture and modern history, the \"Britannica\" has struggled to stay up to date, a problem first analysed systematically by its former editor Walter Yust. Eventually, the \"Britannica\" turned to focus more on its online edition.\nPrint encyclopaedias.\nThe has been compared with other print encyclopaedias, both qualitatively and quantitatively. A well-known comparison is that of Kenneth Kister, who gave a qualitative and quantitative comparison of the \"Britannica\" with two comparable encyclopaedias, \"Collier's Encyclopedia\" and the \"Encyclopedia Americana\". For the quantitative analysis, ten articles were selected at random\u2014circumcision, Charles Drew, Galileo, Philip Glass, heart disease, IQ, panda bear, sexual harassment, Shroud of Turin and Uzbekistan\u2014and letter grades of A\u2013D or F were awarded in four categories: coverage, accuracy, clarity, and recency. In all four categories and for all three encyclopaedias, the four average grades fell between B\u2212 and B+, chiefly because none of the encyclopaedias had an article on sexual harassment in 1994. In the accuracy category, the \"Britannica\" received one \"D\" and seven \"A\"s, \"Encyclopedia Americana\" received eight \"A\"s, and \"Collier's\" received one \"D\" and seven \"A\"s; thus, \"Britannica\" received an average score of 92% for accuracy to \"Americana\"s 95% and \"Collier's\" 92%. In the timeliness category, \"Britannica\" averaged an 86% to \"Americana\"'s 90% and \"Collier's\" 85%.\nIn 2013, the President of Encyclop\u00e6dia Britannica announced that after 244 years, the encyclopedia would cease print production and all future editions would be entirely digital.\nDigital encyclopaedias on optical media.\nThe most notable competitor of the \"Britannica\" among CD/DVD-ROM digital encyclopaedias was \"Encarta\", now discontinued, a modern, multimedia encyclopaedia that incorporated three print encyclopaedias: \"Funk &amp; Wagnalls\", \"Collier's\" and the \"New Merit Scholar's Encyclopedia\". \"Encarta\" was the top-selling multimedia encyclopaedia, based on total US retail sales from January 2000 to February 2006. Both occupied the same price range, with the \"2007 Encyclop\u00e6dia Britannica Ultimate\" CD or DVD costing US$40\u201350 and the Microsoft Encarta Premium 2007 DVD costing US$45. The \"Britannica\" contains 100,000 articles and \"Merriam-Webster's Dictionary and Thesaurus\" (US only), and offers Primary and Secondary School editions. \"Encarta\" contained 66,000 articles, a user-friendly Visual Browser, interactive maps, math, language and homework tools, a US and UK dictionary, and a youth edition. Like \"Encarta\", the \"Britannica\" has been criticized for being biased towards United States audiences; the United Kingdom-related articles are updated less often, maps of the United States are more detailed than those of other countries, and it lacks a UK dictionary. Like the \"Britannica\", \"Encarta\" was available online by subscription, although some content could be accessed free.\nInternet encyclopaedias.\nThe dominant internet encyclopaedia and main alternative to \"Britannica\" is Wikipedia. The key differences between the two lie in accessibility; the model of participation they bring to an encyclopedic project; their respective style sheets and editorial policies; relative ages; the number of subjects treated; the number of languages in which articles are written and made available; and their underlying economic models: unlike \"Britannica\", Wikipedia is a not-for-profit and is not connected with traditional profit- and contract-based publishing distribution networks.\nThe 699 printed articles are generally written by identified contributors, and the roughly 65,000 printed articles are the work of the editorial staff and identified outside consultants. Thus, a \"Britannica\" article either has known authorship or a set of possible authors (the editorial staff). With the exception of the editorial staff, most of the \"Britannica\" contributors are experts in their field\u2014some are Nobel laureates. By contrast, the articles of Wikipedia are written by people of unknown degrees of expertise: most do not claim any particular expertise, and of those who do, many are anonymous and have no verifiable credentials. It is for this lack of institutional vetting, or certification, that former \"Britannica\" editor-in-chief Robert McHenry notes his belief that Wikipedia cannot hope to rival the \"Britannica\" in accuracy.\nIn 2005, the journal \"Nature\" chose articles from both websites in a wide range of science topics and sent them to what it called \"relevant\" field experts for peer review. The experts then compared the competing articles\u2014one from each site on a given topic\u2014side by side, but were not told which article came from which site. \"Nature\" got back 42 usable reviews.\nIn the end, the journal found just eight serious errors, such as general misunderstandings of vital concepts: four from each site. It also discovered many factual errors, omissions or misleading statements: 162 in Wikipedia and 123 in \"Britannica\", an average of 3.86 mistakes per article for Wikipedia and 2.92 for \"Britannica\". Although \"Britannica \"was revealed as the more accurate encyclopedia, with fewer errors, Encyclop\u00e6dia Britannica, Inc. in its detailed 20-page rebuttal called \"Nature\"'s study flawed and misleading and called for a \"prompt\" retraction. It noted that two of the articles in the study were taken from a \"Britannica\" yearbook and not the encyclopaedia, and another two were from \"Compton's Encyclopedia\" (called the \"Britannica Student Encyclopedia\" on the company's website). The rebuttal went on to mention that some of the articles presented to reviewers were combinations of several articles, and that other articles were merely excerpts but were penalized for factual omissions. The company also noted that several of what \"Nature\" called errors were minor spelling variations, and that others were matters of interpretation. \"Nature\" defended its story and declined to retract, stating that, as it was comparing Wikipedia with the web version of \"Britannica\", it used whatever relevant material was available on \"Britannica\"s website.\nInterviewed in February 2009, the managing director of \"Britannica UK\" said: In a January 2016 press release, \"Britannica\" called Wikipedia \"an impressive achievement.\"\nCritical and popular assessments.\nReputation.\nSince the 3rd edition, the \"Britannica\" has enjoyed a popular and critical reputation for general excellence. The 3rd and the 9th editions were pirated for sale in the United States, beginning with \"Dobson's Encyclopaedia\". On the release of the 14th edition, \"Time\" magazine dubbed the \"Britannica\" the \"Patriarch of the Library\". In a related advertisement, naturalist William Beebe was quoted as saying that the \"Britannica\" was \"beyond comparison because there is no competitor.\" References to the \"Britannica\" can be found throughout English literature, most notably in one of Sir Arthur Conan Doyle's favourite Sherlock Holmes stories, \"The Red-Headed League\". The tale was highlighted by the Lord Mayor of London, Gilbert Inglefield, at the bicentennial of the \"Britannica\".\nThe \"Britannica\" has a reputation for summarising knowledge. To further their education, some people have devoted themselves to reading the entire \"Britannica\", taking anywhere from three to 22 years to do so. When Fat'h Ali became the Shah of Persia in 1797, he was given a set of the \"Britannica's\" 3rd edition, which he read completely; after this feat, he extended his royal title to include \"Most Formidable Lord and Master of the \". Writer George Bernard Shaw claimed to have read the complete 9th edition\u2014except for the science articles\u2014and Richard Evelyn Byrd took the \"Britannica\" as reading material for his five-month stay at the South Pole in 1934, while Philip Beaver read it during a sailing expedition. More recently, A.J. Jacobs, an editor at \"Esquire\" magazine, read the entire 2002 version of the 15th edition, describing his experiences in the well-received 2004 book, \"\". Only two people are known to have read two independent editions: the author C. S. Forester and Amos Urban Shirk, an American businessman who read the 11th and 14th editions, devoting roughly three hours per night for four and a half years to read the 11th. Several editors-in-chief of the \"Britannica\" are likely to have read their editions completely, such as William Smellie (1st edition), William Robertson Smith (9th edition), and Walter Yust (14th edition).\nAwards.\nThe CD/DVD-ROM version of the \"Britannica\", \"Encyclop\u00e6dia Britannica Ultimate Reference Suite\", received the 2004 Distinguished Achievement Award from the Association of Educational Publishers. On 15 July 2009, was awarded a spot as one of \"Top Ten Superbrands in the UK\" by a panel of more than 2,000 independent reviewers, as reported by the BBC.\nCoverage of topics.\nTopics are chosen in part by reference to the \"Outline of Knowledge\". The bulk of the \"Britannica\" is devoted to geography (26% of the ), biography (14%), biology and medicine (11%), literature (7%), physics and astronomy (6%), religion (5%), art (4%), Western philosophy (4%), and law (3%). A complementary study of the found that geography accounted for 25% of articles, science 18%, social sciences 17%, biography 17%, and all other humanities 25%. Writing in 1992, one reviewer judged that the \"range, depth, and catholicity of coverage [of the \"Britannica\"] are unsurpassed by any other general Encyclopaedia.\"\nThe \"Britannica\" does not cover topics in equivalent detail; for example, the whole of Buddhism and most other religions is covered in a single article, whereas 14 articles are devoted to Christianity, comprising nearly half of all religion articles. However, the \"Britannica\" has been lauded as the \"least\" biased of general Encyclopaedias marketed to Western readers and praised for its biographies of important women of all eras.\nCriticism of editorial decisions.\nOn rare occasions, the \"Britannica\" has been criticized for its editorial choices. Given its roughly constant size, the encyclopaedia has needed to reduce or eliminate some topics to accommodate others, resulting in controversial decisions. The initial 15th edition (1974\u20131985) was faulted for having reduced or eliminated coverage of children's literature, military decorations, and the French poet Joachim du Bellay; editorial mistakes were also alleged, such as inconsistent sorting of Japanese biographies. Its elimination of the index was condemned, as was the apparently arbitrary division of articles into the and . Summing up, one critic called the initial 15th edition a \"qualified failure...[that] cares more for juggling its format than for preserving.\" More recently, reviewers from the American Library Association were surprised to find that most educational articles had been eliminated from the 1992 , along with the article on psychology.\nSome very few \"Britannica\"-appointed contributors are mistaken. A notorious instance from the \"Britannica's\" early years is the rejection of Newtonian gravity by George Gleig, the chief editor of the 3rd edition (1788\u20131797), who wrote that gravity was caused by the classical element of fire. The \"Britannica\" has also staunchly defended a scientific approach to cultural topics, as it did with William Robertson Smith's articles on religion in the 9th edition, particularly his article stating that the Bible was not historically accurate (1875).\nOther criticisms.\nThe \"Britannica\" has received criticism, especially as editions become outdated. It is expensive to produce a completely new edition of the \"Britannica\", and its editors delay for as long as fiscally sensible (usually about 25 years). For example, despite continuous revision, the 14th edition became outdated after 35 years (1929\u20131964). When American physicist Harvey Einbinder detailed its failings in his 1964 book, \"The Myth of the Britannica\", the encyclopaedia was provoked to produce the 15th edition, which required 10 years of work. It is still difficult to keep the \"Britannica\" current; one recent critic writes, \"it is not difficult to find articles that are out-of-date or in need of revision\", noting that the longer articles are more likely to be outdated than the shorter articles. Information in the is sometimes inconsistent with the corresponding article(s), mainly because of the failure to update one or the other. The bibliographies of the articles have been criticized for being more out-of-date than the articles themselves.\nIn 2005, 12-year-old schoolboy Lucian George found several inaccuracies in the \"Britannica\"\u2018s entries on Poland and wildlife in Eastern Europe.\nIn 2010, an inaccurate entry about the Irish Civil War was discussed in the Irish press following a decision of the Department of Education and Science to pay for online access.\nWriting about the 3rd edition (1788\u20131797), \"Britannica\"s chief editor George Gleig observed that \"perfection seems to be incompatible with the nature of works constructed on such a plan, and embracing such a variety of subjects.\" In March 2006, the \"Britannica\" wrote, \"we in no way mean to imply that \"Britannica\" is error-free; we have never made such a claim\" (although in 1962 Britannica's sales department famously said of the 14th edition \"It is truth. It is unquestionable fact.\") The sentiment is expressed by its original editor, William Smellie:\nHowever, Jorge Cauz (president of Encyclop\u00e6dia Britannica Inc.) asserted in 2012 that \"\"Britannica\" [...] will always be factually correct.\"\nHistory.\nPast owners have included, in chronological order, the Edinburgh, Scotland printers Colin Macfarquhar and Andrew Bell, Scottish bookseller Archibald Constable, Scottish publisher A &amp; C Black, Horace Everett Hooper, Sears Roebuck and William Benton.\nThe present owner of Encyclop\u00e6dia Britannica Inc. is Jacqui Safra, a Brazilian billionaire and actor. Recent advances in information technology and the rise of electronic encyclopaedias such as Encyclop\u00e6dia Britannica Ultimate Reference Suite, \"Encarta\" and Wikipedia have reduced the demand for print encyclopaedias. To remain competitive, Encyclop\u00e6dia Britannica, Inc. has stressed the reputation of the \"Britannica\", reduced its price and production costs, and developed electronic versions on CD-ROM, DVD, and the World Wide Web. Since the early 1930s, the company has promoted spin-off reference works.\nEditions.\nThe \"Britannica\" has been issued in 15 editions, with multi-volume supplements to the 3rd and 4th editions (see the Table below). The 5th and 6th editions were reprints of the 4th, the 10th edition was only a supplement to the 9th, just as the 12th and 13th editions were supplements to the 11th. The 15th underwent massive re-organization in 1985, but the updated, current version is still known as the 15th. The 14th and 15th editions were edited every year throughout their runs, so that later printings of each were entirely different from early ones.\nThroughout history, the \"Britannica\" has had two aims: to be an excellent reference book, and to provide educational material. In 1974, the 15th edition adopted a third goal: to systematize all human knowledge. The history of the \"Britannica\" can be divided into five eras, punctuated by changes in management, or re-organization of the dictionary.\n1768\u20131826.\nIn the first era (1st\u20136th editions, 1768\u20131826), the \"Britannica\" was managed and published by its founders, Colin Macfarquhar and Andrew Bell, by Archibald Constable, and by others. The \"Britannica\" was first published between December 1768 and 1771 in Edinburgh as the \"Encyclop\u00e6dia Britannica, or, A Dictionary of Arts and Sciences, compiled upon a New Plan\". In part, it was conceived in reaction to the French \"Encyclop\u00e9die\" of Denis Diderot and Jean le Rond d'Alembert (published 1751\u201372), which had been inspired by Chambers's \"Cyclopaedia\" (first edition 1728). It went on sale 10 December.\nThe \"Britannica\" of this period was primarily a Scottish enterprise, and it is one of the most enduring legacies of the Scottish Enlightenment. In this era, the \"Britannica\" moved from being a three-volume set (1st edition) compiled by one young editor\u2014William Smellie\u2014to a 20-volume set written by numerous authorities. Several other encyclopaedias competed throughout this period, among them editions of Abraham Rees's \"Cyclop\u00e6dia\" and Coleridge's \"Encyclop\u00e6dia Metropolitana\" and David Brewster's \"Edinburgh Encyclop\u00e6dia\".\n1827\u20131901.\nDuring the second era (7th\u20139th editions, 1827\u20131901), the \"Britannica\" was managed by the Edinburgh publishing firm A &amp; C Black. Although some contributors were again recruited through friendships of the chief editors, notably Macvey Napier, others were attracted by the \"Britannica's\" reputation. The contributors often came from other countries and included the world's most respected authorities in their fields. A general index of all articles was included for the first time in the 7th edition, a practice maintained until 1974.\nProduction of the 9th edition was overseen by Thomas Spencer Baynes, the first English-born editor-in-chief. Dubbed the \"Scholar's Edition\", the 9th edition is the most scholarly of all \"Britannicas\". After 1880, Baynes was assisted by William Robertson Smith. No biographies of living persons were included. James Clerk Maxwell and Thomas Huxley were special advisors on science. However, by the close of the 19th century, the 9th edition was outdated, and the \"Britannica\" faced financial difficulties.\n1901\u20131973.\nIn the third era (10th\u201314th editions, 1901\u20131973), the \"Britannica\" was managed by American businessmen who introduced direct marketing and door-to-door sales. The American owners gradually simplified articles, making them less scholarly for a mass market. The 10th edition was an eleven-volume supplement (including one each of maps and an index) to the 9th, numbered as volumes 25\u201335, but the 11th edition was a completely new work, and is still praised for excellence; its owner, Horace Hooper, lavished enormous effort on its perfection.\nWhen Hooper fell into financial difficulties, the \"Britannica\" was managed by Sears Roebuck for 18 years (1920\u20131923, 1928\u20131943). In 1932, the vice-president of Sears, Elkan Harrison Powell, assumed presidency of the \"Britannica\"; in 1936, he began the policy of continuous revision. This was a departure from earlier practice, in which the articles were not changed until a new edition was produced, at roughly 25-year intervals, some articles unchanged from earlier editions. Powell developed new educational products that built upon the \"Britannica\"s reputation.\nIn 1943, Sears donated the to the University of Chicago. William Benton, then a vice president of the University, provided the working capital for its operation. The stock was divided between Benton and the University, with the University holding an option on the stock. Benton became chairman of the board and managed the \"Britannica\" until his death in 1973. Benton set up the Benton Foundation, which managed the \"Britannica\" until 1996, and whose sole beneficiary was the University of Chicago. In 1968, near the end of this era, the \"Britannica\" celebrated its bicentennial.\n1974\u20131994.\nIn the fourth era (1974\u201394), the \"Britannica\" introduced its 15th edition, which was re-organized into three parts: the , the , and the . Under Mortimer J. Adler (member of the Board of Editors of Encyclop\u00e6dia Britannica since its inception in 1949, and its chair from 1974; director of editorial planning for the 15th edition of \"Britannica\" from 1965), the \"Britannica\" sought not only to be a good reference work and educational tool, but to systematize all human knowledge. The absence of a separate index and the grouping of articles into parallel encyclopaedias (the and ) provoked a \"firestorm of criticism\" of the initial 15th edition. In response, the 15th edition was completely re-organized and indexed for a re-release in 1985. This second version of the 15th edition continued to be published and revised until the 2010 print version. The official title of the 15th edition is the \"New Encyclop\u00e6dia Britannica\", although it has also been promoted as \"Britannica 3\".\nOn 9 March 1976 the US Federal Trade Commission entered an opinion and order enjoining Encyclop\u00e6dia Britannica, Inc. from using: a) deceptive advertising practices in recruiting sales agents and obtaining sales leads, and b) deceptive sales practices in the door-to-door presentations of its sales agents.\n1994\u2013present.\nIn the fifth era (1994\u2013present), digital versions have been developed and released on optical media and online. In 1996, the \"Britannica\" was bought by Jacqui Safra at well below its estimated value, owing to the company's financial difficulties. Encyclop\u00e6dia Britannica, Inc. split in 1999. One part retained the company name and developed the print version, and the other, Britannica.com Inc., developed digital versions. Since 2001, the two companies have shared a CEO, Ilan Yeshua, who has continued Powell's strategy of introducing new products with the \"Britannica\" name. In March 2012, Britannica's president, Jorge Cauz, announced that it would not produce any new print editions of the encyclopaedia, with the 2010 15th edition being the last. The company will focus only on the online edition and other educational tools.\n\"Britannica\"s final print edition was in 2010, a 32-volume set. \"Britannica Global Edition\" was also printed in 2010. It contained 30 volumes and 18,251 pages, with 8,500 photographs, maps, flags, and illustrations in smaller \"compact\" volumes. It contained over 40,000 articles written by scholars from across the world, including Nobel Prize winners. Unlike the 15th edition, it did not contain and sections, but ran A through Z as all editions up to the 14th had. The following is \"Britannica\"s description of the work:\nIn 2020, Encyclopaedia Britannica inc. released the \"Britannica All New Children's Encyclopedia: What We Know and What We Don't\", an encyclopedia aimed primarily at younger readers, covering major topics. The Encyclopedia was widely praised for bringing back the print format.\nDedications.\nThe \"Britannica\" was dedicated to the reigning British monarch from 1788 to 1901 and then, upon its sale to an American partnership, to the British monarch and the President of the United States. Thus, the 11th edition is \"dedicated by Permission to His Majesty George the Fifth, King of Great Britain and Ireland and of the British Dominions beyond the Seas, Emperor of India, and to William Howard Taft, President of the United States of America.\" The order of the dedications has changed with the relative power of the United States and Britain, and with relative sales; the 1954 version of the 14th edition is \"Dedicated by Permission to the Heads of the Two English-Speaking Peoples, Dwight David Eisenhower, President of the United States of America, and Her Majesty, Queen Elizabeth the Second.\" Consistent with this tradition, the 2007 version of the current 15th edition was \"dedicated by permission to the current President of the United States of America, George W. Bush, and Her Majesty, Queen Elizabeth II\", while the 2010 version of the current 15th edition is \"dedicated by permission to Barack Obama, President of the United States of America, and Her Majesty Queen Elizabeth II.\""}
{"id": "9509", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=9509", "title": "Endometrium", "text": "The endometrium is the inner epithelial layer, along with its mucous membrane, of the mammalian uterus. It has a basal layer and a functional layer; the functional layer thickens and then is shed during menstruation in humans and some other mammals, including apes, Old World monkeys, some species of bat, the elephant shrew and the Cairo spiny mouse. In most other mammals, the endometrium is reabsorbed in the estrous cycle. During pregnancy, the glands and blood vessels in the endometrium further increase in size and number. Vascular spaces fuse and become interconnected, forming the placenta, which supplies oxygen and nutrition to the embryo and fetus. The speculated presence of an endometrial microbiota\nhas been argued against.\nStructure.\nThe endometrium consists of a single layer of columnar epithelium plus the stroma on which it rests. The stroma is a layer of connective tissue that varies in thickness according to hormonal influences. In the uterus, simple tubular glands reach from the endometrial surface through to the base of the stroma, which also carries a rich blood supply provided by the spiral arteries. In a woman of reproductive age, two layers of endometrium can be distinguished. These two layers occur only in the endometrium lining the cavity of the uterus, and not in the lining of the Fallopian tubes.\nIn the absence of progesterone, the arteries supplying blood to the functional layer constrict, so that cells in that layer become ischaemic and die, leading to menstruation.\nIt is possible to identify the phase of the menstrual cycle by reference to either the ovarian cycle or the uterine cycle by observing microscopic differences at each phase\u2014for example in the ovarian cycle:\nGene and protein expression.\nAbout 20,000 protein coding genes are expressed in human cells and some 70% of these genes are expressed in the normal endometrium. Just over 100 of these genes are more specifically expressed in the endometrium with only a handful genes being highly endometrium specific. The corresponding specific proteins are expressed in the glandular and stromal cells of the endometrial mucosa. The expression of many of these proteins vary depending on the menstrual cycle, for example the progesterone receptor and thyrotropin-releasing hormone both expressed in the proliferative phase, and PAEP expressed in the secretory phase. Other proteins such as the HOX11 protein that is required for female fertility, is expressed in endometrial stroma cells throughout the menstrual cycle. Certain specific proteins such as the estrogen receptor are also expressed in other types of female tissue types, such as the cervix, fallopian tubes, ovaries and breast.\nMicrobiome speculation.\nThe uterus and endometrium was for a long time thought to be sterile. The cervical plug of mucosa was seen to prevent the entry of any microorganisms ascending from the vagina. In the 1980s this view was challenged when it was shown that uterine infections could arise from weaknesses in the barrier of the cervical plug. Organisms from the vaginal microbiota could enter the uterus during uterine contractions in the menstrual cycle. Further studies sought to identify microbiota specific to the uterus which would be of help in identifying cases of unsuccessful IVF and miscarriages. Their findings were seen to be unreliable due to the possibility of cross-contamination in the sampling procedures used. The well-documented presence of \"Lactobacillus\" species, for example, was easily explained by an increase in the vaginal population being able to seep into the cervical mucous. Another study highlighted the flaws of the earlier studies including cross-contamination. It was also argued that the evidence from studies using germ-free offspring of axenic animals (germ-free) clearly showed the sterility of the uterus. The authors concluded that in light of these findings there was no existence of a microbiome.\nThe normal dominance of Lactobacilli in the vagina is seen as a marker for vaginal health. However, in the uterus this much lower population is seen as invasive in a closed environment that is highly regulated by female sex hormones, and that could have unwanted consequences. In studies of endometriosis \"Lactobacillus\" is not the dominant type and there are higher levels of \"Streptococcus\" and \"Staphylococcus\" species. Half of the cases of bacterial vaginitis showed a polymicrobial biofilm attached to the endometrium.\nFunction.\nThe endometrium is the innermost lining layer of the uterus, and functions to prevent adhesions between the opposed walls of the myometrium, thereby maintaining the patency of the uterine cavity. During the menstrual cycle or estrous cycle, the endometrium grows to a thick, blood vessel-rich, glandular tissue layer. This represents an optimal environment for the implantation of a blastocyst upon its arrival in the uterus. The endometrium is central, echogenic (detectable using ultrasound scanners), and has an average thickness of 6.7\u00a0mm.\nDuring pregnancy, the glands and blood vessels in the endometrium further increase in size and number. Vascular spaces fuse and become interconnected, forming the placenta, which supplies oxygen and nutrition to the embryo and fetus.\nCycle.\nThe endometrial lining undergoes cyclic regeneration. Humans, apes, and some other species display the menstrual cycle, whereas most other mammals are subject to an estrous cycle. In both cases, the endometrium initially proliferates under the influence of estrogen. However, once ovulation occurs, the ovary (specifically the corpus luteum) will produce much larger amounts of progesterone. This changes the proliferative pattern of the endometrium to a secretory lining. Eventually, the secretory lining provides a hospitable environment for one or more blastocysts.\nUpon fertilization, the egg may implant into the uterine wall and provide feedback to the body with human chorionic gonadotropin (HCG). HCG provides continued feedback throughout pregnancy by maintaining the corpus luteum, which will continue its role of releasing progesterone and estrogen. The endometrial lining is either reabsorbed (estrous cycle) or shed (menstrual cycle). In the latter case, the process of shedding involves the breaking down of the lining, the tearing of small connective blood vessels, and the loss of the tissue and blood that had constituted it through the vagina. The entire process occurs over a period of several days. Menstruation may be accompanied by a series of uterine contractions; these help expel the menstrual endometrium.\nIn case of implantation, however, the endometrial lining is neither absorbed nor shed. Instead, it remains as \"decidua\". The decidua becomes part of the placenta; it provides support and protection for the gestation.\nIf there is inadequate stimulation of the lining, due to lack of hormones, the endometrium remains thin and inactive. In humans, this will result in amenorrhea, or the absence of a menstrual period. After menopause, the lining is often described as being atrophic. In contrast, endometrium that is chronically exposed to estrogens, but not to progesterone, may become hyperplastic. Long-term use of oral contraceptives with highly potent progestins can also induce endometrial atrophy.\nIn humans, the cycle of building and shedding the endometrial lining lasts an average of 28 days. The endometrium develops at different rates in different mammals. Various factors including the seasons, climate, and stress can affect its development. The endometrium itself produces certain hormones at different stages of the cycle and this affects other parts of the reproductive system.\nDiseases related with endometrium.\nChorionic tissue can result in marked endometrial changes, known as an Arias-Stella reaction, that have an appearance similar to cancer. Historically, this change was diagnosed as endometrial cancer and it is important only in so far as it should not be misdiagnosed as cancer.\nThin endometrium may be defined as an endometrial thickness of less than 8\u00a0mm. It usually occurs after menopause. Treatments that can improve endometrial thickness include Vitamin E, L-arginine and sildenafil citrate.\nGene expression profiling using cDNA microarray can be used for the diagnosis of endometrial disorders.\nThe European Menopause and Andropause Society (EMAS) released Guidelines with detailed information to assess the endometrium.\nEmbryo transfer.\nAn endometrial thickness of less than 7\u00a0mm decreases the pregnancy rate in in vitro fertilization by an odds ratio of approximately 0.4 compared to an EMT of over 7\u00a0mm. However, such low thickness rarely occurs, and any routine use of this parameter is regarded as not justified.\nObservation of the endometrium by transvaginal ultrasonography is used when administering fertility medication, such as in in vitro fertilization. At the time of embryo transfer, it is favorable to have an endometrium of a thickness of between 7 and 14 mm with a \"triple-line\" configuration, which means that the endometrium contains a hyperechoic (usually displayed as light) line in the middle surrounded by two more hypoechoic (darker) lines. A \"triple-line\" endometrium reflects the separation of the stratum basalis and functionalis layers, and is also observed in the periovulatory period secondary to rising estradiol levels, and disappears after ovulation."}
{"id": "9510", "revid": "800198", "url": "https://en.wikipedia.org/wiki?curid=9510", "title": "Electronic music", "text": "Electronic music is music that employs electronic musical instruments, digital instruments, or circuitry-based music technology in its creation. It includes both music made using electronic and electromechanical means (electroacoustic music). Pure electronic instruments depended entirely on circuitry-based sound generation, for instance using devices such as an electronic oscillator, theremin, or synthesizer. Electromechanical instruments can have mechanical parts such as strings, hammers, and electric elements including magnetic pickups, power amplifiers and loudspeakers. Such electromechanical devices include the telharmonium, Hammond organ, electric piano and the electric guitar.\nThe first electronic musical devices were developed at the end of the 19th century. During the 1920s and 1930s, a number of electronic instruments were introduced and the first compositions featuring them were written. By the 1940s, magnetic audio tape allowed musicians to tape sounds and then modify them by changing the tape speed or direction, leading to the development of electroacoustic tape music in the 1940s, in Egypt and France. Musique concr\u00e8te, created in Paris in 1948, was based on editing together recorded fragments of natural and industrial sounds. Music produced solely from electronic generators was first produced in Germany in 1953. Electronic music was also created in Japan and the United States beginning in the 1950s and Algorithmic composition with computers was first demonstrated in the same decade.\nDuring the 1960s, digital computer music was pioneered, innovation in live electronics took place, and Japanese electronic musical instruments began to influence the music industry. In the early 1970s, Moog synthesizers and Japanese drum machines helped popularize synthesized electronic music. The 1970s also saw electronic music begin to have a significant influence on popular music, with the adoption of polyphonic synthesizers, electronic drums, drum machines and turntables, through the emergence of genres such as disco, krautrock, new wave, synth-pop, hip hop and EDM. In the early 1980s mass produced digital synthesizers, such as the Yamaha DX7, became popular and MIDI (Musical Instrument Digital Interface) was developed. In the same decade, with a greater reliance on synthesizers and the adoption of programmable drum machines, electronic popular music came to the fore. During the 1990s, with the proliferation of increasingly affordable music technology, electronic music production became an established part of popular culture. Contemporary electronic music includes many varieties and ranges from experimental art music to popular forms such as electronic dance music. Pop electronic music is most recognizable in its 4/4 form and more connected with the mainstream than preceding forms which were popular in niche markets.\nOrigins: late 19th century to early 20th century.\nAt the turn of the 20th century, experimentation with emerging electronics led to the first electronic musical instruments. These initial inventions were not sold, but were instead used in demonstrations and public performances. The audiences were presented with reproductions of existing music instead of new compositions for the instruments. While some were considered novelties and produced simple tones, the Telharmonium synthesized the sound of several orchestral instruments with reasonable precision. It achieved viable public interest and made commercial progress into streaming music through telephone networks.\nCritics of musical conventions at the time saw promise in these developments. Ferruccio Busoni encouraged the composition of microtonal music allowed for by electronic instruments. He predicted the use of machines in future music, writing the influential \"Sketch of a New Esthetic of Music\" (1907). Futurists such as Francesco Balilla Pratella and Luigi Russolo began composing music with acoustic noise to evoke the sound of machinery. They predicted expansions in timbre allowed for by electronics in the influential manifesto \"The Art of Noises\" (1913).\nEarly compositions.\nDevelopments of the vacuum tube led to electronic instruments that were smaller, amplified, and more practical for performance. In particular, the theremin, ondes Martenot and trautonium were commercially produced by the early 1930s.\nFrom the late 1920s, the increased practicality of electronic instruments influenced composers such as Joseph Schillinger to adopt them. They were typically used within orchestras, and most composers wrote parts for the theremin that could otherwise be performed with string instruments.\nAvant-garde composers criticized the predominant use of electronic instruments for conventional purposes. The instruments offered expansions in pitch resources that were exploited by advocates of microtonal music such as Charles Ives, Dimitrios Levidis, Olivier Messiaen and Edgard Var\u00e8se. Further, Percy Grainger used the theremin to abandon fixed tonation entirely, while Russian composers such as Gavriil Popov treated it as a source of noise in otherwise-acoustic noise music.\nRecording experiments.\nDevelopments in early recording technology paralleled that of electronic instruments. The first means of recording and reproducing audio was invented in the late 19th century with the mechanical phonograph. Record players became a common household item, and by the 1920s composers were using them to play short recordings in performances.\nThe introduction of electrical recording in 1925 was followed by increased experimentation with record players. Paul Hindemith and Ernst Toch composed several pieces in 1930 by layering recordings of instruments and vocals at adjusted speeds. Influenced by these techniques, John Cage composed \"Imaginary Landscape No. 1\" in 1939 by adjusting the speeds of recorded tones.\nConcurrently, composers began to experiment with newly developed sound-on-film technology. Recordings could be spliced together to create sound collages, such as those by Tristan Tzara, Kurt Schwitters, Filippo Tommaso Marinetti, Walter Ruttmann and Dziga Vertov. Further, the technology allowed sound to be graphically created and modified. These techniques were used to compose soundtracks for several films in Germany and Russia, in addition to the popular \"Dr. Jekyll and Mr. Hyde\" in the United States. Experiments with graphical sound were continued by Norman McLaren from the late 1930s.\nDevelopment: 1940s to 1950s.\nElectroacoustic tape music.\nThe first practical audio tape recorder was unveiled in 1935. Improvements to the technology were made using the AC biasing technique, which significantly improved recording fidelity. As early as 1942, test recordings were being made in stereo. Although these developments were initially confined to Germany, recorders and tapes were brought to the United States following the end of World War II. These were the basis for the first commercially produced tape recorder in 1948.\nIn 1944, prior to the use of magnetic tape for compositional purposes, Egyptian composer Halim El-Dabh, while still a student in Cairo, used a cumbersome wire recorder to record sounds of an ancient \"zaar\" ceremony. Using facilities at the Middle East Radio studios El-Dabh processed the recorded material using reverberation, echo, voltage controls, and re-recording. What resulted is believed to be the earliest tape music composition. The resulting work was entitled \"The Expression of Zaar\" and it was presented in 1944 at an art gallery event in Cairo. While his initial experiments in tape-based composition were not widely known outside of Egypt at the time, El-Dabh is also known for his later work in electronic music at the Columbia-Princeton Electronic Music Center in the late 1950s.\nMusique concr\u00e8te.\nFollowing his work with Studio d'Essai at Radiodiffusion Fran\u00e7aise (RDF), during the early 1940s, Pierre Schaeffer is credited with originating the theory and practice of musique concr\u00e8te. In the late 1940s, experiments in sound based composition using shellac record players were first conducted by Schaeffer. In 1950, the techniques of musique concrete were expanded when magnetic tape machines were used to explore sound manipulation practices such as speed variation (pitch shift) and tape splicing .\nOn 5 October 1948, RDF broadcast Schaeffer's \"Etude aux chemins de fer\". This was the first \"movement\" of \"Cinq \u00e9tudes de bruits\", and marked the beginning of studio realizations and musique concr\u00e8te (or acousmatic art). Schaeffer employed a disk-cutting lathe, four turntables, a four-channel mixer, filters, an echo chamber, and a mobile recording unit. Not long after this, Pierre Henry began collaborating with Schaeffer, a partnership that would have profound and lasting effects on the direction of electronic music. Another associate of Schaeffer, Edgard Var\u00e8se, began work on \"D\u00e9serts\", a work for chamber orchestra and tape. The tape parts were created at Pierre Schaeffer's studio, and were later revised at Columbia University.\nIn 1950, Schaeffer gave the first public (non-broadcast) concert of musique concr\u00e8te at the \u00c9cole Normale de Musique de Paris. \"Schaeffer used a PA system, several turntables, and mixers. The performance did not go well, as creating live montages with turntables had never been done before.\" Later that same year, Pierre Henry collaborated with Schaeffer on \"Symphonie pour un homme seul\" (1950) the first major work of musique concrete. In Paris in 1951, in what was to become an important worldwide trend, RTF established the first studio for the production of electronic music. Also in 1951, Schaeffer and Henry produced an opera, \"Orpheus\", for concrete sounds and voices.\nBy 1951 the work of Schaeffer, composer-percussionist Pierre Henry, and sound engineer Jacques Poullin had received official recognition and The Groupe de Recherches de Musique Concr\u00e8te, Club d 'Essai de la Radiodiffusion-T\u00e9l\u00e9vision Fran\u00e7aise was established at RTF in Paris, the ancestor of the ORTF.\nElektronische Musik.\nKarlheinz Stockhausen worked briefly in Schaeffer's studio in 1952, and afterward for many years at the WDR Cologne's Studio for Electronic Music.\n1954 saw the advent of what would now be considered authentic electric plus acoustic compositions\u2014acoustic instrumentation augmented/accompanied by recordings of manipulated or electronically generated sound. Three major works were premiered that year: Var\u00e8se's \"D\u00e9serts\", for chamber ensemble and tape sounds, and two works by Otto Luening and Vladimir Ussachevsky: \"Rhapsodic Variations for the Louisville Symphony\" and \"A Poem in Cycles and Bells\", both for orchestra and tape. Because he had been working at Schaeffer's studio, the tape part for Var\u00e8se's work contains much more concrete sounds than electronic. \"A group made up of wind instruments, percussion and piano alternates with the mutated sounds of factory noises and ship sirens and motors, coming from two loudspeakers.\"\nAt the German premiere of \"D\u00e9serts\" in Hamburg, which was conducted by Bruno Maderna, the tape controls were operated by Karlheinz Stockhausen. The title \"D\u00e9serts\" suggested to Var\u00e8se not only \"all physical deserts (of sand, sea, snow, of outer space, of empty streets), but also the deserts in the mind of man; not only those stripped aspects of nature that suggest bareness, aloofness, timelessness, but also that remote inner space no telescope can reach, where man is alone, a world of mystery and essential loneliness.\"\nIn Cologne, what would become the most famous electronic music studio in the world, was officially opened at the radio studios of the NWDR in 1953, though it had been in the planning stages as early as 1950 and early compositions were made and broadcast in 1951. The brainchild of Werner Meyer-Eppler, Robert Beyer, and Herbert Eimert (who became its first director), the studio was soon joined by Karlheinz Stockhausen and Gottfried Michael Koenig. In his 1949 thesis \"Elektronische Klangerzeugung: Elektronische Musik und Synthetische Sprache\", Meyer-Eppler conceived the idea to synthesize music entirely from electronically produced signals; in this way, \"elektronische Musik\" was sharply differentiated from French \"musique concr\u00e8te\", which used sounds recorded from acoustical sources.\nIn 1954, Stockhausen composed his \"Elektronische Studie II\"\u2014the first electronic piece to be published as a score. In 1955, more experimental and electronic studios began to appear. Notable were the creation of the Studio di fonologia musicale di Radio Milano, a studio at the NHK in Tokyo founded by Toshiro Mayuzumi, and the Philips studio at Eindhoven, the Netherlands, which moved to the University of Utrecht as the Institute of Sonology in 1960.\n\"With Stockhausen and Mauricio Kagel in residence, it became a year-round hive of charismatic avante-gardism \" on two occasions combining electronically generated sounds with relatively conventional orchestras\u2014in \"Mixtur\" (1964) and \"Hymnen, dritte Region mit Orchester\" (1967). Stockhausen stated that his listeners had told him his electronic music gave them an experience of \"outer space\", sensations of flying, or being in a \"fantastic dream world\".\nMore recently, Stockhausen turned to producing electronic music in his own studio in K\u00fcrten, his last work in the medium being \"Cosmic Pulses\" (2007).\nJapanese electronic music.\nThe earliest group of electronic musical instruments in Japan, Yamaha Magna Organ was built in 1935. however after the World War II, Japanese composers such as Minao Shibata knew of the development of electronic musical instruments. By the late 1940s, Japanese composers began experimenting with electronic music and institutional sponsorship enabled them to experiment with advanced equipment. Their infusion of Asian music into the emerging genre would eventually support Japan's popularity in the development of music technology several decades later.\nFollowing the foundation of electronics company Sony in 1946, composers Toru Takemitsu and Minao Shibata independently explored possible uses for electronic technology to produce music. Takemitsu had ideas similar to musique concr\u00e8te, which he was unaware of, while Shibata foresaw the development of synthesizers and predicted a drastic change in music. Sony began producing popular magnetic tape recorders for government and public use.\nThe avant-garde collective Jikken K\u014db\u014d (Experimental Workshop), founded in 1950, was offered access to emerging audio technology by Sony. The company hired Toru Takemitsu to demonstrate their tape recorders with compositions and performances of electronic tape music. The first electronic tape pieces by the group were \"Toraware no Onna\" (\"Imprisoned Woman\") and \"Piece B\", composed in 1951 by Kuniharu Akiyama. Many of the electroacoustic tape pieces they produced were used as incidental music for radio, film, and theatre. They also held concerts employing a slide show synchronized with a recorded soundtrack. Composers outside of the Jikken K\u014db\u014d, such as Yasushi Akutagawa, Saburo Tominaga and Shir\u014d Fukai, were also experimenting with radiophonic tape music between 1952 and 1953.\nMusique concr\u00e8te was introduced to Japan by Toshiro Mayuzumi, who was influenced by a Pierre Schaeffer concert. From 1952, he composed tape music pieces for a comedy film, a radio broadcast, and a radio drama. However, Schaeffer's concept of \"sound object\" was not influential among Japanese composers, who were mainly interested in overcoming the restrictions of human performance. This led to several Japanese electroacoustic musicians making use of serialism and twelve-tone techniques, evident in Yoshir\u014d Irino's 1951 dodecaphonic piece \"Concerto da\nCamera\", in the organization of electronic sounds in Mayuzumi's \"X, Y, Z for Musique Concr\u00e8te\", and later in Shibata's electronic music by 1956.\nModelling the NWDR studio in Cologne, NHK established an electronic music studio in Tokyo in 1955, which became one of the world's leading electronic music facilities. The NHK Studio was equipped with technologies such as tone-generating and audio processing equipment, recording and radiophonic equipment, ondes Martenot, Monochord and Melochord, sine-wave oscillators, tape recorders, ring modulators, band-pass filters, and four- and eight-channel mixers. Musicians associated with the studio included Toshiro Mayuzumi, Minao Shibata, Joji Yuasa, Toshi Ichiyanagi, and Toru Takemitsu. The studio's first electronic compositions were completed in 1955, including Mayuzumi's five-minute pieces \"Studie I: Music for Sine Wave by Proportion of Prime Number\", \"Music for Modulated Wave by Proportion of Prime Number\" and \"Invention for Square Wave and Sawtooth Wave\" produced using the studio's various tone-generating capabilities, and Shibata's 20-minute stereo piece \"Musique Concr\u00e8te for Stereophonic Broadcast\".\nAmerican electronic music.\nIn the United States, electronic music was being created as early as 1939, when John Cage published \"Imaginary Landscape, No. 1\", using two variable-speed turntables, frequency recordings, muted piano, and cymbal, but no electronic means of production. Cage composed five more \"Imaginary Landscapes\" between 1942 and 1952 (one withdrawn), mostly for percussion ensemble, though No. 4 is for twelve radios and No. 5, written in 1952, uses 42 recordings and is to be realized as a magnetic tape. According to Otto Luening, Cage also performed a \"William Mix\" at Donaueschingen in 1954, using eight loudspeakers, three years after his alleged collaboration. \"Williams Mix\" was a success at the Donaueschingen Festival, where it made a \"strong impression\".\nThe Music for Magnetic Tape Project was formed by members of the New York School (John Cage, Earle Brown, Christian Wolff, David Tudor, and Morton Feldman), and lasted three years until 1954. Cage wrote of this collaboration: \"In this social darkness, therefore, the work of Earle Brown, Morton Feldman, and Christian Wolff continues to present a brilliant light, for the reason that at the several points of notation, performance, and audition, action is provocative.\"\nCage completed \"Williams Mix\" in 1953 while working with the Music for Magnetic Tape Project. The group had no permanent facility, and had to rely on borrowed time in commercial sound studios, including the studio of Louis and Bebe Barron.\nColumbia-Princeton Center.\nIn the same year Columbia University purchased its first tape recorder\u2014a professional Ampex machine\u2014for the purpose of recording concerts. Vladimir Ussachevsky, who was on the music faculty of Columbia University, was placed in charge of the device, and almost immediately began experimenting with it.\nHerbert Russcol writes: \"Soon he was intrigued with the new sonorities he could achieve by recording musical instruments and then superimposing them on one another.\" Ussachevsky said later: \"I suddenly realized that the tape recorder could be treated as an instrument of sound transformation.\" On Thursday, 8 May 1952, Ussachevsky presented several demonstrations of tape music/effects that he created at his Composers Forum, in the McMillin Theatre at Columbia University. These included \"Transposition, Reverberation, Experiment, Composition\", and \"Underwater Valse\". In an interview, he stated: \"I presented a few examples of my discovery in a public concert in New York together with other compositions I had written for conventional instruments.\"\nOtto Luening, who had attended this concert, remarked: \"The equipment at his disposal consisted of an Ampex tape recorder . . . and a simple box-like device designed by the brilliant young engineer, Peter Mauzey, to create feedback, a form of mechanical reverberation. Other equipment was borrowed or purchased with personal funds.\"\nJust three months later, in August 1952, Ussachevsky traveled to Bennington, Vermont at Luening's invitation to present his experiments. There, the two collaborated on various pieces. Luening described the event: \"Equipped with earphones and a flute, I began developing my first tape-recorder composition. Both of us were fluent improvisors and the medium fired our imaginations.\"\nThey played some early pieces informally at a party, where \"a number of composers almost solemnly congratulated us saying, 'This is it' ('it' meaning the music of the future).\"\nWord quickly reached New York City. Oliver Daniel telephoned and invited the pair to \"produce a group of short compositions for the October concert sponsored by the American Composers Alliance and Broadcast Music, Inc., under the direction of Leopold Stokowski at the Museum of Modern Art in New York. After some hesitation, we agreed. . . . Henry Cowell placed his home and studio in Woodstock, New York, at our disposal. With the borrowed equipment in the back of Ussachevsky's car, we left Bennington for Woodstock and stayed two weeks. . . . In late September, 1952, the travelling laboratory reached Ussachevsky's living room in New York, where we eventually completed the compositions.\"\nTwo months later, on 28 October, Vladimir Ussachevsky and Otto Luening presented the first Tape Music concert in the United States. The concert included Luening's \"Fantasy in Space\" (1952)\u2014\"an impressionistic virtuoso piece\" using manipulated recordings of flute\u2014and \"Low Speed\" (1952), an \"exotic composition that took the flute far below its natural range.\" Both pieces were created at the home of Henry Cowell in Woodstock, New York. After several concerts caused a sensation in New York City, Ussachevsky and Luening were invited onto a live broadcast of NBC's Today Show to do an interview demonstration\u2014the first televised electroacoustic performance. Luening described the event: \"I improvised some [flute] sequences for the tape recorder. Ussachevsky then and there put them through electronic transformations.\"\nThe score for \"Forbidden Planet\", by Louis and Bebe Barron, was entirely composed using custom built electronic circuits and tape recorders in 1956 (but no synthesizers in the modern sense of the word).\nAustralia.\nThe world's first computer to play music was CSIRAC, which was designed and built by Trevor Pearcey and Maston Beard. Mathematician Geoff Hill programmed the CSIRAC to play popular musical melodies from the very early 1950s. In 1951 it publicly played the Colonel Bogey March, of which no known recordings exist, only the accurate reconstruction. However, CSIRAC played standard repertoire and was not used to extend musical thinking or composition practice. CSIRAC was never recorded, but the music played was accurately reconstructed. The oldest known recordings of computer-generated music were played by the Ferranti Mark 1 computer, a commercial version of the Baby Machine from the University of Manchester in the autumn of 1951. The music program was written by Christopher Strachey.\nMid-to-late 1950s.\nThe impact of computers continued in 1956. Lejaren Hiller and Leonard Isaacson composed \"Illiac Suite\" for string quartet, the first complete work of computer-assisted composition using algorithmic composition. \"... Hiller postulated that a computer could be taught the rules of a particular style and then called on to compose accordingly.\" Later developments included the work of Max Mathews at Bell Laboratories, who developed the influential MUSIC I program in 1957, one of the first computer programs to play electronic music. Vocoder technology was also a major development in this early era. In 1956, Stockhausen composed \"Gesang der J\u00fcnglinge\", the first major work of the Cologne studio, based on a text from the \"Book of Daniel\". An important technological development of that year was the invention of the Clavivox synthesizer by Raymond Scott with subassembly by Robert Moog.\nIn 1957, Kid Baltan (Dick Raaymakers) and Tom Dissevelt released their debut album, \"Song Of The Second Moon\", recorded at the Philips studio in the Netherlands. The public remained interested in the new sounds being created around the world, as can be deduced by the inclusion of Var\u00e8se's \"Po\u00e8me \u00e9lectronique\", which was played over four hundred loudspeakers at the Philips Pavilion of the 1958 Brussels World Fair. That same year, Mauricio Kagel, an Argentine composer, composed \"Transici\u00f3n II\". The work was realized at the WDR studio in Cologne. Two musicians performed on a piano, one in the traditional manner, the other playing on the strings, frame, and case. Two other performers used tape to unite the presentation of live sounds with the future of prerecorded materials from later on and its past of recordings made earlier in the performance.\nIn 1958, Columbia-Princeton developed the RCA Mark II Sound Synthesizer, the first programmable synthesizer. Prominent composers such as Vladimir Ussachevsky, Otto Luening, Milton Babbitt, Charles Wuorinen, Halim El-Dabh, B\u00fclent Arel and Mario Davidovsky used the RCA Synthesizer extensively in various compositions. One of the most influential composers associated with the early years of the studio was Egypt's Halim El-Dabh who, after having developed the earliest known electronic tape music in 1944, became more famous for \"Leiyla and the Poet\", a 1959 series of electronic compositions that stood out for its immersion and seamless fusion of electronic and folk music, in contrast to the more mathematical approach used by serial composers of the time such as Babbitt. El-Dabh's \"Leiyla and the Poet\", released as part of the album \"Columbia-Princeton Electronic Music Center\" in 1961, would be cited as a strong influence by a number of musicians, ranging from Neil Rolnick, Charles Amirkhanian and Alice Shields to rock musicians Frank Zappa and The West Coast Pop Art Experimental Band.\nFollowing the emergence of differences within the GRMC (Groupe de Recherche de Musique Concr\u00e8te) Pierre Henry, Philippe Arthuys, and several of their colleagues, resigned in April 1958. Schaeffer created a new collective, called Groupe de Recherches Musicales (GRM) and set about recruiting new members including Luc Ferrari, Beatriz Ferreyra, Fran\u00e7ois-Bernard M\u00e2che, Iannis Xenakis, Bernard Parmegiani, and Mireille Chamass-Kyrou. Later arrivals included Ivo Malec, Philippe Carson, Romuald Vandelle, Edgardo Canton and Fran\u00e7ois Bayle.\nExpansion: 1960s.\nThese were fertile years for electronic music\u2014not just for academia, but for independent artists as synthesizer technology became more accessible. By this time, a strong community of composers and musicians working with new sounds and instruments was established and growing. 1960 witnessed the composition of Luening's \"Gargoyles\" for violin and tape as well as the premiere of Stockhausen's \"Kontakte\" for electronic sounds, piano, and percussion. This piece existed in two versions\u2014one for 4-channel tape, and the other for tape with human performers. \"In \"Kontakte\", Stockhausen abandoned traditional musical form based on linear development and dramatic climax. This new approach, which he termed 'moment form', resembles the 'cinematic splice' techniques in early twentieth century film.\"\nThe theremin had been in use since the 1920s but it attained a degree of popular recognition through its use in science-fiction film soundtrack music in the 1950s (e.g., Bernard Herrmann's classic score for \"The Day the Earth Stood Still\").\nIn the UK in this period, the BBC Radiophonic Workshop (established in 1958) came to prominence, thanks in large measure to their work on the BBC science-fiction series \"Doctor Who\". One of the most influential British electronic artists in this period was Workshop staffer Delia Derbyshire, who is now famous for her 1963 electronic realisation of the iconic \"Doctor Who\" theme, composed by Ron Grainer.\nIn 1961 Josef Tal established the \"Centre for Electronic Music in Israel\" at The Hebrew University, and in 1962 Hugh Le Caine arrived in Jerusalem to install his \"Creative Tape Recorder\" in the centre. In the 1990s Tal conducted, together with Dr Shlomo Markel, in cooperation with the Technion \u2013 Israel Institute of Technology, and VolkswagenStiftung a research project (Talmark) aimed at the development of a novel musical notation system for electronic music.\nMilton Babbitt composed his first electronic work using the synthesizer\u2014his \"Composition for Synthesizer\" (1961)\u2014which he created using the RCA synthesizer at the Columbia-Princeton Electronic Music Center.\nThe collaborations also occurred across oceans and continents. In 1961, Ussachevsky invited Var\u00e8se to the Columbia-Princeton Studio (CPEMC). Upon arrival, Varese embarked upon a revision of \"D\u00e9serts\". He was assisted by Mario Davidovsky and B\u00fclent Arel.\nThe intense activity occurring at CPEMC and elsewhere inspired the establishment of the San Francisco Tape Music Center in 1963 by Morton Subotnick, with additional members Pauline Oliveros, Ramon Sender, Anthony Martin, and Terry Riley.\nLater, the Center moved to Mills College, directed by Pauline Oliveros, where it is today known as the Center for Contemporary Music.\nSimultaneously in San Francisco, composer Stan Shaff and equipment designer Doug McEachern, presented the first \u201cAudium\u201d concert at San Francisco State College (1962), followed by a work at the San Francisco Museum of Modern Art (1963), conceived of as in time, controlled movement of sound in space. Twelve speakers surrounded the audience, four speakers were mounted on a rotating, mobile-like construction above. In an SFMOMA performance the following year (1964), \"San Francisco Chronicle\" music critic Alfred Frankenstein commented, \"the possibilities of the space-sound continuum have seldom been so extensively explored\". In 1967, the first Audium, a \"sound-space continuum\" opened, holding weekly performances through 1970. In 1975, enabled by seed money from the National Endowment for the Arts, a new Audium opened, designed floor to ceiling for spatial sound composition and performance. \u201cIn contrast, there are composers who manipulated sound space by locating multiple speakers at various locations in a performance space and then switching or panning the sound between the sources. In this approach, the composition of spatial manipulation is dependent on the location of the speakers and usually exploits the acoustical properties of the enclosure. Examples include Varese's \"Poeme Electronique\" (tape music performed in the Philips Pavilion of the 1958 World Fair, Brussels) and Stanley Schaff's \"Audium\" installation, currently active in San Francisco\u201d. Through weekly programs (over 4,500 in 40 years), Shaff \u201csculpts\u201d sound, performing now-digitized spatial works live through 176 speakers.\nA well-known example of the use of Moog's full-sized Moog modular synthesizer is the 1968 \"Switched-On Bach\" album by Wendy Carlos, which triggered a craze for synthesizer music.\nIn 1969 David Tudor brought a Moog modular synthesizer and Ampex tape machines to the National Institute of Design in Ahmedabad with the support of the Sarabhai family, forming the foundation of India's first electronic music studio. Here a group of composers Jinraj Joshipura, Gita Sarabhai, SC Sharma, IS Mathur and Atul Desai developed experimental sound compositions between 1969 and 1973\nAlong with the Moog modular synthesizer, other makes of this period included ARP and Buchla.\nPietro Grossi was an Italian pioneer of computer composition and tape music, who first experimented with electronic techniques in the early sixties. Grossi was a cellist and composer, born in Venice in 1917. He founded the S 2F M (Studio de Fonologia Musicale di Firenze) in 1963 in order to experiment with electronic sound and composition.\nComputer music.\nMusical melodies were first generated by the computer CSIRAC in Australia in 1950. There were newspaper reports from America and England (early and recently) that computers may have played music earlier, but thorough research has debunked these stories as there is no evidence to support the newspaper reports (some of which were obviously speculative). Research has shown that people \"speculated\" about computers playing music, possibly because computers would make noises, but there is no evidence that they actually did it.\nThe world's first computer to play music was CSIRAC, which was designed and built by Trevor Pearcey and Maston Beard in the 1950s. Mathematician Geoff Hill programmed the CSIRAC to play popular musical melodies from the very early 1950s. In 1951 it publicly played the \"Colonel Bogey March\" of which no known recordings exist.\nHowever, CSIRAC played standard repertoire and was not used to extend musical thinking or composition practice which is current computer-music practice.\nThe first music to be performed in England was a performance of the British National Anthem that was programmed by Christopher Strachey on the Ferranti Mark I, late in 1951. Later that year, short extracts of three pieces were recorded there by a BBC outside broadcasting unit: the National Anthem, \"Ba, Ba Black Sheep\", and \"In the Mood\" and this is recognised as the earliest recording of a computer to play music. This recording can be heard at this Manchester University site. Researchers at the University of Canterbury, Christchurch declicked and restored this recording in 2016 and the results may be heard on SoundCloud.\nThe late 1950s, 1960s and 1970s also saw the development of large mainframe computer synthesis. Starting in 1957, Max Mathews of Bell Labs developed the MUSIC programs, culminating in MUSIC V, a direct digital synthesis language\nLaurie Spiegel developed the algorithmic musical composition software \"Music Mouse\" (1986) for Macintosh, Amiga, and Atari computers.\nStochastic music.\nAn important new development was the advent of computers for the purpose of composing music, as opposed to manipulating or creating sounds. Iannis Xenakis began what is called \"musique stochastique\", or \"stochastic music\", which is a composing method that uses mathematical probability systems. Different probability algorithms were used to create a piece under a set of parameters. Xenakis used computers to compose pieces like \"ST/4\" for string quartet and \"ST/48\" for orchestra (both 1962), \"Morsima-Amorsima\", \"ST/10\", and \"Atr\u00e9es\". He developed the computer system UPIC for translating graphical images into musical results and composed \"Myc\u00e8nes Alpha\" (1978) with it.\nLive electronics.\nIn Europe in 1964, Karlheinz Stockhausen composed \"Mikrophonie I\" for tam-tam, hand-held microphones, filters, and potentiometers, and \"Mixtur\" for orchestra, four sine-wave generators, and four ring modulators. In 1965 he composed \"Mikrophonie II\" for choir, Hammond organ, and ring modulators.\nIn 1966\u201367, Reed Ghazala discovered and began to teach \"circuit bending\"\u2014the application of the creative short circuit, a process of chance short-circuiting, creating experimental electronic instruments, exploring sonic elements mainly of timbre and with less regard to pitch or rhythm, and influenced by John Cage's aleatoric music concept.\nCosey Fanni Tutti's performance art and musical career explored the concept of 'acceptable' music and she went on to explore the use of sound as a means of desire or discomfort.\nWendy Carlos performed selections from her album \"Switched-On Bach\" on stage with a synthesizer with the St. Louis Symphony Orchestra; another live performance was with Kurzweil Baroque Ensemble for \"Bach at the Beacon\" in 1997.\nIn June 2018, Suzanne Ciani released \"LIVE Quadraphonic\", a live album documenting her first solo performance on a Buchla synthesizer in 40 years. It was one of the first quadraphonic vinyl releases in over 30 years.\nJapanese instruments.\nIn the 1950s, Japanese electronic musical instruments began influencing the international music industry. Ikutaro Kakehashi, who founded Ace Tone in 1960, developed his own version of electronic percussion that had been already popular on the overseas electronic organ. At NAMM 1964, he revealed it as the R-1 Rhythm Ace, a hand-operated percussion device that played electronic drum sounds manually as the user pushed buttons, in a similar fashion to modern electronic drum pads.\nIn 1963, Korg released the Donca-Matic DA-20, an electro-mechanical drum machine. In 1965, Nippon Columbia patented a fully electronic drum machine. Korg released the Donca-Matic DC-11 electronic drum machine in 1966, which they followed with the Korg Mini Pops, which was developed as an option for the Yamaha Electone electric organ. Korg's Stageman and Mini Pops series were notable for \"natural metallic percussion\" sounds and incorporating controls for drum \"breaks and fill-ins.\"\nIn 1967, Ace Tone founder Ikutaro Kakehashi patented a preset rhythm-pattern generator using diode matrix circuit similar to the Seeburg's prior filed in 1964 (See Drum machine#History), which he released as the FR-1 Rhythm Ace drum machine the same year. It offered 16 preset patterns, and four buttons to manually play each instrument sound (cymbal, claves, cowbell and bass drum). The rhythm patterns could also be cascaded together by pushing multiple rhythm buttons simultaneously, and the possible combination of rhythm patterns were more than a hundred. Ace Tone's Rhythm Ace drum machines found their way into popular music from the late 1960s, followed by Korg drum machines in the 1970s. Kakehashi later left Ace Tone and founded Roland Corporation in 1972, with and becoming highly influential for the next several decades. The company would go on to have a big impact on popular music, and do more to shape popular electronic music than any other company.\nTurntablism has origins in the invention of direct-drive turntables. Early belt-drive turntables were unsuitable for turntablism, since they had a slow start-up time, and they were prone to wear-and-tear and breakage, as the belt would break from backspin or scratching. The first direct-drive turntable was invented by Shuichi Obata, an engineer at Matsushita (now Panasonic), based in Osaka, Japan. It eliminated belts, and instead employed a motor to directly drive a platter on which a vinyl record rests. In 1969, Matsushita released it as the SP-10, the first direct-drive turntable on the market, and the first in their influential Technics series of turntables. It was succeeded by the Technics SL-1100 and SL-1200 in the early 1970s, and they were widely adopted by hip hop musicians, with the SL-1200 remaining the most widely used turntable in DJ culture for several decades.\nJamaican dub music.\nIn Jamaica, a form of popular electronic music emerged in the 1960s, dub music, rooted in sound system culture. Dub music was pioneered by studio engineers, such as Sylvan Morris, King Tubby, Errol Thompson, Lee \"Scratch\" Perry, and Scientist, producing reggae-influenced experimental music with electronic sound technology, in recording studios and at sound system parties. Their experiments included forms of tape-based composition comparable to aspects of \"musique concr\u00e8te\", an emphasis on repetitive rhythmic structures (often stripped of their harmonic elements) comparable to minimalism, the electronic manipulation of spatiality, the sonic electronic manipulation of pre-recorded musical materials from mass media, deejays toasting over pre-recorded music comparable to live electronic music, remixing music, turntablism, and the mixing and scratching of vinyl.\nDespite the limited electronic equipment available to dub pioneers such as King Tubby and Lee \"Scratch\" Perry, their experiments in remix culture were musically cutting-edge. King Tubby, for example, was a sound system proprietor and electronics technician, whose small front-room studio in the Waterhouse ghetto of western Kingston was a key site of dub music creation.\nLate 1960s to early 1980s.\nRise of popular electronic music.\nIn the late 1960s, pop and rock musicians, including the Beach Boys and the Beatles, began to use electronic instruments, like the theremin and Mellotron, to supplement and define their sound. In his book \"Electronic and Experimental Music\", Thom Holmes recognises the Beatles' 1966 recording \"Tomorrow Never Knows\" as the song that \"ushered in a new era in the use of electronic music in rock and pop music\" due to the band's incorporation of tape loops and reversed and speed-manipulated tape sounds. Also in the late 1960s, the music duo Silver Apples and experimental rock bands like White Noise and the United States of America, are regarded as pioneers to the electronic rock and electronica genres for their work in melding psychedelic rock with oscillators and synthesizers.\nGershon Kingsley's \"Popcorn\" composed in 1969 was the first international electronic dance hit popularised by Hot Butter in 1972 (which leads to a wave of bubblegum pop the following years).\nBy the end of the 1960s, the Moog synthesizer took a leading place in the sound of emerging progressive rock with bands including Pink Floyd, Yes, Emerson, Lake &amp; Palmer, and Genesis making them part of their sound. Instrumental prog rock was particularly significant in continental Europe, allowing bands like Kraftwerk, Tangerine Dream, Can, Neu!, and Faust to circumvent the language barrier. Their synthesiser-heavy \"krautrock\", along with the work of Brian Eno (for a time the keyboard player with Roxy Music), would be a major influence on subsequent electronic rock.\nAmbient dub was pioneered by King Tubby and other Jamaican sound artists, using DJ-inspired ambient electronics, complete with drop-outs, echo, equalization and psychedelic electronic effects. It featured layering techniques and incorporated elements of world music, deep basslines and harmonic sounds. Techniques such as a long echo delay were also used. Other notable artists within the genre include Dreadzone, Higher Intelligence Agency, The Orb, Ott, Loop Guru, Woob and Transglobal Underground.\nDub music influenced electronic musical techniques later adopted by hip hop music, when Jamaican immigrant DJ Kool Herc in the early 1970s introduced Jamaica's sound system culture and dub music techniques to America. One such technique that became popular in hip hop culture was playing two copies of the same record on two turntables in alternation, extending the b-dancers' favorite section. The turntable eventually went on to become the most visible electronic musical instrument, and occasionally the most virtuosic, in the 1980s and 1990s.\nElectronic rock was also produced by several Japanese musicians, including Isao Tomita's \"Electric Samurai: Switched on Rock\" (1972), which featured Moog synthesizer renditions of contemporary pop and rock songs, and Osamu Kitajima's progressive rock album \"Benzaiten\" (1974). The mid-1970s saw the rise of electronic art music musicians such as Jean Michel Jarre, Vangelis, Tomita and Klaus Schulze were a significant influence on the development of new-age music. The \"hi-tech\" appeal of these works created for some years the trend of listing the electronic musical equipment employed in the album sleeves, as a distinctive feature. Electronic music began to enter regularly in radio programming and top-sellers charts, as the French band Space with their 1977 single \"Magic Fly\".\nIn this era, the sound of rock musicians like Mike Oldfield and The Alan Parsons Project (who is credited the first rock song to feature a digital vocoder in 1975, \"The Raven\") used to be arranged and blended with electronic effects and/or music as well, which became much more prominent in the mid-1980s. Jeff Wayne achieved a long lasting success with his 1978 electronic rock musical version of \"The War of the Worlds\".\nFilm soundtracks also benefit of the electronic sound. In 1977, Gene Page recorded a disco version of the hit theme by John Williams from Steven Spielberg film \"Close Encounters of the Third Kind\". Page's version peaked on the R&amp;B chart at #30 in 1978. The score of 1978 film \"Midnight Express\" composed by Italian synth-pioneer Giorgio Moroder won the Academy Award for Best Original Score in 1979, as did it again in 1981 the score by Vangelis for \"Chariots of Fire\".\nAfter the arrival of punk rock, a form of basic electronic rock emerged, increasingly using new digital technology to replace other instruments. The American duo Suicide, who arose from the punk scene in New York, utilized drum machines and synthesizers in a hybrid between electronics and punk on their eponymous 1977 album.\nSynth-pop pioneering bands which enjoyed success for years included Ultravox with their 1977 track \"Hiroshima Mon Amour\" on \"Ha!-Ha!-Ha!\", Yellow Magic Orchestra with their self-titled album (1978), The Buggles with their prominent 1979 debut single \"Video Killed the Radio Star\", Gary Numan with his solo debut album \"The Pleasure Principle\" and single \"Cars\" in 1979, Orchestral Manoeuvres in the Dark with their 1979 single \"Electricity\" featured on their eponymous debut album, Depeche Mode with their first single \"Dreaming of Me\" recorded in 1980 and released in 1981 album \"Speak &amp; Spell\", A Flock of Seagulls with their 1981 single \"Talking\", New Order with \"Ceremony\" in 1981, and The Human League with their 1981 hit \"Don't You Want Me\" from debut album \"Dare\".\nThe definition of MIDI and the development of digital audio made the development of purely electronic sounds much easier, with audio engineers, producers and composers exploring frequently the possibilities of virtually every new model of electronic sound equipment launched by manufacturers. Synth-pop sometimes used synthesizers to replace all other instruments, but was more common that bands had one of more keyboardists in their line-ups along with guitarists, bassists, and/or drummers. These developments led to the growth of synth-pop, which after it was adopted by the New Romantic movement, allowed synthesizers to dominate the pop and rock music of the early 1980s, until the style began to fall from popularity in the mid-to-end of the decade. Along with aforementioned successful pioneers, key acts included Yazoo, Duran Duran, Spandau Ballet, Culture Club, Talk Talk, Japan, and Eurythmics.\nSynth-pop was taken up across the world, with international hits for acts including Men Without Hats, Trans-X and Lime from Canada, Telex from Belgium, Peter Schilling, Sandra, Modern Talking, Propaganda and Alphaville from Germany, Yello from Switzerland and Azul y Negro from Spain. Also, the synth sound is a key feature of Italo-disco.\nSome synth-pop bands created futuristic visual styles of themselves to reinforce the idea of electronic sounds were linked primarily with technology, as Americans Devo and Spaniards Aviador Dro.\nKeyboard synthesizers became so common that even heavy metal rock bands, a genre often regarded as the \"opposite\" in aesthetics, sound and lifestyle from that of electronic pop artists by fans of both sides, achieved worldwide success with themes as 1983 \"Jump\" by Van Halen and 1986 \"The Final Countdown\" by Europe, which feature synths prominently.\nProliferation of electronic music research institutions.\n (EMS), formerly known as Electroacoustic Music in Sweden, is the Swedish national centre for electronic music and sound art. The research organisation started in 1964 and is based in Stockholm.\nSTEIM is a center for research and development of new musical instruments in the electronic performing arts, located in Amsterdam, Netherlands. STEIM has existed since 1969. It was founded by Misha Mengelberg, Louis Andriessen, Peter Schat, Dick Raaymakers, , Reinbert de Leeuw, and Konrad Boehmer. This group of Dutch composers had fought for the reformation of Amsterdam's feudal music structures; they insisted on Bruno Maderna's appointment as musical director of the Concertgebouw Orchestra and enforced the first public fundings for experimental and improvised electronic music in The Netherlands.\nIRCAM in Paris became a major center for computer music research and realization and development of the Sogitec 4X computer system, featuring then revolutionary real-time digital signal processing. Pierre Boulez's \"R\u00e9pons\" (1981) for 24 musicians and 6 soloists used the 4X to transform and route soloists to a loudspeaker system.\nBarry Vercoe describes one of his experiences with early computer sounds:\nKeyboard synthesizers.\nReleased in 1970 by Moog Music, the Mini-Moog was among the first widely available, portable and relatively affordable synthesizers. It became once the most widely used synthesizer at that time in both popular and electronic art music.\nPatrick Gleeson, playing live with Herbie Hancock in the beginning of the 1970s, pioneered the use of synthesizers in a touring context, where they were subject to stresses the early machines were not designed for.\nIn 1974, the WDR studio in Cologne acquired an EMS Synthi 100 synthesizer, which a number of composers used to produce notable electronic works\u2014including Rolf Gehlhaar's \"F\u00fcnf deutsche T\u00e4nze\" (1975), Karlheinz Stockhausen's \"Sirius\" (1975\u201376), and John McGuire's \"Pulse Music III\" (1978).\nThanks to miniaturization of electronics in the 1970s, by the start of the 1980s keyboard synthesizers became lighter and affordable, integrating in a single slim unit all the necessary audio synthesys electronics and the piano-style keyboard itself, in sharp contrast with the bulky machinery and \"cable spaguetty\" employed along the 1960s and 1970s. First with analog synthesizers, the trend followed with digital synthesizers and samplers as well (see below).\nDigital synthesis.\nIn 1975, the Japanese company Yamaha licensed the algorithms for frequency modulation synthesis (FM synthesis) from John Chowning, who had experimented with it at Stanford University since 1971. Yamaha's engineers began adapting Chowning's algorithm for use in a digital synthesizer, adding improvements such as the \"key scaling\" method to avoid the introduction of distortion that normally occurred in analog systems during frequency modulation.\nIn 1980, Yamaha eventually released the first FM digital synthesizer, the Yamaha GS-1, but at an expensive price. In 1983, Yamaha introduced the first stand-alone digital synthesizer, the DX7, which also used FM synthesis and would become one of the best-selling synthesizers of all time. The DX7 was known for its recognizable bright tonalities that was partly due to an overachieving sampling rate of 57\u00a0kHz.\nThe Korg Poly-800 is a synthesizer released by Korg in 1983. Its initial list price of $795 made it the first fully programmable synthesizer that sold for less than $1000. It had 8-voice polyphony with one Digitally controlled oscillator (DCO) per voice.\nThe Casio CZ-101 was the first and best-selling phase distortion synthesizer in the Casio CZ line. Released in November 1984, it was one of the first (if not the first) fully programmable polyphonic synthesizers that was available for under $500.\nThe Roland D-50 is a digital synthesizer produced by Roland and released in April 1987. Its features include subtractive synthesis, on-board effects, a joystick for data manipulation, and an analogue synthesis-styled layout design. The external Roland PG-1000 (1987-1990) programmer could also be attached to the D-50 for more complex manipulation of its sounds.\nSamplers.\nA sampler is an electronic or digital musical instrument which uses sound recordings (or \"samples\") of real instrument sounds (e.g., a piano, violin or trumpet), excerpts from recorded songs (e.g., a five-second bass guitar riff from a funk song) or found sounds (e.g., sirens and ocean waves). The samples are loaded or recorded by the user or by a manufacturer. These sounds are then played back by means of the sampler program itself, a MIDI keyboard, sequencer or another triggering device (e.g., electronic drums) to perform or compose music. Because these samples are usually stored in digital memory, the information can be quickly accessed. A single sample may often be pitch-shifted to different pitches to produce musical scales and chords.\nPrior to computer memory-based samplers, musicians used tape replay keyboards, which store recordings on analog tape. When a key is pressed the tape head contacts the moving tape and plays a sound. The Mellotron was the most notable model, used by a number of groups in the late 1960s and the 1970s, but such systems were expensive and heavy due to the multiple tape mechanisms involved, and the range of the instrument was limited to three octaves at the most. To change sounds a new set of tapes had to be installed in the instrument. The emergence of the digital sampler made sampling far more practical.\nThe earliest digital sampling was done on the EMS Musys system, developed by Peter Grogono (software), David Cockerell (hardware and interfacing) and Peter Zinovieff (system design and operation) at their London (Putney) Studio c. 1969.\nThe first commercially available sampling synthesizer was the Computer Music Melodian by Harry Mendell (1976).\nFirst released in 1977\u201378, the Synclavier I using FM synthesis, re-licensed from Yamaha, and sold mostly to universities, proved to be highly influential among both electronic music composers and music producers, including Mike Thorne, an early adopter from the commercial world, due to its versatility, its cutting-edge technology, and distinctive sounds.\nThe first polyphonic digital sampling synthesizer was the Australian-produced Fairlight CMI, first available in 1979. These early sampling synthesizers used wavetable sample-based synthesis.\nBirth of MIDI.\nIn 1980, a group of musicians and music merchants met to standardize an interface that new instruments could use to communicate control instructions with other instruments and computers. This standard was dubbed Musical Instrument Digital Interface (MIDI) and resulted from a collaboration between leading manufacturers, initially Sequential Circuits, Oberheim, Roland\u2014and later, other participants that included Yamaha, Korg, and Kawai. A paper was authored by Dave Smith of Sequential Circuits and proposed to the Audio Engineering Society in 1981. Then, in August 1983, the MIDI Specification 1.0 was finalized.\nMIDI technology allows a single keystroke, control wheel motion, pedal movement, or command from a microcomputer to activate every device in the studio remotely and in synchrony, with each device responding according to conditions predetermined by the composer.\nMIDI instruments and software made powerful control of sophisticated instruments easily affordable by many studios and individuals. Acoustic sounds became reintegrated into studios via sampling and sampled-ROM-based instruments.\nMiller Puckette developed graphic signal-processing software for 4X called Max (after Max Mathews) and later ported it to Macintosh (with Dave Zicarelli extending it for Opcode) for real-time MIDI control, bringing algorithmic composition availability to most composers with modest computer programming background.\nSequencers and drum machines.\nThe early 1980s saw the rise of bass synthesizers, the most influential being the Roland TB-303, a bass synthesizer and sequencer released in late 1981 that later became a fixture in electronic dance music, particularly acid house. One of the first to use it was Charanjit Singh in 1982, though it wouldn't be popularized until Phuture's \"Acid Tracks\" in 1987. Music sequencers began being used around the mid 20th century, and Tomita's albums in mid-1970s being later examples. In 1978, Yellow Magic Orchestra were using computer-based technology in conjunction with a synthesiser to produce popular music, making their early use of the microprocessor-based Roland MC-8 Microcomposer sequencer.\nDrum machines, also known as rhythm machines, also began being used around the late-1950s, with a later example being Osamu Kitajima's progressive rock album \"Benzaiten\" (1974), which used a rhythm machine along with electronic drums and a synthesizer. In 1977, Ultravox's \"Hiroshima Mon Amour\" was one of the first singles to use the metronome-like percussion of a Roland TR-77 drum machine. In 1980, Roland Corporation released the TR-808, one of the first and most popular programmable drum machines. The first band to use it was Yellow Magic Orchestra in 1980, and it would later gain widespread popularity with the release of Marvin Gaye's \"Sexual Healing\" and Afrika Bambaataa's \"Planet Rock\" in 1982. The TR-808 was a fundamental tool in the later Detroit techno scene of the late 1980s, and was the drum machine of choice for Derrick May and Juan Atkins.\nChiptunes.\nThe characteristic lo-fi sound of chip music was initially the result of early computer's sound chips and sound cards' technical limitations; however, the sound has since become sought after in its own right.\nCommon cheap popular sound chips of the firsts home computers of the 1980s include the SID of the Commodore 64 and General Instrument AY series and clones (as the Yamaha YM2149) used in ZX Spectrum, Amstrad CPC, MSX compatibles and Atari ST models, among others.\nLate 1980s to 1990s.\nRise of dance music.\nSynth-pop continued into the late 1980s, with a format that moved closer to dance music, including the work of acts such as British duos Pet Shop Boys, Erasure and The Communards, achieving success along much of the 1990s.\nThe trend has continued to the present day with modern nightclubs worldwide regularly playing electronic dance music (EDM). Today, electronic dance music has radio stations, websites, and publications like \"Mixmag\" dedicated solely to the genre. Moreover, the genre has found commercial and cultural significance in the United States and North America, thanks to the wildly popular big room house/EDM sound that has been incorporated into U.S. pop music and the rise of large-scale commercial raves such as Electric Daisy Carnival, Tomorrowland and Ultra Music Festival.\nAdvancements.\nOther recent developments included the Tod Machover (MIT and IRCAM) composition \"Begin Again Again\" for \"hypercello\", an interactive system of sensors measuring physical movements of the cellist. Max Mathews developed the \"Conductor\" program for real-time tempo, dynamic and timbre control of a pre-input electronic score. Morton Subotnick released a multimedia CD-ROM \"All My Hummingbirds Have Alibis\".\n2000s and 2010s.\nAs computer technology has become more accessible and music software has advanced, interacting with music production technology is now possible using means that bear no relationship to traditional musical performance practices: for instance, laptop performance (\"laptronica\"), live coding and Algorave. In general, the term Live PA refers to any live performance of electronic music, whether with laptops, synthesizers, or other devices.\nBeginning around the year 2000, a number of software-based virtual studio environments emerged, with products such as Propellerhead's Reason and Ableton Live finding popular appeal. Such tools provide viable and cost-effective alternatives to typical hardware-based production studios, and thanks to advances in microprocessor technology, it is now possible to create high quality music using little more than a single laptop computer. Such advances have democratized music creation, leading to a massive increase in the amount of home-produced electronic music available to the general public via the internet. Software based instruments and effect units (so called \"plugins\") can be incorporated in a computer-based studio using the VST platform. Some of these instruments are more or less exact replicas of existing hardware (such as the Roland D-50, ARP Odyssey, Yamaha DX7 or Korg M1). In many cases, these software-based instruments are sonically indistinguishable from their physical counterpart.\nCircuit bending.\nCircuit bending is the modification of battery powered toys and synthesizers to create new unintended sound effects. It was pioneered by Reed Ghazala in the 1960s and Reed coined the name \"circuit bending\" in 1992.\nModular synth revival.\nFollowing the circuit bending culture, musicians also began to build their own modular synthesizers, causing a renewed interest for the early 1960s designs. Eurorack became a popular system."}
{"id": "9513", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=9513", "title": "Electronic art music", "text": ""}
{"id": "9514", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=9514", "title": "Edvard Grieg", "text": "Edvard Hagerup Grieg ( , ; 15 June 18434 September 1907) was a Norwegian composer and pianist. He is widely considered one of the main Romantic era composers, and his music is part of the standard classical repertoire worldwide. His use and development of Norwegian folk music in his own compositions brought the music of Norway to international consciousness, as well as helping to develop a national identity, much as Jean Sibelius did in Finland and Bed\u0159ich Smetana did in Bohemia.\nGrieg is the most celebrated person from the city of Bergen, with numerous statues depicting his image, and many cultural entities named after him: the city's largest concert building (Grieg Hall), its most advanced music school (Grieg Academy) and its professional choir (Edvard Grieg Kor). The Edvard Grieg Museum at Grieg's former home Troldhaugen is dedicated to his legacy.\nBackground.\nEdvard Hagerup Grieg was born in Bergen, Norway (then part of Sweden\u2013Norway). His parents were Alexander Grieg (1806\u20131875), a merchant and the British Vice-Consul in Bergen; and Gesine Judithe Hagerup (1814\u20131875), a music teacher and daughter of solicitor and politician Edvard Hagerup. The family name, originally spelled Greig, is associated with the Scottish Clann Ghriogair (Clan Gregor). After the Battle of Culloden in Scotland in 1746, Grieg's great-grandfather, Alexander Greig, travelled widely, settling in Norway about 1770, and establishing business interests in Bergen. Grieg's first cousin, twice removed, was Canadian pianist Glenn Gould, whose mother was a Grieg.\nEdvard Grieg was raised in a musical family. His mother was his first piano teacher and taught him to play at the age of six. Grieg studied in several schools, including Tanks Upper Secondary School.\nDuring the summer of 1858, Grieg met the eminent Norwegian violinist Ole Bull, who was a family friend; Bull's brother was married to Grieg's aunt. Bull recognized the 15-year-old boy's talent and persuaded his parents to send him to the Leipzig Conservatory, the piano department of which was directed by Ignaz Moscheles.\nGrieg enrolled in the conservatory, concentrating on piano, and enjoyed the many concerts and recitals given in Leipzig. He disliked the discipline of the conservatory course of study. An exception was the organ, which was mandatory for piano students. About his study in the conservatory, he wrote to his biographer, Aimar Gr\u00f8nvold, in 1881: \"I must admit, unlike Svendsen, that I left Leipzig Conservatory just as stupid as I entered it. Naturally, I did learn something there, but my individuality was still a closed book to me.\"\nDuring the spring of 1860, he survived two life-threatening lung diseases, pleurisy and tuberculosis. Throughout his life, Grieg's health was impaired by a destroyed left lung and considerable deformity of his thoracic spine. He suffered from numerous respiratory infections, and ultimately developed combined lung and heart failure. Grieg was admitted many times to spas and sanatoria both in Norway and abroad. Several of his doctors became his friends.\nCareer.\nDuring 1861, Grieg made his debut as a concert pianist in Karlshamn, Sweden. In 1862, he finished his studies in Leipzig and had his first concert in his home town, where his programme included Beethoven's \"Path\u00e9tique\" sonata.\nIn 1863, Grieg went to Copenhagen, Denmark, and stayed there for three years. He met the Danish composers J. P. E. Hartmann and Niels Gade. He also met his fellow Norwegian composer Rikard Nordraak (composer of the Norwegian national anthem), who became a good friend and source of inspiration. Nordraak died in 1866, and Grieg composed a funeral march in his honor.\nOn 11 June 1867, Grieg married his first cousin, Nina Hagerup (1845\u20131935), a lyric soprano. The next year, their only child, Alexandra, was born. Alexandra died in 1869 from meningitis. During the summer of 1868, Grieg wrote his Piano Concerto in A minor while on holiday in Denmark. Edmund Neupert gave the concerto its premiere performance on 3 April 1869 in the Casino Theatre in Copenhagen. Grieg himself was unable to be there due to conducting commitments in Christiania (now Oslo).\nDuring 1868, Franz Liszt, who had not yet met Grieg, wrote a testimonial for him to the Norwegian Ministry of Education, which resulted in Grieg's obtaining a travel grant. The two men met in Rome in 1870. During Grieg's first visit, they examined Grieg's Violin Sonata No. 1, which pleased Liszt greatly. On his second visit in April, Grieg brought with him the manuscript of his Piano Concerto, which Liszt proceeded to sightread (including the orchestral arrangement). Liszt's rendition greatly impressed his audience, although Grieg said gently to him that he played the first movement too quickly. Liszt also gave Grieg some advice on orchestration (for example, to give the melody of the second theme in the first movement to a solo trumpet, which Grieg himself chose not to accept).\nDuring 1874\u201376, Grieg composed incidental music for the premiere of Henrik Ibsen's play \"Peer Gynt\", at the request of the author.\nGrieg had close ties with the Bergen Philharmonic Orchestra (Harmonien), and later became Music Director of the orchestra from 1880 to 1882. In 1888, Grieg met Tchaikovsky in Leipzig. Grieg was impressed by Tchaikovsky. Tchaikovsky thought very highly of Grieg's music, praising its beauty, originality and warmth.\nOn 6 December 1897, Grieg and his wife performed some of his music at a private concert at Windsor Castle for Queen Victoria and her court.\nGrieg was awarded two honorary doctorates, first by the University of Cambridge in 1894 and the next from the University of Oxford in 1906.\nLater years.\nThe Norwegian government provided Grieg with a pension as he reached retirement age. During the spring of 1903, Grieg made nine 78-rpm gramophone recordings of his piano music in Paris. All of these discs have been reissued on both LPs and CDs, despite limited fidelity. Grieg recorded player piano music rolls for the Hupfeld Phonola piano-player system and Welte-Mignon reproducing system, all of which survive and can be heard today. He also worked with the Aeolian Company for its 'Autograph Metrostyle' piano roll series wherein he indicated the tempo mapping for many of his pieces.\nIn 1899, Grieg cancelled his concerts in France in protest of the Dreyfus Affair, an anti-semitic scandal that was then roiling French politics. Regarding this scandal, Grieg had written that he hoped that the French might, \"Soon return to the spirit of 1789, when the French republic declared that it would defend basic human rights.\" As a result of his statements concerning the affair, he became the target of much French hate mail of that day.\nDuring 1906, he met the composer and pianist Percy Grainger in London. Grainger was a great admirer of Grieg's music and a strong empathy was quickly established. In a 1907 interview, Grieg stated: \"I have written Norwegian Peasant Dances that no one in my country can play, and here comes this Australian who plays them as they ought to be played! He is a genius that we Scandinavians cannot do other than love.\"\nEdvard Grieg died at the Municipal Hospital in Bergen, Norway, on 4 September 1907 at age 64 from heart failure. He had suffered a long period of illness. His last words were \"Well, if it must be so.\"\nThe funeral drew between 30,000 and 40,000 people to the streets of his home town to honor him. Obeying his wish, his own \"Funeral March in Memory of Rikard Nordraak\" was played with orchestration by his friend Johan Halvorsen, who had married Grieg's niece. In addition, the \"Funeral March\" movement from Chopin's Piano Sonata No. 2 was played. Grieg was cremated, and his ashes were entombed in a mountain crypt near his house, Troldhaugen. After the death of his wife, her ashes were placed alongside his.\nEdvard Grieg and his wife were Unitarians and Nina attended the Unitarian church in Copenhagen after his death.\nA century after his death, Grieg's legacy extends beyond the field of music. There is a large statue of Grieg in Seattle, while one of the largest hotels in Bergen (his hometown) is named Quality Hotel Edvard Grieg (with over 370 rooms), and a large crater on the planet Mercury is named after Grieg.\nMusic.\nSome of Grieg's early works include a symphony (which he later suppressed) and a piano sonata. He wrote three violin sonatas and a cello sonata.\nGrieg composed the incidental music for Henrik Ibsen's play \"Peer Gynt\", which includes the excerpts \"In the Hall of the Mountain King\" and \"Morning Mood\". In an 1874 letter to his friend Frants Beyer, Grieg expressed his unhappiness with \"Dance of the Mountain King's Daughter\", one of the movements in the \"Peer Gynt\" incidental music, writing \"I have also written something for the scene in the hall of the mountain King \u2013 something that I literally can't bear listening to because it absolutely reeks of cow-pies, exaggerated Norwegian nationalism, and trollish self-satisfaction! But I have a hunch that the irony will be discernible.\"\nGrieg's \"Holberg Suite\" was originally written for the piano, and later arranged by the composer for string orchestra. Grieg wrote songs in which he set lyrics by poets Heinrich Heine, Johann Wolfgang von Goethe, Henrik Ibsen, Hans Christian Andersen, Rudyard Kipling and others. Russian composer Nikolai Myaskovsky used a theme by Grieg for the variations with which he closed his Third String Quartet. Norwegian pianist Eva Knardahl recorded the composer's complete piano music on 13 LPs for BIS Records from 1977 to 1980. The recordings were reissued during 2006 on 12 compact discs, also on BIS Records. Grieg himself recorded many of these piano works before his death in 1907.\nReferences.\nNotes\nBibliography"}
{"id": "9515", "revid": "32589484", "url": "https://en.wikipedia.org/wiki?curid=9515", "title": "Emancipation Proclamation", "text": "The Emancipation Proclamation, or Proclamation 95, was a presidential proclamation and executive order issued by United States President Abraham Lincoln on September 22, 1862, during the Civil War. The Proclamation read: \nOn January 1, 1863, the Proclamation changed the legal status under federal law of more than 3.5\u00a0million enslaved African Americans in the secessionist Confederate states from enslaved to free. As soon as a slave escaped the control of the Confederate government, either by running away across Union lines or through the advance of federal troops, the person was permanently free. Ultimately, the Union victory brought the proclamation into effect in all of the former Confederacy. \nThe proclamation was directed to all of the areas in rebellion and all segments of the executive branch (including the Army and Navy) of the United States. It proclaimed the freedom of enslaved people in the ten states in rebellion. Even though it excluded areas not in rebellion, it still applied to more than 3.5\u00a0million of the 4\u00a0million enslaved people in the country. Around 25,000 to 75,000 were immediately emancipated in those regions of the Confederacy where the US Army was already in place. It could not be enforced in the areas still in rebellion, but as the Union army took control of Confederate regions, the Proclamation provided the legal framework for the liberation of more than three and a half million enslaved people in those regions. Prior to the Proclamation, in accordance with the Fugitive Slave Act of 1850, escaped enslaved persons were either returned to their masters or held in camps as contraband for later return. The Emancipation Proclamation outraged white Southerners and their sympathizers, who saw it as the beginning of a race war. It energized abolitionists, and undermined those Europeans that wanted to intervene to help the Confederacy. The Proclamation lifted the spirits of African Americans both free and enslaved; it led many to escape from their masters and get to Union lines to obtain their freedom, and to join the Union Army. The Emancipation Proclamation became a historic document because it \"would redefine the Civil War, turning it from a struggle to preserve the Union to one focused on ending slavery, and set a decisive course for how the nation would be reshaped after that historic conflict.\"\nThe Emancipation Proclamation was never challenged in court. To ensure the abolition of slavery in all of the U.S., Lincoln also insisted that Reconstruction plans for Southern states require abolition in new state laws (which occurred during the war in Tennessee, Arkansas, and Louisiana); Lincoln encouraged border states to adopt abolition (which occurred during the war in Maryland, Missouri, and West Virginia) and pushed for passage of the Thirteenth Amendment. Congress passed the 13th Amendment by the necessary two-thirds vote on January 31, 1865, and it was ratified by the states on December 6, 1865. The amendment made chattel slavery and indentured servitude illegal.\nAuthority.\nThe United States Constitution of 1787 did not use the word \"slavery\" but included several provisions about unfree persons. The Three-Fifths Compromise (in Article I, Section 2) allocated Congressional representation based \"on the whole Number of free Persons\" and \"three-fifths of all other Persons\". Under the Fugitive Slave Clause (Article IV, Section 2), \"no person held to service or labour in one state\" would be freed by escaping to another. allowed Congress to pass legislation to outlaw the \"Importation of Persons\", but not until 1808. However, for purposes of the Fifth Amendment\u2014which states that, \"No person shall... be deprived of life, liberty, or property, without due process of law\"\u2014slaves were understood as property. Although abolitionists used the Fifth Amendment to argue against slavery, it became part of the legal basis for treating slaves as property with \"Dred Scott v. Sandford\" (1857). Socially, slavery was also supported in law and in practice by a pervasive culture of white supremacy. Nonetheless, between 1777 and 1804, every Northern state provided for the immediate or gradual abolition of slavery. No Southern state did so, and the slave population of the South continued to grow, peaking at almost four million people at the beginning of the American Civil War, when most slave states sought to break away from the United States.\nLincoln understood that the Federal government's power to end slavery in peacetime was limited by the Constitution which before 1865, committed the issue to individual states. Against the background of the American Civil War, however, Lincoln issued the Proclamation under his authority as \"Commander-in-Chief of the Army and Navy\" under Article II, section 2 of the United States Constitution. As such, he claimed to have the martial power to free persons held as slaves in those states that were in rebellion \"as a fit and necessary war measure for suppressing said rebellion\". He did not have Commander-in-Chief authority over the four slave-holding states that were not in rebellion: Missouri, Kentucky, Maryland and Delaware, and so those states were not named in the Proclamation. The fifth border jurisdiction, West Virginia, where slavery remained legal but was in the process of being abolished, was, in January 1863, still part of the legally recognized, \"reorganized\" state of Virginia, based in Alexandria, which was in the Union (as opposed to the Confederate state of Virginia, based in Richmond).\nCoverage.\nThe Proclamation applied in the ten states that were still in rebellion in 1863, and thus did not cover the nearly 500,000 slaves in the slave-holding border states (Missouri, Kentucky, Maryland or Delaware) which were Union states. Those slaves were freed by later separate state and federal actions.\nThe state of Tennessee had already mostly returned to Union control, under a recognized Union government, so it was not named and was exempted. Virginia was named, but exemptions were specified for the 48 counties then in the process of forming the new state of West Virginia, and seven additional counties and two cities in the Union-controlled Tidewater region of Virginia. Also specifically exempted were New Orleans and 13 named parishes of Louisiana, which were mostly under federal control at the time of the Proclamation. These exemptions left unemancipated an additional 300,000 slaves.\nThe Emancipation Proclamation has been ridiculed, notably in an influential passage by Richard Hofstadter for \"freeing\" only the slaves over which the Union had no power. These slaves were freed due to Lincoln's \"war powers\". This act cleared up the issue of contraband slaves. It automatically clarified the status of over 100,000 now-former slaves. Some 20,000 to 50,000 slaves were freed the day it went into effect in parts of nine of the ten states to which it applied (Texas being the exception). In every Confederate state (except Tennessee and Texas), the Proclamation went into immediate effect in Union-occupied areas and at least 20,000 slaves were freed at once on January 1, 1863.\nThe Proclamation provided the legal framework for the emancipation of nearly all four million slaves as the Union armies advanced, and committed the Union to end slavery, which was a controversial decision even in the North. Hearing of the Proclamation, more slaves quickly escaped to Union lines as the Army units moved South. As the Union armies advanced through the Confederacy, thousands of slaves were freed each day until nearly all (approximately 3.9\u00a0million, according to the 1860 Census) were freed by July 1865.\nWhile the Proclamation had freed most slaves as a war measure, it had not made slavery illegal. Of the states that were exempted from the Proclamation, Maryland, Missouri, Tennessee, and West Virginia prohibited slavery before the war ended. In 1863, President Lincoln proposed a moderate plan for the Reconstruction of the captured Confederate State of Louisiana. Only 10% of the state's electorate had to take the loyalty oath. The state was also required to accept the Proclamation and abolish slavery in its new constitution. Identical Reconstruction plans would be adopted in Arkansas and Tennessee. By December 1864, the Lincoln plan abolishing slavery had been enacted in Louisiana, as well as in Arkansas and Tennessee. In Kentucky, Union Army commanders relied on the proclamations offer of freedom to slaves who enrolled in the Army and provided freedom for an enrollee's entire family; for this and other reasons the number of slaves in the state fell by over 70% during the war. However, in Delaware and Kentucky, slavery continued to be legal until December 18, 1865, when the Thirteenth Amendment went into effect.\nBackground.\nMilitary action prior to emancipation.\nThe Fugitive Slave Act of 1850 required individuals to return runaway slaves to their owners. During the war, Union generals such as Benjamin Butler declared that slaves in occupied areas were contraband of war and accordingly refused to return them. This decision was controversial because it implied recognition of the Confederacy as a separate, independent sovereign state under international law, a notion that Lincoln steadfastly denied. As a result, he did not promote the contraband designation. In addition, as contraband, these people were legally designated as \"property\" when they crossed Union lines and their ultimate status was uncertain.\nGovernmental action toward emancipation.\nIn December 1861, Lincoln sent his first annual message to Congress (the State of the Union Address, but then typically given in writing and not referred to as such). In it he praised the free labor system, as respecting human rights over property rights; he endorsed legislation to address the status of contraband slaves and slaves in loyal states, possibly through buying their freedom with federal taxes, and also the funding of strictly voluntary colonization efforts. In January 1862, Thaddeus Stevens, the Republican leader in the House, called for total war against the rebellion to include emancipation of slaves, arguing that emancipation, by forcing the loss of enslaved labor, would ruin the rebel economy. On March 13, 1862, Congress approved a \"Law Enacting an Additional Article of War\", which stated that from that point onward it was forbidden for Union Army officers to return fugitive slaves to their owners. Pursuant to a law signed by Lincoln, slavery was abolished in the District of Columbia on April 16, 1862, and owners were compensated.\nOn June 19, 1862, Congress prohibited slavery in all current and future United States territories (though not in the states), and President Lincoln quickly signed the legislation. By this act, they repudiated the 1857 opinion of the Supreme Court of the United States in the \"Dred Scott Case\" that Congress was powerless to regulate slavery in U.S. territories. This joint action by Congress and President Lincoln also rejected the notion of popular sovereignty that had been advanced by Stephen A. Douglas as a solution to the slavery controversy, while completing the effort first legislatively proposed by Thomas Jefferson in 1784 to confine slavery within the borders of existing states.\nIn July, Congress passed and Lincoln signed the Confiscation Act of 1862, containing provisions for court proceedings to liberate slaves held by convicted \"rebels\", or of slaves of rebels that had escaped to Union lines. The Act applied in cases of criminal convictions, to those who were slaves of \"disloyal\" masters, and to slaves in rebel territory that was captured by the Union forces. Unlike the first Confiscation Act, the second one explicitly said that all slaves covered under the law would be permanently freed, stating \"all slaves of persons who shall hereafter be engaged in rebellion against the government of the United States, or who shall in any way give aid or comfort thereto, escaping from such persons and taking refuge within the lines of the army; and all slaves captured from such persons or deserted by them and coming under the control of the government of the United States; and all slaves of such person found on [or] being within any place occupied by rebel forces and afterwards occupied by the forces of the United States, shall be deemed captives of war, and shall be forever free of their servitude, and not again held as slaves.\" However, Lincoln's position continued to be that Congress lacked the power to free all slaves within the borders of rebel held states, but Lincoln as commander in chief could do so if he deemed it a proper military measure, and that Lincoln had already drafted plans to do.\nPublic opinion of emancipation.\nAbolitionists had long been urging Lincoln to free all slaves. In the summer of 1862, Republican editor Horace Greeley of the highly influential New York Tribune wrote a famous editorial entitled \"The Prayer of Twenty Millions\" demanding a more aggressive attack on the Confederacy and faster emancipation of the slaves: \"On the face of this wide earth, Mr. President, there is not one ... intelligent champion of the Union cause who does not feel ... that the rebellion, if crushed tomorrow, would be renewed if slavery were left in full vigor and that every hour of deference to slavery is an hour of added and deepened peril to the Union.\" Lincoln responded in his from August 22, 1862, in terms of the limits imposed by his duty as president to save the Union:\nLincoln scholar Harold Holzer wrote in this context about Lincoln's letter: \"Unknown to Greeley, Lincoln composed this after he had already drafted a preliminary Emancipation Proclamation, which he had determined to issue after the next Union military victory. Therefore, this letter, was in truth, an attempt to position the impending announcement in terms of saving the Union, not freeing slaves as a humanitarian gesture. It was one of Lincoln's most skillful public relations efforts, even if it has cast longstanding doubt on his sincerity as a liberator.\" Historian Richard Striner argues that \"for years\" Lincoln's letter has been misread as \"Lincoln only wanted to save the Union.\" However, within the context of Lincoln's entire career and pronouncements on slavery this interpretation is wrong, according to Striner. Rather, Lincoln was softening the strong Northern white supremacist opposition to his imminent emancipation by tying it to the cause of the Union. This opposition would fight for the Union but not to end slavery, so Lincoln gave them the means and motivation to do both, at the same time. In his 2014 book, \"Lincoln's Gamble\", journalist and historian Todd Brewster asserted that Lincoln's desire to reassert the saving of the Union as his sole war goal was, in fact, crucial to his claim of legal authority for emancipation. Since slavery was protected by the Constitution, the only way that he could free the slaves was as a tactic of war\u2014not as the mission itself. But that carried the risk that when the war ended, so would the justification for freeing the slaves. Late in 1862, Lincoln asked his Attorney General, Edward Bates, for an opinion as to whether slaves freed through a war-related proclamation of emancipation could be re-enslaved once the war was over. Bates had to work through the language of the Dred Scott decision to arrive at an answer, but he finally concluded that they could indeed remain free. Still, a complete end to slavery would require a constitutional amendment.\nConflicting advice, to free all slaves, or not free them at all, was presented to Lincoln in public and private. Thomas Nast, a cartoon artist during the Civil War and the late 1800s considered \"Father of the American Cartoon\", composed many works including a two-sided spread that showed the transition from slavery into civilization after President Lincoln signed the Proclamation. Nast believed in equal opportunity and equality for all people, including enslaved Africans or free blacks. A mass rally in Chicago on September 7, 1862, demanded an immediate and universal emancipation of slaves. A delegation headed by William W. Patton met the president at the White House on September 13. Lincoln had declared in peacetime that he had no constitutional authority to free the slaves. Even used as a war power, emancipation was a risky political act. Public opinion as a whole was against it. There would be strong opposition among Copperhead Democrats and an uncertain reaction from loyal border states. Delaware and Maryland already had a high percentage of free blacks: 91.2% and 49.7%, respectively, in 1860.\nDrafting and issuance of the proclamation.\nLincoln first discussed the proclamation with his cabinet in July 1862. He drafted his \"preliminary proclamation\" and read it to Secretary of State William Seward, and Secretary of Navy Gideon Welles, on July 13. Seward and Welles were at first speechless, then Seward referred to possible anarchy throughout the South and resulting foreign intervention; Welles apparently said nothing. On July 22, Lincoln presented it to his entire cabinet as something he had determined to do and he asked their opinion on wording. Although Secretary of War Edwin Stanton supported it, Seward advised Lincoln to issue the proclamation after a major Union victory, or else it would appear as if the Union was giving \"its last shriek of retreat\".\nIn September 1862, the Battle of Antietam gave Lincoln the victory he needed to issue the Emancipation. In the battle, though the Union suffered heavier losses than the Confederates and General McClellan allowed the escape of Robert E. Lee's retreating troops, Union forces turned back a Confederate invasion of Maryland, eliminating more than a quarter of Lee's army in the process. On September 22, 1862, five days after Antietam occurred, and while living at the Soldier's Home, Lincoln called his cabinet into session and issued the Preliminary Emancipation Proclamation. According to Civil War historian James M. McPherson, Lincoln told Cabinet members that he had made a covenant with God, that if the Union drove the Confederacy out of Maryland, he would issue the Emancipation Proclamation. Lincoln had first shown an early draft of the proclamation to Vice President Hannibal Hamlin, an ardent abolitionist, who was more often kept in the dark on presidential decisions. The final proclamation was issued on January 1, 1863. Although implicitly granted authority by Congress, Lincoln used his powers as Commander-in-Chief of the Army and Navy, \"as a necessary war measure\" as the basis of the proclamation, rather than the equivalent of a statute enacted by Congress or a constitutional amendment. Some days after issuing the final Proclamation, Lincoln wrote to Major General John McClernand: \"After the commencement of hostilities I struggled nearly a year and a half to get along without touching the \"institution\"; and when finally I conditionally determined to touch it, I gave a hundred days fair notice of my purpose, to all the States and people, within which time they could have turned it wholly aside, by simply again becoming good citizens of the United States. They chose to disregard it, and I made the peremptory proclamation on what appeared to me to be a military necessity. And being made, it must stand.\"\nInitially, the Emancipation Proclamation effectively freed only a small percentage of the slaves, those who were behind Union lines in areas not exempted. Most slaves were still behind Confederate lines or in exempted Union-occupied areas. Secretary of State William H. Seward commented, \"We show our sympathy with slavery by emancipating slaves where we cannot reach them and holding them in bondage where we can set them free.\" Had any slave state ended its secession attempt before January 1, 1863, it could have kept slavery, at least temporarily. The Proclamation only gave the Lincoln Administration the legal basis to free the slaves in the areas of the South that were still in rebellion on January 1, 1863. It effectively destroyed slavery as the Union armies advanced south and conquered the entire Confederacy.\nThe Emancipation Proclamation also allowed for the enrollment of freed slaves into the United States military. During the war nearly 200,000 blacks, most of them ex-slaves, joined the Union Army. Their contributions gave the North additional manpower that was significant in winning the war. The Confederacy did not allow slaves in their army as soldiers until the last month before its defeat.\nThough the counties of Virginia that were soon to form West Virginia were specifically exempted from the Proclamation (Jefferson County being the only exception), a condition of the state's admittance to the Union was that its constitution provide for the gradual abolition of slavery (an immediate emancipation of all slaves was also adopted there in early 1865). Slaves in the border states of Maryland and Missouri were also emancipated by separate state action before the Civil War ended. In Maryland, a new state constitution abolishing slavery in the state went into effect on November 1, 1864. The Union-occupied counties of eastern Virginia and parishes of Louisiana, which had been exempted from the Proclamation, both adopted state constitutions that abolished slavery in April 1864. In early 1865, Tennessee adopted an amendment to its constitution prohibiting slavery.\nImplementation.\nThe Proclamation was issued in two parts. The first part, issued on September 22, 1862, was a preliminary announcement outlining the intent of the second part, which officially went into effect 100 days later on January 1, 1863, during the second year of the Civil War. It was Abraham Lincoln's declaration that all slaves would be permanently freed in all areas of the Confederacy that had not already returned to federal control by January 1863. The ten affected states were individually named in the second part (South Carolina, Mississippi, Florida, Alabama, Georgia, Louisiana, Texas, Virginia, Arkansas, North Carolina). Not included were the Union slave states of Maryland, Delaware, Missouri and Kentucky. Also not named was the state of Tennessee, in which a Union-controlled military government had already been set up, based in the capital, Nashville. Specific exemptions were stated for areas also under Union control on January 1, 1863, namely 48 counties that would soon become West Virginia, seven other named counties of Virginia including Berkeley and Hampshire counties, which were soon added to West Virginia, New Orleans and 13 named parishes nearby.\nUnion-occupied areas of the Confederate states where the proclamation was put into immediate effect by local commanders included Winchester, Virginia, Corinth, Mississippi, the Sea Islands along the coasts of the Carolinas and Georgia, Key West, Florida, and Port Royal, South Carolina.\nImmediate impact.\nIt has been inaccurately claimed that the Emancipation Proclamation did not free a single slave; historian Lerone Bennett Jr. alleged that the proclamation was a hoax deliberately designed not to free any slaves. However, as a result of the Proclamation, many slaves were freed during the course of the war, beginning with the day it took effect; eyewitness accounts at places such as Hilton Head Island, South Carolina, and Port Royal, South Carolina record celebrations on January 1 as thousands of blacks were informed of their new legal status of freedom. Estimates of how many thousands of slaves were freed immediately by the Emancipation Proclamation are varied. One contemporary estimate put the 'contraband' population of Union-occupied North Carolina at 10,000, and the Sea Islands of South Carolina also had a substantial population. Those 20,000 slaves were freed immediately by the Emancipation Proclamation.\" This Union-occupied zone where freedom began at once included parts of eastern North Carolina, the Mississippi Valley, northern Alabama, the Shenandoah Valley of Virginia, a large part of Arkansas, and the Sea Islands of Georgia and South Carolina. Although some counties of Union-occupied Virginia were exempted from the Proclamation, the lower Shenandoah Valley, and the area around Alexandria were covered. Emancipation was immediately enforced as Union soldiers advanced into the Confederacy. Slaves fled their masters and were often assisted by Union soldiers.\nBooker T. Washington, as a boy of 9 in Virginia, remembered the day in early 1865:\nRunaway slaves who had escaped to Union lines had previously been held by the Union Army as \"contraband of war\" under the Confiscation Acts; when the proclamation took effect, they were told at midnight that they were free to leave. The Sea Islands off the coast of Georgia had been occupied by the Union Navy earlier in the war. The whites had fled to the mainland while the blacks stayed. An early program of Reconstruction was set up for the former slaves, including schools and training. Naval officers read the proclamation and told them they were free.\nSlaves had been part of the \"engine of war\" for the Confederacy. They produced and prepared food; sewed uniforms; repaired railways; worked on farms and in factories, shipping yards, and mines; built fortifications; and served as hospital workers and common laborers. News of the Proclamation spread rapidly by word of mouth, arousing hopes of freedom, creating general confusion, and encouraging thousands to escape to Union lines. George Washington Albright, a teenage slave in Mississippi, recalled that like many of his fellow slaves, his father escaped to join Union forces. According to Albright, plantation owners tried to keep the Proclamation from slaves but news of it came through the \"grapevine\". The young slave became a \"runner\" for an informal group they called the \"4Ls\" (\"Lincoln's Legal Loyal League\") bringing news of the proclamation to secret slave meetings at plantations throughout the region.\nRobert E. Lee saw the Emancipation Proclamation as a way for the Union to bolster the number of soldiers it could place on the field, making it imperative for the Confederacy to increase their own numbers. Writing on the matter after the sack of Fredericksburg, Lee wrote \"In view of the vast increase of the forces of the enemy, of the savage and brutal policy he has proclaimed, which leaves us no alternative but success or degradation worse than death, if we would save the honor of our families from pollution, our social system from destruction, let every effort be made, every means be employed, to fill and maintain the ranks of our armies, until God, in his mercy, shall bless us with the establishment of our independence.\"\nPolitical impact.\nThe Proclamation was immediately denounced by Copperhead Democrats who opposed the war and advocated restoring the union by allowing slavery. Horatio Seymour, while running for the governorship of New York, cast the Emancipation Proclamation as a call for slaves to commit extreme acts of violence on all white southerners, saying it was \"a proposal for the butchery of women and children, for scenes of lust and rapine, and of arson and murder, which would invoke the interference of civilized Europe\". The Copperheads also saw the Proclamation as an unconstitutional abuse of presidential power. Editor Henry A. Reeves wrote in Greenport's \"Republican Watchman\" that \"In the name of freedom of Negroes, [the proclamation] imperils the liberty of white men; to test a utopian theory of equality of races which Nature, History and Experience alike condemn as monstrous, it overturns the Constitution and Civil Laws and sets up Military Usurpation in their Stead.\"\nRacism remained pervasive on both sides of the conflict and many in the North supported the war only as an effort to force the South to stay in the Union. The promises of many Republican politicians that the war was to restore the Union and not about black rights or ending slavery, were now declared lies by their opponents citing the Proclamation. Copperhead David Allen spoke to a rally in Columbiana, Ohio, stating, \"I have told you that this war is carried on for the Negro. There is the proclamation of the President of the United States. Now fellow Democrats I ask you if you are going to be forced into a war against your Brithren of the Southern States for the Negro. I answer No!\" The Copperheads saw the Proclamation as irrefutable proof of their position and the beginning of a political rise for their members; in Connecticut, H. B. Whiting wrote that the truth was now plain even to \"those stupid thick-headed persons who persisted in thinking that the President was a conservative man and that the war was for the restoration of the Union under the Constitution\".\nWar Democrats who rejected the Copperhead position within their party, found themselves in a quandary. While throughout the war they had continued to espouse the racist positions of their party and their disdain of the concerns of slaves, they did see the Proclamation as a viable military tool against the South, and worried that opposing it might demoralize troops in the Union army. The question would continue to trouble them and eventually lead to a split within their party as the war progressed.\nLincoln further alienated many in the Union two days after issuing the preliminary copy of the Emancipation Proclamation by suspending habeas corpus. His opponents linked these two actions in their claims that he was becoming a despot. In light of this and a lack of military success for the Union armies, many War Democrat voters who had previously supported Lincoln turned against him and joined the Copperheads in the off-year elections held in October and November.\nIn the 1862 elections, the Democrats gained 28 seats in the House as well as the governorship of New York. Lincoln's friend Orville Hickman Browning told the president that the Proclamation and the suspension of habeas corpus had been \"disastrous\" for his party by handing the Democrats so many weapons. Lincoln made no response. Copperhead William Javis of Connecticut pronounced the election the \"beginning of the end of the utter downfall of Abolitionism in the United States\".\nHistorians James M. McPherson and Allan Nevins state that though the results looked very troubling, they could be seen favorably by Lincoln; his opponents did well only in their historic strongholds and \"at the national level their gains in the House were the smallest of any minority party's in an off-year election in nearly a generation. Michigan, California, and Iowa all went Republican... Moreover, the Republicans picked up five seats in the Senate.\" McPherson states \"If the election was in any sense a referendum on emancipation and on Lincoln's conduct of the war, a majority of Northern voters endorsed these policies.\"\nConfederate response.\nThe initial Confederate response was one of expected outrage. The Proclamation was seen as vindication for the rebellion, and proof that Lincoln would have abolished slavery even if the states had remained in the Union. In an August 1863 letter to President Lincoln, U.S. Army general Ulysses S. Grant observed that the Proclamation, combined with the usage of black soldiers by the U.S. Army, profoundly angered the Confederacy, saying that \"the emancipation of the Negro, is the heaviest blow yet given the Confederacy. The South rave a great deal about it and profess to be very angry.\" A few months after the Proclamation took effect, the Confederacy passed a law in May 1863 demanding \"full and ample retaliation\" against the U.S. for such measures. The Confederacy stated that the black U.S. soldiers captured while fighting against the Confederacy would be tried as slave insurrectionists in civil courts\u2014a capital offense with automatic sentence of death. Less than a year after the law's passage, the Confederates massacred black U.S. soldiers at Fort Pillow.\nConfederate General Robert E. Lee called the Proclamation a \"savage and brutal policy he has proclaimed, which leaves us no alternative but success or degradation worse than death\"\nHowever, some Confederates welcomed the Proclamation, as they believed it would strengthen pro-slavery sentiment in the Confederacy and, thus, lead to greater enlistment of white men into the Confederate army. According to one Confederate man from Kentucky, \"The Proclamation is worth three hundred thousand soldiers to our Government at least... It shows exactly what this war was brought about for and the intention of its damnable authors.\" Even some Union soldiers concurred with this view and expressed reservations about the Proclamation, not on principle, but rather because they were afraid it would increase the Confederacy's determination to fight on and maintain slavery. One Union soldier from New York stated worryingly after the Proclamation's passage, \"I know enough of the Southern spirit that I think they will fight for the institution of slavery even to extermination.\"\nAs a result of the Proclamation, the price of slaves in the Confederacy increased in the months after its issuance, with one Confederate from South Carolina opining in 1865 that \"now is the time for Uncle to buy some negro women and children.\"\nInternational impact.\nAs Lincoln had hoped, the proclamation turned foreign popular opinion in favor of the Union by gaining the support of anti-slavery countries and countries that had already abolished slavery (especially the developed countries in Europe such as the United Kingdom or France). This shift ended the Confederacy's hopes of gaining official recognition.\nSince the Emancipation Proclamation made the eradication of slavery an explicit Union war goal, it linked support for the South to support for slavery. Public opinion in Britain would not tolerate support for slavery. As Henry Adams noted, \"The Emancipation Proclamation has done more for us than all our former victories and all our diplomacy.\" In Italy, Giuseppe Garibaldi hailed Lincoln as \"the heir of the aspirations of John Brown\". On August 6, 1863, Garibaldi wrote to Lincoln: \"Posterity will call you the great emancipator, a more enviable title than any crown could be, and greater than any merely mundane treasure\".\nMayor Abel Haywood, a representative for workers from Manchester, England, wrote to Lincoln saying, \"We joyfully honor you for many decisive steps toward practically exemplifying your belief in the words of your great founders: 'All men are created free and equal.'\" The Emancipation Proclamation served to ease tensions with Europe over the North's conduct of the war, and combined with the recent failed Southern offensive at Antietam, to remove any practical chance for the Confederacy to receive foreign support in the war.\nGettysburg Address.\nLincoln's Gettysburg Address in November 1863 made indirect reference to the Proclamation and the ending of slavery as a war goal with the phrase \"new birth of freedom\". The Proclamation solidified Lincoln's support among the rapidly growing abolitionist element of the Republican Party and ensured that they would not block his re-nomination in 1864.\nProclamation of Amnesty and Reconstruction (1863).\nIn December 1863, Lincoln issued his \"Proclamation of Amnesty and Reconstruction\", which dealt with the ways the rebel states could reconcile with the Union. Key provisions required that the states accept the \"Emancipation Proclamation\" and thus the freedom of their slaves, and accept the Confiscation Acts, as well as the Act banning of slavery in United States territories.\nPostbellum.\nNear the end of the war, abolitionists were concerned that the Emancipation Proclamation would be construed solely as a war measure, Lincoln's original intent, and would no longer apply once fighting ended. They also were increasingly anxious to secure the freedom of all slaves, not just those freed by the Emancipation Proclamation. Thus pressed, Lincoln staked a large part of his 1864 presidential campaign on a constitutional amendment to abolish slavery uniformly throughout the United States. Lincoln's campaign was bolstered by separate votes in both Maryland and Missouri to abolish slavery in those states. Maryland's new constitution abolishing slavery took effect in November 1864. Slavery in Missouri was ended by executive proclamation of its governor, Thomas C. Fletcher, on January 11, 1865.\nWinning re-election, Lincoln pressed the lame duck 38th Congress to pass the proposed amendment immediately rather than wait for the incoming 39th Congress to convene. In January 1865, Congress sent to the state legislatures for ratification what became the Thirteenth Amendment, banning slavery in all U.S. states and territories. The amendment was ratified by the legislatures of enough states by December 6, 1865, and proclaimed 12 days later. There were approximately 40,000 slaves in Kentucky and 1,000 in Delaware who were liberated then.\nCritiques.\nAs the years went on and American life continued to be deeply unfair towards blacks, cynicism towards Lincoln and the Emancipation Proclamation increased. Perhaps the strongest attack was Lerone Bennett's \"\" (2000), which claimed that Lincoln was a white supremacist who issued the Emancipation Proclamation in lieu of the real racial reforms for which radical abolitionists pushed. In his \"Lincoln's Emancipation Proclamation\", Allen C. Guelzo noted the professional historians' lack of substantial respect for the document, since it has been the subject of few major scholarly studies. He argued that Lincoln was the US's \"last Enlightenment politician\" and as such was dedicated to removing slavery strictly within the bounds of law.\nOther historians have given more credit to Lincoln for what he accomplished within the tensions of his cabinet and a society at war, for his own growth in political and moral stature, and for the promise he held out to the slaves. More might have been accomplished if he had not been assassinated. As Eric Foner wrote:\nLincoln was not an abolitionist or Radical Republican, a point Bennett reiterates innumerable times. He did not favor immediate abolition before the war, and held racist views typical of his time. But he was also a man of deep convictions when it came to slavery, and during the Civil War displayed a remarkable capacity for moral and political growth.\nKal Ashraf wrote:\nPerhaps in rejecting the critical dualism\u2013Lincoln as individual emancipator pitted against collective self-emancipators\u2013there is an opportunity to recognise the greater persuasiveness of the combination. In a sense, yes: a racist, flawed Lincoln did something heroic, and not in lieu of collective participation, but next to, and enabled, by it. To venerate a singular \u2013Great Emancipator' may be as reductive as dismissing the significance of Lincoln's actions. Who he was as a man, no one of us can ever really know. So it is that the version of Lincoln we keep is also the version we make.\nLegacy in the civil rights era.\nDr. Martin Luther King Jr..\nDr. Martin Luther King Jr. made many references to the Emancipation Proclamation during the civil rights movement. These include a speech made at an observance of the hundredth anniversary of the issuing of the Proclamation made in New York City on September 12, 1962 where he placed it alongside the Declaration of Independence as an \"imperishable\" contribution to civilization, and \"All tyrants, past, present and future, are powerless to bury the truths in these declarations\". He lamented that despite a history where the United States \"proudly professed the basic principles inherent in both documents\", it \"sadly practiced the antithesis of these principles\". He concluded \"There is but one way to commemorate the Emancipation Proclamation. That is to make its declarations of freedom real; to reach back to the origins of our nation when our message of equality electrified an unfree world, and reaffirm democracy by deeds as bold and daring as the issuance of the Emancipation Proclamation.\"\nKing's most famous invocation of the Emancipation Proclamation was in a speech from the steps of the Lincoln Memorial at the 1963 March on Washington for Jobs and Freedom (often referred to as the \"I Have a Dream\" speech). King began the speech saying \"Five score years ago, a great American, in whose symbolic shadow we stand, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of captivity. But one hundred years later, we must face the tragic fact that the Negro is still not free. One hundred years later, the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination.\"\nThe \"Second Emancipation Proclamation\".\nIn the early 1960s, Dr. Martin Luther King Jr. and his associates developed a strategy to call on President John F. Kennedy to bypass a Southern segregationist opposition in the Congress by issuing an executive order to put an end to segregation. This envisioned document was referred to as the \"Second Emancipation Proclamation\".\nPresident John F. Kennedy.\nOn June 11, 1963, President Kennedy appeared on national television to address the issue of civil rights. Kennedy, who had been routinely criticized as timid by some of the leaders of the civil rights movement, told Americans that two black students had been peacefully enrolled in the University of Alabama with the aid of the National Guard despite the opposition of Governor George Wallace.\nJohn Kennedy called it a \"moral issue\". Invoking the centennial of the Emancipation Proclamation he said,\nIn the same speech, Kennedy announced he would introduce comprehensive civil rights legislation to the United States Congress which he did a week later (he continued to push for its passage until his assassination in November 1963). Historian Peniel E. Joseph holds Lyndon Johnson's ability to get that bill, the Civil Rights Act of 1964, passed on July 2, 1964 was aided by \"the moral forcefulness of the June 11 speech\" that turned \"the narrative of civil rights from a regional issue into a national story promoting racial equality and democratic renewal\".\nPresident Lyndon B. Johnson.\nDuring the civil rights movement of the 1960s, Lyndon B. Johnson invoked the Emancipation Proclamation holding it up as a promise yet to be fully implemented.\nAs vice president while speaking from Gettysburg on May 30, 1963 (Memorial Day), at the centennial of the Emancipation Proclamation, Johnson connected it directly with the ongoing civil rights struggles of the time saying \"One hundred years ago, the slave was freed. One hundred years later, the Negro remains in bondage to the color of his skin... In this hour, it is not our respective races which are at stake\u2014it is our nation. Let those who care for their country come forward, North and South, white and Negro, to lead the way through this moment of challenge and decision... Until justice is blind to color, until education is unaware of race, until opportunity is unconcerned with color of men's skins, emancipation will be a proclamation but not a fact. To the extent that the proclamation of emancipation is not fulfilled in fact, to that extent we shall have fallen short of assuring freedom to the free.\"\nAs president, Johnson again invoked the proclamation in a speech presenting the Voting Rights Act at a joint session of Congress on Monday, March 15, 1965. This was one week after violence had been inflicted on peaceful civil rights marchers during the Selma to Montgomery marches. Johnson said \"...\u00a0it's not just Negroes, but really it's all of us, who must overcome the crippling legacy of bigotry and injustice. And we shall overcome. As a man whose roots go deeply into Southern soil, I know how agonizing racial feelings are. I know how difficult it is to reshape the attitudes and the structure of our society. But a century has passed\u2014more than 100 years\u2014since the Negro was freed. And he is not fully free tonight. It was more than 100 years ago that Abraham Lincoln\u2014a great President of another party\u2014signed the Emancipation Proclamation. But emancipation is a proclamation and not a fact. A century has passed\u2014more than 100 years\u2014since equality was promised, and yet the Negro is not equal. A century has passed since the day of promise, and the promise is unkept. The time of justice has now come, and I tell you that I believe sincerely that no force can hold it back. It is right in the eyes of man and God that it should come, and when it does, I think that day will brighten the lives of every American.\"\nIn popular culture.\nIn episode 86 of \"The Andy Griffith Show\", Andy asks Barney to explain the Emancipation Proclamation to Opie who is struggling with history at school. Barney brags about his history expertise, yet it is apparent he cannot answer Andy's question. He finally becomes frustrated and explains it is a proclamation for certain people who wanted emancipation.\nThe Emancipation Proclamation is celebrated around the world including on stamps of nations such as the Republic of Togo. The United States commemorative was issued on August 16, 1963, the opening day of the Century of Negro Progress Exposition in Chicago, Illinois. Designed by Georg Olden, an initial printing of 120\u00a0million stamps was authorized."}
