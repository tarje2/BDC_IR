{"id": "6787", "revid": "105732", "url": "https://en.wikipedia.org/wiki?curid=6787", "title": "Chiapas", "text": "Chiapas (), officially the Free and Sovereign State of Chiapas (), is one of the states that make up the 32 federal entities of Mexico. It comprises 124 municipalities and its capital city is Tuxtla Guti\u00e9rrez. Other important population centers in Chiapas include Ocosingo, Tapachula, San Crist\u00f3bal de las Casas, Comit\u00e1n and Arriaga. It is the southernmost state in Mexico, and it borders the states of Oaxaca to the west, Veracruz to the northwest and Tabasco to the north, and the Pet\u00e9n, Quich\u00e9, Huehuetenango, and San Marcos departments of Guatemala to the east and southeast. Chiapas has a coastline along the Pacific Ocean to the south.\nIn general, Chiapas has a humid, tropical climate. In the north, in the area bordering Tabasco, near Teapa, rainfall can average more than per year. In the past, natural vegetation in this region was lowland, tall perennial rainforest, but this vegetation has been almost completely cleared to allow agriculture and ranching. Rainfall decreases moving towards the Pacific Ocean, but it is still abundant enough to allow the farming of bananas and many other tropical crops near Tapachula. On the several parallel \"sierras\" or mountain ranges running along the center of Chiapas, climate can be quite temperate and foggy, allowing the development of cloud forests like those of Reserva de la Biosfera El Triunfo, home to a handful of horned guans, resplendent quetzals, and azure-rumped tanagers.\nChiapas is home to the ancient Mayan ruins of Palenque, Yaxchil\u00e1n, Bonampak, Chinkultic and Tonin\u00e1. It is also home to one of the largest indigenous populations in the country with twelve federally recognized ethnicities.\nHistory.\nThe official name of the state is Chiapas. It is believed to have come from the ancient city of Chiapan, which in N\u00e1huatl means \"the place where the chia sage grows.\" After the Spanish arrived (1522), they established two cities called Chiapas delos Indios and Chiapas delos Espa\u00f1oles (1528), with the name of Provincia de Chiapas for the area around the cities. The first coat of arms of the region dates from 1535 as that of the Ciudad Real (San Crist\u00f3bal de las Casas). Chiapas painter Javier Vargas Ballinas designed the modern coat of arms.\nPre-Columbian Era.\nHunter gatherers began to occupy the central valley of the state around 7000 BCE, but little is known about them. The oldest archaeological remains in the seat are located at the Santa Elena Ranch in Ocozocoautla whose finds include tools and weapons made of stone and bone. It also includes burials. In the pre Classic period from 1800 BCE to 300 CE, agricultural villages appeared all over the state although hunter gather groups would persist for long after the era.\nRecent excavations in the Soconusco region of the state indicate that the oldest civilization to appear in what is now modern Chiapas is that of the Mokaya, which were cultivating corn and living in houses as early as 1500 BCE, making them one of the oldest in Mesoamerica. There is speculation that these were the forefathers of the Olmec, migrating across the Grijalva Valley and onto the coastal plain of the Gulf of Mexico to the north, which was Olmec territory. One of these people's ancient cities is now the archeological site of Chiapa de Corzo, in which was found the oldest calendar known on a piece of ceramic with a date of 36 BCE. This is three hundred years before the Mayans developed their calendar. The descendants of Mokaya are the Mixe-Zoque.\nDuring the pre Classic era, it is known that most of Chiapas was not Olmec, but had close relations with them, especially the Olmecs of the Isthmus of Tehuantepec. Olmec-influenced sculpture can be found in Chiapas and products from the state including amber, magnetite, and ilmenite were exported to Olmec lands. The Olmecs came to what is now the northwest of the state looking for amber with one of the main pieces of evidence for this called the Simojovel Ax.\nMayan civilization began in the pre-Classic period as well, but did not come into prominence until the Classic period (300\u2013900CE). Development of this culture was agricultural villages during the pre-Classic period with city building during the Classic as social stratification became more complex. The Mayans built cities on the Yucat\u00e1n Peninsula and west into Guatemala. In Chiapas, Mayan sites are concentrated along the state's borders with Tabasco and Guatemala, near Mayan sites in those entities. Most of this area belongs to the Lacandon Jungle.\nMayan civilization in the Lacandon area is marked by rising exploitation of rain forest resources, rigid social stratification, fervent local identity, waging war against neighboring peoples. At its height, it had large cities, a writing system, and development of scientific knowledge, such as mathematics and astronomy. Cities were centered on large political and ceremonial structures elaborately decorated with murals and inscriptions. Among these cities are Palenque, Bonampak, Yaxchilan, Chinkultic, Tonin\u00e1 and Ten\u00f3n. The Mayan civilization had extensive trade networks and large markets trading in goods such as animal skins, indigo, amber, vanilla and quetzal feathers. It is not known what ended the civilization but theories range from over population size, natural disasters, disease, and loss of natural resources through over exploitation or climate change.\nNearly all Mayan cities collapsed around the same time, 900CE. From then until 1500 CE, social organization of the region fragmented into much smaller units and social structure became much less complex. There was some influence from the rising powers of central Mexico but two main indigenous groups emerged during this time, the Zoques and the various Mayan descendants. The Chiapans, for whom the state is named, migrated into the center of the state during this time and settled around Chiapa de Corzo, the old Mixe\u2013Zoque stronghold. There is evidence that the Aztecs appeared in the center of the state around Chiapa de Corza in the 15thcentury, but were unable to displace the native Chiapa tribe. However, they had enough influence so that the name of this area and of the state would come from Nahuatl.\nColonial period.\nWhen the Spanish arrived in the 16th century, they found the indigenous peoples divided into Mayan and non-Mayan, with the latter dominated by the Zoques and Chiapa. The first contact between Spaniards and the people of Chiapas came in 1522, when Hern\u00e1n Cort\u00e9s sent tax collectors to the area after Aztec Empire was subdued. The first military incursion was headed by Luis Mar\u00edn, who arrived in 1523. After three years, Mar\u00edn was able to subjugate a number of the local peoples, but met with fierce resistance from the Tzotzils in the highlands. The Spanish colonial government then sent a new expedition under Diego de Mazariegos. Mazariegos had more success than his predecessor, but many natives preferred to commit suicide rather than submit to the Spanish. One famous example of this is the Battle of Tepetchia, where many jumped to their deaths in the Sumidero Canyon.\nIndigenous resistance was weakened by continual warfare with the Spaniards and disease. By 1530 almost all of the indigenous peoples of the area had been subdued with the exception of the Lacandons in the deep jungles who actively resisted until 1695. However, the main two groups, the Tzotzils and Tzeltals of the central highlands were subdued enough to establish the first Spanish city, today called San Crist\u00f3bal de las Casas, in 1528. It was one of two settlements initially called Villa Real de Chiapa de los Espa\u00f1oles and the other called Chiapa de los Indios.\nSoon after, the encomienda system was introduced, which reduced most of the indigenous population to serfdom and many even as slaves as a form of tribute and way of locking in a labor supply for tax payments. The conquistadors brought previously unknown diseases. This, as well as overwork on plantations, dramatically decreased the indigenous population. The Spanish also established missions, mostly under the Dominicans, with the Diocese of Chiapas established in 1538 by Pope Paul III. The Dominican evangelizers became early advocates of the indigenous' people's plight, with Bartolom\u00e9 de las Casas winning a battle with the passing of a law in 1542 for their protection. This order also worked to make sure that communities would keep their indigenous name with a saint's prefix leading to names such as San Juan Chamula and San Lorenzo Zinacant\u00e1n. He also advocated adapting the teaching of Christianity to indigenous language and culture. The encomienda system that had perpetrated much of the abuse of the indigenous peoples declined by the end of the 16th century, and was replaced by haciendas. However, the use and misuse of Indian labor remained a large part of Chiapas politics into modern times. Maltreatment and tribute payments created an undercurrent of resentment in the indigenous population that passed on from generation to generation. One uprising against high tribute payments occurred in the Tzeltal communities in the Los Alto region in 1712. Soon, the Tzoltzils and Ch'ols joined the Tzeltales in rebellion, but within a year the government was able to extinguish the rebellion.\nAs of 1778, Thomas Kitchin described Chiapas as \"the metropolis of the original Mexicans,\" with a population of approximately 20,000, and consisting mainly of indigenous peoples. The Spanish introduced new crops such as sugar cane, wheat, barley and indigo as main economic staples along native ones such as corn, cotton, cacao and beans. Livestock such as cattle, horses and sheep were introduced as well. Regions would specialize in certain crops and animals depending on local conditions and for many of these regions, communication and travel were difficult. Most Europeans and their descendants tended to concentrate in cities such as Ciudad Real, Comit\u00e1n, Chiapa and Tuxtla. Intermixing of the races was prohibited by colonial law but by the end of the 17th century there was a significant mestizo population. Added to this was a population of African slaves brought in by the Spanish in the middle of the 16th century due to the loss of native workforce.\nInitially, \"Chiapas\" referred to the first two cities established by the Spanish in what is now the center of the state and the area surrounding them. Two other regions were also established, the Soconusco and Tuxtla, all under the regional colonial government of Guatemala. Chiapas, Soconusco and Tuxla regions were united to the first time as an \"intendencia\" during the Bourbon Reforms in 1790 as an administrative region under the name of Chiapas. However, within this intendencia, the division between Chiapas and Soconusco regions would remain strong and have consequences at the end of the colonial period.\nEra of Independence.\nFrom the colonial period Chiapas was relatively isolated from the colonial authorities in Mexico City and regional authorities in Guatemala. One reason for this was the rugged terrain. Another was that much of Chiapas was not attractive to the Spanish. It lacked mineral wealth, large areas of arable land, and easy access to markets. This isolation spared it from battles related to Independence. Jos\u00e9 Mar\u00eda Morelos y Pav\u00f3n did enter the city of Tonal\u00e1 but incurred no resistance. The only other insurgent activity was the publication of a newspaper called \"El Pararrayos\" by Mat\u00edas de C\u00f3rdova in San Crist\u00f3bal de las Casas.\nFollowing the end of Spanish rule in New Spain, it was unclear what new political arrangements would emerge. The isolation of Chiapas from centers of power, along with the strong internal divisions in the intendencia caused a political crisis after royal government collapsed in Mexico City in 1821, ending the Mexican War of Independence. During this war, a group of influential Chiapas merchants and ranchers sought the establishment of the Free State of Chiapas. This group became known as the \"La Familia Chiapaneca\". However, this alliance did not last with the lowlands preferring inclusion among the new republics of Central America and the highlands annexation to Mexico. In 1821, a number of cities in Chiapas, starting in Comit\u00e1n, declared the state's separation from the Spanish empire. In 1823, Guatemala became part of the United Provinces of Central America, which united to form a federal republic that would last from 1823 to 1839. With the exception of the pro-Mexican Ciudad Real (San Crist\u00f3bal) and some others, many Chiapanecan towns and villages favored a Chiapas independent of Mexico and some favored unification with Guatemala.\nElites in highland cities pushed for incorporation into Mexico. In 1822, then-Emperor Agust\u00edn de Iturbide decreed that Chiapas was part of Mexico. In 1823, the Junta General de Gobierno was held and Chiapas declared independence again. In July 1824, the Soconusco District of southwestern Chiapas split off from Chiapas, announcing that it would join the Central American Federation. In September of the same year, a referendum was held on whether the intendencia would join Central America or Mexico, with many of the elite endorsing union with Mexico. This referendum ended in favor of incorporation with Mexico (allegedly through manipulation of the elite in the highlands), but the Soconusco region maintained a neutral status until 1842, when Oaxacans under General Antonio L\u00f3pez de Santa Anna occupied the area, and declared it reincorporated into Mexico. Elites of the area would not accept this until 1844. Guatemala would not recognize Mexico's annexation of the Soconusco region until 1895 even though a final border between Chiapas and the country was finalized until 1882. The State of Chiapas was officially declared in 1824, with its first constitution in 1826. Ciudad Real was renamed San Crist\u00f3bal de las Casas in 1828.\nIn the decades after the official end of the war, the provinces of Chiapas and Soconusco unified, with power concentrated in San Crist\u00f3bal de las Casas. The state's society evolved into three distinct spheres: indigenous peoples, mestizos from the farms and haciendas and the Spanish colonial cities. Most of the political struggles were between the last two groups especially over who would control the indigenous labor force. Economically, the state lost one of its main crops, indigo, to synthetic dyes. There was a small experiment with democracy in the form of \"open city councils\" but it was shortlived because voting was heavily rigged.\nThe Universidad Pontificia y Literaria de Chiapas was founded in 1826, with Mexico's second teacher's college founded in the state in 1828.\nEra of the Liberal Reform.\nWith the ouster of conservative Antonio L\u00f3pez de Santa Anna, Mexican liberals came to power. The Reform War (1858\u20131861) fought between Liberals, who favored federalism and sought economic development, decreased power of the Roman Catholic Church, and Mexican army, and Conservatives, who favored centralized autocratic government, retention of elite privileges, did not lead to any military battles in the state. Despite that it strongly affected Chiapas politics. In Chiapas, the Liberal-Conservative division had its own twist. Much of the division between the highland and lowland ruling families was for whom the Indians should work for and for how long as the main shortage was of labor. These families split into Liberals in the lowlands, who wanted further reform and Conservatives in the highlands who still wanted to keep some of the traditional colonial and church privileges. For most of the early and mid 19th century, Conservatives held most of the power and were concentrated in the larger cities of San Crist\u00f3bal de las Casas, Chiapa (de Corzo), Tuxtla and Comit\u00e1n. As Liberals gained the upper hand nationally in the mid-19th century, one Liberal politician \u00c1ngel Albino Corzo gained control of the state. Corzo became the primary exponent of Liberal ideas in the southeast of Mexico and defended the Palenque and Pichucalco areas from annexation by Tabasco. However, Corzo's rule would end in 1875, when he opposed the regime of Porfirio D\u00edaz.\nLiberal land reforms would have negative effects on the state's indigenous population unlike in other areas of the country. Liberal governments expropriated lands that were previously held by the Spanish Crown and Catholic Church in order to sell them into private hands. This was not only motivated by ideology, but also due to the need to raise money. However, many of these lands had been in a kind of \"trust\" with the local indigenous populations, who worked them. Liberal reforms took away this arrangement and many of these lands fell into the hands of large landholders who when made the local Indian population work for three to five days a week just for the right to continue to cultivate the lands. This requirement caused many to leave and look for employment elsewhere. Most became \"free\" workers on other farms, but they were often paid only with food and basic necessities from the farm shop. If this was not enough, these workers became indebted to these same shops and then unable to leave.\nThe opening up of these lands also allowed many whites and mestizos (often called Ladinos in Chiapas) to encroach on what had been exclusively indigenous communities in the state. These communities had had almost no contact with the Ladino world, except for a priest. The new Ladino landowners occupied their acquired lands as well as others, such as shopkeepers, opened up businesses in the center of Indian communities. In 1848, a group of Tzeltals plotted to kill the new mestizos in their midst, but this plan was discovered, and was punished by the removal of large number of the community's male members. The changing social order had severe negative effects on the indigenous population with alcoholism spreading, leading to more debts as it was expensive. The struggles between Conservatives and Liberals nationally disrupted commerce and confused power relations between Indian communities and Ladino authorities. It also resulted in some brief respites for Indians during times when the instability led to uncollected taxes.\nOne other effect that Liberal land reforms had was the start of coffee plantations, especially in the Soconusco region. One reason for this push in this area was that Mexico was still working to strengthen its claim on the area against Guatemala's claims on the region. The land reforms brought colonists from other areas of the country as well as foreigners from England, the United States and France. These foreign immigrants would introduce coffee production to the areas, as well as modern machinery and professional administration of coffee plantations. Eventually, this production of coffee would become the state's most important crop.\nAlthough the Liberals had mostly triumphed in the state and the rest of the country by the 1860s, Conservatives still held considerable power in Chiapas. Liberal politicians sought to solidify their power among the indigenous groups by weakening the Roman Catholic Church. The more radical of these even allowed indigenous groups the religious freedoms to return to a number of native rituals and beliefs such as pilgrimages to natural shrines such as mountains and waterfalls.\nThis culminated in the Chiapas \"caste war\", which was an uprising of Tzotzils beginning in 1868. The basis of the uprising was the establishment of the \"three stones cult\" in Tzajahemal. Agustina G\u00f3mez Checheb was a girl tending her father's sheep when three stones fell from the sky. Collecting them, she put them on her father's altar and soon claimed that the stone communicated with her. Word of this soon spread and the \"talking stones\" of Tzajahemel soon became a local indigenous pilgrimage site. The cult was taken over by one pilgrim, Pedro D\u00edaz Cuzcat, who also claimed to be able to communicate with the stones, and had knowledge of Catholic ritual, becoming a kind of priest. However, this challenged the traditional Catholic faith and non Indians began to denounce the cult. Stories about the cult include embellishments such as the crucifixion of a young Indian boy.\nThis led to the arrest of Checheb and Cuzcat in December 1868. This caused resentment among the Tzotzils. Although the Liberals had earlier supported the cult, Liberal landowners had also lost control of much of their Indian labor and Liberal politicians were having a harder time collecting taxes from indigenous communities. An Indian army gathered at Zontehuitz then attacked various villages and haciendas. By the following June the city of San Crist\u00f3bal was surrounded by several thousand Indians, who offered the exchanged of several Ladino captives for their religious leaders and stones. Chiapas governor Domingu\u00e9z came to San Crist\u00f3bal with about three hundred heavily armed men, who then attacked the Indian force armed only with sticks and machetes. The indigenous force was quickly dispersed and routed with government troops pursuing pockets of guerrilla resistance in the mountains until 1870. The event effectively returned control of the indigenous workforce back to the highland elite.\nPorfiriato, 1876\u20131911.\nThe Porfirio D\u00edaz era at the end of the 19th century and beginning of the 20th was initially thwarted by regional bosses called caciques, bolstered by a wave of Spanish and mestizo farmers who migrated to the state and added to the elite group of wealthy landowning families. There was some technological progress such as a highway from San Crist\u00f3bal to the Oaxaca border and the first telephone line in the 1880s, but Porfirian era economic reforms would not begin until 1891 with Governor Emilio Rabasa. This governor took on the local and regional caciques and centralized power into the state capital, which he moved from San Crist\u00f3bal de las Casas to Tuxtla in 1892. He modernized public administration, transportation and promoted education. Rabasa also introduced the telegraph, limited public schooling, sanitation and road construction, including a route from San Crist\u00f3bal to Tuxtla then Oaxaca, which signaled the beginning of favoritism of development in the central valley over the highlands. He also changed state policies to favor foreign investment, favored large land mass consolidation for the production of cash crops such as henequen, rubber, guayule, cochineal and coffee. Agricultural production boomed, especially coffee, which induced the construction of port facilities in Tonal\u00e1. The economic expansion and investment in roads also increased access to tropical commodities such as hardwoods, rubber and chicle.\nThese still required cheap and steady labor to be provided by the indigenous population. By the end of the 19th century, the four main indigenous groups, Tzeltals, Tzotzils, Tojolabals and Ch\u2019ols were living in \"reducciones\" or reservations, isolated from one another. Conditions on the farms of the Porfirian era was serfdom, as bad if not worse than for other indigenous and mestizo populations leading to the Mexican Revolution. While this coming event would affect the state, Chiapas did not follow the uprisings in other areas that would end the Porfirian era.\nJapanese immigration to Mexico began in 1897 when the first thirty five migrants arrived in Chiapas to work on coffee farms, so that Mexico was the first Latin American country to receive organized Japanese immigration. Although this colony ultimately failed, there remains a small Japanese community in Acacoyagua, Chiapas.\nEarly 20th century to 1960.\nIn the early 20th century and into the Mexican Revolution, the production of coffee was particularly important but labor-intensive. This would lead to a practice called \"enganche\" (hook), where recruiters would lure workers with advanced pay and other incentives such as alcohol and then trap them with debts for travel and other items to be worked off. This practice would lead to a kind of indentured servitude and uprisings in areas of the state, although they never led to large rebel armies as in other parts of Mexico.\nA small war broke out between Tuxtla Guti\u00e9rrez and San Cristobal in 1911. San Crist\u00f3bal, allied with San Juan Chamula, tried to regain the state's capital but the effort failed. San Crist\u00f3bal de las Casas, which had a very limited budget, to the extent that it had to ally with San Juan Chamula challenged Tuxtla Gutierrez which, with only a small ragtag army overwhelmingly defeated the army helped by chamulas from San Crist\u00f3bal. There were three years of peace after that until troops allied with the \"First Chief\" of the revolutionary Constitutionalist forces, Venustiano Carranza, entered in 1914 taking over the government, with the aim of imposing the \"Ley de Obreros\" (Workers' Law) to address injustices against the state's mostly indigenous workers. Conservatives responded violently months later when they were certain the Carranza forces would take their lands. This was mostly by way of guerrilla actions headed by farm owners who called themselves the \"Mapaches\". This action continued for six years, until President Carranza was assassinated in 1920 and revolutionary general \u00c1lvaro Obreg\u00f3n became president of Mexico. This allowed the Mapaches to gain political power in the state and effectively stop many of the social reforms occurring in other parts of Mexico.\nThe Mapaches continued to fight against socialists and communists in Mexico from 1920 to 1936, to maintain their control over the state. In general, elite landowners also allied with the nationally dominant party founded by Plutarco El\u00edas Calles following the assassination of president-elect Obreg\u00f3n in 1928; that party was renamed the Institutional Revolutionary Party in 1946. Through that alliance, they could block land reform in this way as well. The Mapaches were first defeated in 1925 when an alliance of socialists and former Carranza loyalists had Carlos A. Vidal selected as governor, although he was assassinated two years later. The last of the Mapache resistance was overcome in the early 1930s by Governor Victorico Grajales, who pursued President L\u00e1zaro C\u00e1rdenas' social and economic policies including persecution of the Catholic Church. These policies would have some success in redistributing lands and organizing indigenous workers but the state would remain relatively isolated for the rest of the 20thcentury. The territory was reorganized into municipalities in 1916. The current state constitution was written in 1921.\nThere was political stability from the 1940s to the early 1970s; however, regionalism regained with people thinking of themselves as from their local city or municipality over the state. This regionalism impeded the economy as local authorities restrained outside goods. For this reason, construction of highways and communications were pushed to help with economic development. Most of the work was done around Tuxtla Guti\u00e9rrez and Tapachula. This included the Sureste railroad connecting northern municipalities such as Pichucalco, Salto de Agua, Palenque, Catazaj\u00e1 and La Libertad. The Cristobal Colon highway linked Tuxtla to the Guatemalan border. Other highways included El Escopetazo to Pichucalco, a highway between San Crist\u00f3bal and Palenque with branches to Cuxtepeques and LaFrailesca. This helped to integrate the state's economy, but it also permitted the political rise of communal land owners called ejidatarios.\nMid-20th century to 1990.\nIn the mid-20th century, the state experienced a significant rise in population, which outstripped local resources, especially land in the highland areas. Since the 1930s, many indigenous and mestizos have migrated from the highland areas into the Lacandon Jungle with the populations of Altamirano, Las Margaritas, Ocosingo and Palenque rising from less than 11,000 in 1920 to over 376,000 in 2000. These migrants came to the jungle area to clear forest and grow crops and raise livestock, especially cattle. Economic development in general raised the output of the state, especially in agriculture, but it had the effect of deforesting many areas, especially the Lacandon. Added to this was there were still serf like conditions for many workers and insufficient educational infrastructure. Population continued to increase faster than the economy could absorb. There were some attempts to resettle peasant farmers onto non cultivated lands, but they were met with resistance. President Gustavo D\u00edaz Ordaz awarded a land grant to the town of Venustiano Carranza in 1967, but that land was already being used by cattle-ranchers who refused to leave. The peasants tried to take over the land anyway, but when violence broke out, they were forcibly removed. In Chiapas poor farmland and severe poverty afflict the Mayan Indians which led to unsuccessful non violent protests and eventually armed struggle started by the Zapatista National Liberation Army in January 1994.\nThese events began to lead to political crises in the 1970s, with more frequent land invasions and takeovers of municipal halls. This was the beginning of a process that would lead to the emergence of the Zapatista movement in the 1990s. Another important factor to this movement would be the role of the Catholic Church from the 1960s to the 1980s. In 1960, Samuel Ruiz became the bishop of the Diocese of Chiapas, centered in San Crist\u00f3bal. He supported and worked with Marist priests and nuns following an ideology called liberation theology. In 1974, he organized a statewide \"Indian Congress\" with representatives from the Tzeltal, Tzotzil, Tojolabal and Ch'ol peoples from 327 communities as well as Marists and the Maoist People's Union. This congress was the first of its kind with the goal of uniting the indigenous peoples politically. These efforts were also supported by leftist organizations from outside Mexico, especially to form unions of ejido organizations. These unions would later form the base of the EZLN organization. One reason for the Church's efforts to reach out to the indigenous population was that starting in the 1970s, a shift began from traditional Catholic affiliation to Protestant, Evangelical and other Christian sects.\nThe 1980s saw a large wave of refugees coming into the state from Central America as a number of these countries, especially Guatemala, were in the midst of violent political turmoil. The Chiapas/Guatemala border had been relatively porous with people traveling back and forth easily in the 19th and 20thcenturies, much like the Mexico/U.S. border around the same time. This is in spite of tensions caused by Mexico's annexation of the Soconusco region in the 19thcentury. The border between Mexico and Guatemala had been traditionally poorly guarded, due to diplomatic considerations, lack of resources and pressure from landowners who need cheap labor sources.\nThe arrival of thousands of refugees from Central America stressed Mexico's relationship with Guatemala, at one point coming close to war as well as a politically destabilized Chiapas. Although Mexico is not a signatory to the UN Convention Relating to the Status of Refugees, international pressure forced the government to grant official protection to at least some of the refugees. Camps were established in Chiapas and other southern states, and mostly housed Mayan peoples. However, most Central American refugees from that time never received any official status, estimated by church and charity groups at about half a million from El Salvador alone. The Mexican government resisted direct international intervention in the camps, but eventually relented somewhat because of finances. By 1984, there were 92 camps with 46,000 refugees in Chiapas, concentrated in three areas, mostly near the Guatemalan border. To make matters worse, the Guatemalan army conducted raids into camps on Mexican territories with significant casualties, terrifying the refugees and local populations. From within Mexico, refugees faced threats by local governments who threatened to deport them, legally or not, and local paramilitary groups funded by those worried about the political situation in Central American spilling over into the state. The official government response was to militarize the areas around the camps, which limited international access and migration into Mexico from Central America was restricted. By 1990, it was estimated that there were over 200,000 Guatemalans and half a million from El Salvador, almost all peasant farmers and most under age twenty.\nIn the 1980s, the politization of the indigenous and rural populations of the state that began in the 1960s and 1970s continued. In 1980, several ejido (communal land organizations) joined to form the Union of Ejidal Unions and United Peasants of Chiapas, generally called the Union of Unions, or UU. It had a membership of 12,000 families from over 180 communities. By 1988, this organization joined with other to form the ARIC-Union of Unions (ARIC-UU) and took over much of the Lacandon Jungle portion of the state. Most of the members of these organization were from Protestant and Evangelical sects as well as \"Word of God\" Catholics affiliated with the political movements of the Diocese of Chiapas. What they held in common was indigenous identity vis-\u00e0-vis the non-indigenous, using the old 19th century \"caste war\" word \"Ladino\" for them.\nEconomic liberalization and the EZLN.\nThe adoption of liberal economic reforms by the Mexican federal government clashed with the leftist political ideals of these groups, notably as the reforms were believed to have begun to have negative economic effects on poor farmers, especially small-scale indigenous coffee-growers. Opposition would coalesce into the Zapatista movement in the 1990s. Although the Zapatista movement couched its demands and cast its role in response to contemporary issues, especially in its opposition to neoliberalism, it operates in the tradition of a long line of peasant and indigenous uprisings that have occurred in the state since the colonial era. This is reflected in its indigenous vs. Mestizo character. However, the movement was an economic one as well. Although the area has extensive resources, much of the local population of the state, especially in rural areas, did not benefit from this bounty. In the 1990s, two thirds of the state's residents did not have sewage service, only a third had electricity and half did not have potable water. Over half of the schools offered education only to the third grade and most pupils dropped out by the end of first grade. Grievances, strongest in the San Crist\u00f3bal and Lacandon Jungle areas, were taken up by a small leftist guerrilla band led by a man called only \"Subcomandante Marcos.\"\nThis small band, called the Zapatista Army of National Liberation (Ej\u00e9rcito Zapatista de Liberaci\u00f3n Nacional, EZLN), came to the world's attention when on January 1, 1994 (the day the NAFTA treaty went into effect) EZLN forces occupied and took over the towns of San Cristobal de las Casas, Las Margaritas, Altamirano, Ocosingo and three others. They read their proclamation of revolt to the world and then laid siege to a nearby military base, capturing weapons and releasing many prisoners from the jails. This action followed previous protests in the state in opposition to neoliberal economic policies.\nAlthough it has been estimated as having no more than 300 armed guerrilla members, the EZLN paralyzed the Mexican government, which balked at the political risks of direct confrontation. The major reason for this was that the rebellion caught the attention of the national and world press, as Marcos made full use of the then-new Internet to get the group's message out, putting the spotlight on indigenous issues in Mexico in general. Furthermore, the opposition press in Mexico City, especially \"La Jornada\", actively supported the rebels. These factors encouraged the rebellion to go national. Many blamed the unrest on infiltration of leftists among the large Central American refugee population in Chiapas, and the rebellion opened up splits in the countryside between those supporting and opposing the EZLN. Zapatista sympathizers have included mostly Protestants and Word of God Catholics, opposing those \"traditionalist\" Catholics who practiced a syncretic form of Catholicism and indigenous beliefs. This split had existed in Chiapas since the 1970s, with the latter group supported by the caciques and others in the traditional power-structure. Protestants and Word of God Catholics (allied directly with the bishopric in San Crist\u00f3bal) tended to oppose traditional power structures.\nThe Bishop of Chiapas, Samuel Ruiz, and the Diocese of Chiapas reacted by offering to mediate between the rebels and authorities. However, because of this diocese's activism since the 1960s, authorities accused the clergy of being involved with the rebels. There was some ambiguity about the relationship between Ruiz and Marcos and it was a constant feature of news coverage, with many in official circles using such to discredit Ruiz. Eventually, the activities of the Zapatistas began to worry the Roman Catholic Church in general and to upstage the diocese's attempts to re establish itself among Chiapan indigenous communities against Protestant evangelization. This would lead to a breach between the Church and the Zapatistas.\nThe Zapatista story remained in headlines for a number of years. One reason for this was the December 1997 massacre of forty-five unarmed Tzotzil peasants, mostly women and children, in the Zapatista-controlled village of Acteal in the Chenhal\u00f3 municipality just north of San Crist\u00f3bal. This allowed many media outlets in Mexico to step up their criticisms of the government.\nDespite this, the armed conflict was brief, mostly because the Zapatistas, unlike many other guerilla movements, did not try to gain traditional political power. It focused more on trying to manipulate public opinion in order to obtain concessions from the government. This has linked the Zapatistas to other indigenous and identity-politics movements that arose in the late-20th century. The main concession that the group received was the San Andr\u00e9s Accords (1996), also known as the Law on Indian Rights and Culture. The Accords appear to grant certain indigenous zones autonomy, but this is against the Mexican constitution, so its legitimacy has been questioned. Zapatista declarations since the mid-1990s have called for a new constitution. the government had not found a solution to this problem. The revolt also pressed the government to institute anti-poverty programs such as \"Progresa\" (later called \"Oportunidades\") and the \"Puebla-Panama Plan\" \u2013 aiming to increase trade between southern Mexico and Central America.\nAs of the first decade of the 2000s the Zapatista movement remained popular in many indigenous communities. The uprising gave indigenous peoples a more active role in the state's politics. However, it did not solve the economic issues that many peasant farmers face, especially the lack of land to cultivate. This problem has been at crisis proportions since the 1970s, and the government's reaction has been to encourage peasant farmers\u2014mostly indigenous\u2014to migrate into the sparsely populated Lacandon Jungle, a trend since earlier in the century.\nFrom the 1970s on, some 100,000 people set up homes in this rainforest area, with many being recognized as \"ejidos\", or communal land-holding organizations. These migrants included Tzeltals, Tojolabals, Ch'ols and mestizos, mostly farming corn and beans and raising livestock. However, the government changed policies in the late 1980s with the establishment of the Montes Azules Biosphere Reserve, as much of the Lacandon Jungle had been destroyed or severely damaged. While armed resistance has wound down, the Zapatistas have remained a strong political force, especially around San Crist\u00f3bal and the Lacandon Jungle, its traditional bases. Since the Accords, they have shifted focus in gaining autonomy for the communities they control.\nSince the 1994 uprising, migration into the Lacandon Jungle has significantly increased, involving illegal settlements and cutting in the protected biosphere reserve. The Zapatistas support these actions as part of indigenous rights, but that has put them in conflict with international environmental groups and with the indigenous inhabitants of the rainforest area, the Lacandons. Environmental groups state that the settlements pose grave risks to what remains of the Lacandon, while the Zapatistas accuse them of being fronts for the government, which wants to open the rainforest up to multinational corporations. Added to this is the possibility that significant oil and gas deposits exist under this area.\nThe Zapatista movement has had some successes. The agricultural sector of the economy now favors \"ejidos\" and other commonly-owned land. There have been some other gains economically as well. In the last decades of the 20th century, Chiapas's traditional agricultural economy has diversified somewhat with the construction of more roads and better infrastructure by the federal and state governments. Tourism has become important in some areas of the state, especially in San Crist\u00f3bal de las Casas and Palenque.\nIts economy is important to Mexico as a whole as well, producing coffee, corn, cacao, tobacco, sugar, fruit, vegetables and honey for export. It is also a key state for the nation's petrochemical and hydroelectric industries. A significant percentage of PEMEX's drilling and refining takes place in Chiapas and Tabasco, and Chiapas produces fifty-five percent of Mexico's hydroelectric energy.\nHowever, Chiapas remains one of the poorest states in Mexico. Ninety-four of its 111 municipalities have a large percentage of the population living in poverty. In areas such as Ocosingo, Altamirano and Las Margaritas, the towns where the Zapatistas first came into prominence in 1994, 48% of the adults were illiterate. Chiapas is still considered isolated and distant from the rest of Mexico, both culturally and geographically. It has significantly underdeveloped infrastructure compared to the rest of the country, and its significant indigenous population with isolationist tendencies keep the state distinct culturally. Cultural stratification, neglect and lack of investment by the Mexican federal government has exacerbated this problem.\nGeography.\nPolitical geography.\nChiapas is located in the south east of Mexico, bordering the states of Tabasco, Veracruz and Oaxaca with the Pacific Ocean to the south and Guatemala to the east. It has a territory of 74,415\u00a0km2, the eighth largest state in Mexico. The state consists of 118 municipalities organized into nine political regions called Center, Altos, Fronteriza, Frailesca, Norte, Selva, Sierra, Soconusco and Istmo-Costa. There are 18 cities, twelve towns (villas) and 111 pueblos (villages). Major cities include Tuxtla Guti\u00e9rrez, San Crist\u00f3bal de las Casas, Tapachula, Palenque, Comit\u00e1n, and Chiapa de Corzo.\nGeographical regions.\nThe state has a complex geography with seven distinct regions according to the Mullerried classification system. These include the Pacific Coast Plains, the Sierra Madre de Chiapas, the Central Depression, the Central Highlands, the Eastern Mountains, the Northern Mountains and the Gulf Coast Plains. The Pacific Coast Plains is a strip of land parallel to the ocean. It is composed mostly of sediment from the mountains that border it on the northern side. It is uniformly flat, and stretches from the Bernal Mountain south to Tonal\u00e1. It has deep salty soils due to its proximity to the sea. It has mostly deciduous rainforest although most has been converted to pasture for cattle and fields for crops. It has numerous estuaries with mangroves and other aquatic vegetation.\nThe Sierra Madre de Chiapas runs parallel to the Pacific coastline of the state, northwest to southeast as a continuation of the Sierra Madre del Sur. This area has the highest altitudes in Chiapas including the Tacan\u00e1 Volcano, which rises above sea level. Most of these mountains are volcanic in origin although the nucleus is metamorphic rock. It has a wide range of climates but little arable land. It is mostly covered in middle altitude rainforest, high altitude rainforest, and forests of oaks and pines. The mountains partially block rain clouds from the Pacific, a process known as Orographic lift, which creates a particularly rich coastal region called the Soconusco. The main commercial center of the sierra is the town of Motozintla, also near the Guatemalan border.\nThe Central Depression is in the center of the state. It is an extensive semi flat area bordered by the Sierra Madre de Chiapas, the Central Highlands and the Northern Mountains. Within the depression there are a number of distinct valleys. The climate here can be very hot and humid in the summer, especially due to the large volume of rain received in July and August. The original vegetation was lowland deciduous forest with some rainforest of middle altitudes and some oaks above above sea level.\nThe Central Highlands, also referred to as Los Altos, are mountains oriented from northwest to southeast with altitudes ranging from above sea level. The western highlands are displaced faults, while the eastern highlands are mainly folds of sedimentary formationsmainly limestone, shale, and sandstone. These mountains, along the Sierra Madre of Chiapas become the Cuchumatanes where they extend over the border into Guatemala. Its topography is mountainous with many narrow valleys and karst formations called uvalas or polj\u00e9s, depending on the size. Most of the rock is limestone allowing for a number of formations such as caves and sinkholes. There are also some isolated pockets of volcanic rock with the tallest peaks being the Tzontehuitz and Huitepec volcanos. There are no significant surface water systems as they are almost all underground. The original vegetation was forest of oak and pine but these have been heavily damaged. The highlands climate in the Koeppen modified classification system for Mexico is humid temperate C(m) and subhumid temperate C (w 2 ) (w). This climate exhibits a summer rainy season and a dry winter, with possibilities of frost from December to March. The Central Highlands have been the population center of Chiapas since the Conquest. European epidemics were hindered by the tierra fr\u00eda climate, allowing the indigenous peoples in the highlands to retain their large numbers.\nThe Eastern Mountains (Monta\u00f1as del Oriente) are in the east of the state, formed by various parallel mountain chains mostly made of limestone and sandstone. Its altitude varies from . This area receives moisture from the Gulf of Mexico with abundant rainfall and exuberant vegetation, which creates the Lacandon Jungle, one of the most important rainforests in Mexico. The Northern Mountains (Monta\u00f1as del Norte) are in the north of the state. They separate the flatlands of the Gulf Coast Plains from the Central Depression. Its rock is mostly limestone. These mountains also receive large amounts of rainfall with moisture from the Gulf of Mexico giving it a mostly hot and humid climate with rains year round. In the highest elevations around , temperatures are somewhat cooler and do experience a winter. The terrain is rugged with small valleys whose natural vegetation is high altitude rainforest.\nThe Gulf Coast Plains (Llanura Costera del Golfo) stretch into Chiapas from the state of Tabasco, which gives it the alternate name of the Tabasque\u00f1a Plains. These plains are found only in the extreme north of the state. The terrain is flat and prone to flooding during the rainy season as it was built by sediments deposited by rivers and streams heading to the Gulf.\nLacandon Jungle.\nThe Lacandon Jungle is situated in north eastern Chiapas, centered on a series of canyonlike valleys called the Ca\u00f1adas, between smaller mountain ridges oriented from northwest to southeast. The ecosystem covers an area of approximately extending from Chiapas into northern Guatemala and southern Yucat\u00e1n Peninsula and into Belize. This area contains as much as 25% of Mexico's total species diversity, most of which has not been researched. It has a predominantly hot and humid climate (Am w\" i g) with most rain falling from summer to part of fall, with an average of between 2300 and 2600\u00a0mm per year. There is a short dry season from March to May. The predominate wild vegetation is perennial high rainforest. The Lacandon comprises a biosphere reserve (Montes Azules); four natural protected areas (Bonampak, Yaxchilan, Chan Kin, and Lacantum); and the communal reserve (La Cojolita), which functions as a biological corridor with the area of Pet\u00e9n in Guatemala. Flowing within the Rainforest is the Usumacinta River, considered to be one of the largest rivers in Mexico and seventh largest in the world based on volume of water.\nDuring the 20th century, the Lacandon has had a dramatic increase in population and along with it, severe deforestation. The population of municipalities in this area, Altamirano, Las Margaritas, Ocosingo and Palenque have risen from 11,000 in 1920 to over 376,000 in 2000. Migrants include Ch'ol, Tzeltal, Tzotzil, Tojolabal indigenous peoples along with mestizos, Guatemalan refugees and others. Most of these migrants are peasant farmers, who cut forest to plant crops. However, the soil of this area cannot support annual crop farming for more than three or four harvests. The increase in population and the need to move on to new lands has pitted migrants against each other, the native Lacandon people, and the various ecological reserves for land. It is estimated that only ten percent of the original Lacandon rainforest in Mexico remains, with the rest strip-mined, logged and farmed. It once stretched over a large part of eastern Chiapas but all that remains is along the northern edge of the Guatemalan border. Of this remaining portion, Mexico is losing over five percent each year.\nThe best preserved portion of the Lacandon is within the Montes Azules Biosphere Reserve. It is centered on what was a commercial logging grant by the Porfirio D\u00edaz government, which the government later nationalized. However, this nationalization and conversion into a reserve has made it one of the most contested lands in Chiapas, with the already existing ejidos and other settlements within the park along with new arrivals squatting on the land.\nSoconusco.\nThe Soconusco region encompasses a coastal plain and a mountain range with elevations of up to above sea levels paralleling the Pacific Coast. The highest peak in Chiapas is the Tacan\u00e1 Volcano at above sea level. In accordance with an 1882 treaty, the dividing line between Mexico and Guatemala goes right over the summit of this volcano. The climate is tropical, with a number of rivers and evergreen forests in the mountains. This is Chiapas\u2019 major coffee-producing area, as it has the best soils and climate for coffee.\nBefore the arrival of the Spanish, this area was the principal source of cocoa seeds in the Aztec empire, which they used as currency, and for the highly prized quetzal feathers used by the nobility. It would become the first area to produce coffee, introduced by an Italian entrepreneur on the La Chacara farm. Coffee is cultivated on the slopes of these mountains mostly between asl. Mexico produces about 4\u00a0million sacks of green coffee each year, fifth in the world behind Brazil, Colombia, Indonesia and Vietnam. Most producers are small with plots of land under . From November to January, the annual crop is harvested and processed employing thousands of seasonal workers. Lately, a number of coffee haciendas have been developing tourism infrastructure as well.\nEnvironment and protected areas.\nChiapas is located in the tropical belt of the planet, but the climate is moderated in many areas by altitude. For this reason, there are hot, semi-hot, temperate and even cold climates. Some areas have abundant rainfall year-round and others receive most of their rain between May and October, with a dry season from November to April. The mountain areas affect wind and moisture flow over the state, concentrating moisture in certain areas of the state. They also are responsible for some cloud-covered rainforest areas in the Sierra Madre.\nChiapas' rainforests are home to thousands of animals and plants, some of which cannot be found anywhere else in the world. Natural vegetation varies from lowland to highland tropical forest, pine and oak forests in the highest altitudes and plains area with some grassland. Chiapas is ranked second in forest resources in Mexico with valued woods such as pine, cypress, \"Liquidambar\", oak, cedar, mahogany and more. The Lacandon Jungle is one of the last major tropical rainforests in the northern hemisphere with an extension of . It contains about sixty percent of Mexico's tropical tree species, 3,500 species of plants, 1,157 species of invertebrates and over 500 of vertebrate species. Chiapas has one of the greatest diversities in wildlife in the Americas. There are more than 100 species of amphibians, 700 species of birds, fifty of mammals and just over 200 species of reptiles. In the hot lowlands, there are armadillos, monkeys, pelicans, wild boar, jaguars, crocodiles, iguanas and many others. In the temperate regions there are species such as bobcats, salamanders, a large red lizard Abronia lythrochila, weasels, opossums, deer, ocelots and bats. The coastal areas have large quantities of fish, turtles, and crustaceans, with many species in danger of extinction or endangered as they are endemic only to this area. The total biodiversity of the state is estimated at over 50,000 species of plants and animals. The diversity of species is not limited to the hot lowlands. The higher altitudes also have mesophile forests, oak/pine forests in the Los Altos, Northern Mountains and Sierra Madre and the extensive estuaries and mangrove wetlands along the coast.\nChiapas has about thirty percent of Mexico's fresh water resources. The Sierra Madre divides them into those that flow to the Pacific and those that flow to the Gulf of Mexico. Most of the first are short rivers and streams; most longer ones flow to the Gulf. Most Pacific side rivers do not drain directly into this ocean but into lagoons and estuaries. The two largest rivers are the Grijalva and the Usumacinta, with both part of the same system. The Grijalva has four dams built on it the Belisario Dominguez (La Angostura); Manuel Moreno Torres (Chicoas\u00e9n); Nezahualc\u00f3yotl (Malpaso); and Angel Albino Corzo (Pe\u00f1itas). The Usumacinta divides the state from Guatemala and is the longest river in Central America. In total, the state has of surface waters, of coastline, control of of ocean, of estuaries and ten lake systems. Laguna Miramar is a lake in the Montes Azules reserve and the largest in the Lacandon Jungle at 40\u00a0km in diameter. The color of its waters varies from indigo to emerald green and in ancient times, there were settlements on its islands and its caves on the shoreline. The Catazaj\u00e1 Lake is 28\u00a0km north of the city of Palenque. It is formed by rainwater captured as it makes it way to the Usumacinta River. It contains wildlife such as manatees and iguanas and it is surrounded by rainforest. Fishing on this lake is an ancient tradition and the lake has an annual bass fishing tournament. The Welib J\u00e1 Waterfall is located on the road between Palenque and Bonampak.\nThe state has thirty-six protected areas at the state and federal levels along with 67 areas protected by various municipalities. The Sumidero Canyon National Park was decreed in 1980 with an extension of . It extends over two of the regions of the state, the Central Depression and the Central Highlands over the municipalities of Tuxtla Guti\u00e9rrez, Nuevo Usumacinta, Chiapa de Corzo and San Fernando. The canyon has steep and vertical sides that rise to up to 1000 meters from the river below with mostly tropical rainforest but some areas with xerophile vegetation such as cactus can be found. The river below, which has cut the canyon over the course of twelve million years, is called the Grijalva. The canyon is emblematic for the state as it is featured in the state seal. The Sumidero Canyon was once the site of a battle between the Spaniards and Chiapanecan Indians. Many Chiapanecans chose to throw themselves from the high edges of the canyon rather than be defeated by Spanish forces. Today, the canyon is a popular destination for ecotourism. Visitors can take boat trips down the river that runs through the canyon and see the area's many birds and abundant vegetation.\nThe Montes Azules Integral Biosphere Reserve was decreed in 1978. It is located in the northeast of the state in the Lacandon Jungle. It covers in the municipalities of Maravilla Tenejapa, Ocosingo and Las Margaritas. It conserves highland perennial rainforest. The jungle is in the Usumacinta River basin east of the Chiapas Highlands. It is recognized by the United Nations Environment Programme for its global biological and cultural significance. In 1992, the Lacantun Reserve, which includes the Classic Maya archaeological sites of Yaxchilan and Bonampak, was added to the biosphere reserve.\nAgua Azul Waterfall Protection Area is in the Northern Mountains in the municipality of Tumbal\u00e1. It covers an area of of rainforest and pine-oak forest, centered on the waterfalls it is named after. It is located in an area locally called the \"Mountains of Water\", as many rivers flow through there on their way to the Gulf of Mexico. The rugged terrain encourages waterfalls with large pools at the bottom, that the falling water has carved into the sedimentary rock and limestone. Agua Azul is one of the best known in the state. The waters of the Agua Azul River emerge from a cave that forms a natural bridge of thirty meters and five small waterfalls in succession, all with pools of water at the bottom. In addition to Agua Azul, the area has other attractions\u2014such as the Shumulj\u00e1 River, which contains rapids and waterfalls, the Misol H\u00e1 Waterfall with a thirty-meter drop, the Bol\u00f3n Ajau Waterfall with a fourteen-meter drop, the Gallito Copet\u00f3n rapids, the Blacquiazules Waterfalls, and a section of calm water called the Agua Clara.\nThe El Ocote Biosphere Reserve was decreed in 1982 located in the Northern Mountains at the boundary with the Sierra Madre del Sur in the municipalities of Ocozocoautla, Cintalapa and Tecpat\u00e1n. It has a surface area of and preserves a rainforest area with karst formations. The Lagunas de Montebello National Park was decreed in 1959 and consists of near the Guatemalan border in the municipalities of La Independencia and La Trinitaria. It contains two of the most threatened ecosystems in Mexico the \"cloud rainforest\" and the Soconusco rainforest. The El Triunfo Biosphere Reserve, decreed in 1990, is located in the Sierra Madre de Chiapas in the municipalities of Acacoyagua, \u00c1ngel Albino Corzo, Montecristo de Guerrero, La Concordia, Mapastepec, Pijijiapan, Siltepec and Villa Corzo near the Pacific Ocean with . It conserves areas of tropical rainforest and many freshwater systems endemic to Central America. It is home to around 400 species of birds including several rare species such as the horned guan, the quetzal and the azure-rumped tanager. The Palenque National Forest is centered on the archaeological site of the same name and was decreed in 1981. It is located in the municipality of Palenque where the Northern Mountains meet the Gulf Coast Plain. It extends over of tropical rainforest. The Laguna B\u00e9lgica Conservation Zone is located in the north west of the state in the municipality of Ocozocoautla. It covers forty-two hectares centered on the B\u00e9lgica Lake. The El Zapotal Ecological Center was established in 1980. Nah\u00e1 \u2013 Metzabok is an area in the Lacandon Jungle whose name means \"place of the black lord\" in Nahuatl. It extends over and in 2010, it was included in the World Network of Biosphere Reserves. Two main communities in the area are called Nah\u00e1 and Metzabok. They were established in the 1940s, but the oldest communities in the area belong to the Lacandon people. The area has large numbers of wildlife including endangered species such as eagles, quetzals and jaguars.\nDemographics.\nGeneral statistics.\nAs of 2010, the population is 4,796,580, the eighth most populous state in Mexico. The 20th century saw large population growth in Chiapas. From fewer than one million inhabitants in 1940, the state had about two million in 1980, and over 4\u00a0million in 2005. Overcrowded land in the highlands was relieved when the rainforest to the east was subject to land reform. Cattle ranchers, loggers, and subsistence farmers migrated to the rain forest area. The population of the Lacandon was only one thousand people in 1950, but by the mid-1990s this had increased to 200 thousand. As of 2010, 78% lives in urban communities with 22% in rural communities. While birthrates are still high in the state, they have come down in recent decades from 7.4 per woman in 1950. However, these rates still mean significant population growth in raw numbers. About half of the state's population is under age 20, with an average age of 19. In 2005, there were 924,967 households, 81% headed by men and the rest by women. Most households were nuclear families (70.7%) with 22.1% consisting of extended families.\nMore migrate out of Chiapas than migrate in, with emigrants leaving for Tabasco, Oaxaca, Veracruz, State of Mexico and the Federal District primarily.\nWhile Catholics remain the majority, their numbers have dropped as many have converted to Protestant denominations in recent decades. The National Presbyterian Church in Mexico has a large following in Chiapas; some estimate that 40% of the population are followers of the Presbyterian church.\nThere are a number of people in the state with African features. These are the descendants of slaves brought to the state in the 16th century. There are also those with predominantly European features who are the descendants of the original Spanish colonizers as well as later immigrants to Mexico. The latter mostly came at the end of the 19th and early 20th century under the Porfirio D\u00edaz regime to start plantations.\nIndigenous population.\nNumbers and influence.\nOver the history of Chiapas, there have been 3 main indigenous groups: the Mixes-Zoques, the Mayas and the Chiapa. Today, there are an estimated fifty-six linguistic groups. As of the 2005 Census, there were 957,255 people who spoke an indigenous language out of a total population of about 3.5\u00a0million. Of this one million, one third do not speak Spanish. Out of Chiapas' 111 municipios, 99 have Majority indigenous populations. 22 municipalities have indigenous populations over 90%, and 36 municipalities have native populations exceeding 50%. However, despite population growth in indigenous villages, the percentage of indigenous to non indigenous continues to fall with less than 35% indigenous. Indian populations are concentrated in a few areas, with the largest concentration of indigenous-language-speaking individuals is living in 5 of Chiapas's 9 economic regions: Los Altos, Selva, Norte, Fronteriza, and Sierra. The remaining three regions, Soconusco, Centro and Costa, have populations that are considered to be dominantly mestizo.\nThe state has about 13.5% of all of Mexico's indigenous population, and it has been ranked among the ten \"most indianized\" states, with only Campeche, Oaxaca, Quintana Roo and Yucat\u00e1n having been ranked above it between 1930 and the present. These indigenous peoples have been historically resistant to assimilation into the broader Mexican society, with it best seen in the retention rates of indigenous languages and the historic demands for autonomy over geographic areas as well as cultural domains. Much of the latter has been prominent since the Zapatista uprising in 1994.\nMost of Chiapas' indigenous groups are descended from the Mayans, speaking languages that are closely related to one another, belonging to the Western Maya language group. The state was part of a large region dominated by the Mayans during the Classic period. The most numerous of these Mayan groups include the Tzeltal, Tzotzil, Ch'ol, Zoque, Tojolabal, Lacandon and Mam, which have traits in common such as syncretic religious practices, and social structure based on kinship. The most common Western Maya languages are Tzeltal and Tzotzil along with Chontal, Ch\u2019ol, Tojolabal, Chuj, Kanjobal, Acatec, Jacaltec and Motozintlec.\n12 of Mexico's officially recognized native peoples live in the state have conserved their language, customs, history, dress and traditions to a significant degree. The primary groups include the Tzeltal, Tzotzil, Ch'ol, Tojolabal, Zoque, Chuj, Kanjobal, Mam, Jacalteco, Moch\u00f3 Cakchiquel and Lacandon. Most indigenous communities are found in the municipalities of the Centro, Altos, Norte and Selva regions, with many having indigenous populations of over fifty percent. These include Bochil, Sital\u00e1, Pantepec, Simojovel to those with over ninety percent indigenous such as San Juan Cancuc, Huixt\u00e1n, Tenejapa, Tila, Oxchuc, Tapalapa, Zinacant\u00e1n, Mitontic, Ocotepec, Chamula, and Chalchihuit\u00e1n. The most numerous indigenous communities are the Tzeltal and Tzotzil peoples, who number about 400,000 each, together accounting for about half of the state's indigenous population. The next most numerous are the Ch\u2019ol with about 200,000 people and the Tojolabal and Zoques, who number about 50,000 each. The top 3 municipalities in Chiapas with indigenous language speakers 3 years of age and older are: Ocosingo (133,811), Chilon (96,567), and San Juan Chamula (69,475). These 3 municipalities accounted for 24.8% (299,853) of all indigenous language speakers 3 years or older in the state of Chiapas, out of a total of 1,209,057 indigenous language speakers 3 years or older.\nAlthough most indigenous language speakers are bilingual, especially in the younger generations, many of these languages have shown resilience. 4 of Chiapas' indigenous languages Tzeltal, Tzotzil, Tojolabal and Chol are high-vitality languages, meaning that a high percentage of these ethnicities speak the language and that there is a high rate of monolingualism in it. It is used in over 80% of homes. Zoque is considered to be of medium-vitality with a rate of bilingualism of over 70% and home use somewhere between 65% and 80%. Maya is considered to be of low-vitality with almost all of its speakers bilingual with Spanish. The most spoken indigenous languages as of 2010 are Tzeltal with 461,236 speakers, Tzotzil with 417,462, Ch\u2019ol with 191,947 and Zoque with 53,839. In total, there are 1,141,499 who speak an indigenous language or 27% of the total population. Of these 14% do not speak Spanish. Studies done between 1930 and 2000 have indicated that Spanish is not dramatically displacing these languages. In raw number, speakers of these languages are increasing, especially among groups with a long history of resistance to Spanish/Mexican domination. Language maintenance has been strongest in areas related to where the Zapatista uprising took place such as the municipalities of Altamirano, Chamula, Chanal, Larr\u00e1inzar, Las Margaritas, Ocosingo, Palenque, Sabanilla, San Crist\u00f3bal de Las Casas and Simojovel.\nThe state's rich indigenous tradition along with its associated political uprisings, especially that of 1994, has great interest from other parts of Mexico and abroad. It has been especially appealing to a variety of academics including many anthropologists, archeologists, historians, psychologists and sociologists. The concept of \"mestizo\" or mixed indigenous European heritage became important to Mexico's identity by the time of Independence, but Chiapas has kept its indigenous identity to the present day. Since the 1970s, this has been supported by the Mexican government as it has shifted from cultural policies that favor a \"multicultural\" identity for the country. One major exception to the separatist, indigenous identity has been the case of the Chiapa people, from whom the state's name comes, who have mostly been assimilated and intermarried into the mestizo population.\nMost Indigenous communities have economies based primarily on traditional agriculture such as the cultivation and processing of corn, beans and coffee as a cash crop and in the last decade, many have begun producing sugarcane and jatropha for refinement into biodiesel and ethanol for automobile fuel. The raising of livestock, particularly chicken and turkey and to a lesser extent beef and farmed fish is also a major economic activity. Many indigenous, in particular the Maya are employed in the production of traditional clothing, fabrics, textiles, wood items, artworks and traditional goods such as jade and amber works. Tourism has provided a number of a these communities with markets for their handcrafts and works, some of which are very profitable.\nSan Crist\u00f3bal de las Casas and San Juan Chamula maintain a strong indigenous identity. On market day, many indigenous people from rural areas come into San Crist\u00f3bal to buy and sell mostly items for everyday use such as fruit, vegetables, animals, cloth, consumer goods and tools. San Juan Chamula is considered to be a center of indigenous culture, especially its elaborate festivals of Carnival and Day of Saint John. It was common for politicians, especially during Institutional Revolutionary Party's dominance to visit here during election campaigns and dress in indigenous clothing and carry a carved walking stick, a traditional sign of power. Relations between the indigenous ethnic groups is complicated. While there have been inter ethnic political activism such as that promoted by the Diocese of Chiapas in the 1970s and the Zapatista movement in the 1990s, there has been inter-indigenous conflict as well. Much of this has been based on religion, pitting those of the traditional Catholic/indigenous beliefs who support the traditional power structure against Protestants, Evangelicals and Word of God Catholics (directly allied with the Diocese) who tend to oppose it. This is particularly significant problem among the Tzeltals and Tzotzils. Starting in the 1970s, traditional leaders in San Juan Chamula began expelling dissidents from their homes and land, amounting to about 20,000 indigenous forced to leave over a thirty-year period. It continues to be a serious social problem although authorities downplay it. Recently there has been political, social and ethnic conflict between the Tzotzil who are more urbanized and have a significant number of Protestant practitioners and the Tzeltal who are predominantly Catholic and live in smaller farming communities. Many Protestant Tzotzil have accused the Tzeltal of ethnic discrimination and intimidation due to their religious beliefs and the Tzeltal have in return accused the Tzotzil of singling them out for discrimination.\nClothing, especially women's clothing, varies by indigenous group. For example, women in Ocosingo tend to wear a blouse with a round collar embroidered with flowers and a black skirt decorated with ribbons and tied with a cloth belt. The Lacandon people tend to wear a simple white tunic. They also make a ceremonial tunic from bark, decorated with astronomy symbols. In Tenejapa, women wear a huipil embroidered with Mayan fretwork along with a black wool rebozo. Men wear short pants, embroidered at the bottom.\nTzeltals.\nThe Tzeltals call themselves Winik atel, which means \"working men.\" This is the largest ethnicity in the state, mostly living southeast of San Crist\u00f3bal with the largest number in Amatenango. Today, there are about 500,000 Tzeltal Indians in Chiapas. Tzeltal Mayan, part of the Mayan language family, today is spoken by about 375,000 people making it the fourth-largest language group in Mexico. There are two main dialects; highland (or Oxchuc) and lowland (or Bachajonteco). This language, along with Tzotzil, is from the Tzeltalan subdivision of the Mayan language family. Lexico-statistical studies indicate that these two languages probably became differentiated from one another around 1200 Most children are bilingual in the language and Spanish although many of their grandparents are monolingual Tzeltal speakers.\nEach Tzeltal community constitutes a distinct social and cultural unit with its own well-defined lands, wearing apparel, kinship system, politico-religious organization, economic resources, crafts, and other cultural features. Women are distinguished by a black skirt with a wool belt and an undyed cotton bloused embroidered with flowers. Their hair is tied with ribbons and covered with a cloth. Most men do not use traditional attire. Agriculture is the basic economic activity of the Tzeltal people. Traditional Mesoamerican crops such as maize, beans, squash, and chili peppers are the most important, but a variety of other crops, including wheat, manioc, sweet potatoes, cotton, chayote, some fruits, other vegetables, and coffee.\nTzotzils.\nTzotzil speakers number just slightly less than theTzeltals at 226,000, although those of the ethnicity are probably higher. Tzotzils are found in the highlands or Los Altos and spread out towards the northeast near the border with Tabasco. However, Tzotzil communities can be found in almost every municipality of the state. They are concentrated in Chamula, Zinacant\u00e1n, Chenalh\u00f3, and Simojovel. Their language is closely related to Tzeltal and distantly related to Yucatec Mayan and Lacandon. Men dress in short pants tied with a red cotton belt and a shirt that hangs down to their knees. They also wear leather huaraches and a hat decorated with ribbons. The women wear a red or blue skirt, a short huipil as a blouse, and use a chal or rebozo to carry babies and bundles. Tzotzil communities are governed by a katinab who is selected for life by the leaders of each neighborhood. The Tzotzils are also known for their continued use of the temazcal for hygiene and medicinal purposes.\nCh\u2019ols.\nThe Ch\u2019ols of Chiapas migrated to the northwest of the state starting about 2,000 years ago, when they were concentrated in Guatemala and Honduras. Those Ch\u2019ols who remained in the south are distinguished by the name Chort\u00eds. Chiapas Ch\u2019ols are closely related to the Chontal in Tabasco as well. Choles are found in Tila, Tumbal\u00e1, Sabanilla, Palenque, and Salto de Agua, with an estimated population of about 115,000 people. The Ch\u2019ol language belongs to the Maya family and is related to Tzeltal, Tzotzil, Lacandon, Tojolabal, and Yucatec Mayan. There are three varieties of Chol (spoken in Tila, Tumbal\u00e1, and Sabanilla), all mutually intelligible. Over half of speakers are monolingual in the Chol language. Women wear a long navy blue or black skirt with a white blouse heavily embroidered with bright colors and a sash with a red ribbon. The men only occasionally use traditional dress for events such as the feast of the Virgin of Guadalupe. This dress usually includes pants, shirts and huipils made of undyed cotton, with leather huaraches, a carrying sack and a hat. The fundamental economic activity of the Ch\u2019ols is agriculture. They primarily cultivate corn and beans, as well as sugar cane, rice, coffee, and some fruits. They have Catholic beliefs strongly influenced by native ones. Harvests are celebrated on the Feast of Saint Rose on 30 August.\nTojolabals.\nThe Totolabals are estimated at 35,000 in the highlands. According to oral tradition, the Tojolabales came north from Guatemala. The largest community is Ingeniero Gonz\u00e1lez de Le\u00f3n in the La Ca\u00f1ada region, an hour outside the municipal seat of Las Margaritas. Tojolabales are also found in Comit\u00e1n, Trinitaria, Altamirano and La Independencia. This area is filled with rolling hills with a temperate and moist climate. There are fast moving rivers and jungle vegetation. Tojolabal is related to Kanjobal, but also to Tzeltal and Tzotzil. However, most of the youngest of this ethnicity speak Spanish. Women dress traditionally from childhood with brightly colored skirts decorated with lace or ribbons and a blouse decorated with small ribbons, and they cover their heads with kerchiefs. They embroider many of their own clothes but do not sell them. Married women arrange their hair in two braids and single women wear it loose decorated with ribbons. Men no longer wear traditional garb daily as it is considered too expensive to make.\nZoques.\nThe Zoques are found in 3,000 square kilometers the center and west of the state scattered among hundreds of communities. These were one of the first native peoples of Chiapas, with archeological ruins tied to them dating back as far as 3500 BCE. Their language is not Mayan but rather related to Mixe, which is found in Oaxaca and Veracruz. By the time the Spanish arrived, they had been reduced in number and territory. Their ancient capital was Quechula, which was covered with water by the creation of the Malpaso Dam, along with the ruins of Guelegas, which was first buried by an eruption of the Chichonal volcano. There are still Zoque ruins at Janepaguay, the Ocozocuautla and La Ci\u00e9nega valleys.\nLacandons.\nThe Lacandons are one of the smallest native indigenous groups of the state with a population estimated between 600 and 1,000. They are mostly located in the communities of Lacanj\u00e1 Chansayab, Naj\u00e1, and Mensabak in the Lacandon Jungle. They live near the ruins of Bonampak and Yaxchilan and local lore states that the gods resided here when they lived on Earth. They inhabit about a million hectares of rainforest but from the 16th century to the present, migrants have taken over the area, most of which are indigenous from other areas of Chiapas. This dramatically altered their lifestyle and worldview. Traditional Lacandon shelters are huts made with fonds and wood with an earthen floor, but this has mostly given way to modern structures.\nMoch\u00f3s.\nThe Moch\u00f3s or Motozintlecos are concentrated in the municipality of Motozintla on the Guatemalan border. According to anthropologists, these people are an \"urban\" ethnicity as they are mostly found in the neighborhoods of the municipal seat. Other communities can be found near the Tacan\u00e1 volcano, and in the municipalities of Tuzant\u00e1n and Belisario Dominguez. The name \"Moch\u00f3\" comes from a response many gave the Spanish whom they could not understand and means \"I don't know.\" This community is in the process of disappearing as their numbers shrink.\nMams.\nThe Mams are a Mayan ethnicity that numbers about 20,000 found in thirty municipalities, especially Tapachula, Motozintla, El Porvenir, Cacahoat\u00e1n and Amatenango in the southeastern Sierra Madre of Chiapas. The Mame language is one of the most ancient Mayan languages with 5,450 Mame speakers were tallied in Chiapas in the 2000 census. These people first migrated to the border region between Chiapas and Guatemala at the end of the nineteenth century, establishing scattered settlements. In the 1960s, several hundred migrated to the Lacandon rain forest near the confluence of the Santo Domingo and Jatat\u00e9 Rivers. Those who live in Chiapas are referred to locally as the \"Mexican Mam (or Mame)\" to differientiate them from those in Guatemala. Most live around the Tacan\u00e1 volcano, which the Mams call \"our mother\" as it is considered to be the source of the fertility of the area's fields. The masculine deity is the Tajumulco volcano, which is in Guatemala.\nGuatemalan migrant groups.\nIn the last decades of the 20th century, Chiapas received a large number of indigenous refugees, especially from Guatemala, many of whom remain in the state. These have added ethnicities such as the Kekchi, Chuj, Ixil, Kanjobal, K'iche' and Cakchikel to the population. The Kanjobal mainly live along the border between Chiapas and Guatemala, with almost 5,800 speakers of the language tallied in the 2000 census. It is believed that a significant number of these Kanjobal-speakers may have been born in Guatemala and immigrated to Chiapas, maintaining strong cultural ties to the neighboring nation.\nEconomy.\nEconomic indicators.\nChiapas accounts for 1.73% of Mexico's GDP. The primary sector, agriculture, produces 15.2% of the state's GDP. The secondary sector, mostly energy production, but also commerce, services and tourism, accounts for 21.8%. The share of the GDP coming from services is rising while that of agriculture is falling. The state is divided into nine economic regions. These regions were established in the 1980s in order to facilitate statewide economic planning. Many of these regions are based on state and federal highway systems. These include Centro, Altos, Fronteriza, Frailesca, Norte, Selva, Sierra, Soconusco and Istmo-Costa.\nDespite being rich in resources, Chiapas, along with Oaxaca and Guerrero, lags behind the rest of the country in almost all socioeconomic indicators. , there were 889,420 residential units; 71% had running water, 77.3% sewerage, and 93.6% electricity. Construction of these units varies from modern construction of block and concrete to those constructed of wood and laminate.\nBecause of its high rate of economic marginalization, more people migrate from Chiapas than migrate to it. Most of its socioeconomic indicators are the lowest in the country including income, education, health and housing. It has a significantly higher percentage of illiteracy than the rest of the country, although that situation has improved since the 1970s when over 45% were illiterate and 1980s, about 32%. The tropical climate presents health challenges, with most illnesses related to the gastro-intestinal tract and parasites. As of 2005, the state has 1,138 medical facilities: 1098 outpatient and 40 inpatient. Most are run by IMSS and ISSSTE and other government agencies. The implementation of NAFTA had negative effects on the economy, particularly by lowering prices for agricultural products. It made the southern states of Mexico poorer in comparison to those in the north, with over 90% of the poorest municipalities in the south of the country. As of 2006, 31.8% work in communal services, social services and personal services. 18.4% work in financial services, insurance and real estate, 10.7% work in commerce, restaurants and hotels, 9.8% work in construction, 8.9% in utilities, 7.8% in transportation, 3.4% in industry (excluding handcrafts), and 8.4% in agriculture.\nAlthough until the 1960s, many indigenous communities were considered by scholars to be autonomous and economically isolated, this was never the case. Economic conditions began forcing many to migrate to work, especially in agriculture for non-indigenous. However, unlike many other migrant workers, most indigenous in Chiapas have remained strongly tied to their home communities. A study as early as the 1970s showed that 77 percent of heads of household migrated outside of the Chamula municipality as local land did not produce sufficiently to support families. In the 1970s, cuts in the price of corn forced many large landowners to convert their fields into pasture for cattle, displacing many hired laborers, cattle required less work. These agricultural laborers began to work for the government on infrastructure projects financed by oil revenue. It is estimated that in the 1980s to 1990s as many as 100,000 indigenous people moved from the mountain areas into cities in Chiapas, with some moving out of the state to Mexico City, Canc\u00fan and Villahermosa in search of employment.\nAgriculture, livestock, forestry and fishing.\nAgriculture, livestock, forestry and fishing employ over 53% of the state's population; however, its productivity is considered to be low. Agriculture includes both seasonal and perennial plants. Major crops include corn, beans, sorghum, soybeans, peanuts, sesame seeds, coffee, cacao, sugar cane, mangos, bananas, and palm oil. These crops take up 95% of the cultivated land in the state and 90% of the agricultural production. Only four percent of fields are irrigated with the rest dependent on rainfall either seasonally or year round. Chiapas ranks second among the Mexican states in the production of cacao, the product used to make chocolate, and is responsible for about 60 percent of Mexico's total coffee output. The production of bananas, cacao and corn make Chiapas Mexico's second largest agricultural producer overall.\nCoffee is the state's most important cash crop with a history from the 19th century. The crop was introduced in 1846 by Jeronimo Manchinelli who brought 1,500 seedlings from Guatemala on his farm La Chacara. This was followed by a number of other farms as well. Coffee production intensified during the regime of Porfirio D\u00edaz and the Europeans who came to own many of the large farms in the area. By 1892, there were 22 coffee farms in the region, among them Nueva Alemania, Hamburgo, Chiripa, Irlanda, Argovia, San Francisco, and Linda Vista in the Soconusco region. Since then coffee production has grown and diversified to include large plantations, the use and free and forced labor and a significant sector of small producers. While most coffee is grown in the Soconusco, other areas grow it, including the municipalities of Oxchuc, Panthel\u00f3, El Bosque, Tenejapa, Chenalh\u00f3, Larr\u00e1inzar, and Chalchihuit\u00e1n, with around six thousand producers. It also includes organic coffee producers with 18\u00a0million tons grown annually 60,000 producers. One third of these producers are indigenous women and other peasant farmers who grow the coffee under the shade of native trees without the use of agro chemicals. Some of this coffee is even grown in environmentally protected areas such as the El Triunfo reserve, where ejidos with 14,000 people grow the coffee and sell it to cooperativers who sell it to companies such as Starbucks, but the main market is Europe. Some growers have created cooperatives of their own to cut out the middleman.\nRanching occupies about three million hectares of natural and induced pasture, with about 52% of all pasture induced. Most livestock is done by families using traditional methods. Most important are meat and dairy cattle, followed by pigs and domestic fowl. These three account for 93% of the value of production. Annual milk production in Chiapas totals about 180\u00a0million liters per year. The state's cattle production, along with timber from the Lacandon Jungle and energy output gives it a certain amount of economic clouts compared to other states in the region.\nForestry is mostly based on conifers and common tropical species producing 186,858\u00a0m3 per year at a value of 54,511,000 pesos. Exploited non-wood species include the Camedor palm tree for its fronds. The fishing industry is underdeveloped but includes the capture of wild species as well as fish farming. Fish production is generated both from the ocean as well as the many freshwater rivers and lakes. In 2002, 28,582 tons of fish valued at 441.2\u00a0million pesos was produced. Species include tuna, shark, shrimp, mojarra and crab.\nIndustry and energy.\nThe state's abundant rivers and streams have been dammed to provide about fifty-five percent of the country's hydroelectric energy. Much of this is sent to other states accounting for over six percent of all of Mexico's energy output. Main power stations are located at Malpaso, La Angostura, Chicoas\u00e9n and Pe\u00f1itas, which produce about eight percent of Mexico's hydroelectric energy. Manuel Moreno Torres plant on the Grijalva River the most productive in Mexico. All of the hydroelectric plants are owned and operated by the Federal Electricity Commission (Comisi\u00f3n Federal de Electricidad, CFE).\nChiapas is rich in petroleum reserves. Oil production began during the 1980s and Chiapas has become the fourth largest producer of crude oil and natural gas among the Mexican states. Many reserves are yet untapped, but between 1984 and 1992, PEMEX drilled nineteen oil wells in the Lacandona Jungle. Currently, petroleum reserves are found in the municipalities of Ju\u00e1rez, Ostuac\u00e1n, Pichucalco and Reforma in the north of the state with 116 wells accounting for about 6.5% of the country's oil production. It also provides about a quarter of the country's natural gas. This production equals of natural gas and 17,565,000 barrels of oil per year.\nIndustry is limited to small and micro enterprises and include auto parts, bottling, fruit packing, coffee and chocolate processing, production of lime, bricks and other construction materials, sugar mills, furniture making, textiles, printing and the production of handcrafts. The two largest enterprises is the Comisi\u00f3n Federal de Electricidad and a Petr\u00f3leos Mexicanos refinery. Chiapas opened its first assembly plant in 2002, a fact that highlights the historical lack of industry in this area.\nHandcrafts.\nChiapas is one of the states that produces a wide variety of handcrafts and folk art in Mexico. One reason for this is its many indigenous ethnicities who produce traditional items out of identity as well as commercial reasons. One commercial reason is the market for crafts provided by the tourism industry. Another is that most indigenous communities can no longer provide for their own needs through agriculture. The need to generate outside income has led to many indigenous women producing crafts communally, which has not only had economic benefits but also involved them in the political process as well. Unlike many other states, Chiapas has a wide variety of wood resources such as cedar and mahogany as well as plant species such as reeds, ixtle and palm. It also has minerals such as obsidian, amber, jade and several types of clay and animals for the production of leather, dyes from various insects used to create the colors associated with the region. Items include various types of handcrafted clothing, dishes, jars, furniture, roof tiles, toys, musical instruments, tools and more.\nChiapas\u2019 most important handcraft is textiles, most of which is cloth woven on a backstrap loom. Indigenous girls often learn how to sew and embroider before they learn how to speak Spanish. They are also taught how to make natural dyes from insects, and weaving techniques. Many of the items produced are still for day-to-day use, often dyed in bright colors with intricate embroidery. They include skirts, belts, rebozos, blouses, huipils and shoulder wraps called chals. Designs are in red, yellow, turquoise blue, purple, pink, green and various pastels and decorated with designs such as flowers, butterflies, and birds, all based on local flora and fauna. Commercially, indigenous textiles are most often found in San Crist\u00f3bal de las Casas, San Juan Chamula and Zinacant\u00e1n. The best textiles are considered to be from Magdalenas, Larr\u00e1inzar, Venustiano Carranza and Sibaca.\nOne of the main minerals of the state is amber, much of which is 25\u00a0million years old, with quality comparable to that found in the Dominican Republic. Chiapan amber has a number of unique qualities, including much that is clear all the way through and some with fossilized insects and plants. Most Chiapan amber is worked into jewelry including pendants, rings and necklaces. Colors vary from white to yellow/orange to a deep red, but there are also green and pink tones as well. Since pre-Hispanic times, native peoples have believed amber to have healing and protective qualities. The largest amber mine is in Simojovel, a small village 130\u00a0km from Tuxtla Guti\u00e9rrez, which produces 95% of Chiapas' amber. Other mines are found in Huitiup\u00e1n, Totolapa, El Bosque, Pueblo Nuevo Solistahuac\u00e1n, Pantelh\u00f3 and San Andr\u00e9s Duraznal. According to the Museum of Amber in San Crist\u00f3bal, almost 300\u00a0kg of amber is extracted per month from the state. Prices vary depending on quality and color.\nThe major center for ceramics in the state is the city of Amatenango del Valle, with its barro blanco (white clay) pottery. The most traditional ceramic in Amatenango and Aguacatenango is a type of large jar called a cantaro used to transport water and other liquids. Many pieces created from this clay are ornamental as well as traditional pieces for everyday use such as comals, dishes, storage containers and flowerpots. All pieces here are made by hand using techniques that go back centuries. Other communities that produce ceramics include Chiapa de Corzo, Tonal\u00e1, Ocuilpa, Suchiapa and San Crist\u00f3bal de las Casas.\nWood crafts in the state center on furniture, brightly painted sculptures and toys. The Tzotzils of San Juan de Chamula are known for their sculptures as well as for their sturdy furniture. Sculptures are made from woods such as cedar, mahogany and strawberry tree. Another town noted for their sculptures is Tecpat\u00e1n. The making lacquer to use in the decoration of wooden and other items goes back to the colonial period. The best-known area for this type of work, called \"laca\" is Chiapa de Corzo, which has a museum dedicated to it. One reason this type of decoration became popular in the state was that it protected items from the constant humidity of the climate. Much of the laca in Chiapa de Corzo is made in the traditional way with natural pigments and sands to cover gourds, dipping spoons, chests, niches and furniture. It is also used to create the Parachicos masks.\nTraditional Mexican toys, which have all but disappeared in the rest of Mexico, are still readily found here and include the cajita de la serpiente, yo yos, ball in cup and more. Other wooden items include masks, cooking utensils, and tools. One famous toy is the \"mu\u00f1ecos zapatistas\" (Zapatista dolls), which are based on the revolutionary group that emerged in the 1990s.\nTourism and general commerce/services.\nNinety-four percent of the state's commercial outlets are small retail stores with about 6% wholesalers. There are 111 municipal markets, 55 tianguis, three wholesale food markets and 173 large vendors of staple products. The service sector is the most important to the economy, with mostly commerce, warehousing and tourism.\nTourism brings large numbers of visitors to the state each year. Most of Chiapas' tourism is based on its culture, colonial cities and ecology. The state has a total of 491 ranked hotels with 12,122 rooms. There are also 780 other establishments catering primarily to tourism, such as services and restaurants.\nThere are three main tourist routes: the Maya Route, the Colonial Route and the Coffee Route. The Maya Route runs along the border with Guatemala in the Lacandon Jungle and includes the sites of Palenque, Bonampak, Yaxchilan along with the natural attractions of Agua Azul Waterfalls, Misol-H\u00e1 Waterfall, and the Catazaj\u00e1 Lake. Palenque is the most important of these sites, and one of the most important tourist destinations in the state. Yaxchilan was a Mayan city along the Usumacinta River. It developed between 350 and 810 CE. Bonampak is known for its well preserved murals. These Mayan sites have made the state an attraction for international tourism. These sites contain a large number of structures, most of which date back thousands of years, especially to the sixth century. In addition to the sites on the Mayan Route, there are others within the state away from the border such as Tonin\u00e1, near the city of Ocosingo.\nThe Colonial Route is mostly in the central highlands with a significant number of churches, monasteries and other structures from the colonial period along with some from the 19th century and even into the early 20th. The most important city on this route is San Crist\u00f3bal de las Casas, located in the Los Altos region in the Jovel Valley. The historic center of the city is filled with tiled roofs, patios with flowers, balconies, Baroque facades along with Neoclassical and Moorish designs. It is centered on a main plaza surrounded by the cathedral, the municipal palace, the Portales commercial area and the San Nicol\u00e1s church. In addition, it has museums dedicated to the state's indigenous cultures, one to amber and one to jade, both of which have been mined in the state. Other attractions along this route include Comit\u00e1n de Dom\u00ednguez and Chiapa de Corzo, along with small indigenous communities such as San Juan Chamula. The state capital of Tuxtla Guti\u00e9rrez does not have many colonial era structures left, but it lies near the area's most famous natural attraction of the Sumidero Canyon. This canyon is popular with tourists who take boat tours into it on the Grijalva River to see such features such as caves (La Cueva del Hombre, La Cueva del Silencio) and the Christmas Tree, which is a rock and plant formation on the side of one of the canyon walls created by a seasonal waterfall.\nThe Coffee Route begins in Tapachula and follows a mountainous road into the Suconusco regopm. The route passes through Puerto Chiapas, a port with modern infrastructure for shipping exports and receiving international cruises. The route visits a number of coffee plantations, such as Hamburgo, Chiripa, Violetas, Santa Rita, Lindavista, Per\u00fa-Par\u00eds, San Antonio Chicarras and Rancho Alegre. These haciendas provide visitors with the opportunity to see how coffee is grown and initially processed on these farms. They also offer a number of ecotourism activities such as mountain climbing, rafting, rappelling and mountain biking. There are also tours into the jungle vegetation and the Tacan\u00e1 Volcano. In addition to coffee, the region also produces most of Chiapas\u2019 soybeans, bananas and cacao.\nThe state has a large number of ecological attractions most of which are connected to water. The main beaches on the coastline include Puerto Arista, Boca del Cielo, Playa Linda, Playa Aventuras, Playa Azul and Santa Brigida. Others are based on the state's lakes and rivers. Laguna Verde is a lake in the Coapilla municipality. The lake is generally green but its tones constantly change through the day depending on how the sun strikes it. In the early morning and evening hours there can also be blue and ochre tones as well. The El Chifl\u00f3n Waterfall is part of an ecotourism center located in a valley with reeds, sugarcane, mountains and rainforest. It is formed by the San Vicente River and has pools of water at the bottom popular for swimming. The Las Nubes Ecotourism center is located in the Las Margaritas municipality near the Guatemalan border. The area features a number of turquoise blue waterfalls with bridges and lookout points set up to see them up close.\nStill others are based on conservation, local culture and other features. The Las Guacamayas Ecotourism Center is located in the Lacandon Jungle on the edge of the Montes Azules reserve. It is centered on the conservation of the red macaw, which is in danger of extinction. The Tziscao Ecotourism Center is centered on a lake with various tones. It is located inside the Lagunas de Montebello National Park, with kayaking, mountain biking and archery. Lacanj\u00e1 Chansayab is located in the interior of the Lacandon Jungle and a major Lacandon people community. It has some activities associated with ecotourism such as mountain biking, hiking and cabins. The Grutas de Rancho Nuevo Ecotourism Center is centered on a set of caves in which appear capricious forms of stalagmite and stalactites. There is horseback riding as well.\nCulture.\nArchitecture.\nArchitecture in the state begins with the archeological sites of the Mayans and other groups who established color schemes and other details that echo in later structures. After the Spanish subdued the area, the building of Spanish style cities began, especially in the highland areas.\nMany of the colonial-era buildings are related to Dominicans who came from Seville. This Spanish city had much Arabic influence in its architecture, and this was incorporated into the colonial architecture of Chiapas, especially in structures dating from the 16th to 18th centuries. However, there are a number of architectural styles and influences present in Chiapas colonial structures, including colors and patterns from Oaxaca and Central America along with indigenous ones from Chiapas.\nThe main colonial structures are the cathedral and Santo Domingo church of San Crist\u00f3bal, the Santo Domingo monastery and La Pila in Chiapa de Corzo. The San Crist\u00f3bal cathedral has a Baroque facade that was begun in the 16th century but by the time it was finished in the 17th, it had a mix of Spanish, Arabic, and indigenous influences. It is one of the most elaborately decorated in Mexico.\nThe churches and former monasteries of Santo Domingo, La Merced and San Francisco have ornamentation similar to that of the cathedral. The main structures in Chiapa de Corzo are the Santo Domingo monastery and the La Pila fountain. Santo Domingo has indigenous decorative details such as double headed eagles as well as a statue of the founding monk. In San Crist\u00f3bal, the Diego de Mazariegos house has a Plateresque facade, while that of Francisco de Montejo, built later in the 18th century has a mix of Baroque and Neoclassical. Art Deco structures can be found in San Crist\u00f3bal and Tapachula in public buildings as well as a number of rural coffee plantations from the Porfirio D\u00edaz era.\nArt and literature.\nArt in Chiapas is based on the use of color and has strong indigenous influence. This dates back to cave paintings such as those found in Sima de las Cotorras near Tuxtla Guti\u00e9rrez and the caverns of Rancho Nuevo where human remains and offerings were also found. The best-known pre-Hispanic artwork is the Maya murals of Bonampak, which are the only Mesoamerican murals to have been preserved for over 1500 years. In general, Mayan artwork stands out for its precise depiction of faces and its narrative form. Indigenous forms derive from this background and continue into the colonial period with the use of indigenous color schemes in churches and modern structures such as the municipal palace in Tapachula. Since the colonial period, the state has produced a large number of painters and sculptors. Noted 20th-century artists include L\u00e1zaro G\u00f3mez, Ramiro Jim\u00e9nez Chac\u00f3n, H\u00e9ctor Ventura Cruz, M\u00e1ximo Prado Pozo, and Gabriel Gallegos Ramos.\nThe two best-known poets from the state are Jaime Sabines and Rosario Castellanos, both from prominent Chiapan families. The first was a merchant and diplomat and the second was a teacher, diplomat, theatre director and the director of the Instituto Nacional Indigenista. Jaime Sabines is widely regarded as Mexico's most influential contemporary poet. His work celebrates everyday people in common settings.\nMusic.\nThe most important instrument in the state is the marimba. In the pre-Hispanic period, indigenous peoples had already been producing music with wooden instruments. The marimba was introduced by African slaves brought to Chiapas by the Spanish. However, it achieved its widespread popularity in the early 20th century due to the formation of the Cuarteto Marimbistico de los Hermanos G\u00f3mez in 1918, who popularized the instrument and the popular music that it plays not only in Chiapas but in various parts of Mexico and into the United States. Along with Cuban Juan Arozamena, they composed the piece \"Las chiapanecas\" considered to be the unofficial anthem of the state. In the 1940s, they were also featured in a number of Mexican films. Marimbas are constructed in Venustiano Carranza, Chiapas de Corzo and Tuxtla Guti\u00e9rrez.\nCuisine.\nLike the rest of Mesoamerica, the basic diet has been based on corn and Chiapas cooking retains strong indigenous influence. One important ingredient is chipilin, a fragrant and strongly flavored herb and hoja santa, the large anise-scented leaves used in much of southern Mexican cuisine. Chiapan dishes do not incorporate many chili peppers as part of their dishes. Rather, chili peppers are most often found in the condiments. One reason for that is that a local chili pepper, called the simojovel, is far too hot to use except very sparingly. Chiapan cuisine tends to rely more on slightly sweet seasonings in their main dishes such as cinnamon, plantains, prunes and pineapple are often found in meat and poultry dishes.\nTamales are a major part of the diet and often include chipil\u00edn mixed into the dough and hoja santa, within the tamale itself or used to wrap it. One tamale native to the state is the \"picte\", a fresh sweet corn tamale. Tamales juacanes are filled with a mixture of black beans, dried shrimp, and pumpkin seeds.\nMeats are centered on the European introduced beef, pork and chicken as many native game animals are in danger of extinction. Meat dishes are frequently accompanied by vegetables such as squash, chayote and carrots. Black beans are the favored type. Beef is favored, especially a thin cut called tasajo usually served in a sauce. Pepita con tasajo is a common dish at festivals especially in Chiapa de Corzo. It consists of a squash seed based sauced over reconstituted and shredded dried beef. As a cattle raising area, beef dishes in Palenque are particularly good. Pux-Xax\u00e9 is a stew with beef organ meats and mole sauce made with tomato, chili bolita and corn flour. Tzispol\u00e1 is a beef broth with chunks of meat, chickpeas, cabbage and various types of chili peppers. Pork dishes include cochito, which is pork in an adobo sauce. In Chiapa de Corzo, their version is cochito horneado, which is a roast suckling pig flavored with adobo. Seafood is a strong component in many dishes along the coast. Turula is dried shrimp with tomatoes. Sausages, ham and other cold cuts are most often made and consumed in the highlands.\nIn addition to meat dishes, there is chirmol, a cooked tomato sauced flavored with chili pepper, onion and cilantro and zats, butterfly caterpillars from the Altos de Chiapas that are boiled in salted water, then saut\u00e9ed in lard and eaten with tortillas, limes, and green chili pepper.\nSopa de pan consists of layers of bread and vegetables covered with a broth seasoned with saffron and other flavorings. A Comit\u00e1n speciality is hearts of palm salad in vinaigrette and Palenque is known for many versions of fried plaintains, including filled with black beans or cheese.\nCheese making is important, especially in the municipalities of Ocosingo, Rayon and Pijijiapan. Ocosingo has its own self-named variety, which is shipped to restaurants and gourmet shops in various parts of the country. Regional sweets include crystallized fruit, coconut candies, flan and compotes. San Cristobal is noted for its sweets, as well as chocolates, coffee and baked goods.\nWhile Chiapas is known for good coffee, there are a number of other local beverages. The oldest is pozol, originally the name for a fermented corn dough. This dough has its origins in the pre-Hispanic period. To make the beverage, the dough is dissolved in water and usually flavored with cocoa and sugar, but sometimes it is left to ferment further. It is then served very cold with much ice. Taxcalate is a drink made from a powder of toasted corn, achiote, cinnamon and sugar prepared with milk or water. Pumbo is a beverage made with pineapple, club soda, vodka, sugar syrup and much ice. Pox is a drink distilled from sugar cane.\nReligion.\nLike in the rest of Mexico, Christianity was introduced to the native populations of Chiapas by the Spanish conquistadors. However, Catholic beliefs were mixed with indigenous ones to form what is now called \"traditionalist\" Catholic belief. The Diocese of Chiapas comprises almost the entire state, and centered on San Cristobal de las Casas. It was founded in 1538 by Pope Paul III to evangelize the area with its most famous bishop of that time Bartolom\u00e9 de las Casas. Evangelization focused on grouping indigenous peoples into communities centered on a church. This bishop not only graciously evangelized the people in their own language, he worked to introduce many of the crafts still practiced today. While still a majority, only fifty-eight percent of Chiapas residents profess the Catholic faith as of 2010, compared to 83% of the rest of the country.\nSome indigenous people mix Christianity with Indian beliefs. One particular area where this is strong is the central highlands in small communities such as San Juan Chamula. In one church in San Cristobal, Mayan rites including the sacrifice of animals is permitted inside the church to ask for good health or to \"ward off the evil eye.\"\nStarting in the 1970s, there has been a shift away from traditional Catholic affiliation to Protestant, Evangelical and other Christian denominations. Presbyterians and Pentecostals attracted a large number of converts, with percentages of Protestants in the state rising from five percent in 1970 to twenty-one percent in 2000. This shift has had a political component as well, with those making the switch tending to identify across ethnic boundaries, especially across indigenous ethnic boundaries and being against the traditional power structure. The National Presbyterian Church in Mexico is particularly strong in Chiapas, the state can be described as one of the strongholds of the denomination.\nBoth Protestants and Word of God Catholics tend to oppose traditional cacique leadership and often worked to prohibit the sale of alcohol. The latter had the effect of attracting many women to both movements.\nThe growing number of Protestants, Evangelicals and Word of God Catholics challenging traditional authority has caused religious strife in a number of indigenous communities. Tensions have been strong, at times, especially in rural areas such as San Juan Chamula. Tension among the groups reached its peak in the 1990s with a large number of people injured during open clashes. In the 1970s, caciques began to expel dissidents from their communities for challenging their power, initially with the use of violence. By 2000, more than 20,000 people had been displaced, but state and federal authorities did not act to stop the expulsions. Today, the situation has quieted but the tension remains, especially in very isolated communities.\nIslam.\nThe Spanish Murabitun community, the \"Comunidad Isl\u00e1mica en Espa\u00f1a\", based in Granada in Spain, and one of its missionaries, Muhammad Nafia (formerly Aureliano P\u00e9rez), now emir of the Comunidad Isl\u00e1mica en M\u00e9xico, arrived in the state of Chiapas shortly after the Zapatista uprising and established a commune in the city of San Crist\u00f3bal. The group, characterized as anti-capitalistic, entered an ideological pact with the socialist Zapatistas group. President Vicente Fox voiced concerns about the influence of the fundamentalism and possible connections to the Zapatistas and the Basque terrorist organization Euskadi Ta Askatasuna (ETA), but it appeared that converts had no interest in political extremism. By 2015, many indigenous Mayans and more than 700 Tzotzils have converted to Islam. In San Crist\u00f3bal, the Murabitun established a pizzeria, a carpentry workshop and a Quranic school (madrasa) where children learned Arabic and prayed five times a day in the backroom of a residential building, and women in head scarves have become a common sight. Nowadays, most of the Mayan Muslims have left the Murabitun and established ties with the CCIM, now following the orthodox Sunni school of Islam. They built the Al-Kausar Mosque in San Cristobal de las Casas. Nevertheless, the vast majority of Native Mexicans today are Non-Muslims.\nArchaeology.\nThe earliest population of Chiapas was in the coastal Soconusco region, where the Chantuto peoples appeared, going back to 5500 BC. This was the oldest Mesoamerican culture discovered to date.\nThe largest and best-known archaeological sites in Chiapas belong to the Mayan civilization. Apart from a few works by Franciscan friars, knowledge of Maya civilisation largely disappeared after the Spanish Conquest. In the mid-19th century, John Lloyd Stephens and Frederick Catherwood traveled though the sites in Chiapas and other Mayan areas and published their writings and illustrations. This led to serious work on the culture including the deciphering of its hieroglyphic writing.\nIn Chiapas, principal Mayan sites include Palenque, Tonin\u00e1, Bonampak, Chinkoltic and Tenam Puentes, all or near in the Lacandon Jungle. They are technically more advanced than earlier Olmec sites, which can best be seen in the detailed sculpting and novel construction techniques, including structures of four stories in height. Mayan sites are not only noted for large numbers of structures, but also for glyphs, other inscriptions, and artwork that has provided a relatively complete history of many of the sites.\nPalenque is the most important Mayan and archaeological site. Though much smaller than the huge sites at Tikal or Cop\u00e1n, Palenque contains some of the finest architecture, sculpture and stucco reliefs the Mayans ever produced. The history of the Palenque site begins in 431 with its height under Pakal I (615\u2013683), Chan-Bahlum II (684\u2013702) and Kan-Xul who reigned between 702 and 721. However, the power of Palenque would be lost by the end of the century. Pakal's tomb was not discovered inside the Temple of Inscriptions until 1949. Today, Palenque is a World Heritage Site and one of the best-known sites in Mexico.\nYaxchilan flourished in the 8th and 9th centuries. The site contains impressive ruins, with palaces and temples bordering a large plaza upon a terrace above the Usumacinta River. The architectural remains extend across the higher terraces and the hills to the south of the river, overlooking both the river itself and the lowlands beyond. Yaxchilan is known for the large quantity of excellent sculpture at the site, such as the monolithic carved stelae and the narrative stone reliefs carved on lintels spanning the temple doorways. Over 120 inscriptions have been identified on the various monuments from the site. The major groups are the Central Acropolis, the West Acropolis and the South Acropolis. The South Acropolis occupies the highest part of the site. The site is aligned with relation to the Usumacinta River, at times causing unconventional orientation of the major structures, such as the two ballcourts.\nThe city of Bonampak features some of the finest remaining Maya murals. The realistically rendered paintings depict human sacrifices, musicians and scenes of the royal court. In fact the name means \u201cpainted murals.\u201d It is centered on a large plaza and has a stairway that leads to the Acropolis. There are also a number of notable steles.\nTonin\u00e1 is near the city of Ocosingo with its main features being the Casa de Piedra (House of Stone) and Acropolis. The latter is a series of seven platforms with various temples and steles. This site was a ceremonial center that flourished between 600 and 900 CE.\nThe capital of \u00a0Sak Tz\u2019i\u2019 (an Ancient Maya kingdom) now named Lacanja Tzeltal, was revealed by researchers led by associate anthropology professor Charles Golden and bioarchaeologist Andrew Scherer in the Chiapas in the backyard of a Mexican farmer in 2020.\nMultiple domestic constructions used by the population for religious purposes. \u201cPlaza Muk\u2019ul Ton\u201d or Monuments Plaza where people used to gather for ceremonies was also unearthed by the team.\nPre-Mayan cultures.\nWhile the Mayan sites are the best-known, there are a number of other important sites in the state, including many older than the Maya civilization.\nThe oldest sites are in the coastal Soconusco region. This includes the Mokaya culture, the oldest ceramic culture of Mesoamerica. Later, Paso de la Amada became important. Many of these sites are in Mazatan, Chiapas area.\nIzapa became an important pre-Mayan site as well.\nThere are also other ancient sites including Tapachula and Tepcat\u00e1n, and Pijijiapan. These sites contain numerous embankments and foundations that once lay beneath pyramids and other buildings. Some of these buildings have disappeared and others have been covered by jungle for about 3,000 years, unexplored.\nPijijiapan and Izapa are on the Pacific coast and were the most important pre Hispanic cities for about 1,000 years, as the most important commercial centers between the Mexican Plateau and Central America. Sima de las Cotorras is a sinkhole 140 meters deep with a diameter of 160 meters in the municipality of Ocozocoautla. It contains ancient cave paintings depicting warriors, animals and more. It is best known as a breeding area for parrots, thousands of which leave the area at once at dawn and return at dusk. The state as its Museo Regional de Antropologia e Historia located in Tuxtla Guti\u00e9rrez focusing on the pre Hispanic peoples of the state with a room dedicated to its history from the colonial period.\nEducation.\nThe average number of years of schooling is 6.7, which is the beginning of middle school, compared to the Mexico average of 8.6. 16.5% have no schooling at all, 59.6% have only primary school/secondary school, 13.7% finish high school or technical school and 9.8% go to university. Eighteen out of every 100 people 15 years or older cannot read or write, compared to 7/100 nationally. Most of Chiapas\u2019 illiterate population are indigenous women, who are often prevented from going to school. School absenteeism and dropout rates are highest among indigenous girls.\nThere are an estimated 1.4\u00a0million students in the state from preschool on up. The state has about 61,000 teachers and just over 17,000 centers of educations. Preschool and primary schools are divided into modalities called general, indigenous, private and community educations sponsored by CONAFE. Middle school is divided into technical, telesecundaria (distance education) and classes for working adults. About 98% of the student population of the state is in state schools. Higher levels of education include \"professional medio\" (vocational training), general high school and technology-focused high school. At this level, 89% of students are in public schools. There are 105 universities and similar institutions with 58 public and 47 private serving over 60,500 students.\nThe state university is the Universidad Aut\u00f3noma de Chiapas (UNACH). It was begun when an organization to establish a state level institution was formed in 1965, with the university itself opening its doors ten years later in 1975. The university project was partially supported by UNESCO in Mexico. It integrated older schools such as the Escuela de Derecho (Law School), which originated in 1679; the Escuela de Ingenier\u00eda Civil (School of Civil Engineering), founded in 1966; and the Escuela de Comercio y Administraci\u00f3n, which was located in Tuxtla Guti\u00e9rrez.\nInfrastructure.\nTransport.\nThe state has approximately of highway with 10,857 federally maintained and 11,660 maintained by the state. Almost all of these kilometers are paved. Major highways include the Las Choapas-Raudales-Ocozocoautla, which links the state to Oaxaca, Veracruz, Puebla and Mexico City. Major airports include Llano San Juan in Ocozocoautla, Francisco Sarabia National Airport (which was replaced by \u00c1ngel Albino Corzo International Airport) in Tuxtla Guti\u00e9rrez and Coraz\u00f3n de Mar\u00eda Airport (which closed in 2010) in San Crist\u00f3bal de las Casas. These are used for domestic flights with the airports in Palenque and Tapachula providing international service into Guatemala. There are 22 other airfields in twelve other municipalities. Rail lines extend over 547.8\u00a0km. There are two major lines: one in the north of the state that links the center and southeast of the country, and the Costa Panamericana route, which runs from Oaxaca to the Guatemalan border.\nChiapas' main port is just outside the city of Tapachula called the Puerto Chiapas. It faces of ocean, with of warehouse space. Next to it there is an industrial park that covers . Puerto Chiapas has of area with a capacity to receive 1,800 containers as well as refrigerated containers. The port serves the state of Chiapas and northern Guatemala. Puerto Chiapas serves to import and export products across the Pacific to Asia, the United States, Canada and South America. It also has connections with the Panama Canal. A marina serves yachts in transit.\nThere is an international airport located away as well as a railroad terminal ending at the port proper. Over the past five years the port has grown with its newest addition being a terminal for cruise ships with tours to the Izapa site, the Coffee Route, the city of Tapachula, Pozuelos Lake and an Artesanal Chocolate Tour. Principal exports through the port include banana and banana trees, corn, fertilizer and tuna.\nMedia.\nThere are thirty-six AM radio stations and sixteen FM stations. There are thirty-seven local television stations and sixty-six repeaters. Newspapers of Chiapas include: \"Chiapas Hoy\", \"Cuarto Poder \", \"El Heraldo de Chiapas\", \"El Orbe\", \"La Voz del Sureste\", and \"Noticias de Chiapas.\""}
{"id": "6788", "revid": "12416903", "url": "https://en.wikipedia.org/wiki?curid=6788", "title": "Chrysler Building", "text": "The Chrysler Building is an Art Deco skyscraper in the Turtle Bay neighborhood on the East Side of Manhattan, New York City, at the intersection of 42nd Street and Lexington Avenue near Midtown Manhattan. At , it is the tallest brick building in the world with a steel framework, and was the world's tallest building for 11 months after its completion in 1930. , the Chrysler is the 11th-tallest building in the city, tied with The New York Times Building.\nOriginally a project of real estate developer and former New York State Senator William H. Reynolds, the building was constructed by Walter Chrysler, the head of the Chrysler Corporation. The construction of the Chrysler Building, an early skyscraper, was characterized by a competition with 40 Wall Street and the Empire State Building to become the world's tallest building. Although the Chrysler Building was built and designed specifically for the car manufacturer, the corporation did not pay for its construction and never owned it; Walter Chrysler decided to fund the entire cost so his children could inherit it. An annex was completed in 1952, and the building was sold by the Chrysler family the next year, with numerous subsequent owners.\nWhen the Chrysler Building opened, there were mixed reviews of the building's design, ranging from views of it as inane and unoriginal to the idea that it was modernist and iconic. Perceptions of the building have slowly evolved into its now being seen as a paragon of the Art Deco architectural style; and in 2007, it was ranked ninth on the \"List of America's Favorite Architecture\" by the American Institute of Architects. The building was designated a New York City landmark in 1978, and was added to the National Register of Historic Places as a National Historic Landmark in 1976.\nSite.\nThe Chrysler Building is on the eastern side of Lexington Avenue between 42nd and 43rd streets. The land was donated to The Cooper Union for the Advancement of Science and Art in 1902. The site is roughly a trapezoid with a frontage on Lexington Avenue; a frontage on 42nd Street; and a frontage on 43rd Street. The site bordered the old Boston Post Road, which predated, and ran aslant of, the Manhattan street grid established by the Commissioners' Plan of 1811. As a result, the east side of the building's base is similarly aslant.\nThe Grand Hyatt New York hotel and the Graybar Building are across Lexington Avenue, while the Socony\u2013Mobil Building is across 42nd Street. In addition, the Chanin Building is to the southwest, diagonally across Lexington Avenue and 42nd Street.\nHistory.\nContext.\nIn the mid-1920s, New York's metropolitan area surpassed\u00a0London's as the world's most populous metropolitan area and its population exceeded ten million by the early 1930s. The era was characterized by profound social and technological changes. Consumer goods such as radio, cinema, and the automobile became widespread.\u00a0In 1927, Walter Chrysler's automotive company, the Chrysler Corporation, became the third-largest car manufacturer in the United States, behind\u00a0Ford and\u00a0General Motors. The following year, Chrysler was named \"Time\"\u00a0magazine's \"Person of the Year\".\nThe economic boom of the 1920s and speculation in the real estate market fostered a wave of new skyscraper projects in New York City. The Chrysler Building was built as part of an ongoing building boom that resulted in the city having the world's tallest building from 1908 to 1974. Following the end of World War I, European and American architects came to see simplified design as the epitome of the modern era and Art Deco skyscrapers as symbolizing progress, innovation, and modernity. The 1916 Zoning Resolution restricted the height that street-side exterior walls of New York City buildings could rise before needing to be setback from the street. This led to the construction of Art Deco structures in New York City with significant setbacks, large volumes, and striking silhouettes that were often elaborately decorated. Art Deco buildings were constructed for only a short period of time; but because that period was during the city's late-1920s\u00a0real\u00a0estate\u00a0boom, the numerous skyscrapers built in the Art Deco style predominated in the city skyline, giving it the romantic quality seen in films and plays. The Chrysler Building project was shaped by these circumstances.\nDevelopment.\nPlanning.\nOriginally, the Chrysler Building was to be the Reynolds Building, a project of real estate developer and former\u00a0New York State\u00a0Senator William\u00a0H. Reynolds. Prior to his involvement in planning the building, Reynolds was best known for developing Coney Island's Dreamland amusement park.\u00a0When the amusement park was destroyed by fire in 1911, Reynolds turned his attention to\u00a0Manhattan real estate, where he set out to build the tallest building in the world.\nIn 1921, Reynolds rented a large plot of land at the corner of Lexington Avenue and 42nd Street with the intention of building a tall building on the site. In 1927, after several years of delays, Reynolds hired the architect\u00a0William Van Alen to design a forty-story building there. Van Alen's original design featured many Modernist stylistic elements, with glazed, curved windows at the corners.\nVan Alen was respected in his field for his work on the Albemarle Building at Broadway and 24th Street, designing it in collaboration with his partner\u00a0H. Craig Severance.\u00a0Van Alen and Severance complemented each other, with Van Alen being an original, imaginative architect and Severance being a shrewd businessperson who handled the firm's finances.\u00a0However, the relationship between them became tense over disagreements on how best to run the firm.\u00a0The breaking point came after a 1924 article in the\u00a0\"Architectural Review\", praising the Albemarle Building's design; Van Alen was attributed as the designer in the firm, while Severance's\u00a0role was altogether ignored. The architects' partnership dissolved acrimoniously several months later, with lawsuits over the firm's clients and assets lasting over a year. The rivalry ended up being decisive for the design of the future Chrysler Building, since Severance's more traditional architectural style would otherwise have restrained Van Alen's more modern outlook.\nRefinement of designs.\nBy February 2, 1928, the proposed building's height had been increased to 54 stories, which would have made it the tallest building in Midtown. The proposal was changed again two weeks later, with official plans for a 63-story building. A little more than a week after that, the plan was changed for the third time, with two additional stories added. By this time, 42nd Street and Lexington Avenue were both hubs for construction activity, due to the removal of the Third Avenue Elevated's 42nd Street spur, which was seen as a blight on the area. The adjacent 56-story Chanin Building was also under construction. Because of the elevated spur's removal, real estate speculators believed that Lexington Avenue would become the \"Broadway of the East Side\", causing a ripple effect that would spur developments farther east.\nIn April 1928, Reynolds signed a 67-year lease for the plot and finalized the details of his ambitious project. Van Alen's original design for the skyscraper called for a base with first-floor showroom windows that would be triple-height, and above would be 12 stories with glass-wrapped corners, to create the impression that the tower was floating in mid-air. Reynolds's main contribution to the building's design was his insistence that it have a metallic crown, despite Van Alen's initial opposition; the metal-and-crystal crown would have looked like \"a jeweled sphere\" at night. Originally, the skyscraper would have risen , with 67 floors. These plans were approved in June 1928. Van Alen's drawings were unveiled in the following August and published in a magazine run by the\u00a0American Institute of Architects (AIA).\nEventually, this design would prove too advanced and expensive for Reynolds. He instead devised an alternate design for the Reynolds Building, which was published in August 1928. The new design was much more conservative, with an Italianate dome that a critic compared to Governor Al Smith's bowler hat, and a brick arrangement on the upper floors that simulated windows in the corners, a detail that remains in the current Chrysler Building. This design almost exactly reflected the shape, setbacks, and the layout of the windows of the current building, but with a different dome.\nFinal plans and start of construction.\nWith the design complete, groundbreaking for the Reynolds Building took place on September 19, 1928, but Reynolds did not have the means to carry on construction. Reynolds sold the plot, lease, plans, and architect's services to Walter Chrysler for $2 million on October 15, 1928. That same day, the Goodwin Construction Company began demolition of what had been built. A contract was awarded on October 28, and demolition was completed on November 9. Chrysler's initial plans for the building were similar to Reynolds's, but with the 808-foot building having 68 floors instead of 67. The plans entailed a ground-floor pedestrian arcade; a facade of stone below the fifth floor and brick-and-terracotta above; and a three-story bronze-and-glass \"observation dome\" at the top. However, Chrysler wanted a more progressive design, and he worked with Van Alen to redesign the skyscraper to be tall. At the new height, Chrysler's building would be taller than the Woolworth Building, a building in lower Manhattan that was the world's tallest at the time. At one point, Chrysler had requested that Van Alen shorten the design by ten floors, but reneged on that decision after realizing that the increased height would also result in increased publicity.\nFrom late 1928 to early 1929, modifications to the design of the dome continued. In March 1929, the press published details of an \"artistic dome\" that had the shape of a giant thirty-pointed star, which would be crowned by a sculpture five meters high. The final design of the dome included several arches and triangular windows. Lower down, the design was affected by Walter Chrysler's intention to make the building the Chrysler Corporation's headquarters, and as such, various architectural details were modeled after Chrysler automobile products, such as the hood ornaments of the Plymouth (see ). The building's gargoyles on the 31st floor and the eagles on the 61st floor, were created to represent flight, and to embody the machine age of the time. Even the topmost needle was built using a process similar to one Chrysler used to manufacture his cars, with precise \"hand craftmanship\". In his autobiography, Chrysler says he suggested that his building be taller than the Eiffel Tower.\nMeanwhile, excavation of the new building's foundation began in mid-November 1928 and was completed in mid-January 1929, when bedrock was reached. A total of of rock and of soil was excavated for the foundation, equal to 63% of the future building's weight. Construction of the building proper began on January 21, 1929. The Carnegie Steel Company provided the steel beams, the first of which was installed on March 27; and by April 9, the first upright beams had been set into place. The steel structure was \"a few floors\" high by June 1929, 35 floors high by early August, and completed by September. Despite a frantic steelwork construction pace of about four floors per week, no workers died during the construction of the skyscraper's steelwork. Chrysler lauded this achievement, saying, \"It is the first time that any structure in the world has reached such a height, yet the entire steel construction was accomplished without loss of life\". In total, 391,881 rivets were used, and approximately 3,826,000 bricks were manually laid to create the non-loadbearing walls of the skyscraper. Walter Chrysler personally financed the construction with his income from his car company. The Chrysler Building's height officially surpassed the Woolworth's on October 16, 1929, thereby becoming the world's tallest structure.\nCompetition for \"world's tallest building\" title.\nThe same year that the Chrysler Building's construction started, banker George L. Ohrstrom proposed the construction of a 47-story office building at 40 Wall Street downtown. Shortly thereafter Ohrstrom modified his project to have 60 floors, but it was still below Woolworth and the 808-foot Chrysler Building project as announced in 1928. H. Craig Severance, Van Alen's former partner and the architect of 40 Wall Street, increased 40 Wall's height to with 62 floors in April of that year. It would thus exceed the Woolworth's height by and the Chrysler's by . 40 Wall Street and the Chrysler Building started competing for the distinction of \"world's tallest building\". The Empire State Building, on 34th Street and Fifth Avenue, entered the competition in 1929. The race was defined by at least five other proposals, although only the Empire State Building would survive the Wall Street Crash of 1929. The \"Race into the Sky\", as popular media called it at the time, was representative of the country's optimism in the 1920s, which helped fuel the building boom in major cities. The 40 Wall Street tower was revised from to 925 feet in April 1929, which would make it the world's tallest. Severance then publicly claimed the title of the world's tallest building. Construction of 40 Wall Street began in May 1929 at a frantic pace, and it was completed twelve months later.\nIn response, Van Alen obtained permission for a spire and had it secretly constructed inside the frame of his building. The spire was delivered to the site in four different sections. On October 23, 1929, one week after surpassing the Woolworth Building's height and one day before the catastrophic Wall Street Crash of 1929 started, the spire was assembled. According to one account, \"the bottom section of the spire was hoisted to the top of the building's dome and lowered into the 66th floor of the building.\" Then, within 90 minutes the rest of the spire's pieces were raised and riveted in sequence, helping raise the tower's height to 1,046 feet. Van Alen, who witnessed the process from the street along with its engineers and Walter Chrysler, compared the experience to watching a butterfly leaving its cocoon.\nIn \"The Structure and Metal Work of the Chrysler Building\", an article published in the October 1930 edition of \"Architectural Forum\", Van Alen explained the design and construction of the crown and needle:\nThe steel tip brought the Chrysler Building to a height of , greatly exceeding 40 Wall Street's height. However, contemporary news media did not write of the spire's erection, nor were there any press releases celebrating the spire's erection. Even the \"New York Herald Tribune\", which had virtually continuous coverage of the tower's construction, did not report on the spire's installation until days after the spire had been raised.\nChrysler realized that his tower's height would exceed the Empire State Building's as well, having ordered Van Alen to change the Chrysler's original roof from a stubby Romanesque dome to the narrow steel spire. However, the Empire State's developer John J. Raskob reviewed the plans and realized that he could add five more floors and a spire of his own to his 80-story building, and subsequently acquired the nearby plots needed to support that building's height extension. Two days later, the Empire State Building's co-developer, former Governor Al Smith, announced the updated plans for that skyscraper, with an observation deck on the 86th-floor roof at a height of , higher than the Chrysler's 71st-floor observation deck at .\nCompletion.\nIn January 1930, it was announced that the Chrysler Corporation would maintain offices in the Chrysler Building during Automobile Show Week, and the first leases by outside tenants were announced in April 1930, before the building was officially completed. The building was formally opened on May 27, 1930, in a ceremony that coincided with the 42nd Street Property Owners and Merchants Association's meeting that year. In the lobby of the building, a bronze plaque that read \"in recognition of Mr. Chrysler's contribution to civic advancement\" was unveiled. Former Governor Smith, former Assemblyman Martin G. McCue, and 42nd Street Association president George W. Sweeney were among those in attendance. By June, it was reported that 65% of the available space had been leased. By August, the building was declared complete, but the New York City Department of Construction did not mark it as finished until February 1932.\nThe added height of the spire allowed the Chrysler Building to surpass 40 Wall Street as the tallest building in the world and the Eiffel Tower as the tallest structure. The Chrysler Building was thus the first man-made structure to be taller than ; and as one newspaper noted, the tower was also taller than the highest points of five states. The Chrysler Building was appraised at $14 million, but was exempt from city taxes per an 1859 law that gave tax exemptions to sites owned by the Cooper Union. The city had attempted to repeal the tax exemption, but Cooper Union had opposed that measure. Because the Chrysler Building retains the tax exemption, it has paid Cooper Union for the use of their land since opening.\nVan Alen's satisfaction at these accomplishments was likely muted by Walter Chrysler's later refusal to pay the balance of his architectural fee. Chrysler alleged that Van Alen had received bribes from suppliers, and Van Alen had not signed any contracts with Walter Chrysler when he took over the project. Van Alen sued and the courts ruled in his favor, requiring Chrysler to pay Van Alen $840,000, or 6% of the total budget of the building. However, the lawsuit against Chrysler markedly diminished Van Alen's reputation as an architect, which, along with the effects of the Great Depression and negative criticism, ended up ruining his career. Van Alen ended his career as professor of sculpture at the nearby Beaux-Arts Institute of Design and died in 1954. According to author Neal Bascomb, \"The Chrysler Building was his greatest accomplishment, and the one that guaranteed his obscurity.\"\nThe Chrysler Building's distinction as the world's tallest building was short-lived. John Raskob realized the 1,050-foot Empire State Building would only be taller than the Chrysler Building, and Raskob was afraid that Walter Chrysler might try to \"pull a trick like hiding a rod in the spire and then sticking it up at the last minute.\" Another revision brought the Empire State Building's roof to , making it the tallest building in the world by far when it opened on May 1, 1931. However, the Chrysler Building is still the world's tallest steel-supported brick building. The Chrysler Building fared better commercially than the Empire State Building did: by 1935, the Chrysler had already rented 70% of its floor area, while the Empire State had only leased 23% of its area and was popularly derided as the \"Empty State Building\".\nThe Chrysler Corporation was not involved in the construction or ownership of the Chrysler Building, although it was built and designed for the corporation. It was a project of Walter P. Chrysler for his children. In his autobiography, Chrysler wrote that he wanted to erect the building \"so that his sons would have something to be responsible for\".\nUse.\n20th century.\nThe Chrysler family inherited the property after the death of Walter Chrysler in 1940, with the property being under the ownership of W.P. Chrysler Building Corporation. In 1944, the corporation filed plans to build a 38-story annex to the east of the building, at 666 Third Avenue. In 1949, this was revised to a 32-story annex costing $9 million. The annex building, designed by Reinhard, Hofmeister &amp; Walquist, had a facade similar to that of the original Chrysler Building. The stone for the original building was no longer manufactured, and had to be specially replicated. Construction started on the annex in June 1950, and the first tenants started leasing in June 1951. The building itself was completed by 1952, and a sky bridge connecting the two buildings' seventh floors was built in 1959.\nThe family sold the building in 1953 to William Zeckendorf for its assessed price of $18 million. The 1953 deal included the annex and the nearby Graybar Building, which along with the Chrysler Building sold for a combined $52 million. The new owners were Zeckendorf's company Webb and Knapp, who held a 75% interest in the sale, and the Graysler Corporation, who held a 25% stake. At the time, it was reported to be the largest real estate sale in New York City's history. In 1957, the Chrysler Building, its annex, and the Graybar Building were sold for $66 million to Lawrence Wien's realty syndicate, setting a new record for the largest sale in the city. In 1960, the complex was purchased by Sol Goldman and Alex DiLorenzo, who received a mortgage from the Massachusetts Mutual Life Insurance Company. In 1961, the building's stainless steel elements, including the needle, crown, gargoyles, and entrance doors, were polished for the first time. A group of ten workers steam-cleaned the facade below the 30th floor, and manually cleaned the portion of the tower above the 30th floor, for a cost of about $200,000.\nMassachusetts Mutual obtained outright ownership in 1975 after Goldman and DiLorenzo defaulted on the mortgage. The company purchased the building for $35 million. In 1978, they devised plans to renovate the facade, heating, ventilation, air\u2010conditioning, elevators, lobby murals, and Cloud Club headquarters in a $23 million project. This renovation was completed in 1979. They delegated the leasing of the building's space to the Edward S. Gordon Company, which leased of vacant space within five years. During Massachusetts Mutual's ownership of the Chrysler Building, the tower received two historic designations. The building was designated as a National Historic Landmark in 1976, and as a New York City Landmark in 1978, although the city only landmarked the lobby and facade. Massachusetts Mutual had opposed the city landmark designation because it \"would cause 'inevitable delay' in moving new tenants into the skyscraper\". At the time, the building had of vacant floor space, representing 40% of the total floor area. In September 1979, the building was sold again, this time to entrepreneur and Washington Redskins owner Jack Kent Cooke, in a deal that also transferred ownership of the Los Angeles Kings and Lakers to Jerry Buss.\nThe spire underwent a restoration that was completed in 1995. The joints in the now-closed observation deck were polished, and the facade restored, as part of a $1.5 million project. Some damaged steel strips of the needle were replaced and several parts of the gargoyles were re-welded together. The cleaning received the New York Landmarks Conservancy's Lucy G. Moses Preservation Award for 1997. Cooke died in 1997, and creditors moved to foreclose on the estate's unpaid fees soon after. Tishman Speyer Properties and the Travelers Insurance Group bought the Chrysler Center in 1997\u20131998 for about $220\u00a0million (equal to $ million in ) from a consortium of banks and the estate of Jack Kent Cooke. Tishman Speyer Properties had negotiated a 150-year lease from the Cooper Union, and the college continues to own the land under the Chrysler Building. Cooper Union's name is on the deed.\n21st century.\nIn 2001, a 75% stake in the building was sold, for US$300 million (equal to $ million in ), to TMW, the German arm of an Atlanta-based investment fund. In June 2008, it was reported that the Abu Dhabi Investment Council was in negotiations to buy TMW's 75% economic interest, a 15% interest from Tishman Speyer Properties in the building, and a share of the Trylons retail structure next door for US$800 million. In July 2008, it was announced that the transaction had been completed, and that the Abu Dhabi Investment Council was now 90% owner of the building, with Tishman Speyer retaining 10%.\nFrom 2010 to 2011, the building's energy, plumbing, and waste management systems were renovated. This resulted in a 21% decrease in the building's total energy consumption, a 64% decrease in water consumption, and an 81% rate of waste being recycled. In 2012, the building received a LEED Gold accreditation from the U.S. Green Building Council, which recognized the building's environmental sustainability and energy efficiency.\nThe Abu Dhabi Investment Council and Tishman Speyer put the Chrysler Building on sale again in January 2019. It was reported in March 2019 that Aby Rosen's RFR Holding LLC, in a joint venture with the Austrian SIGNA Group, had reached an agreement to purchase the Chrysler Building, albeit at a steeply discounted price, for US$150 million.\nDesign.\nThe Chrysler Building is considered a leading example of Art Deco architecture. It is constructed of a steel frame in-filled with masonry, with areas of decorative metal cladding. The structure contains 3,862 exterior windows. Approximately fifty metal ornaments protrude at the building's corners on five floors reminiscent of gargoyles on Gothic cathedrals. The 31st-floor contains gargoyles and replicas of the 1929 Chrysler radiator caps, the 61st-floor eagles, a nod to America's national bird.\nThe Chrysler Building uses bright \"Nirosta\" stainless steel extensively in its design, an austenitic alloy developed in Germany by Krupp (a German acronym for \"nichtrostender Stahl\", meaning \"non-rusting steel\"). It was the first use of this \"18-8 stainless steel\" in an American project, composed of 18% chromium and 8% nickel. Nirosta was used in the exterior ornaments, the window frames, the crown, and the needle. The steel was an integral part of Van Alen's design, as E.E. Thum explains: \"The use of permanently bright metal was of greatest aid in the carrying of rising lines and the diminishing circular forms in the roof treatment, so as to accentuate the gradual upward swing until it literally dissolves into the sky...\" Stainless steel producers used the Chrysler Building to evaluate the durability of the product in architecture. In 1929, the American Society for Testing Materials created an inspection committee to study its performance, which regarded the Chrysler Building as the best location to do so; a subcommittee examined the building's panels every five years until 1960, when the inspections were canceled because the panels had shown minimal deterioration.\nForm.\nThe Chrysler Building's height and legally mandated setbacks influenced Van Alen in his design. The walls of the lowermost sixteen floors rise directly from the sidewalk property lines, except for a recess on one side that gives the building a \"U\"-shaped floor plan above the fourth floor. There are setbacks on floors 16, 18, 23, 28, and 31, making the building compliant with the 1916 Zoning Resolution. This gives the building the appearance of a ziggurat on one side and a U-shaped palazzo on the other. Above the 31st floor, there are no more setbacks until the 60th floor, above which the structure is funneled into a Maltese cross shape that \"blends the square shaft to the finial\", according to author and photographer Cervin Robinson.\nThe floor plans of the first sixteen floors were made as large as possible to optimize the amount of rental space nearest ground level, which was seen as most desirable. The U-shaped cut above the fourth floor served as a shaft for air flow and illumination. The area between floors 28 and 31 added \"visual interest to the middle of the building, preventing it from being dominated by the heavy detail of the lower floors and the eye-catching design of the finial. They provide a base to the column of the tower, effecting a transition between the blocky lower stories and the lofty shaft.\"\nFacade.\nBase and shaft.\nThe ground floor exterior is covered in polished black granite from Shastone, while the three floors above it are clad in white marble from Georgia. There are two main entrances, on Lexington Avenue and on 42nd Street, each three floors high with Shastone granite surrounding each proscenium-shaped entryway. At some distance into each main entryway, there are revolving doors \"beneath intricately patterned metal and glass screens\", designed so as to embody the Art Deco tenet of amplifying the entrance's visual impact. A smaller side entrance on 43rd Street is one story high. There are storefronts consisting of large Nirosta-steel-framed windows at ground level, with office windows on the second through fourth floors.\nThe west and east elevations of the building contain the air shafts above the fourth floor, while the north and south sides contain the receding setbacks. Below the 16th floor, the facade is clad with white brick interrupted by white-marble bands in a manner similar to a basket weaving. The windows, arranged in grids, do not have window sills, the frames being flush with the facade. Between the 16th and 24th floors, the exterior exhibits vertical white brick columns that are separated by windows on each floor. This visual effect is made possible by the presence of aluminum spandrels between the columns of windows on each floor. There are abstract reliefs on the 20th through 22nd-floor spandrels, while the 24th floor contains decorative pineapples.\nAbove the third setback, consisting of the 24th through 27th floors, the facade contains horizontal bands and zigzagged gray-and-black brick motifs. The section above the fourth setback, between the 27th and 31st floors, serves as a podium for the main shaft of the building. At each corner of the 31st floor, large car-hood ornaments made of Nirosta steel serve as visually striking objects that make the base look larger. These corner extensions help counter a common optical illusion seen in tall buildings with horizontal bands, whose taller floors would normally look larger. The 31st floor also contains a gray and white frieze of hubcaps and fenders, which symbolizes both the Chrysler Corporation and serves as a visual signature of the building's Art Deco design. The bonnet embellishments take the shape of Mercury's winged helmet and resemble hood ornaments installed on Chrysler vehicles at the time.\nThe shaft of the tower was designed to emphasize both the horizontal and vertical: each of the tower's four sides contains three columns of windows, each framed by bricks and an unbroken marble pillar that rises along the entirety of each side. The spandrels separating the windows contain \"alternating vertical stripes in gray and white brick\", while each corner contains horizontal rows of black brick.\nCrown and spire.\nThe Chrysler Building is renowned for, and recognized by, its terraced crown, which is an extension of the main tower. Composed of seven radiating terraced arches, Van Alen's design of the crown is a cruciform groin vault of seven concentric members with transitioning setbacks, mounted one behind another. The entire crown is clad with Nirosta steel, ribbed and riveted in a radiating sunburst pattern with many triangular vaulted windows, reminiscent of the spokes of a wheel. The windows are repeated, in smaller form, on the terraced crown's seven narrow setbacks. Due to the curved shape of the dome, the Nirosta sheets had to be measured on site, so most of the work was carried out in workshops on the building's 67th and 75th floors. According to Robinson, the terraced crown \"continue[s] the wedding-cake layering of the building itself. This concept is carried forward from the 61st floor, whose eagle gargoyles echo the treatment of the 31st, to the spire, which extends the concept of 'higher and narrower' forward to infinite height and infinitesimal width. This unique treatment emphasizes the building's height, giving it an other worldly atmosphere reminiscent of the fantastic architecture of Coney Island or the Far East.\"\nTelevision station WCBS-TV (Channel 2) originated its transmission from the top of the Chrysler Building in 1938. WCBS-TV transmissions were shifted to the Empire State Building in 1960 in response to competition from RCA's transmitter on that building. For many years WPAT-FM and WTFM (now WKTU) also transmitted from the Chrysler Building, but their move to the Empire State Building by the 1970s ended commercial broadcasting from the structure.\nThe crown and spire are illuminated by a combination of fluorescent lights framing the crown's distinctive triangular windows and colored floodlights that face toward the building, allowing it to be lit in a variety of schemes for special occasions. The V-shaped fluorescent \"tube lighting\" \u2013 hundreds of 480V 40W bulbs framing 120 window openings \u2013 was added in 1981, although it had been part of the original design. Until 1998, the lights were turned off at 2\u00a0a.m., but \"The New York Observer\" columnist Ron Rosenbaum convinced Tishman Speyer to keep the lights on until 6\u00a0a.m. Since 2015, the Chrysler Building and other city skyscrapers have been part of the Audubon Society's Lights Out program, turning off their lights during bird migration seasons.\nInterior.\nThe interior of the building contains several innovative elements. The partitions between the offices are soundproofed and divided into interchangeable sections, so that the layout of any could be changed quickly and comfortably. Pipes under the floors carry both telephone and electricity cables.\nLobby.\nThe triangular lobby is regarded as a paragon of the Art Deco style, with clear influences of German Expressionism. Chrysler wanted the design to impress other architects and automobile magnates, so he imported various materials without giving consideration to the extra costs incurred. He covered the walls with huge slabs of African red granite. On the floor, he marked a path from the entrances to the elevators using travertine from Siena. Originally, Van Alen's plans for the lobby included four large supporting columns, but they were removed after Chrysler objected on the grounds that the columns made the lobby appear \"cramped\". Opposite the main entrance is a security guard's desk topped by a digital clock.\nThe lobby has dim lighting that gives it a somewhat subdued quality, although the appliqu\u00e9s of the lamps are striking and iconic. Both combine to create an intimate atmosphere and act to highlight the place. Vertical bars of fluorescent light are covered with Belgian blue marble and Mexican amber onyx, which soften and diffuse the light, to both illuminate and blend with the red marble walls. The lobby also contains four elevator banks, each with a different design.\nThe ceiling contains a mural named \"Transport and Human Endeavor\", commissioned from Edward Trumbull in 1930. The mural's theme is \"energy and man's application of it to the solution of his problems\", and it pays homage to the Golden Age of Aviation and the Machine Age. The mural is painted in the shape of a \"Y\" with ocher and golden tones. The central image of the mural is a \"muscled giant whose brain directs his boundless energy to the attainment of the triumphs of this mechanical era\", according to a 1930 pamphlet that advertised the building. The mural's Art Deco style is manifested in characteristic triangles, sharp angles, slightly curved lines, chrome ornaments, and numerous patterns. The mural depicts several silver planes, including the \"Spirit of St. Louis\", as well as furnaces of incandescent steel and the building itself. There is a wall panel dedicated to the work of clinchers, surveyors, masons, carpenters, plasterers, and builders. Fifty different figures were modeled after workers who participated in its construction. In 1999, the mural was returned to its original state after a restoration that removed the polyurethane coating and filled-in holes added in the 1970s.\nPresently, the lobby is the only publicly accessible part of the Chrysler Building. When the building opened, the first and second floors housed a public exhibition of Chrysler vehicles. The exhibition, known as the Chrysler Automobile Salon, was near the corner of Lexington Avenue and 42nd Streets, and opened in 1936. The ground floor featured \"invisible glass\" display windows, a diameter turntable upon which automobiles were displayed, and a ceiling with lights arranged in concentric circles. Escalators led to the showroom's second floor where Plymouths, Dodges, and DeSotos were sold. The Chrysler Salon remained operational through at least the 1960s.\nElevators.\nThere are 32 elevators in the skyscraper, clustered into four banks. At the time of opening, 28 of these elevators were for passenger use. Each bank serves different floors within the building, with several \"express\" elevators going from the lobby to a few landings in between, while \"local\" elevators connect the landings with the floors above these intermediate landings. As per Walter Chrysler's wishes, the elevators were designed to run at a rate of , despite the speed restriction enforced in all city elevators at the time. This restriction was loosened soon after the Empire State Building opened in 1931, as that building had also been equipped with high-speed elevators. The Chrysler Building also had three of the longest elevator shafts in the world at the time of completion.\nOver the course of a year, Van Alen painstakingly designed these elevators with the assistance of L.T.M. Ralston, who was in charge of developing the elevator cabs' mechanical parts. The cabs were manufactured by the Otis Elevator Company, while the doors were made by the Tyler Company. The dimensions of each elevator were deep by wide. The doors are made of metal and covered with eight types of exotic woods. When the doors are closed, they resemble \"tall fans set off by metallic palm fronds rising through a series of silver parabolas, whose edges were set off by curved lilies\" from the outside, as noted by Curcio. However, when a set of doors is open, the cab behind the doors resembles \"an exquisite Art Deco room\". These elements were influenced by ancient Egyptian designs, which significantly impacted the Art Deco style. According to Vincent Curcio, \"these elevator interiors were perhaps the single most beautiful and, next to the dome, the most important feature of the entire building.\"\nEven though the woods in the elevator cabs were arranged in four basic patterns, each cab had a unique combination of woods. Curcio stated that \"if anything the building is based on patterned fabrics, [the elevators] certainly are. Three of the designs could be characterized as having 'geometric', 'Mexican' and vaguely 'art nouveau' motifs, which reflect the various influences on the design of the entire building.\" The roof of each elevator was covered with a metal plate whose design was unique to that cab, which in turn was placed on a polished wooden pattern that was also customized to the cab. Hidden behind these plates were ceiling fans. Curcio wrote that these elevators \"are among the most beautiful small enclosed spaces in New York, and it is fair to say that no one who has seen or been in them has forgotten them\". Curcio compared the elevators to the curtains of a Ziegfeld production, noting that each lobby contains lighting that peaks in the middle and slopes down on either side. The decoration of the cabs' interiors was also a nod to the Chrysler Corporation's vehicles: cars built during the building's early years had dashboards with wooden moldings. Both the doors and cab interiors were considered to be works of extraordinary marquetry.\nBasement.\nOn the 42nd Street side of the Chrysler Building, a staircase from the street leads directly under the building to the New York City Subway's at Grand Central\u201342nd Street station. It is part of the structure's original design. The Interborough Rapid Transit Company, which at the time was the operator of all the routes serving the 42nd Street station, originally sued to block construction of the new entrance because it would cause crowding, but the New York City Board of Transportation pushed to allow the corridor anyway. Chrysler eventually built and paid for the building's subway entrance. Work on the new entrance started in March 1930 and it opened along with the Chrysler Building two months later.\nThe basement also had a \"hydrozone water bottling unit\" that would filter tap water into drinkable water for the building's tenants. The drinkable water would then be bottled and shipped to higher floors.\nUpper stories.\nCloud Club.\nThe private Cloud Club formerly occupied the 66th through 68th floors. It opened in July 1930 with some three hundred members, all wealthy males who formed the city's elite. Its creation was spurred by Texaco's wish for a proper restaurant for its executives prior to renting fourteen floors in the building. The Cloud Club was a compromise between William Van Alen's modern style and Walter Chrysler's stately and traditional tastes. A member had to be elected, and if accepted, paid an initial fee of $200, plus a $150 to $300 annual fee.\nThere was a Tudor-style foyer on the 66th floor with oak paneling, and an old English-style grill room with wooden floors, wooden beams, wrought-iron chandeliers, and glass and lead doors. The main dining room, on the 67th floor, was connected to the 66th floor by a Renaissance-style marble and bronze staircase and had a futuristic appearance, with polished granite columns and etched glass appliqu\u00e9s in Art Deco style. There was a mural of a cloud on the ceiling, and a mural of Manhattan on the dining room's north side. It is believed that the dining room was an inspiration for the Rainbow Room and the Rockefeller Center Luncheon Club, both at 30 Rockefeller Center. On the same floor, Walter Chrysler and Texaco both had private dining rooms. Chrysler's dining room had a black and frosted-blue glass frieze of automobile workers. The 68th floor mainly contained service spaces.\nIn the 1950s and 1960s, members left the Cloud Club for other clubs. Texaco, whose executives comprised most of the Cloud Club's membership, moved to Westchester County in 1977, and the club closed two years later. Although there have been several projects to rehabilitate the club or transform it into a disco or a gastronomic club, these plans have never materialized, as then-owner Cooke reportedly did not want a \"conventional\" restaurant operating within the old club. Tishman Speyer rented the top two floors of the old Cloud Club. The old staircase has been removed, as have many of the original decorations, which prompted objections from the Art Deco Society of New York.\nPrivate Chrysler offices.\nOriginally, Walter Chrysler had a two-story apartment on the 69th and 70th floors with a fireplace and a private office. The office also contained a gymnasium and the loftiest bathrooms in the city. The office had a medieval ambience with leaded windows, elaborate wooden doors, and heavy plaster. Chrysler did not use his gym much, instead choosing to stay at the Chrysler Corporation's headquarters in Detroit. Subsequently, the 69th and 70th floors were converted into a dental clinic. In 2005, a report by \"The New York Times\" found that one of the dentists, Charles Weiss, had operated at the clinic's current rooftop location since 1969. The office still had the suite's original bathroom and gymnasium. Chrysler also had a unit on the 58th through 60th floors, which served as his residence.\nObservation deck.\nFrom the building's opening until 1945, it contained a observation deck on the 71st floor, called \"Celestial\". For fifty cents visitors could transit its circumference through a corridor with vaulted ceilings painted with celestial motifs and bedecked with small hanging glass planets. The center of the observatory contained the toolbox that Walter P. Chrysler used at the beginning of his career as a mechanic; it was later preserved at the Chrysler Technology Center in Auburn Hills, Michigan. An image of the building resembling a rocket hung above it. According to a contemporary brochure, views of up to were possible on a clear day; but the small triangular windows of the observatory created strange angles that made viewing difficult, depressing traffic. When the Empire State Building opened in 1931 with two observatories at a higher elevation, the Chrysler observatory lost its clientele.\nAfter the observatory closed, it was used to house radio and television broadcasting equipment. Since 1986, the old observatory has housed the office of architects Harvey Morse and Cowperwood Interests. , a new observation deck has been proposed for the 61st floor of the building. The new deck will take advantage of that floor's setbacks to create an outdoor space.\nAttic.\nThe stories above the 71st floor are designed mostly for exterior appearance, functioning mainly as landings for the stairway to the spire and do not contain office space. They are very narrow, have low and sloping roofs, and are only used to house radio transmitters and other mechanical and electrical equipment. For example, the 73rd floor houses the motors of the elevators and a water tank, of which are reserved for extinguishing fires.\nChrysler Center.\nChrysler Center is the name of the building complex consisting of the Chrysler Building, Chrysler Building East, and the commercial pavilion between the two, called Chrysler Trylons. In 1998, Tishman Speyer acquired the entire complex and proceeded to renovate it completely over the next two years.\nThe Chrysler Building annex at 666 Third Avenue, also known as the Kent Building at the time, was renovated and renamed Chrysler Building East. This International Style building, built in 1952, is high and has 32 floors. The mechanical systems were modernized and the interior was modified. Renowned architect Philip Johnson replaced the glass facade with darker glass and added a extension. After the addition, the total area of this building was .\nFinally, a new building, which was also designed by Philip Johnson, was built between the original skyscraper and the annex. This became the Chrysler Trylons, a commercial pavilion three stories high with a retail area of . Its design, consisting of three triangular glass pyramids that intersect each other, was inspired by the triangular windows of the Chrysler Building's crown. The building's design was so complex that a replica was built at Rimouski, Quebec. Johnson designed Chrysler Trylons as \"a monument for 42nd Street [...] to give you the top of the Chrysler Building at street level.\"\nAfter these modifications, the total leasable area of the complex was . The total cost of this project was about one hundred million dollars. This renovation has won several awards and commendations, including an Energy Star rating from the Environmental Protection Agency; a LEED Gold designation; and the Skyscraper Museum Outstanding Renovation Award of 2001.\nTenants.\nThe Chrysler Corporation moved into the building as an anchor tenant in 1930. In addition to the Chrysler Salon on the first and second floors, parts of the building had the Chrysler Corporation's offices, as well as a lounge and a theater for showing films of Chrysler products. Other original large tenants included Time, Inc. and Texaco oil. Needing more office space, Time moved to Rockefeller Center in 1937. Texaco relocated to a more suburban workplace in Purchase, New York, in 1977. In addition, the offices of Shaw Walker and J. S. Bache &amp; Company were immediately atop the Chrysler Salon, while A. B. Dick, Pan American World Airways, Adams Hats, Schrafft's, and Florsheim Shoes also had offices in the building.\nNotable modern tenants include:\nImpact.\nCritical reception.\nThe completed Chrysler Building garnered mixed reviews in the press. Van Alen was hailed as the \"Doctor of Altitude\" by \"Architect\" magazine, while architect Kenneth Murchison called Van Alen the \"Ziegfeld of his profession\", comparing him to popular Broadway producer Florenz Ziegfeld Jr.. The building was praised for being \"an expression of the intense activity and vibrant life of our day\", and for \"teem[ing] with the spirit of modernism, ... the epitome of modern business life, stand[ing] for progress in architecture and in modern building methods.\" An anonymous critic wrote in \"Architectural Forum\" October 1930 issue: \"The Chrysler...stands by itself, something apart and alone. It is simply the realization, the fulfillment in metal and masonry, of a one-man dream, a dream of such ambitions and such magnitude as to defy the comprehension and the criticism of ordinary men or by ordinary standards.\" Conversely, journalist George S. Chappell called the Chrysler's design \"distinctly a stunt design, evolved to make the man in the street look up\". Douglas Haskell stated that the building \"embodies no compelling, organic idea\", and alleged that Van Alen had abandoned \"some of his best innovations in behalf of stunts and new 'effects'\". Others compared the Chrysler Building to \"an upended swordfish\", or claimed it had a \"Little Nemo\"-like design. Lewis Mumford, a supporter of the International Style and one of the foremost architectural critics of the United States at the time, despised the building for its \"inane romanticism, meaningless voluptuousness, [and] void symbolism\". The public also had mixed reviews of the Chrysler Building, as Murchison wrote: \"Some think it's a freak; some think it's a stunt.\"\nLater reviews were more positive. Architect Robert A. M. Stern wrote that the Chrysler Building was \"the most extreme example of the [1920s and 1930s] period's stylistic experimentation\", as contrasted with 40 Wall Street and its \"thin\" detailing. George H. Douglas wrote in 2004 that the Chrysler Building \"remains one of the most appealing and awe-inspiring of skyscrapers\". Architect Le Corbusier called the building \"hot jazz in stone and steel\". Architectural critic Ada Louise Huxtable stated that the building had \"a wonderful, decorative, evocative aesthetic\", while Paul Goldberger noted the \"compressed, intense energy\" of the lobby, the \"magnificent\" elevators, and the \"magical\" view from the crown.\nThe city's Landmarks Preservation Commission said that the tower \"embodies the romantic essence of the New York City skyscraper\". The travel guide \"Frommer's\" gave the building an \"exceptional\" recommendation, with author Pauline Frommer writing, \"In the Chrysler Building we see the roaring-twenties version of what Alan Greenspan called 'irrational exuberance'\u2014a last burst of corporate headquarter building before stocks succumbed to the thudding crash of 1929.\"\nAs icon.\nThe Chrysler Building appears in several films set in New York and is widely considered one of the most positively acclaimed buildings in the city. A 1996 survey of New York architects revealed it as their favorite, and \"The New York Times\" described it in 2005 as \"the single most important emblem of architectural imagery on the New York skyline\". In mid-2005, the Skyscraper Museum in Lower Manhattan asked 100 architects, builders, critics, engineers, historians, and scholars, among others, to choose their 10 favorites among 25 of the city's towers. The Chrysler Building came in first place, with 90 respondents placing it on their ballots. In 2007, the building ranked ninth among 150 buildings in the AIA's \"List of America's Favorite Architecture\".\nThe Chrysler Building is widely heralded as an Art Deco icon. \"Fodor's New York City 2010\" described the building as being \"one of the great art deco masterpieces\" which \"wins many a New Yorker's vote for the city's most iconic and beloved skyscraper\". \"Frommer's\" states that the Chrysler was \"one of the most impressive Art Deco buildings ever constructed\". \"Insight Guides\" 2016 edition maintains that the Chrysler Building is considered among the city's \"most beautiful\" buildings. Its distinctive profile has inspired similar skyscrapers worldwide including One Liberty Place in Philadelphia, Two Prudential Plaza in Chicago, and the Al Kazim Towers in Dubai.\nIn popular culture.\nWhile seen in many films, the Chrysler Building almost never appears as a main setting in them, prompting architect and author James Sanders to quip it should win \"the Award for Best Supporting Skyscraper\". The building was supposed to be featured in the 1933 film \"King Kong\", but only makes a cameo at the end thanks to its producers opting for the Empire State Building in a central role. The Chrysler Building notably appears in the background of \"The Wiz\" (1978); as the setting of much of \"Q - The Winged Serpent\" (1982); in the initial credits of \"The Shadow of the Witness\" (1987); and during or after apocalyptic events in \"Independence Day\" (1996), \"Armageddon\" (1998), \"Deep Impact\" (1998), \"Godzilla\" (1998), and \"A.I. Artificial Intelligence\" (2001). The building also appears in other films, such as \"Spider-Man\" (2002), \"\" (2007), \"Two Weeks Notice\" (2002), \"The Sorcerer's Apprentice\" (2010) and \"Men in Black 3\" (2012). In The Avengers (2012), Thor uses the building as an apparent amplifier to increase the effectiveness of his hammer's lighting power.\nThe Chrysler Building is frequently the subject of photographers. In December 1929, Walter Chrysler hired the famed Margaret Bourke-White to capture it for publicity purposes. She took the images from a scaffold high and worked in a 61st-floor studio designed by John Vassos, until she was evicted in 1934. According to one account, Bourke-White wanted to live in the building for the duration of the photo shoot, but the only person able to do so was the janitor, so she was instead relegated to co-leasing a studio with Time Inc. In 1930, several of her photographs were used in a special report on skyscrapers in the then-new \"Fortune\" magazine. In 1934, Bourke-White's partner Oscar Graubner took a famous photo called \"Margaret Bourke-White atop the Chrysler Building\", which depicts her taking a photo of the city's skyline while sitting on one of the 61st-floor eagle ornaments. On October 5, 1998, Christie's auctioned the photograph for $96,000. In addition, during a January 1931 dance organized by the Society of Beaux-Arts, six architects, including Van Alen, were photographed while wearing costumes resembling the buildings that each architect designed.\nThe building is also mentioned in the lyrics of several songs, as well as in the number \"It's the Hard Knock Life\" for the musical \"Annie\". In the Squaresoft (now Square Enix) videogame \"Parasite Eve\", the building is the setting for the post-game content."}
{"id": "6789", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=6789", "title": "Condiment for seasoning minestrone", "text": ""}
{"id": "6790", "revid": "7852030", "url": "https://en.wikipedia.org/wiki?curid=6790", "title": "Cape Breton (disambiguation)", "text": "Cape Breton Island is an island in the Canadian province of Nova Scotia, in Canada.\nCape Breton may also refer to:"}
{"id": "6792", "revid": "300", "url": "https://en.wikipedia.org/wiki?curid=6792", "title": "CND", "text": ""}
{"id": "6794", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6794", "title": "Comet Shoemaker\u2013Levy 9", "text": "Comet Shoemaker\u2013Levy 9 (formally designated D/1993\u00a0F2) was a comet that broke apart in July 1992 and collided with Jupiter in July 1994, providing the first direct observation of an extraterrestrial collision of Solar System objects. This generated a large amount of coverage in the popular media, and the comet was closely observed by astronomers worldwide. The collision provided new information about Jupiter and highlighted its possible role in reducing space debris in the inner Solar System.\nThe comet was discovered by astronomers Carolyn and Eugene M. Shoemaker and David Levy in 1993. Shoemaker\u2013Levy 9 (SL9) had been captured by Jupiter and was orbiting the planet at the time. It was located on the night of March 24 in a photograph taken with the Schmidt telescope at the Palomar Observatory in California. It was the first active comet observed to be orbiting a planet, and had probably been captured by Jupiter around 20\u201330 years earlier.\nCalculations showed that its unusual fragmented form was due to a previous closer approach to Jupiter in July 1992. At that time, the orbit of Shoemaker\u2013Levy 9 passed within Jupiter's Roche limit, and Jupiter's tidal forces had acted to pull apart the comet. The comet was later observed as a series of fragments ranging up to in diameter. These fragments collided with Jupiter's southern hemisphere between July 16 and 22, 1994 at a speed of approximately (Jupiter's escape velocity) or . The prominent scars from the impacts were more easily visible than the Great Red Spot and persisted for many months.\nDiscovery.\nWhile conducting a program of observations designed to uncover near-Earth objects, the Shoemakers and Levy discovered Comet Shoemaker\u2013Levy 9 on the night of March 24, 1993, in a photograph taken with the Schmidt telescope at the Palomar Observatory in California. The comet was thus a serendipitous discovery, but one that quickly overshadowed the results from their main observing program.\nComet Shoemaker\u2013Levy 9 was the ninth periodic comet (a comet whose orbital period is 200 years or less) discovered by the Shoemakers and Levy, hence its name. It was their eleventh comet discovery overall including their discovery of two non-periodic comets, which use a different nomenclature. The discovery was announced in IAU Circular 5725 on March 26, 1993.\nThe discovery image gave the first hint that comet Shoemaker\u2013Levy 9 was an unusual comet, as it appeared to show multiple nuclei in an elongated region about 50\u00a0arcseconds long and 10\u00a0arcseconds wide. Brian G. Marsden of the Central Bureau for Astronomical Telegrams noted that the comet lay only about 4\u00a0degrees from Jupiter as seen from Earth, and that although this could be a line-of-sight effect, its apparent motion in the sky suggested that the comet was physically close to the planet.\nComet with a Jovian orbit.\nOrbital studies of the new comet soon revealed that it was orbiting Jupiter rather than the Sun, unlike all other comets known at the time. Its orbit around Jupiter was very loosely bound, with a period of about 2 years and an apoapsis (the point in the orbit farthest from the planet) of . Its orbit around the planet was highly eccentric (\"e\" = 0.9986).\nTracing back the comet's orbital motion revealed that it had been orbiting Jupiter for some time. It is likely that it was captured from a solar orbit in the early 1970s, although the capture may have occurred as early as the mid-1960s. Several other observers found images of the comet in precovery images obtained before March 24, including Kin Endate from a photograph exposed on March 15, S. Otomo on March 17, and a team led by Eleanor Helin from images on March 19. An image of the comet on a Schmidt photographic plate taken on March 19 was identified on March 21 by M. Lindgren, in a project searching for comets near Jupiter. However, as his team were expecting comets to be inactive or at best exhibit a weak dust coma, and SL9 had a peculiar morphology, its true nature was not recognised until the official announcement 5 days later. No precovery images dating back to earlier than March 1993 have been found. Before the comet was captured by Jupiter, it was probably a short-period comet with an aphelion just inside Jupiter's orbit, and a perihelion interior to the asteroid belt.\nThe volume of space within which an object can be said to orbit Jupiter is defined by Jupiter's Hill sphere (also called the Roche sphere). When the comet passed Jupiter in the late 1960s or early 1970s, it happened to be near its aphelion, and found itself slightly within Jupiter's Hill sphere. Jupiter's gravity nudged the comet towards it. Because the comet's motion with respect to Jupiter was very small, it fell almost straight toward Jupiter, which is why it ended up on a Jove-centric orbit of very high eccentricity\u2014that is to say, the ellipse was nearly flattened out.\nThe comet had apparently passed extremely close to Jupiter on July 7, 1992, just over above its cloud tops\u2014a smaller distance than Jupiter's radius of , and well within the orbit of Jupiter's innermost moon Metis and the planet's Roche limit, inside which tidal forces are strong enough to disrupt a body held together only by gravity. Although the comet had approached Jupiter closely before, the July 7 encounter seemed to be by far the closest, and the fragmentation of the comet is thought to have occurred at this time. Each fragment of the comet was denoted by a letter of the alphabet, from \"fragment A\" through to \"fragment W\", a practice already established from previously observed fragmented comets.\nMore exciting for planetary astronomers was that the best orbital calculations suggested that the comet would pass within of the center of Jupiter, a distance smaller than the planet's radius, meaning that there was an extremely high probability that SL9 would collide with Jupiter in July 1994. Studies suggested that the train of nuclei would plow into Jupiter's atmosphere over a period of about five days.\nPredictions for the collision.\nThe discovery that the comet was likely to collide with Jupiter caused great excitement within the astronomical community and beyond, as astronomers had never before seen two significant Solar System bodies collide. Intense studies of the comet were undertaken, and as its orbit became more accurately established, the possibility of a collision became a certainty. The collision would provide a unique opportunity for scientists to look inside Jupiter's atmosphere, as the collisions were expected to cause eruptions of material from the layers normally hidden beneath the clouds.\nAstronomers estimated that the visible fragments of SL9 ranged in size from a few hundred metres (around ) to across, suggesting that the original comet may have had a nucleus up to across\u2014somewhat larger than Comet Hyakutake, which became very bright when it passed close to the Earth in 1996. One of the great debates in advance of the impact was whether the effects of the impact of such small bodies would be noticeable from Earth, apart from a flash as they disintegrated like giant meteors. The most optimistic prediction was that large, asymmetric ballistic fireballs would rise above the limb of Jupiter and into sunlight to be visible from Earth.\nOther suggested effects of the impacts were seismic waves travelling across the planet, an increase in stratospheric haze on the planet due to dust from the impacts, and an increase in the mass of the Jovian ring system. However, given that observing such a collision was completely unprecedented, astronomers were cautious with their predictions of what the event might reveal.\nImpacts.\nAnticipation grew as the predicted date for the collisions approached, and astronomers trained terrestrial telescopes on Jupiter. Several space observatories did the same, including the Hubble Space Telescope, the ROSAT X-ray-observing satellite, and significantly the \"Galileo\" spacecraft, then on its way to a rendezvous with Jupiter scheduled for 1995. Although the impacts took place on the side of Jupiter hidden from Earth, \"Galileo\", then at a distance of from the planet, was able to see the impacts as they occurred. Jupiter's rapid rotation brought the impact sites into view for terrestrial observers a few minutes after the collisions.\nTwo other space probes made observations at the time of the impact: the \"Ulysses\" spacecraft, primarily designed for solar observations, was pointed towards Jupiter from its location away, and the distant \"Voyager 2\" probe, some from Jupiter and on its way out of the Solar System following its encounter with Neptune in 1989, was programmed to look for radio emission in the 1\u2013390\u00a0kHz range and make observations with its ultraviolet spectrometer.\nThe first impact occurred at 20:13\u00a0UTC on July 16, 1994, when fragment A of the nucleus entered Jupiter's southern hemisphere at a speed of about . Instruments on \"Galileo\" detected a fireball that reached a peak temperature of about , compared to the typical Jovian cloudtop temperature of about , before expanding and cooling rapidly to about after 40\u00a0seconds. The plume from the fireball quickly reached a height of over . A few minutes after the impact fireball was detected, \"Galileo\" measured renewed heating, probably due to ejected material falling back onto the planet. Earth-based observers detected the fireball rising over the limb of the planet shortly after the initial impact.\nDespite published predictions, astronomers had not expected to see the fireballs from the impacts and did not have any idea how visible the other atmospheric effects of the impacts would be from Earth. Observers soon saw a huge dark spot after the first impact. The spot was visible even in very small telescopes, and was about (one Earth radius) across. This and subsequent dark spots were thought to have been caused by debris from the impacts, and were markedly asymmetric, forming crescent shapes in front of the direction of impact.\nOver the next six days, 21 distinct impacts were observed, with the largest coming on July 18 at 07:33 UTC when fragment G struck Jupiter. This impact created a giant dark spot over across, and was estimated to have released an energy equivalent to 6,000,000\u00a0megatons of TNT (600 times the world's nuclear arsenal). Two impacts 12\u00a0hours apart on July 19 created impact marks of similar size to that caused by fragment G, and impacts continued until July 22, when fragment W struck the planet.\nObservations and discoveries.\nChemical studies.\nObservers hoped that the impacts would give them a first glimpse of Jupiter beneath the cloud tops, as lower material was exposed by the comet fragments punching through the upper atmosphere. Spectroscopic studies revealed absorption lines in the Jovian spectrum due to diatomic sulfur (S2) and carbon disulfide (CS2), the first detection of either in Jupiter, and only the second detection of S2 in any astronomical object. Other molecules detected included ammonia (NH3) and hydrogen sulfide (H2S). The amount of sulfur implied by the quantities of these compounds was much greater than the amount that would be expected in a small cometary nucleus, showing that material from within Jupiter was being revealed. Oxygen-bearing molecules such as sulfur dioxide were not detected, to the surprise of astronomers.\nAs well as these molecules, emission from heavy atoms such as iron, magnesium and silicon was detected, with abundances consistent with what would be found in a cometary nucleus. Although a substantial amount of water was detected spectroscopically, it was not as much as predicted, meaning that either the water layer thought to exist below the clouds was thinner than predicted, or that the cometary fragments did not penetrate deeply enough.\nWaves.\nAs predicted, the collisions generated enormous waves that swept across Jupiter at speeds of and were observed for over two hours after the largest impacts. The waves were thought to be travelling within a stable layer acting as a waveguide, and some scientists thought the stable layer must lie within the hypothesised tropospheric water cloud. However, other evidence seemed to indicate that the cometary fragments had not reached the water layer, and the waves were instead propagating within the stratosphere.\nOther observations.\nRadio observations revealed a sharp increase in continuum emission at a wavelength of after the largest impacts, which peaked at 120% of the normal emission from the planet. This was thought to be due to synchrotron radiation, caused by the injection of relativistic electrons\u2014electrons with velocities near the speed of light\u2014into the Jovian magnetosphere by the impacts.\nAbout an hour after fragment K entered Jupiter, observers recorded auroral emission near the impact region, as well as at the antipode of the impact site with respect to Jupiter's strong magnetic field. The cause of these emissions was difficult to establish due to a lack of knowledge of Jupiter's internal magnetic field and of the geometry of the impact sites. One possible explanation was that upwardly accelerating shock waves from the impact accelerated charged particles enough to cause auroral emission, a phenomenon more typically associated with fast-moving solar wind particles striking a planetary atmosphere near a magnetic pole.\nSome astronomers had suggested that the impacts might have a noticeable effect on the Io torus, a torus of high-energy particles connecting Jupiter with the highly volcanic moon Io. High resolution spectroscopic studies found that variations in the ion density, rotational velocity, and temperatures at the time of impact and afterwards were within the normal limits.\nVoyager 2 failed to detect anything with calculations showing that the fireballs were just below the craft's limit of detection. Ulysses also failed to detect anything.\nPost-impact analysis.\nSeveral models were devised to compute the density and size of Shoemaker\u2013Levy 9. Its average density was calculated to be about ; the breakup of a much less dense comet would not have resembled the observed string of objects. The size of the parent comet was calculated to be about in diameter. These predictions were among the few that were actually confirmed by subsequent observation.\nOne of the surprises of the impacts was the small amount of water revealed compared to prior predictions. Before the impact, models of Jupiter's atmosphere had indicated that the break-up of the largest fragments would occur at atmospheric pressures of anywhere from 30 kilopascals to a few tens of megapascals (from 0.3 to a few hundred bar), with some predictions that the comet would penetrate a layer of water and create a bluish shroud over that region of Jupiter.\nAstronomers did not observe large amounts of water following the collisions, and later impact studies found that fragmentation and destruction of the cometary fragments in an 'airburst' probably occurred at much higher altitudes than previously expected, with even the largest fragments being destroyed when the pressure reached , well above the expected depth of the water layer. The smaller fragments were probably destroyed before they even reached the cloud layer.\nLonger-term effects.\nThe visible scars from the impacts could be seen on Jupiter for many months. They were extremely prominent, and observers described them as even more easily visible than the Great Red Spot. A search of historical observations revealed that the spots were probably the most prominent transient features ever seen on the planet, and that although the Great Red Spot is notable for its striking color, no spots of the size and darkness of those caused by the SL9 impacts had ever been recorded before, or since.\nSpectroscopic observers found that ammonia and carbon disulfide persisted in the atmosphere for at least fourteen months after the collisions, with a considerable amount of ammonia being present in the stratosphere as opposed to its normal location in the troposphere.\nCounterintuitively, the atmospheric temperature dropped to normal levels much more quickly at the larger impact sites than at the smaller sites: at the larger impact sites, temperatures were elevated over a region wide, but dropped back to normal levels within a week of the impact. At smaller sites, temperatures higher than the surroundings persisted for almost two weeks. Global stratospheric temperatures rose immediately after the impacts, then fell to below pre-impact temperatures 2\u20133\u00a0weeks afterwards, before rising slowly to normal temperatures.\nFrequency of impacts.\nSL9 is not unique in having orbited Jupiter for a time; five comets, (including 82P/Gehrels, 147P/Kushida\u2013Muramatsu, and 111P/Helin\u2013Roman\u2013Crockett) are known to have been temporarily captured by the planet.\nCometary orbits around Jupiter are unstable, as they will be highly elliptical and likely to be strongly perturbed by the Sun's gravity at apojove (the farthest point on the orbit from the planet).\nBy far the most massive planet in the Solar System, Jupiter can capture objects relatively frequently, but the size of SL9 makes it a rarity: one post-impact study estimated that comets in diameter impact the planet once in approximately 500 years and those in diameter do so just once in every 6,000 years.\nThere is very strong evidence that comets have previously been fragmented and collided with Jupiter and its satellites. During the Voyager missions to the planet, planetary scientists identified 13 crater chains on Callisto and three on Ganymede, the origin of which was initially a mystery. Crater chains seen on the Moon often radiate from large craters, and are thought to be caused by secondary impacts of the original ejecta, but the chains on the Jovian moons did not lead back to a larger crater. The impact of SL9 strongly implied that the chains were due to trains of disrupted cometary fragments crashing into the satellites.\nImpact of July 19, 2009.\nOn July 19, 2009, exactly 15 years after the SL9 impacts, a new black spot about the size of the Pacific Ocean appeared in Jupiter's southern hemisphere. Thermal infrared measurements showed the impact site was warm and spectroscopic analysis detected the production of excess hot ammonia and silica-rich dust in the upper regions of Jupiter's atmosphere. Scientists have concluded that another impact event had occurred, but this time a more compact and strong object, probably a small undiscovered asteroid, was the cause.\nJupiter as a \"cosmic vacuum cleaner\".\nThe impact of SL9 highlighted Jupiter's role as a \"cosmic vacuum cleaner\" for the inner Solar System (Jupiter barrier). The planet's strong gravitational influence leads to many small comets and asteroids colliding with the planet, and the rate of cometary impacts on Jupiter is thought to be between 2,000 and 8,000 times higher than the rate on Earth.\nThe extinction of the non-avian dinosaurs at the end of the Cretaceous period is generally thought to have been caused by the Cretaceous\u2013Paleogene impact event, which created the Chicxulub crater, demonstrating that impacts are a serious threat to life on Earth. Astronomers have speculated that without Jupiter to mop up potential impactors, extinction events might have been more frequent on Earth, and complex life might not have been able to develop. This is part of the argument used in the Rare Earth hypothesis.\nIn 2009, it was shown that the presence of a smaller planet at Jupiter's position in the Solar System might increase the impact rate of comets on the Earth significantly. A planet of Jupiter's mass still seems to provide increased protection against asteroids, but the total effect on all orbital bodies within the Solar System is unclear. This and other recent models call into question the nature of Jupiter's influence on Earth impacts."}
{"id": "6796", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=6796", "title": "Ceres Brewery", "text": "The Ceres Brewery was a beer and soft drink producing facility in \u00c5rhus, Denmark, that operated from 1856 until 2008. Although the brewery was closed by its owner Royal Unibrew the Ceres brand continues, with the product brewed at other facilities. The area where the brewery stood is being redeveloped for residential and commercial use and has been named CeresByen (Ceres City).\nHistory.\nCeres Brewery was founded by Malthe Conrad Lottrup, a grocer, with chemists A. S. Aagard and Knud Redelien, as the city's seventh brewery. It was named after the Roman goddess Ceres, and its opening was announced in the local newspaper, \"Stiftstidende\", in 1856.\nLottrup expanded the brewery after ten years, adding a grand new building as his private residence.\nHe was succeeded by his son-in-law, Laurits Christian Meulengracht, who ran the brewery for almost thirty years, expanding it further before selling it to \u00d8stjyske Bryggerier, another brewing firm.\nThe Ceres brewery was named an official purveyor to the Royal Danish Court in 1914."}
{"id": "6797", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=6797", "title": "Cable TV", "text": ""}
{"id": "6798", "revid": "12711397", "url": "https://en.wikipedia.org/wiki?curid=6798", "title": "CATV", "text": ""}
{"id": "6799", "revid": "41373646", "url": "https://en.wikipedia.org/wiki?curid=6799", "title": "COBOL", "text": "COBOL (; an acronym for \"common business-oriented language\") is a compiled English-like computer programming language designed for business use. It is an imperative, procedural and, since 2002, object-oriented language. COBOL is primarily used in business, finance, and administrative systems for companies and governments. COBOL is still widely used in applications deployed on mainframe computers, such as large-scale batch and transaction processing jobs. However, due to its declining popularity and the retirement of experienced COBOL programmers, programs are being migrated to new platforms, rewritten in modern languages or replaced with software packages. Most programming in COBOL is now purely to maintain existing applications; however, many large financial institutions were still developing new systems in COBOL as late as 2006 due to the mainframe processing speed.\nCOBOL was designed in 1959 by CODASYL and was partly based on the programming language FLOW-MATIC designed by Grace Hopper. It was created as part of a US Department of Defense effort to create a portable programming language for data processing. It was originally seen as a stopgap, but the Department of Defense promptly forced computer manufacturers to provide it, resulting in its widespread adoption. It was standardized in 1968 and has since been revised four times. Expansions include support for structured and object-oriented programming. The current standard is \"ISO/IEC 1989:2014\".\nCOBOL statements have an English-like syntax, which was designed to be self-documenting and highly readable. However, it is verbose and uses over 300 reserved words. In contrast with modern, succinct syntax like , COBOL has a more English-like syntax (in this case, ).\nCOBOL code is split into four \"divisions\" (identification, environment, data, and procedure) containing a rigid hierarchy of sections, paragraphs and sentences. Lacking a large standard library, the standard specifies 43 statements, 87 functions and just one class.\nAcademic computer scientists were generally uninterested in business applications when COBOL was created and were not involved in its design; it was (effectively) designed from the ground up as a computer language for business, with an emphasis on inputs and outputs, whose only data types were numbers and strings of text.\nCOBOL has been criticized throughout its life for its verbosity, design process, and poor support for structured programming. These weaknesses result in monolithic and, though intended to be English-like, not easily comprehensible and verbose programs.\nHistory and specification.\nBackground.\nIn the late 1950s, computer users and manufacturers were becoming concerned about the rising cost of programming. A 1959 survey had found that in any data processing installation, the programming cost US$800,000 on average and that translating programs to run on new hardware would cost $600,000. At a time when new programming languages were proliferating at an ever-increasing rate, the same survey suggested that if a common business-oriented language were used, conversion would be far cheaper and faster.\nOn 8 April 1959, Mary K. Hawes, a computer scientist at Burroughs Corporation, called a meeting of representatives from academia, computer users, and manufacturers at the University of Pennsylvania to organize a formal meeting on common business languages. Representatives included Grace Hopper (inventor of the English-like data processing language FLOW-MATIC), Jean Sammet and Saul Gorn.\nAt the April meeting, the group asked the Department of Defense (DoD) to sponsor an effort to create a common business language. The delegation impressed Charles A. Phillips, director of the Data System Research Staff at the DoD, who thought that they \"thoroughly understood\" the DoD's problems. The DoD operated 225 computers, had a further 175 on order and had spent over $200 million on implementing programs to run on them. Portable programs would save time, reduce costs and ease modernization.\nCharles Phillips agreed to sponsor the meeting and tasked the delegation with drafting the agenda.\nCOBOL 60.\nOn 28 and 29 May 1959 (exactly one year after the Z\u00fcrich ALGOL 58 meeting), a meeting was held at the Pentagon to discuss the creation of a common programming language for business. It was attended by 41 people and was chaired by Phillips. The Department of Defense was concerned about whether it could run the same data processing programs on different computers. FORTRAN, the only mainstream language at the time, lacked the features needed to write such programs.\nRepresentatives enthusiastically described a language that could work in a wide variety of environments, from banking and insurance to utilities and inventory control. They agreed unanimously that more people should be able to program and that the new language should not be restricted by the limitations of contemporary technology. A majority agreed that the language should make maximal use of English, be capable of change, be machine-independent and be easy to use, even at the expense of power.\nThe meeting resulted in the creation of a steering committee and short, intermediate and long-range committees. The short-range committee was given to September (three months) to produce specifications for an interim language, which would then be improved upon by the other committees. Their official mission, however, was to identify the strengths and weaknesses of existing programming languages and did not explicitly direct them to create a new language.\nThe deadline was met with disbelief by the short-range committee.\nOne member, Betty Holberton, described the three-month deadline as \"gross optimism\" and doubted that the language really would be a stopgap.\nThe steering committee met on 4 June and agreed to name the entire activity as the \"Committee on Data Systems Languages\", or CODASYL, and to form an executive committee.\nThe short-range committee was made up of members representing six computer manufacturers and three government agencies. The six computer manufacturers were Burroughs Corporation, IBM, Minneapolis-Honeywell (Honeywell Labs), RCA, Sperry Rand, and Sylvania Electric Products. The three government agencies were the US Air Force, the Navy's David Taylor Model Basin, and the National Bureau of Standards (now the National Institute of Standards and Technology). The committee was chaired by Joseph Wegstein of the US National Bureau of Standards. Work began by investigating data description, statements, existing applications and user experiences.\nThe committee mainly examined the FLOW-MATIC, AIMACO and COMTRAN programming languages.\nThe FLOW-MATIC language was particularly influential because it had been implemented and because AIMACO was a derivative of it with only minor changes.\nFLOW-MATIC's inventor, Grace Hopper, also served as a technical adviser to the committee. FLOW-MATIC's major contributions to COBOL were long variable names, English words for commands and the separation of data descriptions and instructions.\nHopper is sometimes referred to as \"the mother of COBOL\" or \"the grandmother of COBOL\", although Jean Sammet, a lead designer of COBOL, stated that Hopper \"was not the mother, creator or developer of Cobol\".\nIBM's COMTRAN language, invented by Bob Bemer, was regarded as a competitor to FLOW-MATIC by a short-range committee made up of colleagues of Grace Hopper.\nSome of its features were not incorporated into COBOL so that it would not look like IBM had dominated the design process, and Jean Sammet said in 1981 that there had been a \"strong anti-IBM bias\" from some committee members (herself included).\nIn one case, after Roy Goldfinger, author of the COMTRAN manual and intermediate-range committee member, attended a subcommittee meeting to support his language and encourage the use of algebraic expressions, Grace Hopper sent a memo to the short-range committee reiterating Sperry Rand's efforts to create a language based on English.\nIn 1980, Grace Hopper commented that \"COBOL 60 is 95% FLOW-MATIC\" and that COMTRAN had had an \"extremely small\" influence. Furthermore, she said that she would claim that work was influenced by both FLOW-MATIC and COMTRAN only to \"keep other people happy [so they] wouldn't try to knock us out\".\nFeatures from COMTRAN incorporated into COBOL included formulas, the clause, an improved codice_1 statement, which obviated the need for GO TOs, and a more robust file management system.\nThe usefulness of the committee's work was subject of great debate. While some members thought the language had too many compromises and was the result of design by committee, others felt it was better than the three languages examined. Some felt the language was too complex; others, too simple.\nControversial features included those some considered useless or too advanced for data processing users. Such features included boolean expressions, formulas and table \"\" (indices). Another point of controversy was whether to make keywords context-sensitive and the effect that would have on readability. Although context-sensitive keywords were rejected, the approach was later used in PL/I and partially in COBOL from 2002. Little consideration was given to interactivity, interaction with operating systems (few existed at that time) and functions (thought of as purely mathematical and of no use in data processing).\nThe specifications were presented to the Executive Committee on 4 September. They fell short of expectations: Joseph Wegstein noted that \"it contains rough spots and requires some additions\", and Bob Bemer later described them as a \"hodgepodge\". The subcommittee was given until December to improve it.\nAt a mid-September meeting, the committee discussed the new language's name. Suggestions included \"BUSY\" (Business System), \"INFOSYL\" (Information System Language) and \"COCOSYL\" (Common Computer Systems Language). It is unclear who coined the name \"COBOL\", although Bob Bemer later claimed it had been his suggestion.\nIn October, the intermediate-range committee received copies of the FACT language specification created by Roy Nutt. Its features impressed the committee so much that they passed a resolution to base COBOL on it.\nThis was a blow to the short-range committee, who had made good progress on the specification. Despite being technically superior, FACT had not been created with portability in mind or through manufacturer and user consensus. It also lacked a demonstrable implementation, allowing supporters of a FLOW-MATIC-based COBOL to overturn the resolution. RCA representative Howard Bromberg also blocked FACT, so that RCA's work on a COBOL implementation would not go to waste.\nIt soon became apparent that the committee was too large for any further progress to be made quickly. A frustrated Howard Bromberg bought a $15 tombstone with \"COBOL\" engraved on it and sent it to Charles Phillips to demonstrate his displeasure.\nA sub-committee was formed to analyze existing languages and was made up of six individuals:\nThe sub-committee did most of the work creating the specification, leaving the short-range committee to review and modify their work before producing the finished specification.\nThe specifications were approved by the Executive Committee on 8 January 1960, and sent to the government printing office, which printed these as \"COBOL 60\". The language's stated objectives were to allow efficient, portable programs to be easily written, to allow users to move to new systems with minimal effort and cost, and to be suitable for inexperienced programmers.\nThe CODASYL Executive Committee later created the COBOL Maintenance Committee to answer questions from users and vendors and to improve and expand the specifications.\nDuring 1960, the list of manufacturers planning to build COBOL compilers grew. By September, five more manufacturers had joined CODASYL (Bendix, Control Data Corporation, General Electric (GE), National Cash Register and Philco), and all represented manufacturers had announced COBOL compilers. GE and IBM planned to integrate COBOL into their own languages, GECOM and COMTRAN, respectively. In contrast, International Computers and Tabulators planned to replace their language, CODEL, with COBOL.\nMeanwhile, RCA and Sperry Rand worked on creating COBOL compilers. The first COBOL program ran on 17 August on an RCA 501.\nOn 6 and 7 December, the same COBOL program (albeit with minor changes) ran on an RCA computer and a Remington-Rand Univac computer, demonstrating that compatibility could be achieved.\nThe relative influences of which languages were used continues to this day in the recommended advisory printed in all COBOL reference manuals:\nCOBOL-61 to COBOL-65.\nMany logical flaws were found in \"COBOL 60\", leading GE's Charles Katz to warn that it could not be interpreted unambiguously. A reluctant short-term committee enacted a total cleanup and, by March 1963, it was reported that COBOL's syntax was as definable as ALGOL's, although semantic ambiguities remained.\nEarly COBOL compilers were primitive and slow. A 1962 US Navy evaluation found compilation speeds of 3\u201311 statements per minute. By mid-1964, they had increased to 11\u20131000 statements per minute. It was observed that increasing memory would drastically increase speed and that compilation costs varied wildly: costs per statement were between $0.23 and $18.91.\nIn late 1962, IBM announced that COBOL would be their primary development language and that development of COMTRAN would cease.\nThe COBOL specification was revised three times in the five years after its publication.\nCOBOL-60 was replaced in 1961 by COBOL-61. This was then replaced by the COBOL-61 Extended specifications in 1963, which introduced the sort and report writer facilities.\nThe added facilities corrected flaws identified by Honeywell in late 1959 in a letter to the short-range committee.\nCOBOL Edition 1965 brought further clarifications to the specifications and introduced facilities for handling mass storage files and tables.\nCOBOL-68.\nEfforts began to standardize COBOL to overcome incompatibilities between versions. In late 1962, both ISO and the United States of America Standards Institute (now ANSI) formed groups to create standards. ANSI produced \"USA Standard COBOL X3.23\" in August 1968, which became the cornerstone for later versions. This version was known as American National Standard (ANS) COBOL and was adopted by ISO in 1972.\nCOBOL-74.\nBy 1970, COBOL had become the most widely used programming language in the world.\nIndependently of the ANSI committee, the CODASYL Programming Language Committee was working on improving the language. They described new versions in 1968, 1969, 1970 and 1973, including changes such as new inter-program communication, debugging and file merging facilities as well as improved string-handling and library inclusion features.\nAlthough CODASYL was independent of the ANSI committee, the \"CODASYL Journal of Development\" was used by ANSI to identify features that were popular enough to warrant implementing.\nThe Programming Language Committee also liaised with ECMA and the Japanese COBOL Standard committee.\nThe Programming Language Committee was not well-known, however. The vice-president, William Rinehuls, complained that two-thirds of the COBOL community did not know of the committee's existence. It was also poor, lacking the funds to make public documents, such as minutes of meetings and change proposals, freely available.\nIn 1974, ANSI published a revised version of (ANS) COBOL, containing new features such as file organizations, the statement and the segmentation module.\nDeleted features included the statement, the statement (which was replaced by ) and the implementer-defined random access module (which was superseded by the new sequential and relative I/O modules). These made up 44 changes, which rendered existing statements incompatible with the new standard.\nThe report writer was slated to be removed from COBOL, but was reinstated before the standard was published. ISO later adopted the updated standard in 1978.\nCOBOL-85.\nIn June 1978, work began on revising COBOL-74. The proposed standard (commonly called COBOL-80) differed significantly from the previous one, causing concerns about incompatibility and conversion costs. In January 1981, Joseph T. Brophy, Senior Vice-President of Travelers Insurance, threatened to sue the standard committee because it was not upwards compatible with COBOL-74. Mr. Brophy described previous conversions of their 40-million-line code base as \"non-productive\" and a \"complete waste of our programmer resources\".\nLater that year, the Data Processing Management Association (DPMA) said it was \"strongly opposed\" to the new standard, citing \"prohibitive\" conversion costs and enhancements that were \"forced on the user\".\nDuring the first public review period, the committee received 2,200 responses, of which 1,700 were negative form letters.\nOther responses were detailed analyses of the effect COBOL-80 would have on their systems; conversion costs were predicted to be at least 50 cents per line of code. Fewer than a dozen of the responses were in favor of the proposed standard.\nISO TC97-SC5 installed in 1979 the international COBOL Experts Group, on initiative of Wim Ebbinkhuijsen. The group consisted of COBOL experts from many countries, including the United States. Its goal was to achieve mutual understanding and respect between ANSI and the rest of the world with regard to the need of new COBOL features. After three years, ISO changed the status of the group to a formal Working Group: WG 4 COBOL. The group took primary ownership and development of the COBOL standard, where ANSI did most of the proposals.\nIn 1983, the DPMA withdrew its opposition to the standard, citing the responsiveness of the committee to public concerns. In the same year, a National Bureau of Standards study concluded that the proposed standard would present few problems. A year later, a COBOL-80 compiler was released to DEC VAX users, who noted that conversion of COBOL-74 programs posed few problems. The new codice_2 statement and inline codice_3 were particularly well received and improved productivity, thanks to simplified control flow and debugging.\nThe second public review drew another 1,000 (mainly negative) responses, while the last drew just 25, by which time many concerns had been addressed.\nIn 1985, the ISO Working Group 4 accepted the then-version of the ANSI proposed standard, made several changes and set it as the new ISO standard COBOL 85. It was published in late 1985.\nSixty features were changed or deprecated and many were added, such as:\nThe new standard was adopted by all national standard bodies, including ANSI.\nTwo amendments followed in 1989 and 1993, the first introducing intrinsic functions and the other providing corrections.\nCOBOL 2002 and object-oriented COBOL.\nIn 1997, Gartner Group estimated that there were a total of 200 billion lines of COBOL in existence, which ran 80% of all business programs.\nIn the early 1990s, work began on adding object-orientation in the next full revision of COBOL. Object-oriented features were taken from C++ and Smalltalk.\nThe initial estimate was to have this revision completed by 1997, and an ISO Committee Draft (CD) was available by 1997. Some vendors (including Micro Focus, Fujitsu, and IBM) introduced object-oriented syntax based on drafts of the full revision. The final approved ISO standard was approved and published in late 2002.\nFujitsu/GTSoftware, Micro Focus and RainCode introduced object-oriented COBOL compilers targeting the .NET Framework.\nThere were many other new features, many of which had been in the \"CODASYL COBOL Journal of Development\" since 1978 and had missed the opportunity to be included in COBOL-85. These other features included:\nThree corrigenda were published for the standard: two in 2006 and one in 2009.\nCOBOL 2014.\nBetween 2003 and 2009, three technical reports were produced describing object finalization, XML processing and collection classes for COBOL.\nCOBOL 2002 suffered from poor support: no compilers completely supported the standard. Micro Focus found that it was due to a lack of user demand for the new features and due to the abolition of the NIST test suite, which had been used to test compiler conformance. The standardization process was also found to be slow and under-resourced.\nCOBOL 2014 includes the following changes:\nLegacy.\nCOBOL programs are used globally in governments and businesses and are running on diverse operating systems such as z/OS, z/VSE, VME, Unix, OpenVMS and Windows. In 1997, the Gartner Group reported that 80% of the world's business ran on COBOL with over 200 billion lines of code and 5 billion lines more being written annually.\nNear the end of the 20th century, the year 2000 problem (Y2K) was the focus of significant COBOL programming effort, sometimes by the same programmers who had designed the systems decades before. The particular level of effort required to correct COBOL code has been attributed to the large amount of business-oriented COBOL, as business applications use dates heavily, and to fixed-length data fields. After the clean-up effort put into these programs for Y2K, a 2003 survey found that many remained in use.\nThe authors said that the survey data suggest \"a gradual decline in the importance of Cobol in application development over the [following] 10 years unless ... integration with other languages and technologies can be adopted\".\nIn 2006 and 2012, \"Computerworld\" surveys found that over 60% of organizations used COBOL (more than C++ and Visual Basic .NET) and that for half of those, COBOL was used for the majority of their internal software. 36% of managers said they planned to migrate from COBOL, and 25% said they would like to if it was cheaper. Instead, some businesses have migrated their systems from expensive mainframes to cheaper, more modern systems, while maintaining their COBOL programs.\nTestimony before the House of Representatives in 2016 indicated that COBOL is still in use by many federal agencies. Reuters reported in 2017 that 43% of banking systems still used COBOL with over 220 billion lines of COBOL code in use.\nBy 2019, the number of COBOL programmers was shrinking fast due to retirements, leading to an impending skills gap in business and government organizations which still use mainframe systems for high-volume transaction processing. Efforts to rewrite systems in newer languages have proven expensive and problematic, as has the outsourcing of code maintenance, thus proposals to train more people in COBOL are advocated.\nDuring the COVID-19 pandemic and the ensuing surge of unemployment, several US states reported a shortage of skilled COBOL programmers to support the legacy systems used for unemployment benefit management. Many of these systems had been in the process of conversion to more modern programming languages prior to the pandemic, but the process had to be put on hold. Similarly, the US Internal Revenue Service rushed to patch its COBOL-based Individual Master File in order to disburse the tens of millions of payments mandated by the Coronavirus Aid, Relief, and Economic Security Act.\nFeatures.\nSyntax.\nCOBOL has an English-like syntax, which is used to describe nearly everything in a program. For example, a condition can be expressed as \u00a0 or more concisely as \u00a0\u00a0 or \u00a0. More complex conditions can be \"abbreviated\" by removing repeated conditions and variables. For example, \u00a0\u00a0 can be shortened to . To support this English-like syntax, COBOL has over 300 keywords. Some of the keywords are simple alternative or pluralized spellings of the same word, which provides for more English-like statements and clauses; e.g., the and keywords can be used interchangeably, as can and , and and .\nEach COBOL program is made up of four basic lexical items: words, literals, picture character-strings (see ) and separators. Words include reserved words and user-defined identifiers. They are up to 31 characters long and may include letters, digits, hyphens and underscores. Literals include numerals (e.g. ) and strings (e.g. ). Separators include the space character and commas and semi-colons followed by a space.\nA COBOL program is split into four divisions: the identification division, the environment division, the data division and the procedure division. The identification division specifies the name and type of the source element and is where classes and interfaces are specified. The environment division specifies any program features that depend on the system running it, such as files and character sets. The data division is used to declare variables and parameters. The procedure division contains the program's statements. Each division is sub-divided into sections, which are made up of paragraphs.\nMetalanguage.\nCOBOL's syntax is usually described with a unique metalanguage using braces, brackets, bars and underlining. The metalanguage was developed for the original COBOL specifications. Although Backus\u2013Naur form did exist at the time, the committee had not heard of it.\nAs an example, consider the following description of an codice_12 statement:\nformula_1\nThis description permits the following variants:\nADD 1 TO x\nADD 1, a, b TO x ROUNDED, y, z ROUNDED\nADD a, b TO c\n ON SIZE ERROR\n DISPLAY \"Error\"\nEND-ADD\nADD a TO b\n NOT SIZE ERROR\n DISPLAY \"No error\"\n ON SIZE ERROR\n DISPLAY \"Error\"\nCode format.\nCOBOL can be written in two formats: fixed (the default) or free. In fixed-format, code must be aligned to fit in certain areas (a hold-over from using punched cards). Until COBOL 2002, these were:\nIn COBOL 2002, Areas A and B were merged to form the program-text area, which now ends at an implementor-defined column.\nCOBOL 2002 also introduced free-format code. Free-format code can be placed in any column of the file, as in newer programming languages. Comments are specified using codice_13, which can be placed anywhere and can also be used in fixed-format source code. Continuation lines are not present, and the codice_14 directive replaces the codice_15 indicator.\nIdentification division.\nThe identification division identifies the following code entity and contains the definition of a class or interface.\nObject-oriented programming.\nClasses and interfaces have been in COBOL since 2002. Classes have factory objects, containing class methods and variables, and instance objects, containing instance methods and variables. Inheritance and interfaces provide polymorphism. Support for generic programming is provided through parameterized classes, which can be instantiated to use any class or interface. Objects are stored as references which may be restricted to a certain type. There are two ways of calling a method: the statement, which acts similarly to , or through inline method invocation, which is analogous to using functions.\nINVOKE my-class \"foo\" RETURNING var\nMOVE my-class::\"foo\" TO var *&gt; Inline method invocation\nCOBOL does not provide a way to hide methods. Class data can be hidden, however, by declaring it without a clause, which leaves the user with no way to access it. Method overloading was added in COBOL 2014.\nEnvironment division.\nThe environment division contains the configuration section and the input-output section. The configuration section is used to specify variable features such\nas currency signs, locales and character sets. The input-output section contains file-related information.\nFiles.\nCOBOL supports three file formats, or ': sequential, indexed and relative. In sequential files, records are contiguous and must be traversed sequentially, similarly to a linked list. Indexed files have one or more indexes which allow records to be randomly accessed and which can be sorted on them. Each record must have a unique key, but other, ', record keys need not be unique. Implementations of indexed files vary between vendors, although common implementations, such as C\u2011ISAM and VSAM, are based on IBM's ISAM. Relative files, like indexed files, have a unique record key, but they do not have alternate keys. A relative record's key is its ordinal position; for example, the 10th record has a key of 10. This means that creating a record with a key of 5 may require the creation of (empty) preceding records. Relative files also allow for both sequential and random access.\nA common non-standard extension is the \" organization, used to process text files. Records in a file are terminated by a newline and may be of varying length.\nData division.\nThe data division is split into six sections which declare different items: the file section, for file records; the working-storage section, for static variables; the local-storage section, for automatic variables; the linkage section, for parameters and the return value; the report section and the screen section, for text-based user interfaces.\nAggregated data.\nData items in COBOL are declared hierarchically through the use of level-numbers which indicate if a data item is part of another. An item with a higher level-number is subordinate to an item with a lower one. Top-level data items, with a level-number of 1, are called '. Items that have subordinate aggregate data are called '; those that do not are called \". Level-numbers used to describe standard data items are between 1 and 49.\n 01 some-record. *&gt; Aggregate group record item\n 05 num PIC 9(10). *&gt; Elementary item\n 05 the-date. *&gt; Aggregate (sub)group record item\n 10 the-year PIC 9(4). *&gt; Elementary item\n 10 the-month PIC 99. *&gt; Elementary item\n 10 the-day PIC 99. *&gt; Elementary item\nIn the above example, elementary item and group item are subordinate to the record , while elementary items , , and are part of the group item .\nSubordinate items can be disambiguated with the (or ) keyword. For example, consider the example code above along with the following example:\n 01 sale-date.\n 05 the-year PIC 9(4).\n 05 the-month PIC 99.\n 05 the-day PIC 99.\nThe names , , and are ambiguous by themselves, since more than one data item is defined with those names. To specify a particular data item, for instance one of the items contained within the group, the programmer would use (or the equivalent ). (This syntax is similar to the \"dot notation\" supported by most contemporary languages.)\nOther data levels.\nA level-number of 66 is used to declare a re-grouping of previously defined items, irrespective of how those items are structured. This data level, also referred to by the associated , is rarely used and, circa 1988, was usually found in old programs. Its ability to ignore the hierarchical and logical structure data meant its use was not recommended and many installations forbade its use.\n 01 customer-record.\n 05 cust-key PIC X(10).\n 05 cust-name.\n 10 cust-first-name PIC X(30).\n 10 cust-last-name PIC X(30).\n 05 cust-dob PIC 9(8).\n 05 cust-balance PIC 9(7)V99.\n 66 cust-personal-details RENAMES cust-name THRU cust-dob.\n 66 cust-all-details RENAMES cust-name THRU cust-balance.\nA 77 level-number indicates the item is stand-alone, and in such situations is equivalent to the level-number 01. For example, the following code declares two 77-level data items, and , which are non-group data items that are independent of (not subordinate to) any other data items:\n 77 property-name PIC X(80).\n 77 sales-region PIC 9(5).\nAn 88 level-number declares a \" (a so-called 88-level) which is true when its parent data item contains one of the values specified in its clause. For example, the following code defines two 88-level condition-name items that are true or false depending on the current character data value of the data item. When the data item contains a value of , the condition-name is true, whereas when it contains a value of or , the condition-name is true. If the data item contains some other value, both of the condition-names are false.\n 01 wage-type PIC X.\n 88 wage-is-hourly VALUE \"H\".\n 88 wage-is-yearly VALUE \"S\", \"Y\".\nData types.\nStandard COBOL provides the following data types:\nType safety is variable in COBOL. Numeric data is converted between different representations and sizes silently and alphanumeric data can be placed in any data item that can be stored as a string, including numeric and group data. In contrast, object references and pointers may only be assigned from items of the same type and their values may be restricted to a certain type.\nPICTURE clause.\nA (or ) clause is a string of characters, each of which represents a portion of the data item and what it may contain. Some picture characters specify the type of the item and how many characters or digits it occupies in memory. For example, a indicates a decimal digit, and an indicates that the item is signed. Other picture characters (called ' and ' characters) specify how an item should be formatted. For example, a series of characters define character positions as well as how a leading sign character is to be positioned within the final character data; the rightmost non-numeric character will contain the item's sign, while other character positions corresponding to a to the left of this position will contain a space. Repeated characters can be specified more concisely by specifying a number in parentheses after a picture character; for example, is equivalent to . Picture specifications containing only digit () and sign () characters define purely ' data items, while picture specifications containing alphabetic () or alphanumeric () characters define ' data items. The presence of other formatting characters define ' or ' data items.\nUSAGE clause.\nThe clause declares the format data is stored in. Depending on the data type, it can either complement or be used instead of a clause. While it can be used to declare pointers and object references, it is mostly geared towards specifying numeric types. These numeric formats are:\nReport writer.\nThe report writer is a declarative facility for creating reports. The programmer need only specify the report layout and the data required to produce it, freeing them from having to write code to handle things like page breaks, data formatting, and headings and footings.\nReports are associated with report files, which are files which may only be written to through report writer statements.\n FD report-out REPORT sales-report.\nEach report is defined in the report section of the data division. A report is split into report groups which define the report's headings, footings and details. Reports work around hierarchical \". Control breaks occur when a key variable changes it value; for example, when creating a report detailing customers' orders, a control break could occur when the program reaches a different customer's orders. Here is an example report description for a report which gives a salesperson's sales and which warns of any invalid records:\n RD sales-report\n PAGE LIMITS 60 LINES\n FIRST DETAIL 3\n CONTROLS seller-name.\n 01 TYPE PAGE HEADING.\n 03 COL 1 VALUE \"Sales Report\".\n 03 COL 74 VALUE \"Page\".\n 03 COL 79 PIC Z9 SOURCE PAGE-COUNTER.\n 01 sales-on-day TYPE DETAIL, LINE + 1.\n 03 COL 3 VALUE \"Sales on\".\n 03 COL 12 PIC 99/99/9999 SOURCE sales-date.\n 03 COL 21 VALUE \"were\".\n 03 COL 26 PIC $$$$9.99 SOURCE sales-amount.\n 01 invalid-sales TYPE DETAIL, LINE + 1.\n 03 COL 3 VALUE \"INVALID RECORD:\".\n 03 COL 19 PIC X(34) SOURCE sales-record.\n 01 TYPE CONTROL HEADING seller-name, LINE + 2.\n 03 COL 1 VALUE \"Seller:\".\n 03 COL 9 PIC X(30) SOURCE seller-name.\nThe above report description describes the following layout:\nFour statements control the report writer: , which prepares the report writer for printing; , which prints a report group; , which suppresses the printing of a report group; and , which terminates report processing. For the above sales report example, the procedure division might look like this:\n OPEN INPUT sales, OUTPUT report-out\n INITIATE sales-report\n PERFORM UNTIL 1 &lt;&gt; 1\n READ sales\n AT END\n EXIT PERFORM\n END-READ\n VALIDATE sales-record\n IF valid-record\n GENERATE sales-on-day\n ELSE\n GENERATE invalid-sales\n END-IF\n END-PERFORM\n TERMINATE sales-report\n CLOSE sales, report-out\nUse of the Report Writer facility tended to vary considerably; some organizations used it extensively and some not at all. In addition, implementations of Report Writer ranged in quality, with those at the lower end sometimes using excessive amounts of memory at runtime.\nProcedure division.\nProcedures.\nThe sections and paragraphs in the procedure division (collectively called procedures) can be used as labels and as simple subroutines. Unlike in other divisions, paragraphs do not need to be in sections.\nExecution goes down through the procedures of a program until it is terminated.\nTo use procedures as subroutines, the verb is used.\nA statement somewhat resembles a procedure call in a modern language in the sense that execution returns to the code following the statement at the end of the called code; however, it does not provide any mechanism for parameter passing or for returning a result value. If a subroutine is invoked using a simple statement like , then control returns at the end of the called procedure. However, is unusual in that it may be used to call a range spanning a sequence of several adjacent procedures. This is done with the construct:\nPROCEDURE so-and-so.\n PERFORM ALPHA\n PERFORM ALPHA THRU GAMMA\n STOP RUN.\nALPHA.\n DISPLAY 'A'.\nBETA.\n DISPLAY 'B'.\nGAMMA.\n DISPLAY 'C'.\nThe output of this program will be: \"A A B C\".\n also differs from conventional procedure calls in that there is, at least traditionally, no notion of a call stack. As a consequence, nested invocations are possible (a sequence of code being 'ed may execute a statement itself), but require extra care if parts of the same code are executed by both invocations. The problem arises when the code in the inner invocation reaches the exit point of the outer invocation. More formally, if control passes through the exit point of a invocation that was called earlier but has not completed yet, the COBOL 2002 standard officially stipulates that the behaviour is undefined.\nThe reason is that COBOL, rather than a \"return address\", operates with what may be called a continuation address. When control flow reaches the end of any procedure, the continuation address is looked up and control is transferred to that address. Before the program runs, the continuation address for every procedure is initialised to the start address of the procedure that comes next in the program text so that, if no statements happen, control flows from top to bottom through the program. But when a statement executes, it modifies the continuation address of the called procedure (or the last procedure of the called range, if was used), so that control will return to the call site at the end. The original value is saved and is restored afterwards, but there is only one storage position. If two nested invocations operate on overlapping code, they may interfere which each other's management of the continuation address in several ways.\nThe following example (taken from ) illustrates the problem:\nLABEL1.\n DISPLAY '1'\n PERFORM LABEL2 THRU LABEL3\n STOP RUN.\nLABEL2.\n DISPLAY '2'\n PERFORM LABEL3 THRU LABEL4.\nLABEL3.\n DISPLAY '3'.\nLABEL4.\n DISPLAY '4'.\nOne might expect that the output of this program would be \"1 2 3 4 3\": After displaying \"2\", the second causes \"3\" and \"4\" to be displayed, and then the first invocation continues on with \"3\". In traditional COBOL implementations, this is not the case. Rather, the first statement sets the continuation address at the end of so that it will jump back to the call site inside . The second statement sets the return at the end of but does not modify the continuation address of , expecting it to be the default continuation. Thus, when the inner invocation arrives at the end of , it jumps back to the outer statement, and the program stops having printed just \"1 2 3\". On the other hand, in some COBOL implementations like the open-source TinyCOBOL compiler, the two statements do not interfere with each other and the output is indeed \"1 2 3 4 3\". Therefore, the behaviour in such cases is not only (perhaps) surprising, it is also not portable.\nA special consequence of this limitation is that cannot be used to write recursive code. Another simple example to illustrate this (slightly simplified from ):\n MOVE 1 TO A\n PERFORM LABEL\n STOP RUN.\nLABEL.\n DISPLAY A\n IF A &lt; 3\n ADD 1 TO A\n PERFORM LABEL\n END-IF\n DISPLAY 'END'.\nOne might expect that the output is \"1 2 3 END END END\", and in fact that is what some COBOL compilers will produce. But some compilers, like IBM COBOL, will produce code that prints \"1 2 3 END END END END ...\" and so on, printing \"END\" over and over in an endless loop. Since there is limited space to store backup continuation addresses, the backups get overwritten in the course of recursive invocations, and all that can be restored is the jump back to .\nStatements.\nCOBOL 2014 has 47 statements (also called \"), which can be grouped into the following broad categories: control flow, I/O, data manipulation and the report writer. The report writer statements are covered in the report writer section.\nControl flow.\nCOBOL's conditional statements are and . is a switch-like statement with the added capability of evaluating multiple values and conditions. This can be used to implement decision tables. For example, the following might be used to control a CNC lathe: \nEVALUATE TRUE ALSO desired-speed ALSO current-speed\n WHEN lid-closed ALSO min-speed THRU max-speed ALSO LESS THAN desired-speed\n PERFORM speed-up-machine\n WHEN lid-closed ALSO min-speed THRU max-speed ALSO GREATER THAN desired-speed\n PERFORM slow-down-machine\n WHEN lid-open ALSO ANY ALSO NOT ZERO\n PERFORM emergency-stop\n WHEN OTHER\n CONTINUE\nEND-EVALUATE\nThe statement is used to define loops which are executed a condition is true (not true, which is more common in other languages). It is also used to call procedures or ranges of procedures (see the procedures section for more details). and call subprograms and methods, respectively. The name of the subprogram/method is contained in a string which may be a literal or a data item. Parameters can be passed by reference, by content (where a copy is passed by reference) or by value (but only if a prototype is available).\n unloads subprograms from memory. causes the program to jump to a specified procedure.\nThe statement is a return statement and the statement stops the program. The statement has six different formats: it can be used as a return statement, a break statement, a continue statement, an end marker or to leave a procedure.\nExceptions are raised by a statement and caught with a handler, or \", defined in the portion of the procedure division. Declaratives are sections beginning with a statement which specify the errors to handle. Exceptions can be names or objects. is used in a declarative to jump to the statement after the one that raised the exception or to a procedure outside the . Unlike other languages, uncaught exceptions may not terminate the program and the program can proceed unaffected.\nI/O.\nFile I/O is handled by the self-describing , , , and statements along with a further three: , which updates a record; , which selects subsequent records to access by finding a record with a certain key; and , which releases a lock on the last record accessed.\nUser interaction is done using and .\nData manipulation.\nThe following verbs manipulate data:\nFiles and tables are sorted using and the verb merges and sorts files. The verb provides records to sort and retrieves sorted records in order.\nScope termination.\nSome statements, such as and , may themselves contain statements. Such statements may be terminated in two ways: by a period (\"\"), which terminates \"all\" unterminated statements contained, or by a scope terminator, which terminates the nearest matching open statement.\nIF invalid-record\n IF no-more-records\n NEXT SENTENCE\n ELSE\n READ record-file\n AT END SET no-more-records TO TRUE.\nIF invalid-record\n IF no-more-records\n CONTINUE\n ELSE\n READ record-file\n AT END SET no-more-records TO TRUE\n END-READ\n END-IF\nEND-IF\nNested statements terminated with a period are a common source of bugs. For example, examine the following code:\nIF x\n DISPLAY y.\n DISPLAY z.\nHere, the intent is to display codice_19 and codice_20 if condition codice_21 is true. However, codice_20 will be displayed whatever the value of codice_21 because the codice_1 statement is terminated by an erroneous period after .\nAnother bug is a result of the dangling else problem, when two codice_1 statements can associate with an codice_26.\nIF x\n IF y\n DISPLAY a\nELSE\n DISPLAY b.\nIn the above fragment, the codice_26 associates with the \u00a0\u00a0 statement instead of the \u00a0\u00a0 statement, causing a bug. Prior to the introduction of explicit scope terminators, preventing it would require \u00a0\u00a0 to be placed after the inner codice_1.\nSelf-modifying code.\nThe original (1959) COBOL specification supported the infamous \u00a0\u00a0 statement, for which many compilers generated self-modifying code. codice_29 and codice_30 are procedure labels, and the single \u00a0\u00a0 statement in procedure codice_29 executed after such an statement means \u00a0\u00a0 instead. Many compilers still support it,\nbut it was deemed obsolete in the COBOL 1985 standard and deleted in 2002.\nThe statement was poorly regarded because it undermined \"locality of context\" and made a program's overall logic difficult to comprehend. As textbook author Daniel D. McCracken wrote in 1976, when \"someone who has never seen the program before must become familiar with it as quickly as possible, sometimes under critical time pressure because the program has failed ... the sight of a GO TO statement in a paragraph by itself, signaling as it does the existence of an unknown number of ALTER statements at unknown locations throughout the program, strikes fear in the heart of the bravest programmer.\"\nHello, world.\nA \"Hello, world\" program in COBOL:\n IDENTIFICATION DIVISION.\n PROGRAM-ID. hello-world.\n PROCEDURE DIVISION.\n DISPLAY \"Hello, world!\"\nWhen the \u2013 now famous \u2013 \"Hello, World!\" program example in \"The C Programming Language\" was first published in 1978 a similar mainframe COBOL program sample would have been submitted through JCL, very likely using a punch card reader, and 80 column punch cards. The listing below, \"with an empty DATA DIVISION\", was tested using Linux and the System/370 Hercules emulator running MVS 3.8J. The JCL, written in July 2015, is derived from the Hercules tutorials and samples hosted by Jay Moseley. In keeping with COBOL programming of that era, HELLO, WORLD is displayed in all capital letters.\n//COBUCLG JOB (001),'COBOL BASE TEST', 00010000\n// CLASS=A,MSGCLASS=A,MSGLEVEL=(1,1) 00020000\n//BASETEST EXEC COBUCLG 00030000\n//COB.SYSIN DD * 00040000\n 00000* VALIDATION OF BASE COBOL INSTALL 00050000\n 01000 IDENTIFICATION DIVISION. 00060000\n 01100 PROGRAM-ID. 'HELLO'. 00070000\n 02000 ENVIRONMENT DIVISION. 00080000\n 02100 CONFIGURATION SECTION. 00090000\n 02110 SOURCE-COMPUTER. GNULINUX. 00100000\n 02120 OBJECT-COMPUTER. HERCULES. 00110000\n 02200 SPECIAL-NAMES. 00120000\n 02210 CONSOLE IS CONSL. 00130000\n 03000 DATA DIVISION. 00140000\n 04000 PROCEDURE DIVISION. 00150000\n 04100 00-MAIN. 00160000\n 04110 DISPLAY 'HELLO, WORLD' UPON CONSL. 00170000\n 04900 STOP RUN. 00180000\n//LKED.SYSLIB DD DSNAME=SYS1.COBLIB,DISP=SHR 00190000\n// DD DSNAME=SYS1.LINKLIB,DISP=SHR 00200000\n//GO.SYSPRINT DD SYSOUT=A 00210000\n// 00220000\nAfter submitting the JCL, the MVS console displayed:\n 19.52.48 JOB 3 $HASP100 COBUCLG ON READER1 COBOL BASE TEST\n 19.52.48 JOB 3 IEF677I WARNING MESSAGE(S) FOR JOB COBUCLG ISSUED\n 19.52.48 JOB 3 $HASP373 COBUCLG STARTED - INIT 1 - CLASS A - SYS BSP1\n 19.52.48 JOB 3 IEC130I SYSPUNCH DD STATEMENT MISSING\n 19.52.48 JOB 3 IEC130I SYSLIB DD STATEMENT MISSING\n 19.52.48 JOB 3 IEC130I SYSPUNCH DD STATEMENT MISSING\n 19.52.48 JOB 3 IEFACTRT - Stepname Procstep Program Retcode\n 19.52.48 JOB 3 COBUCLG BASETEST COB IKFCBL00 RC= 0000\n 19.52.48 JOB 3 COBUCLG BASETEST LKED IEWL RC= 0000\n 19.52.48 JOB 3 +HELLO, WORLD\n 19.52.48 JOB 3 COBUCLG BASETEST GO PGM=*.DD RC= 0000\n 19.52.48 JOB 3 $HASP395 COBUCLG ENDED\n\"Line 10 of the console listing above is highlighted for effect, the highlighting is not part of the actual console output\".\nThe associated compiler listing generated over four pages of technical detail and job run information, for the single line of output from the 14 lines of COBOL.\nReception.\nLack of structure.\nIn the 1970s, adoption of the structured programming paradigm was becoming increasingly widespread. Edsger Dijkstra, a preeminent computer scientist, wrote a letter to the editor of Communications of the ACM, published 1975 entitled \"How do we tell truths that might hurt?\", in which he was critical of COBOL and several other contemporary languages; remarking that \"the use of COBOL cripples the mind\".\nIn a published dissent to Dijkstra's remarks, the computer scientist Howard E. Tompkins claimed that unstructured COBOL tended to be \"written by programmers that have never had the benefit of structured COBOL taught well\", arguing that the issue was primarily one of training.\nOne cause of spaghetti code was the statement. Attempts to remove s from COBOL code, however, resulted in convoluted programs and reduced code quality. s were largely replaced by the statement and procedures, which promoted modular programming and gave easy access to powerful looping facilities. However, could only be used with procedures so loop bodies were not located where they were used, making programs harder to understand.\nCOBOL programs were infamous for being monolithic and lacking modularization.\nCOBOL code could only be modularized through procedures, which were found to be inadequate for large systems. It was impossible to restrict access to data, meaning a procedure could access and modify data item. Furthermore, there was no way to pass parameters to a procedure, an omission Jean Sammet regarded as the committee's biggest mistake.\nAnother complication stemmed from the ability to a specified sequence of procedures. This meant that control could jump to and return from any procedure, creating convoluted control flow and permitting a programmer to break the single-entry single-exit rule.\nThis situation improved as COBOL adopted more features. COBOL-74 added subprograms, giving programmers the ability to control the data each part of the program could access. COBOL-85 then added nested subprograms, allowing programmers to hide subprograms. Further control over data and code came in 2002 when object-oriented programming, user-defined functions and user-defined data types were included.\nNevertheless, much important legacy COBOL software uses unstructured code, which has become unmaintainable. It can be too risky and costly to modify even a simple section of code, since it may be used from unknown places in unknown ways.\nCompatibility issues.\nCOBOL was intended to be a highly portable, \"common\" language. However, by 2001, around 300 dialects had been created. One source of dialects was the standard itself: the 1974 standard was composed of one mandatory nucleus and eleven functional modules, each containing two or three levels of support. This permitted 104,976 official variants.\nCOBOL-85 was not fully compatible with earlier versions, and its development was controversial. Joseph T. Brophy, the CIO of Travelers Insurance, spearheaded an effort to inform COBOL users of the heavy reprogramming costs of implementing the new standard. As a result, the ANSI COBOL Committee received more than 2,200 letters from the public, mostly negative, requiring the committee to make changes. On the other hand, conversion to COBOL-85 was thought to increase productivity in future years, thus justifying the conversion costs.\nVerbose syntax.\nCOBOL syntax has often been criticized for its verbosity. Proponents say that this was intended to make the code self-documenting, easing program maintenance. COBOL was also intended to be easy for programmers to learn and use, while still being readable to non-technical staff such as managers.\nThe desire for readability led to the use of English-like syntax and structural elements, such as nouns, verbs, clauses, sentences, sections, and divisions. Yet by 1984, maintainers of COBOL programs were struggling to deal with \"incomprehensible\" code and the main changes in COBOL-85 were there to help ease maintenance.\nJean Sammet, a short-range committee member, noted that \"little attempt was made to cater to the professional programmer, in fact people whose main interest is programming tend to be very unhappy with COBOL\" which she attributed to COBOL's verbose syntax.\nIsolation from the computer science community.\nThe COBOL community has always been isolated from the computer science community. No academic computer scientists participated in the design of COBOL: all of those on the committee came from commerce or government. Computer scientists at the time were more interested in fields like numerical analysis, physics and system programming than the commercial file-processing problems which COBOL development tackled. Jean Sammet attributed COBOL's unpopularity to an initial \"snob reaction\" due to its inelegance, the lack of influential computer scientists participating in the design process and a disdain for business data processing. The COBOL specification used a unique \"notation\", or metalanguage, to define its syntax rather than the new Backus\u2013Naur form which the committee did not know of. This resulted in \"severe\" criticism.\nLater, COBOL suffered from a shortage of material covering it; it took until 1963 for introductory books to appear (with Richard D. Irwin publishing a college textbook on COBOL in 1966). By 1985, there were twice as many books on Fortran and four times as many on BASIC as on COBOL in the Library of Congress. University professors taught more modern, state-of-the-art languages and techniques instead of COBOL which was said to have a \"trade school\" nature. Donald Nelson, chair of the CODASYL COBOL committee, said in 1984 that \"academics ... hate COBOL\" and that computer science graduates \"had 'hate COBOL' drilled into them\". A 2013 poll by Micro Focus found that 20% of university academics thought COBOL was outdated or dead and that 55% believed their students thought COBOL was outdated or dead. The same poll also found that only 25% of academics had COBOL programming on their curriculum even though 60% thought they should teach it.\nIn contrast, in 2003, COBOL featured in 80% of information systems curricula in the United States, the same proportion as C++ and Java.\nThere was also significant condescension towards COBOL in the business community from users of other languages, for example FORTRAN or assembler, implying that COBOL could be used only for non-challenging problems.\nConcerns about the design process.\nDoubts have been raised about the competence of the standards committee. Short-term committee member Howard Bromberg said that there was \"little control\" over the development process and that it was \"plagued by discontinuity of personnel and ... a lack of talent.\" Jean Sammet and Jerome Garfunkel also noted that changes introduced in one revision of the standard would be reverted in the next, due as much to changes in who was in the standard committee as to objective evidence.\nCOBOL standards have repeatedly suffered from delays: COBOL-85 arrived five years later than hoped,\nCOBOL 2002 was five years late,\nand COBOL 2014 was six years late.\nTo combat delays, the standard committee allowed the creation of optional addenda which would add features more quickly than by waiting for the next standard revision. However, some committee members raised concerns about incompatibilities between implementations and frequent modifications of the standard.\nInfluences on other languages.\nCOBOL's data structures influenced subsequent programming languages. Its record and file structure influenced PL/I and Pascal, and the codice_32 clause was a predecessor to Pascal's variant records. Explicit file structure definitions preceded the development of database management systems and aggregated data was a significant advance over Fortran's arrays.\ncodice_16 data declarations were incorporated into PL/I, with minor changes.\nCOBOL's facility, although considered \"primitive\", influenced the development of include directives.\nThe focus on portability and standardization meant programs written in COBOL could be portable and facilitated the spread of the language to a wide variety of hardware platforms and operating systems. Additionally, the well-defined division structure restricts the definition of external references to the Environment Division, which simplifies platform changes in particular."}
{"id": "6801", "revid": "20483999", "url": "https://en.wikipedia.org/wiki?curid=6801", "title": "Crew", "text": "A crew is a body or a class of people who work at a common activity, generally in a structured or hierarchical organization. A location in which a crew works is called a crewyard or a workyard. The word has nautical resonances: the tasks involved in operating a ship, particularly a sailing ship, providing numerous specialities within a ship's crew, often organised with a chain of command. Traditional nautical usage strongly distinguishes officers from crew, though the two groups combined form the ship's company. Members of a crew are often referred to by the title \"Crewman\".\n\"Crew\" also refers to the sport of rowing, where teams row competitively in racing shells."}
{"id": "6803", "revid": "40160147", "url": "https://en.wikipedia.org/wiki?curid=6803", "title": "CCD", "text": "CCD may refer to:"}
{"id": "6804", "revid": "122969", "url": "https://en.wikipedia.org/wiki?curid=6804", "title": "Charge-coupled device", "text": "A charge-coupled device (CCD) is an integrated circuit containing an array of linked, or coupled, capacitors. Under the control of an external circuit, each capacitor can transfer its electric charge to a neighboring capacitor. CCD sensors are a major technology used in digital imaging.\nIn a CCD image sensor, pixels are represented by p-doped metal\u2013oxide\u2013semiconductor (MOS) capacitors. These MOS capacitors, the basic building blocks of a CCD, are biased above the threshold for inversion when image acquisition begins, allowing the conversion of incoming photons into electron charges at the semiconductor-oxide interface; the CCD is then used to read out these charges. Although CCDs are not the only technology to allow for light detection, CCD image sensors are widely used in professional, medical, and scientific applications where high-quality image data are required. In applications with less exacting quality demands, such as consumer and professional digital cameras, active pixel sensors, also known as CMOS sensors (complementary MOS sensors), are generally used. However, the large quality advantage CCDs enjoyed early on has narrowed over time and since the late 2010s CMOS sensors are the dominant technology, having largely if not completely replaced CCD image sensors.\nHistory.\nThe basis for the CCD is the metal\u2013oxide\u2013semiconductor (MOS) structure, with MOS capacitors being the basic building blocks of a CCD, and a depleted MOS structure used as the photodetector in early CCD devices.\nIn the late 1960s, Willard Boyle and George E. Smith at Bell Labs were researching MOS technology while working on semiconductor bubble memory. They realized that an electric charge was the analogy of the magnetic bubble and that it could be stored on a tiny MOS capacitor. As it was fairly straightforward to fabricate a series of MOS capacitors in a row, they connected a suitable voltage to them so that the charge could be stepped along from one to the next. This led to the invention of the charge-coupled device by Boyle and Smith in 1969. They conceived of the design of what they termed, in their notebook, \"Charge 'Bubble' Devices\".\nThe initial paper describing the concept in April 1970 listed possible uses as memory, a delay line, and an imaging device. The device could also be used as a shift register. The essence of the design was the ability to transfer charge along the surface of a semiconductor from one storage capacitor to the next. The concept was similar in principle to the bucket-brigade device (BBD), which was developed at Philips Research Labs during the late 1960s.\nThe first experimental device demonstrating the principle was a row of closely spaced metal squares on an oxidized silicon surface electrically accessed by wire bonds. It was demonstrated by Gil Amelio, Michael Francis Tompsett and George Smith in April 1970. This was the first experimental application of the CCD in image sensor technology, and used a depleted MOS structure as the photodetector. The first patent () on the application of CCDs to imaging was assigned to Tompsett, who filed the application in 1971.\nThe first working CCD made with integrated circuit technology was a simple 8-bit shift register, reported by Tompsett, Amelio and Smith in August 1970. This device had input and output circuits and was used to demonstrate its use as a shift register and as a crude eight pixel linear imaging device. Development of the device progressed at a rapid rate. By 1971, Bell researchers led by Michael Tompsett were able to capture images with simple linear devices.\nSeveral companies, including Fairchild Semiconductor, RCA and Texas Instruments, picked up on the invention and began development programs. Fairchild's effort, led by ex-Bell researcher Gil Amelio, was the first with commercial devices, and by 1974 had a linear 500-element device and a 2-D 100 \u00d7 100 pixel device. Steven Sasson, an electrical engineer working for Kodak, invented the first digital still camera using a Fairchild CCD in 1975.\nThe interline transfer (ILT) CCD device was proposed by L. Walsh and R. Dyck at Fairchild in 1973 to reduce smear and eliminate a mechanical shutter. To further reduce smear from bright light sources, the frame-interline-transfer (FIT) CCD architecture was developed by K. Horii, T. Kuroda and T. Kunii at Matsushita (now Panasonic) in 1981.\nThe first KH-11 KENNEN reconnaissance satellite equipped with charge-coupled device array ( pixels) technology for imaging was launched in December 1976. Under the leadership of Kazuo Iwama, Sony started a large development effort on CCDs involving a significant investment. Eventually, Sony managed to mass-produce CCDs for their camcorders. Before this happened, Iwama died in August 1982; subsequently, a CCD chip was placed on his tombstone to acknowledge his contribution. The first mass-produced consumer CCD video camera, the CCD-G5, was released by Sony in 1983, based on a prototype developed by Yoshiaki Hagiwara in 1981.\nEarly CCD sensors suffered from shutter lag. This was largely resolved with the invention of the pinned photodiode (PPD). It was invented by Nobukazu Teranishi, Hiromitsu Shiraki and Yasuo Ishihara at NEC in 1980. They recognized that lag can be eliminated if the signal carriers could be transferred from the photodiode to the CCD. This led to their invention of the pinned photodiode, a photodetector structure with low lag, low noise, high quantum efficiency and low dark current. It was first publicly reported by Teranishi and Ishihara with A. Kohono, E. Oda and K. Arai in 1982, with the addition of an anti-blooming structure. The new photodetector structure invented at NEC was given the name \"pinned photodiode\" (PPD) by B.C. Burkey at Kodak in 1984. In 1987, the PPD began to be incorporated into most CCD devices, becoming a fixture in consumer electronic video cameras and then digital still cameras. Since then, the PPD has been used in nearly all CCD sensors and then CMOS sensors.\nIn January 2006, Boyle and Smith were awarded the National Academy of Engineering Charles Stark Draper Prize, and in 2009 they were awarded the Nobel Prize for Physics, for their invention of the CCD concept. Michael Tompsett was awarded the 2010 National Medal of Technology and Innovation, for pioneering work and electronic technologies including the design and development of the first CCD imagers. He was also awarded the 2012 IEEE Edison Medal for \"pioneering contributions to imaging devices including CCD Imagers, cameras and thermal imagers\".\nBasics of operation.\nIn a CCD for capturing images, there is a photoactive region (an epitaxial layer of silicon), and a transmission region made out of a shift register (the CCD, properly speaking).\nAn image is projected through a lens onto the capacitor array (the photoactive region), causing each capacitor to accumulate an electric charge proportional to the light intensity at that location. A one-dimensional array, used in line-scan cameras, captures a single slice of the image, whereas a two-dimensional array, used in video and still cameras, captures a two-dimensional picture corresponding to the scene projected onto the focal plane of the sensor. Once the array has been exposed to the image, a control circuit causes each capacitor to transfer its contents to its neighbor (operating as a shift register). The last capacitor in the array dumps its charge into a charge amplifier, which converts the charge into a voltage. By repeating this process, the controlling circuit converts the entire contents of the array in the semiconductor to a sequence of voltages. In a digital device, these voltages are then sampled, digitized, and usually stored in memory; in an analog device (such as an analog video camera), they are processed into a continuous analog signal (e.g. by feeding the output of the charge amplifier into a low-pass filter), which is then processed and fed out to other circuits for transmission, recording, or other processing.\nDetailed physics of operation.\nCharge generation.\nBefore the MOS capacitors are exposed to light, they are biased into the depletion region; in n-channel CCDs, the silicon under the bias gate is slightly \"p\"-doped or intrinsic. The gate is then biased at a positive potential, above the threshold for strong inversion, which will eventually result in the creation of an \"n\" channel below the gate as in a MOSFET. However, it takes time to reach this thermal equilibrium: up to hours in high-end scientific cameras cooled at low temperature. Initially after biasing, the holes are pushed far into the substrate, and no mobile electrons are at or near the surface; the CCD thus operates in a non-equilibrium state called deep depletion.\nThen, when electron\u2013hole pairs are generated in the depletion region, they are separated by the electric field, the electrons move toward the surface, and the holes move toward the substrate. Four pair-generation processes can be identified:\nThe last three processes are known as dark-current generation, and add noise to the image; they can limit the total usable integration time. The accumulation of electrons at or near the surface can proceed either until image integration is over and charge begins to be transferred, or thermal equilibrium is reached. In this case, the well is said to be full. The maximum capacity of each well is known as the well depth, typically about 105 electrons per pixel.\nDesign and manufacturing.\nThe photoactive region of a CCD is, generally, an epitaxial layer of silicon. It is lightly \"p\" doped (usually with boron) and is grown upon a substrate material, often p++. In buried-channel devices, the type of design utilized in most modern CCDs, certain areas of the surface of the silicon are ion implanted with phosphorus, giving them an n-doped designation. This region defines the channel in which the photogenerated charge packets will travel. Simon Sze details the advantages of a buried-channel device:\nThis thin layer (= 0.2\u20130.3 micron) is fully depleted and the accumulated photogenerated charge is kept away from the surface. This structure has the advantages of higher transfer efficiency and lower dark current, from reduced surface recombination. The penalty is smaller charge capacity, by a factor of 2\u20133 compared to the surface-channel CCD. The gate oxide, i.e. the capacitor dielectric, is grown on top of the epitaxial layer and substrate.\nLater in the process, polysilicon gates are deposited by chemical vapor deposition, patterned with photolithography, and etched in such a way that the separately phased gates lie perpendicular to the channels. The channels are further defined by utilization of the LOCOS process to produce the channel stop region.\nChannel stops are thermally grown oxides that serve to isolate the charge packets in one column from those in another. These channel stops are produced before the polysilicon gates are, as the LOCOS process utilizes a high-temperature step that would destroy the gate material. The channel stops are parallel to, and exclusive of, the channel, or \"charge carrying\", regions.\nChannel stops often have a p+ doped region underlying them, providing a further barrier to the electrons in the charge packets (this discussion of the physics of CCD devices assumes an electron transfer device, though hole transfer is possible).\nThe clocking of the gates, alternately high and low, will forward and reverse bias the diode that is provided by the buried channel (n-doped) and the epitaxial layer (p-doped). This will cause the CCD to deplete, near the p\u2013n junction and will collect and move the charge packets beneath the gates\u2014and within the channels\u2014of the device.\nCCD manufacturing and operation can be optimized for different uses. The above process describes a frame transfer CCD. While CCDs may be manufactured on a heavily doped p++ wafer it is also possible to manufacture a device inside p-wells that have been placed on an n-wafer. This second method, reportedly, reduces smear, dark current, and infrared and red response. This method of manufacture is used in the construction of interline-transfer devices.\nAnother version of CCD is called a peristaltic CCD. In a peristaltic charge-coupled device, the charge-packet transfer operation is analogous to the peristaltic contraction and dilation of the digestive system. The peristaltic CCD has an additional implant that keeps the charge away from the silicon/silicon dioxide interface and generates a large lateral electric field from one gate to the next. This provides an additional driving force to aid in transfer of the charge packets.\nArchitecture.\nThe CCD image sensors can be implemented in several different architectures. The most common are full-frame, frame-transfer, and interline. The distinguishing characteristic of each of these architectures is their approach to the problem of shuttering.\nIn a full-frame device, all of the image area is active, and there is no electronic shutter. A mechanical shutter must be added to this type of sensor or the image smears as the device is clocked or read out.\nWith a frame-transfer CCD, half of the silicon area is covered by an opaque mask (typically aluminum). The image can be quickly transferred from the image area to the opaque area or storage region with acceptable smear of a few percent. That image can then be read out slowly from the storage region while a new image is integrating or exposing in the active area. Frame-transfer devices typically do not require a mechanical shutter and were a common architecture for early solid-state broadcast cameras. The downside to the frame-transfer architecture is that it requires twice the silicon real estate of an equivalent full-frame device; hence, it costs roughly twice as much.\nThe interline architecture extends this concept one step further and masks every other column of the image sensor for storage. In this device, only one pixel shift has to occur to transfer from image area to storage area; thus, shutter times can be less than a microsecond and smear is essentially eliminated. The advantage is not free, however, as the imaging area is now covered by opaque strips dropping the fill factor to approximately 50 percent and the effective quantum efficiency by an equivalent amount. Modern designs have addressed this deleterious characteristic by adding microlenses on the surface of the device to direct light away from the opaque regions and on the active area. Microlenses can bring the fill factor back up to 90 percent or more depending on pixel size and the overall system's optical design.\nThe choice of architecture comes down to one of utility. If the application cannot tolerate an expensive, failure-prone, power-intensive mechanical shutter, an interline device is the right choice. Consumer snap-shot cameras have used interline devices. On the other hand, for those applications that require the best possible light collection and issues of money, power and time are less important, the full-frame device is the right choice. Astronomers tend to prefer full-frame devices. The frame-transfer falls in between and was a common choice before the fill-factor issue of interline devices was addressed. Today, frame-transfer is usually chosen when an interline architecture is not available, such as in a back-illuminated device.\nCCDs containing grids of pixels are used in digital cameras, optical scanners, and video cameras as light-sensing devices. They commonly respond to 70 percent of the incident light (meaning a quantum efficiency of about 70 percent) making them far more efficient than photographic film, which captures only about 2 percent of the incident light.\nMost common types of CCDs are sensitive to near-infrared light, which allows infrared photography, night-vision devices, and zero lux (or near zero lux) video-recording/photography. For normal silicon-based detectors, the sensitivity is limited to 1.1\u00a0\u03bcm. One other consequence of their sensitivity to infrared is that infrared from remote controls often appears on CCD-based digital cameras or camcorders if they do not have infrared blockers.\nCooling reduces the array's dark current, improving the sensitivity of the CCD to low light intensities, even for ultraviolet and visible wavelengths. Professional observatories often cool their detectors with liquid nitrogen to reduce the dark current, and therefore the thermal noise, to negligible levels.\nFrame transfer CCD.\nThe frame transfer CCD imager was the first imaging structure proposed for CCD Imaging by Michael Tompsett at Bell Laboratories. A frame transfer CCD is a specialized CCD, often used in astronomy and some professional video cameras, designed for high exposure efficiency and correctness.\nThe normal functioning of a CCD, astronomical or otherwise, can be divided into two phases: exposure and readout. During the first phase, the CCD passively collects incoming photons, storing electrons in its cells. After the exposure time is passed, the cells are read out one line at a time. During the readout phase, cells are shifted down the entire area of the CCD. While they are shifted, they continue to collect light. Thus, if the shifting is not fast enough, errors can result from light that falls on a cell holding charge during the transfer. These errors are referred to as \"vertical smear\" and cause a strong light source to create a vertical line above and below its exact location. In addition, the CCD cannot be used to collect light while it is being read out. Unfortunately, a faster shifting requires a faster readout, and a faster readout can introduce errors in the cell charge measurement, leading to a higher noise level.\nA frame transfer CCD solves both problems: it has a shielded, not light sensitive, area containing as many cells as the area exposed to light. Typically, this area is covered by a reflective material such as aluminium. When the exposure time is up, the cells are transferred very rapidly to the hidden area. Here, safe from any incoming light, cells can be read out at any speed one deems necessary to correctly measure the cells' charge. At the same time, the exposed part of the CCD is collecting light again, so no delay occurs between successive exposures.\nThe disadvantage of such a CCD is the higher cost: the cell area is basically doubled, and more complex control electronics are needed.\nIntensified charge-coupled device.\nAn intensified charge-coupled device (ICCD) is a CCD that is optically connected to an image intensifier that is mounted in front of the CCD.\nAn image intensifier includes three functional elements: a photocathode, a micro-channel plate (MCP) and a phosphor screen. These three elements are mounted one close behind the other in the mentioned sequence. The photons which are coming from the light source fall onto the photocathode, thereby generating photoelectrons. The photoelectrons are accelerated towards the MCP by an electrical control voltage, applied between photocathode and MCP. The electrons are multiplied inside of the MCP and thereafter accelerated towards the phosphor screen. The phosphor screen finally converts the multiplied electrons back to photons which are guided to the CCD by a fiber optic or a lens.\nAn image intensifier inherently includes a shutter functionality: If the control voltage between the photocathode and the MCP is reversed, the emitted photoelectrons are not accelerated towards the MCP but return to the photocathode. Thus, no electrons are multiplied and emitted by the MCP, no electrons are going to the phosphor screen and no light is emitted from the image intensifier. In this case no light falls onto the CCD, which means that the shutter is closed. The process of reversing the control voltage at the photocathode is called \"gating\" and therefore ICCDs are also called gateable CCD cameras.\nBesides the extremely high sensitivity of ICCD cameras, which enable single photon detection, the gateability is one of the major advantages of the ICCD over the EMCCD cameras. The highest performing ICCD cameras enable shutter times as short as 200 picoseconds.\nICCD cameras are in general somewhat higher in price than EMCCD cameras because they need the expensive image intensifier. On the other hand, EMCCD cameras need a cooling system to cool the EMCCD chip down to temperatures around . This cooling system adds additional costs to the EMCCD camera and often yields heavy condensation problems in the application.\nICCDs are used in night vision devices and in various scientific applications.\nElectron-multiplying CCD.\nAn electron-multiplying CCD (EMCCD, also known as an L3Vision CCD, a product commercialized by e2v Ltd., GB, L3CCD or Impactron CCD, a now-discontinued product offered in the past by Texas Instruments) is a charge-coupled device in which a gain register is placed between the shift register and the output amplifier. The gain register is split up into a large number of stages. In each stage, the electrons are multiplied by impact ionization in a similar way to an avalanche diode. The gain probability at every stage of the register is small (\"P\" &lt; 2%), but as the number of elements is large (N &gt; 500), the overall gain can be very high (formula_1), with single input electrons giving many thousands of output electrons. Reading a signal from a CCD gives a noise background, typically a few electrons. In an EMCCD, this noise is superimposed on many thousands of electrons rather than a single electron; the devices' primary advantage is thus their negligible readout noise. The use of avalanche breakdown for amplification of photo charges had already been described in the in 1973 by George E. Smith/Bell Telephone Laboratories.\nEMCCDs show a similar sensitivity to intensified CCDs (ICCDs). However, as with ICCDs, the gain that is applied in the gain register is stochastic and the \"exact\" gain that has been applied to a pixel's charge is impossible to know. At high gains (&gt; 30), this uncertainty has the same effect on the signal-to-noise ratio (SNR) as halving the quantum efficiency (QE) with respect to operation with a gain of unity. However, at very low light levels (where the quantum efficiency is most important), it can be assumed that a pixel either contains an electron\u2014or not. This removes the noise associated with the stochastic multiplication at the risk of counting multiple electrons in the same pixel as a single electron. To avoid multiple counts in one pixel due to coincident photons in this mode of operation, high frame rates are essential. The dispersion in the gain is shown in the graph on the right. For multiplication registers with many elements and large gains it is well modelled by the equation:\nformula_2 if formula_3\nwhere \"P\" is the probability of getting \"n\" output electrons given \"m\" input electrons and a total mean multiplication register gain of \"g\".\nBecause of the lower costs and better resolution, EMCCDs are capable of replacing ICCDs in many applications. ICCDs still have the advantage that they can be gated very fast and thus are useful in applications like range-gated imaging. EMCCD cameras indispensably need a cooling system\u2014using either thermoelectric cooling or liquid nitrogen\u2014to cool the chip down to temperatures in the range of . This cooling system unfortunately adds additional costs to the EMCCD imaging system and may yield condensation problems in the application. However, high-end EMCCD cameras are equipped with a permanent hermetic vacuum system confining the chip to avoid condensation issues.\nThe low-light capabilities of EMCCDs find use in astronomy and biomedical research, among other fields. In particular, their low noise at high readout speeds makes them very useful for a variety of astronomical applications involving low light sources and transient events such as lucky imaging of faint stars, high speed photon counting photometry, Fabry-P\u00e9rot spectroscopy and high-resolution spectroscopy. More recently, these types of CCDs have broken into the field of biomedical research in low-light applications including small animal imaging, single-molecule imaging, Raman spectroscopy, super resolution microscopy as well as a wide variety of modern fluorescence microscopy techniques thanks to greater SNR in low-light conditions in comparison with traditional CCDs and ICCDs.\nIn terms of noise, commercial EMCCD cameras typically have clock-induced charge (CIC) and dark current (dependent on the extent of cooling) that together lead to an effective readout noise ranging from 0.01 to 1 electrons per pixel read. However, recent improvements in EMCCD technology have led to a new generation of cameras capable of producing significantly less CIC, higher charge transfer efficiency and an EM gain 5 times higher than what was previously available. These advances in low-light detection lead to an effective total background noise of 0.001 electrons per pixel read, a noise floor unmatched by any other low-light imaging device.\nUse in astronomy.\nDue to the high quantum efficiencies of charge-coupled device (CCD) (the ideal quantum efficiency is 100%, one generated electron per incident photon), linearity of their outputs, ease of use compared to photographic plates, and a variety of other reasons, CCDs were very rapidly adopted by astronomers for nearly all UV-to-infrared applications.\nThermal noise and cosmic rays may alter the pixels in the CCD array. To counter such effects, astronomers take several exposures with the CCD shutter closed and opened. The average of images taken with the shutter closed is necessary to lower the random noise. Once developed, the dark frame average image is then subtracted from the open-shutter image to remove the dark current and other systematic defects (dead pixels, hot pixels, etc.) in the CCD. Newer Skipper CCDs counter noise by collecting data with the same collected charge multiple times.\nThe Hubble Space Telescope, in particular, has a highly developed series of steps (\u201cdata reduction pipeline\u201d) to convert the raw CCD data to useful images.\nCCD cameras used in astrophotography often require sturdy mounts to cope with vibrations from wind and other sources, along with the tremendous weight of most imaging platforms. To take long exposures of galaxies and nebulae, many astronomers use a technique known as auto-guiding. Most autoguiders use a second CCD chip to monitor deviations during imaging. This chip can rapidly detect errors in tracking and command the mount motors to correct for them.\nAn unusual astronomical application of CCDs, called drift-scanning, uses a CCD to make a fixed telescope behave like a tracking telescope and follow the motion of the sky. The charges in the CCD are transferred and read in a direction parallel to the motion of the sky, and at the same speed. In this way, the telescope can image a larger region of the sky than its normal field of view. The Sloan Digital Sky Survey is the most famous example of this, using the technique to produce a survey of over a quarter of the sky.\nIn addition to imagers, CCDs are also used in an array of analytical instrumentation including spectrometers and interferometers.\nColor cameras.\nDigital color cameras generally use a Bayer mask over the CCD. Each square of four pixels has one filtered red, one blue, and two green (the human eye is more sensitive to green than either red or blue). The result of this is that luminance information is collected at every pixel, but the color resolution is lower than the luminance resolution.\nBetter color separation can be reached by three-CCD devices (3CCD) and a dichroic beam splitter prism, that splits the image into red, green and blue components. Each of the three CCDs is arranged to respond to a particular color. Many professional video camcorders, and some semi-professional camcorders, use this technique, although developments in competing CMOS technology have made CMOS sensors, both with beam-splitters and bayer filters, increasingly popular in high-end video and digital cinema cameras. Another advantage of 3CCD over a Bayer mask device is higher quantum efficiency (higher light sensitivity), because most of the light from the lens enters one of the silicon sensors, while a Bayer mask absorbs a high proportion (more than 2/3) of the light falling on each pixel location.\nFor still scenes, for instance in microscopy, the resolution of a Bayer mask device can be enhanced by microscanning technology. During the process of color co-site sampling, several frames of the scene are produced. Between acquisitions, the sensor is moved in pixel dimensions, so that each point in the visual field is acquired consecutively by elements of the mask that are sensitive to the red, green, and blue components of its color. Eventually every pixel in the image has been scanned at least once in each color and the resolution of the three channels become equivalent (the resolutions of red and blue channels are quadrupled while the green channel is doubled).\nSensor sizes.\nSensors (CCD / CMOS) come in various sizes, or image sensor formats. These sizes are often referred to with an inch fraction designation such as 1/1.8\u2033 or 2/3\u2033 called the optical format. This measurement actually originates back in the 1950s and the time of Vidicon tubes.\nBlooming.\nWhen a CCD exposure is long enough, eventually the electrons that collect in the \"bins\" in the brightest part of the image will overflow the bin, resulting in blooming. The structure of the CCD allows the electrons to flow more easily in one direction than another, resulting in vertical streaking.\nSome anti-blooming features that can be built into a CCD reduce its sensitivity to light by using some of the pixel area for a drain structure.\nJames M. Early developed a vertical anti-blooming drain that would not detract from the light collection area, and so did not reduce light sensitivity."}
{"id": "6805", "revid": "40374695", "url": "https://en.wikipedia.org/wiki?curid=6805", "title": "Communist", "text": ""}
{"id": "6806", "revid": "910180", "url": "https://en.wikipedia.org/wiki?curid=6806", "title": "Computer memory", "text": "In computing, memory is a device or system that is used to store information for immediate use in a computer or related computer hardware and digital electronic devices. The term \"memory\" is often synonymous with the term \"primary storage\" or \"main memory\". An archaic synonym for memory is store.\nComputer memory operates at a high speed compared to storage that is slower but offers higher capacities. If needed, contents of the computer memory can be transferred to storage; a common way of doing this is through a memory management technique called \"virtual memory\". \nModern memory is implemented as semiconductor memory, where data is stored within memory cells built from MOS transistors on an integrated circuit. There are two main kinds of semiconductor memory, volatile and non-volatile. Examples of non-volatile memory are flash memory and ROM, PROM, EPROM and EEPROM memory. Examples of volatile memory are primary storage, which is typically dynamic random-access memory (DRAM), and fast CPU cache memory, which is typically static random-access memory (SRAM) that is fast but energy-consuming, offering lower memory areal density than DRAM.\nMost semiconductor memory is organized into memory cells or bistable flip-flops, each storing one bit (0 or 1). Flash memory organization includes both one bit per memory cell and multi-level cell capable of storing multiple bits per cell. The memory cells are grouped into words of fixed word length, for example, 1, 2, 4, 8, 16, 32, 64 or 128 bits. Each word can be accessed by a binary address of \"N\" bits, making it possible to store 2\"N\" words in the memory.\nHistory.\nIn the early 1940s, memory technology often permitted a capacity of a few bytes. The first electronic programmable digital computer, the ENIAC, using thousands of octal-base radio vacuum tubes, could perform simple calculations involving 20 numbers of ten decimal digits which were held in the vacuum tube.\nThe next significant advance in computer memory came with acoustic delay line memory, developed by J. Presper Eckert in the early 1940s. Through the construction of a glass tube filled with mercury and plugged at each end with a quartz crystal, delay lines could store bits of information in the form of sound waves propagating through mercury, with the quartz crystals acting as transducers to read and write bits. Delay line memory was limited to a capacity of up to a few hundred thousand bits to remain efficient.\nTwo alternatives to the delay line, the Williams tube and Selectron tube, originated in 1946, both using electron beams in glass tubes as means of storage. Using cathode ray tubes, Fred Williams invented the Williams tube, which was the first random-access computer memory. The Williams tube was more capacious than the Selectron tube (the Selectron was limited to 256 bits, while the Williams tube could store thousands) and less expensive. The Williams tube was nevertheless frustratingly sensitive to environmental disturbances.\nEfforts began in the late 1940s to find non-volatile memory. Magnetic-core memory allowed for recall of memory after power loss. It was developed by Frederick W. Viehe and An Wang in the late 1940s, and improved by Jay Forrester and Jan A. Rajchman in the early 1950s, before being commercialised with the Whirlwind computer in 1953. Magnetic-core memory was the dominant form of memory until the development of MOS semiconductor memory in the 1960s.\nSemiconductor memory began in the early 1960s with bipolar memory, which used bipolar transistors. Bipolar semiconductor memory made from discrete devices was first shipped by Texas Instruments to the United States Air Force in 1961. The same year, the concept of solid-state memory on an integrated circuit (IC) chip was proposed by applications engineer Bob Norman at Fairchild Semiconductor. The first bipolar semiconductor memory IC chip was the SP95 introduced by IBM in 1965. While bipolar memory offered improved performance over magnetic-core memory, it could not compete with the lower price of magnetic-core, which remained dominant up until the late 1960s. Bipolar memory failed to replace magnetic-core memory because bipolar flip-flop circuits were too large and expensive.\nMOS memory.\nThe invention of the MOSFET (metal\u2013oxide\u2013semiconductor field-effect transistor, or MOS transistor), by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959, enabled the practical use of metal\u2013oxide\u2013semiconductor (MOS) transistors as memory cell storage elements. MOS memory was developed by John Schmidt at Fairchild Semiconductor in 1964. In addition to higher performance, MOS semiconductor memory was cheaper and consumed less power than magnetic core memory. In 1965, J. Wood and R. Ball of the Royal Radar Establishment proposed digital storage systems that use CMOS (complementary MOS) memory cells, in addition to MOSFET power devices for the power supply, switched cross-coupling, switches and delay line storage. The development of silicon-gate MOS integrated circuit (MOS IC) technology by Federico Faggin at Fairchild in 1968 enabled the production of MOS memory chips. NMOS memory was commercialized by IBM in the early 1970s. MOS memory overtook magnetic core memory as the dominant memory technology in the early 1970s.\nThe two main types of volatile random-access memory (RAM) are static random-access memory (SRAM) and dynamic random-access memory (DRAM). Bipolar SRAM was invented by Robert Norman at Fairchild Semiconductor in 1963, followed by the development of MOS SRAM by John Schmidt at Fairchild in 1964. SRAM became an alternative to magnetic-core memory, but required six MOS transistors for each bit of data. Commercial use of SRAM began in 1965, when IBM introduced their SP95 SRAM chip for the System/360 Model 95.\nToshiba introduced bipolar DRAM memory cells for its Toscal BC-1411 electronic calculator in 1965. While it offered improved performance over magnetic-core memory, bipolar DRAM could not compete with the lower price of the then dominant magnetic-core memory. MOS technology is the basis for modern DRAM. In 1966, Dr. Robert H. Dennard at the IBM Thomas J. Watson Research Center was working on MOS memory. While examining the characteristics of MOS technology, he found it was capable of building capacitors, and that storing a charge or no charge on the MOS capacitor could represent the 1 and 0 of a bit, while the MOS transistor could control writing the charge to the capacitor. This led to his development of a single-transistor DRAM memory cell. In 1967, Dennard filed a patent under IBM for a single-transistor DRAM memory cell, based on MOS technology. This led to the first commercial DRAM IC chip, the Intel 1103, in October 1970. Synchronous dynamic random-access memory (SDRAM) later debuted with the Samsung KM48SL2000 chip in 1992.\nThe term \"memory\" is also often used to refer to non-volatile memory, specifically flash memory. It has origins in read-only memory (ROM). Programmable read-only memory (PROM) was invented by Wen Tsing Chow in 1956, while working for the Arma Division of the American Bosch Arma Corporation. In 1967, Dawon Kahng and Simon Sze of Bell Labs proposed that the floating gate of a MOS semiconductor device could be used for the cell of a reprogrammable read-only memory (ROM), which led to Dov Frohman of Intel inventing EPROM (erasable PROM) in 1971. EEPROM (electrically erasable PROM) was developed by Yasuo Tarui, Yutaka Hayashi and Kiyoko Naga at the Electrotechnical Laboratory in 1972. Flash memory was invented by Fujio Masuoka at Toshiba in the early 1980s. Masuoka and colleagues presented the invention of NOR flash in 1984, and then NAND flash in 1987. Toshiba commercialized NAND flash memory in 1987.\nDevelopments in technology and economies of scale have made possible so-called Very Large Memory (VLM) computers.\nVolatile memory.\nVolatile memory is computer memory that requires power to maintain the stored information. Most modern semiconductor volatile memory is either static RAM (SRAM) or dynamic RAM (DRAM). SRAM retains its contents as long as the power is connected and is simpler for interfacing, but uses six transistors per bit. Dynamic RAM is more complicated for interfacing and control, needing regular refresh cycles to prevent losing its contents, but uses only one transistor and one capacitor per bit, allowing it to reach much higher densities and much cheaper per-bit costs.\nSRAM is not worthwhile for desktop system memory, where DRAM dominates, but is used for their cache memories. SRAM is commonplace in small embedded systems, which might only need tens of kilobytes or less. Volatile memory technologies that have attempted to compete or replace SRAM and DRAM include Z-RAM and A-RAM.\nNon-volatile memory.\nNon-volatile memory is computer memory that can retain the stored information even when not powered. Examples of non-volatile memory include read-only memory (see ROM), flash memory, most types of magnetic computer storage devices (e.g. hard disk drives, floppy disks and magnetic tape), optical discs, and early computer storage methods such as paper tape and punched cards.\nForthcoming non-volatile memory technologies include FERAM, CBRAM, PRAM, STT-RAM, SONOS, RRAM, racetrack memory, NRAM, 3D XPoint, and millipede memory.\nSemi-volatile memory.\nA third category of memory is \"semi-volatile\". The term is used to describe a memory which has some limited non-volatile duration after power is removed, but then data is ultimately lost. A typical goal when using a semi-volatile memory is to provide high performance/durability/etc. associated with volatile memories, while providing some benefits of a true non-volatile memory.\nFor example, some non-volatile memory types can wear out, where a \"worn\" cell has increased volatility but otherwise continues to work. Data locations which are written frequently can thus be directed to use worn circuits. As long as the location is updated within some known retention time, the data stays valid. If the retention time \"expires\" without an update, then the value is copied to a less-worn circuit with longer retention. Writing first to the worn area allows a high write rate while avoiding wear on the not-worn circuits.\nAs a second example, an STT-RAM can be made non-volatile by building large cells, but the cost per bit and write power go up, while the write speed goes down. Using small cells improves cost, power, and speed, but leads to semi-volatile behavior. In some applications the increased volatility can be managed to provide many benefits of a non-volatile memory, for example by removing power but forcing a wake-up before data is lost; or by caching read-only data and discarding the cached data if the power-off time exceeds the non-volatile threshold.\nThe term semi-volatile is also used to describe semi-volatile behavior constructed from other memory types. For example, a volatile and a non-volatile memory may be combined, where an external signal copies data from the volatile memory to the non-volatile memory, but if power is removed without copying, the data is lost. Or, a battery-backed volatile memory, and if external power is lost there is some known period where the battery can continue to power the volatile memory, but if power is off for an extended time, the battery runs down and data is lost.\nManagement.\nProper management of memory is vital for a computer system to operate properly. Modern operating systems have complex systems to properly manage memory. Failure to do so can lead to bugs, slow performance, and at worst case, takeover by viruses and malicious software.\nBugs.\nImproper management of memory is a common cause of bugs, including the following types:\nEarly computer systems.\nIn early computer systems, programs typically specified the location to write memory and what data to put there. This location was a physical location on the actual memory hardware. The slow processing of such computers did not allow for the complex memory management systems used today. Also, as most such systems were single-task, sophisticated systems were not required as much.\nThis approach has its pitfalls. If the location specified is incorrect, this will cause the computer to write the data to some other part of the program. The results of an error like this are unpredictable. In some cases, the incorrect data might overwrite memory used by the operating system. Computer crackers can take advantage of this to create viruses and malware.\nVirtual memory.\nVirtual memory is a system where all physical memory is controlled by the operating system. When a program needs memory, it requests it from the operating system. The operating system then decides in what physical location to place the program's code and data.\nThis offers several advantages. Computer programmers no longer need to worry about where their data is physically stored or whether the user's computer will have enough memory. It also allows multiple types of memory to be used. For example, some data can be stored in physical RAM chips while other data is stored on a hard drive (e.g. in a swapfile), functioning as an extension of the cache hierarchy. This drastically increases the amount of memory available to programs. The operating system will place actively used data in physical RAM, which is much faster than hard disks. When the amount of RAM is not sufficient to run all the current programs, it can result in a situation where the computer spends more time moving data from RAM to disk and back than it does accomplishing tasks; this is known as thrashing.\nProtected memory.\nProtected memory is a system where each program is given an area of memory to use and is not permitted to go outside that range. Use of protected memory greatly enhances both the reliability and security of a computer system.\nWithout protected memory, it is possible that a bug in one program will alter the memory used by another program. This will cause that other program to run off of corrupted memory with unpredictable results. If the operating system's memory is corrupted, the entire computer system may crash and need to be rebooted. At times programs intentionally alter the memory used by other programs. This is done by viruses and malware to take over computers. It may also be used benignly by desirable programs which are intended to modify other programs; in the modern age, this is generally considered bad programming practice for application programs, but it may be used by system development tools such as debuggers, for example to insert breakpoints or hooks.\nProtected memory assigns programs their own areas of memory. If the operating system detects that a program has tried to alter memory that does not belong to it, the program is terminated (or otherwise restricted or redirected). This way, only the offending program crashes, and other programs are not affected by the misbehavior (whether accidental or intentional).\nProtected memory systems almost always include virtual memory as well."}
{"id": "6808", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6808", "title": "Citrate cycle", "text": ""}
{"id": "6809", "revid": "41304627", "url": "https://en.wikipedia.org/wiki?curid=6809", "title": "CDC", "text": "CDC may refer to:"}
{"id": "6810", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=6810", "title": "Cipro", "text": ""}
{"id": "6811", "revid": "1023507606", "url": "https://en.wikipedia.org/wiki?curid=6811", "title": "Centers for Disease Control and Prevention", "text": "The United States Centers for Disease Control and Prevention (CDC or U.S. CDC) is the national public health agency of the United States. It is a United States federal agency, under the Department of Health and Human Services, and is headquartered in Atlanta, Georgia.\nThe agency professes its main goal to be the protection of public health and safety through the control and prevention of disease, injury, and disability in the US and worldwide. The CDC focuses national attention on developing and applying disease control and prevention. It especially focuses its attention on infectious disease, food borne pathogens, environmental health, occupational safety and health, health promotion, injury prevention and educational activities designed to improve the health of United States citizens. The CDC also conducts research and provides information on non-infectious diseases, such as obesity and diabetes, and is a founding member of the International Association of National Public Health Institutes.\nHistory.\nEstablishment.\nThe Communicable Disease Center was founded July 1, 1946, as the successor to the World War II Malaria Control in War Areas program of the Office of National Defense Malaria Control Activities.\nPreceding its founding, organizations with global influence in malaria control were the Malaria Commission of the League of Nations and the Rockefeller Foundation. The Rockefeller Foundation greatly supported malaria control, sought to have the governments take over some of its efforts, and collaborated with the agency.\nThe new agency was a branch of the U.S. Public Health Service and Atlanta was chosen as the location because malaria was endemic in the Southern United States. The agency changed names (see infobox on top) before adopting the name \"Communicable Disease Center\" in 1946. Offices were located on the sixth floor of the Volunteer Building on Peachtree Street.\nWith a budget at the time of about $1million, 59 percent of its personnel were engaged in mosquito abatement and habitat control with the objective of control and eradication of malaria in the United States (see National Malaria Eradication Program).\nAmong its 369 employees, the main jobs at CDC were originally entomology and engineering. In CDC's initial years, more than six and a half million homes were sprayed, mostly with DDT. In 1946, there were only seven medical officers on duty and an early organization chart was drawn, somewhat fancifully, in the shape of a mosquito. Under Joseph Walter Mountin, the CDC continued to advocate for public health issues and pushed to extend its responsibilities to many other communicable diseases.\nIn 1947, the CDC made a token payment of $10 to Emory University for of land on Clifton Road in DeKalb County, still the home of CDC headquarters as of 2019. CDC employees collected the money to make the purchase. The benefactor behind the \"gift\" was Robert W. Woodruff, chairman of the board of The Coca-Cola Company. Woodruff had a long-time interest in malaria control, which had been a problem in areas where he went hunting. The same year, the PHS transferred its San Francisco based plague laboratory into the CDC as the Epidemiology Division, and a new Veterinary Diseases Division was established.\nGrowth.\nAn Epidemic Intelligence Service (EIS) was established in 1951, originally due to biological warfare concerns arising from the Korean War; it evolved into two-year postgraduate training program in epidemiology, and a prototype for Field Epidemiology Training Programs (FETP), now found in numerous countries, reflecting CDC's influence in promoting this model internationally.\nThe mission of the CDC expanded beyond its original focus on malaria to include sexually transmitted diseases when the Venereal Disease Division of the U.S. Public Health Service (PHS) was transferred to the CDC in 1957. Shortly thereafter, Tuberculosis Control was transferred (in 1960) to the CDC from PHS, and then in 1963 the Immunization program was established.\nIt became the National Communicable Disease Center (NCDC) effective July 1, 1967, and the Center for Disease Control (CDC) on June 24, 1970. At the end of the Public Health Service reorganizations of 1966\u20131973, it was promoted to being a principal operating agency of PHS. It was renamed the Centers for Disease Control effective October 14, 1980. In 1987, the National Center for Health Statistics became part of CDC. An act of the United States Congress appended the words \"and Prevention\" to the name effective October 27, 1992. However, Congress directed that the initialism CDC be retained because of its name recognition.\nSince the 1990s, the CDC focus has broadened to include chronic diseases, disabilities, injury control, workplace hazards, environmental health threats, and terrorism preparedness. CDC combats emerging diseases and other health risks, including birth defects, West Nile virus, obesity, avian, swine, and pandemic flu, E. coli, and bioterrorism, to name a few. The organization would also prove to be an important factor in preventing the abuse of penicillin. In May 1994 the CDC admitted having sent samples of communicable diseases to the Iraqi government from 1984 through 1989 which were subsequently repurposed for biological warfare, including Botulinum toxin, West Nile virus, Yersinia pestis and Dengue fever virus.\nRecent history.\nOn April 21, 2005, then\u2013CDC Director Julie Gerberding formally announced the reorganization of CDC to \"confront the challenges of 21st-century health threats\". She established four Coordinating Centers. In 2009 the Obama Administration re-evaluated this change and ordered them cut as an unnecessary management layer.\nAs of 2013, the CDC's Biosafety Level 4 laboratories are among the few that exist in the world. They constitute one of only two official repositories of smallpox in the world. The second smallpox store resides at the State Research Center of Virology and Biotechnology VECTOR in the Russian Federation. In 2014, the CDC revealed they had discovered several misplaced smallpox samples while their lab workers were 'potentially infected' with anthrax.\nThe city of Atlanta annexed the property of the CDC headquarters effective January 1, 2018, as a part of the city's largest annexation within a period of 65 years; the Atlanta City Council had voted to do so the prior December. The CDC had requested that the Atlanta city government annex the area. The headquarters were located in an unincorporated area, statistically in the Druid Hills census-designated place.\nOrganization.\nThe CDC is organized into \"Centers, Institutes, and Offices\" (CIOs), with each organizational unit implementing the agency's activities in a particular area of expertise while also providing intra-agency support and resource-sharing for cross-cutting issues and specific health threats. Generally, CDC \"Offices\" are subdivided into Centers, which in turn are composed of Divisions and Branches. However, the Center for Global Health and the National Institute for Occupational Safety and Health are freestanding organizational units and do not belong to a parent Office.\nAs of August 2019, the CIOs are:\nThe Office of Public Health Preparedness was created during the 2001 anthrax attacks shortly after the terrorist attacks of September 11, 2001. Its purpose was to coordinate among the government the response to a range of biological terrorism threats.\nLocations.\nMost CDC centers are located in Atlanta. A few of the centers are based in or operate other domestic locations:\nIn addition, CDC operates quarantine facilities in 20 cities in the U.S.\nBudget.\nCDC's budget for fiscal year 2018 is $11.9billion. The CDC offers grants that help many organizations each year advance health, safety and awareness at the community level throughout the United States. The CDC awards over 85 percent of its annual budget through these grants.\nWorkforce.\n, CDC staff numbered approximately 15,000 personnel (including 6,000 contractors and 840 United States Public Health Service Commissioned Corps officers) in 170 occupations. Eighty percent held bachelor's degrees or higher; almost half had advanced degrees (a master's degree or a doctorate such as a PhD, D.O., or M.D.).\nCommon CDC job titles include engineer, entomologist, epidemiologist, biologist, physician, veterinarian, behavioral scientist, nurse, medical technologist, economist, public health advisor, health communicator, toxicologist, chemist, computer scientist, and statistician.\nThe CDC also operates a number of notable training and fellowship programs, including those indicated below.\nEpidemic Intelligence Service (EIS).\nThe Epidemic Intelligence Service (EIS) is composed of \"boots-on-the-ground disease detectives\" who investigate public health problems domestically and globally. When called upon by a governmental body, EIS officers may embark on short-term epidemiological assistance assignments, or \"Epi-Aids\", to provide technical expertise in containing and investigating disease outbreaks. The EIS program is a model for the international Field Epidemiology Training Program.\nPublic Health Associates Program.\nThe CDC also operates the Public Health Associate Program (PHAP), a two-year paid fellowship for recent college graduates to work in public health agencies all over the United States. PHAP was founded in 2007 and currently has 159 associates in 34 states.\nLeadership.\nThe Director of CDC is a Senior Executive Service position that may be filled either by a career employee, or as a political appointment that does not require Senate confirmation, with the latter method typically being used. The director serves at the pleasure of the President and may be fired at any time. The CDC director concurrently serves as the Administrator of the Agency for Toxic Substances and Disease Registry.\nTwenty directors have served the CDC or its predecessor agencies, including three who have served during the Trump administration (including Anne Schuchat who twice served as acting director).\nAreas of focus.\nCommunicable diseases.\nThe CDC's programs address more than 400 diseases, health threats, and conditions that are major causes of death, disease, and disability. The CDC's website has information on various infectious (and noninfectious) diseases, including smallpox, measles, and others.\nInfluenza.\nThe CDC targets the transmission of influenza, including the H1N1 swine flu, and launched websites to educate people about hygiene.\nDivision of Select Agents and Toxins.\nWithin the division are two programs: the Federal Select Agent Program (FSAP) and the Import Permit Program. The FSAP is run jointly with an office within the U.S. Department of Agriculture, regulating agents that can cause disease in humans, animals, and plants. The Import Permit Program regulates the importation of \"infectious biological materials.\"\nThe CDC runs a program that protects the public from rare and dangerous substances such as anthrax and the Ebola virus. The program, called the Federal Select Agent Program, calls for inspections of labs in the U.S. that work with dangerous pathogens.\nDuring the 2014 Ebola outbreak in West Africa, the CDC helped coordinate the return of two infected American aid workers for treatment at Emory University Hospital, the home of a special unit to handle highly infectious diseases.\nAs a response to the 2014 Ebola outbreak, Congress passed a Continuing Appropriations Resolution allocating $30,000,000 towards CDC's efforts to fight the virus.\nNon-communicable diseases.\nThe CDC also works on non-communicable diseases, including chronic diseases caused by obesity, physical inactivity and tobacco-use.\nAntibiotic resistance.\nThe CDC implemented their \"National Action Plan for Combating Antibiotic Resistant Bacteria\" as a measure against the spread of antibiotic resistance in the United States. This initiative has a budget of $161million and includes the development of the Antibiotic Resistance Lab Network.\nGlobal health.\nGlobally, the CDC works with other organizations to address global health challenges and contain disease threats at their source. They work with many international organizations such as the World Health Organization (WHO) as well as ministries of health and other groups on the front lines of outbreaks. The agency maintains staff in more than 60 countries, including some from the U.S. but more from the countries in which they operate. The agency's global divisions include the Division of Global HIV and TB (DGHT), the Division of Parasitic Diseases and Malaria (DPDM), the Division of Global Health Protection (DGHP), and the Global Immunization Division (GID).\nThe CDC is integral in working with the WHO to implement the \"International Health Regulations\" (IHR), an agreement between 196 countries to prevent, control, and report on the international spread of disease, through initiatives including the Global Disease Detection Program (GDD).\nThe CDC is also a lead implementer of key U.S. global health initiatives such as the President's Emergency Plan for AIDS Relief (PEPFAR) and the President's Malaria Initiative.\nTravelers' health.\nThe CDC collects and publishes health information for travelers in a comprehensive book, \"CDC Health Information for International Travel\", which is commonly known as the \"yellow book.\" The book is available online and in print as a new edition every other year and includes current travel health guidelines, vaccine recommendations, and information on specific travel destinations. The CDC also issues travel health notices on its website, consisting of three levels:\n\"Watch\": Level 1 (practice usual precautions)\n\"Alert\": Level 2 (practice enhanced precautions)\n\"Warning\": Level 3 (avoid nonessential travel)\nVaccine safety.\nThe CDC monitors the safety of vaccines in the U.S. via the Vaccine Adverse Event Reporting System (VAERS), a national vaccine safety surveillance program run by CDC and the FDA. \"VAERS detects possible safety issues with U.S. vaccines by collecting information about adverse events (possible side effects or health problems) after vaccination.\" The CDC's Safety Information by Vaccine page provides a list of the latest safety information, side effects, and answers to common questions about CDC recommended vaccines.\nFoundation.\nThe CDC Foundation operates independently from CDC as a private, nonprofit 501(c)(3) organization incorporated in the State of Georgia. The creation of the Foundation was authorized by section 399F of the Public Health Service Act to support the mission of CDC in partnership with the private sector, including organizations, foundations, businesses, educational groups, and individuals.\nControversies.\nTuskegee study of untreated syphilis in Black men.\nFor 15 years, the CDC had direct oversight over the Tuskegee syphilis experiment. In the study, which lasted from 1932 to 1972, a group of Black men (nearly 400 of whom had syphilis) were studied to learn more about the disease. The disease was left untreated in the men, who had not given their informed consent to serve as research subjects. The Tuskegee Study was initiated in 1932 by the Public Health Service, with the CDC taking over the Tuskegee Health Benefit Program in 1995.\nGun violence.\nAn area of partisan dispute related to CDC funding is studying firearms effectiveness. Although the CDC was one of the first agencies to study gun violence as a public health issue, in 1996 the Dickey Amendment, passed with the support of the National Rifle Association, states \"none of the funds available for injury prevention and control at the Centers for Disease Control and Prevention may be used to advocate or promote gun control\". Advocates for gun control oppose the amendment and have tried to overturn it.\nLooking at the history of the passage of the Dickey Ammendment, in 1992, Mark L. Rosenberg and five CDC colleagues founded the CDC's National Center for Injury Prevention and Control, with an annual budget of approximately $260,000. They focused on \"identifying causes of firearm deaths, and methods to prevent them\". Their first report, published in the \"New England Journal of Medicine\" in 1993 entitled \"Guns are a Risk Factor for Homicide in the Home\", reported \"mere presence of a gun in a home increased the risk of a firearm-related death by 2.7 percent, and suicide fivefold\u2014a \"huge\" increase.\" In response, the NRA launched a \"campaign to shut down the Injury Center.\" Two conservative pro-gun groups, Doctors for Responsible Gun Ownership and Doctors for Integrity and Policy Research joined the pro-gun effort, and, by 1995, politicians also supported the pro-gun initiative. In 1996, Jay Dickey (R) Arkansas introduced the Dickey Amendment statement stating \"none of the funds available for injury prevention and control at the Centers for Disease Control and Prevention may be used to advocate or promote gun control\" as a rider. in the 1996 appropriations bill.\" In 1997, \"Congress re-directed all of the money for gun research to the study of traumatic brain injury.\" David Satcher, CDC head 1993-98 before he was fired advocated for firearms research. In 2016 over a dozen \"public health insiders, including current and former CDC senior leaders\" told \"The Trace\" interviewers that CDC senior leaders took a cautious stance in their interpretation of the Dickey Amendment and that they could do more but were afraid of political and personal retribution. Rosenberg told \"The Trace\", \"Right now, there is nothing stopping them from addressing this life-and-death national problem!\"\nIn 2013, the American Medical Association, the American Psychological Association, and the American Academy of Pediatrics sent a letter to the leaders of the Senate Appropriations Committee asking them \"to support at least $10million within the Centers for Disease Control and Prevention (CDC) in FY 2014 along with sufficient new taxes at the National Institutes of Health to support research into the causes and prevention of violence. Furthermore, we urge Members to oppose any efforts to reduce, eliminate, or condition CDC funding related to violence prevention research.\" Congress maintained the ban in subsequent budgets.\nCOVID-19.\nThe first confirmed case of COVID-19 was discovered in the U.S. on January 20, 2020. But widespread COVID-19 testing in the United States was effectively stalled until February 28, when federal officials revised a faulty CDC test, and days afterward, when the Food and Drug Administration began loosening rules that had restricted other labs from developing tests. In February 2020, as the CDC's early coronavirus test malfunctioned nationwide, CDC Director Robert R. Redfield reassured fellow officials on the White House Coronavirus Task Force that the problem would be quickly solved, according to White House officials. It took about three weeks to sort out the failed test kits, which may have been contaminated during their processing in a CDC lab. Later investigations by the FDA and the Department of Health and Human Services found that the CDC had violated its own protocols in developing its tests. In November 2020, \"NPR\" reported that an internal review document they obtained revealed that the CDC was aware that the first batch of tests which were issued in early January had a chance of being wrong 33 percent of the time, but they released them anyway.\nIn May 2020, \"The Atlantic\" reported that the CDC was conflating the results of two different types of coronavirus tests \u2014 tests that diagnose current coronavirus infections, and tests that measure whether someone has ever had the virus. The magazine said this distorted several important metrics, provided the country with an inaccurate picture of the state of the pandemic, and overstated the country's testing ability.\nIn July 2020, the Trump administration ordered hospitals to bypass the CDC and instead send all COVID-19 patient information to a database at the Department of Health and Human Services. Some health experts opposed the order and warned that the data might become politicized or withheld from the public. On July 15, the CDC alarmed health care groups by temporarily removing COVID-19 dashboards from its website. It restored the data a day later.\nIn August 2020, the CDC recommended that people showing no COVID-19 symptoms do not need testing. The new guidelines alarmed many public health experts. The guidelines were crafted by the White House Coronavirus Task Force without the sign-off of Anthony Fauci of the NIH. Objections by other experts at the CDC went unheard. Officials said that a CDC document in July arguing for \"the importance of reopening schools\" was also crafted outside the CDC. On August 16, the chief of staff, Kyle McGowan, and his deputy, Amanda Campbell, resigned from the agency. The testing guidelines were reversed on September 18, 2020, after public controversy.\nIn September 2020, the CDC drafted an order requiring masks on all public transportation in the United States, but the White House Coronavirus Task Force blocked the order, refusing to discuss it, according to two federal health officials.\nIn October, it was disclosed that White House advisers had repeatedly altered the writings of CDC scientists about COVID-19, including recommendations on church choirs, social distancing in bars and restaurants, and summaries of public-health reports.\nIn the lead up to 2020 Thanksgiving, at a press conference on November 20 the CDC advised Americans not to travel for the holiday saying, \"It's not a requirement. It's a recommendation for the American public to consider.\" The White House coronavirus task force had its first public briefing in months on that date but travel was not mentioned.\nControversy over the Morbidity and Mortality Weekly Report.\nDuring the pandemic the CDC Morbidity and Mortality Weekly Report (MMWR) came under pressure from political appointees at the Department of Health and Human Services (HHS) to modify its reporting so as not to conflict with what Trump was saying about the pandemic. Starting in June 2020, Michael Caputo, the HHS assistant secretary for public affairs, and his chief advisor Paul Alexander tried to delay, suppress, change, and retroactively edit MMR releases about the effectiveness of potential treatments for COVID-19, the transmissibility of the virus, and other issues where the president had taken a public stance. Alexander tried unsuccessfully to get personal approval of all issues of MMWR before they went out. Caputo claimed this oversight was necessary because MMWR reports were being tainted by \"political content\"; he demanded to know the political leanings of the scientists who reported that hydroxychloroquine had little benefit as a treatment while Trump was saying the opposite. In emails Alexander accused CDC scientists of attempting to \"hurt the president\" and writing \"hit pieces on the administration\". In October 2020, emails obtained by \"Politico\" showed that Alexander requested multiple alterations in a report. The published alterations included a title being changed from \"Children, Adolescents, and Young Adults\" to \"Persons.\" One current and two former CDC officials who reviewed the email exchanges said they were troubled by the \"intervention to alter scientific reports viewed as untouchable prior to the Trump administration\" that \"appeared to minimize the risks of the coronavirus to children by making the report\u2019s focus on children less clear.\"\nEroding trust in the CDC as a result of COVID-19 controversies.\nA poll conducted in September 2020 found that nearly 8 in 10 Americans trusted the CDC, a decrease from 87 percent in April 2020. Another poll showed an even larger drop in trust with the results dropping 16 percentage points.As the trustworthiness eroded, so too did the information it disseminates. The diminishing level of trust in the CDC and the information releases also incited \"vaccine hesitancy\" with the result that \"just 53 percent of Americans said they would be somewhat or extremely likely to get a vaccine.\"\nIn September 2020, amid the accusations and the faltering image of the CDC the agency's leadership was called into question. Former Acting Director at the CDC, Richard Besser, said of Dr. Redfield that \u201cI find it concerning that the CDC director has not been outspoken when there have been instances of clear political interference in the interpretation of science.\u201d In addition, Mark Rosenberg, the first director of CDC\u2019s National Center for Injury Prevention and Control, also questioned Redfield's leadership and his lack of defense of the science.\nHistorically the CDC has not been a political agency, however, the COVID-19 pandemic, and specifically the Trump Administration's handling of the pandemic, resulted in a \"dangerous shift\" according to a previous CDC director and others. Four previous directors claim that the agency's voice was \"muted for political reasons.\" Politicization of the agency has continued into the Biden administration as COVID-19 guidance is contradicted by State guidance and the agency is criticized as \"CDC's credibility is eroding\".\nIn 2021, the CDC, then under the leadership of the Biden Administration, received criticism for its mixed messaging surrounding COVID-19 vaccines, mask-wearing guidance, and the state of the pandemic.\nPopular culture.\nZombie Apocalypse campaign.\nOn May 16, 2011, the Centers for Disease Control and Prevention's blog what to do to prepare for a zombie invasion. While the article did not claim that such a scenario was possible, it did use the popular culture appeal as a means of urging citizens to prepare for all potential hazards, such as earthquakes, tornadoes, and floods.\nAccording to David Daigle, the Associate Director for Communications, Public Health Preparedness and Response, the idea arose when his team was discussing their upcoming hurricane-information campaign and Daigle mused that \"we say pretty much the same things every year, in the same way, and I just wonder how many people are paying attention.\" A social-media employee mentioned that the subject of zombies had come up a lot on Twitter when she had been tweeting about the Fukushima Daiichi nuclear disaster and radiation. The team realized that a campaign like this would most likely reach a different audience from the one that normally pays attention to hurricane-preparedness warnings and went to work on the zombie campaign, launching it right before hurricane season began. \"The whole idea was, if you're prepared for a zombie apocalypse, you're prepared for pretty much anything,\" said Daigle.\nOnce the blog article was posted, the CDC announced an open contest for YouTube submissions of the most creative and effective videos covering preparedness for a zombie apocalypse (or apocalypse of any kind), to be judged by the \"CDC Zombie Task Force\". Submissions were open until October 11, 2011. They also released a zombie-themed graphic novella available on their website. Zombie-themed educational materials for teachers are available on the site."}
{"id": "6813", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=6813", "title": "Chandrasekhar limit", "text": "The Chandrasekhar limit () is the maximum mass of a stable white dwarf star. The currently accepted value of the Chandrasekhar limit is about ().\nWhite dwarfs resist gravitational collapse primarily through electron degeneracy pressure, compared to main sequence stars, which resist collapse through thermal pressure. The Chandrasekhar limit is the mass above which electron degeneracy pressure in the star's core is insufficient to balance the star's own gravitational self-attraction. Consequently, a white dwarf with a mass greater than the limit is subject to further gravitational collapse, evolving into a different type of stellar remnant, such as a neutron star or black hole. Those with masses up to the limit remain stable as white dwarfs.\nThe limit was named after Subrahmanyan Chandrasekhar. Chandrasekhar improved upon the accuracy of the calculation in 1930 by calculating the limit for a polytrope model of a star in hydrostatic equilibrium, and comparing his limit to the earlier limit found by E. C. Stoner for a uniform density star. Importantly, the existence of a limit, based on the conceptual breakthrough of combining relativity with Fermi degeneracy, was indeed first established in separate papers published by Wilhelm Anderson and E. C. Stoner in 1929. The limit was initially ignored by the community of scientists because such a limit would logically require the existence of black holes, which were considered a scientific impossibility at the time. The fact that the roles of Stoner and Anderson are often overlooked in the astronomy community has been noted.\nPhysics.\nElectron degeneracy pressure is a quantum-mechanical effect arising from the Pauli exclusion principle. Since electrons are fermions, no two electrons can be in the same state, so not all electrons can be in the minimum-energy level. Rather, electrons must occupy a band of energy levels. Compression of the electron gas increases the number of electrons in a given volume and raises the maximum energy level in the occupied band. Therefore, the energy of the electrons increases on compression, so pressure must be exerted on the electron gas to compress it, producing electron degeneracy pressure. With sufficient compression, electrons are forced into nuclei in the process of electron capture, relieving the pressure.\nIn the nonrelativistic case, electron degeneracy pressure gives rise to an equation of state of the form , where is the pressure, is the mass density, and is a constant. Solving the hydrostatic equation leads to a model white dwarf that is a polytrope of index \u2013 and therefore has radius inversely proportional to the cube root of its mass, and volume inversely proportional to its mass.\nAs the mass of a model white dwarf increases, the typical energies to which degeneracy pressure forces the electrons are no longer negligible relative to their rest masses. The velocities of the electrons approach the speed of light, and special relativity must be taken into account. In the strongly relativistic limit, the equation of state takes the form . This yields a polytrope of index 3, which has a total mass, , depending only on .\nFor a fully relativistic treatment, the equation of state used interpolates between the equations for small and for large . When this is done, the model radius still decreases with mass, but becomes zero at . This is the Chandrasekhar limit. The curves of radius against mass for the non-relativistic and relativistic models are shown in the graph. They are colored blue and green, respectively. has been set equal to 2. Radius is measured in standard solar radii or kilometers, and mass in standard solar masses.\nCalculated values for the limit vary depending on the nuclear composition of the mass. Chandrasekhar, eq. (36), eq. (58), eq. (43) gives the following expression, based on the equation of state for an ideal Fermi gas:\nwhere:\nAs is the Planck mass, the limit is of the order of\nThe limiting mass can be obtained formally from the Chandrasekhar's white dwarf equation by taking the limit of large central density.\nA more accurate value of the limit than that given by this simple model requires adjusting for various factors, including electrostatic interactions between the electrons and nuclei and effects caused by nonzero temperature. Lieb and Yau have given a rigorous derivation of the limit from a relativistic many-particle Schr\u00f6dinger equation.\nHistory.\nIn 1926, the British physicist Ralph H. Fowler observed that the relationship between the density, energy, and temperature of white dwarfs could be explained by viewing them as a gas of nonrelativistic, non-interacting electrons and nuclei that obey Fermi\u2013Dirac statistics. This Fermi gas model was then used by the British physicist Edmund Clifton Stoner in 1929 to calculate the relationship among the mass, radius, and density of white dwarfs, assuming they were homogeneous spheres. Wilhelm Anderson applied a relativistic correction to this model, giving rise to a maximum possible mass of approximately . In 1930, Stoner derived the internal energy\u2013density equation of state for a Fermi gas, and was then able to treat the mass\u2013radius relationship in a fully relativistic manner, giving a limiting mass of approximately (for ). Stoner went on to derive the pressure\u2013density equation of state, which he published in 1932. These equations of state were also previously published by the Soviet physicist Yakov Frenkel in 1928, together with some other remarks on the physics of degenerate matter. Frenkel's work, however, was ignored by the astronomical and astrophysical community.\nA series of papers published between 1931 and 1935 had its beginning on a trip from India to England in 1930, where the Indian physicist Subrahmanyan Chandrasekhar worked on the calculation of the statistics of a degenerate Fermi gas. In these papers, Chandrasekhar solved the hydrostatic equation together with the nonrelativistic Fermi gas equation of state, and also treated the case of a relativistic Fermi gas, giving rise to the value of the limit shown above. Chandrasekhar reviews this work in his Nobel Prize lecture. This value was also computed in 1932 by the Soviet physicist Lev Landau, who, however, did not apply it to white dwarfs and concluded that quantum laws might be invalid for stars heavier than 1.5 solar mass.\nChandrasekhar's work on the limit aroused controversy, owing to the opposition of the British astrophysicist Arthur Eddington. Eddington was aware that the existence of black holes was theoretically possible, and also realized that the existence of the limit made their formation possible. However, he was unwilling to accept that this could happen. After a talk by Chandrasekhar on the limit in 1935, he replied:\nEddington's proposed solution to the perceived problem was to modify relativistic mechanics so as to make the law universally applicable, even for large . Although Niels Bohr, Fowler, Wolfgang Pauli, and other physicists agreed with Chandrasekhar's analysis, at the time, owing to Eddington's status, they were unwilling to publicly support Chandrasekhar., pp.\u00a0110\u2013111 Through the rest of his life, Eddington held to his position in his writings, including his work on his fundamental theory. The drama associated with this disagreement is one of the main themes of \"Empire of the Stars\", Arthur I. Miller's biography of Chandrasekhar. In Miller's view:\nApplications.\nThe core of a star is kept from collapsing by the heat generated by the fusion of nuclei of lighter elements into heavier ones. At various stages of stellar evolution, the nuclei required for this process are exhausted, and the core collapses, causing it to become denser and hotter. A critical situation arises when iron accumulates in the core, since iron nuclei are incapable of generating further energy through fusion. If the core becomes sufficiently dense, electron degeneracy pressure will play a significant part in stabilizing it against gravitational collapse.\nIf a main-sequence star is not too massive (less than approximately 8 solar masses), it eventually sheds enough mass to form a white dwarf having mass below the Chandrasekhar limit, which consists of the former core of the star. For more-massive stars, electron degeneracy pressure does not keep the iron core from collapsing to very great density, leading to formation of a neutron star, black hole, or, speculatively, a quark star. (For very massive, low-metallicity stars, it is also possible that instabilities destroy the star completely.) During the collapse, neutrons are formed by the capture of electrons by protons in the process of electron capture, leading to the emission of neutrinos., pp.\u00a01046\u20131047. The decrease in gravitational potential energy of the collapsing core releases a large amount of energy on the order of 1046\u00a0joules (100\u00a0foes). Most of this energy is carried away by the emitted neutrinos and the kinetic energy of the expanding shell of gas; only about 1% is emitted as optical light. This process is believed responsible for supernovae of types Ib, Ic, and II.\nType Ia supernovae derive their energy from runaway fusion of the nuclei in the interior of a white dwarf. This fate may befall carbon\u2013oxygen white dwarfs that accrete matter from a companion giant star, leading to a steadily increasing mass. As the white dwarf's mass approaches the Chandrasekhar limit, its central density increases, and, as a result of compressional heating, its temperature also increases. This eventually ignites nuclear fusion reactions, leading to an immediate carbon detonation, which disrupts the star and causes the supernova., \u00a75.1.2\nA strong indication of the reliability of Chandrasekhar's formula is that the absolute magnitudes of supernovae of Type Ia are all approximately the same; at maximum luminosity, is approximately \u221219.3, with a standard deviation of no more than 0.3., (1) A 1-sigma interval therefore represents a factor of less than 2 in luminosity. This seems to indicate that all type Ia supernovae convert approximately the same amount of mass to energy.\nSuper-Chandrasekhar mass supernovas.\nIn April\u00a02003, the Supernova Legacy Survey observed a type\u00a0Ia supernova, designated SNLS-03D3bb, in a galaxy approximately 4\u00a0billion light years away. According to a group of astronomers at the University of Toronto and elsewhere, the observations of this supernova are best explained by assuming that it arose from a white dwarf that had grown to twice the mass of the Sun before exploding. They believe that the star, dubbed the \"Champagne Supernova\" may have been spinning so fast that a centrifugal tendency allowed it to exceed the limit. Alternatively, the supernova may have resulted from the merger of two white dwarfs, so that the limit was only violated momentarily. Nevertheless, they point out that this observation poses a challenge to the use of type\u00a0Ia supernovae as standard candles.\nSince the observation of the Champagne Supernova in 2003, several more type\u00a0Ia supernovae have been observed that are very bright, and thought to have originated from white dwarfs whose masses exceeded the Chandrasekhar limit. These include SN 2006gz, SN 2007if, and SN 2009dc. The super-Chandrasekhar mass white dwarfs that gave rise to these supernovae are believed to have had masses up to 2.4\u20132.8\u00a0solar masses. One way to potentially explain the problem of the Champagne Supernova was considering it the result of an aspherical explosion of a white dwarf. However, spectropolarimetric observations of SN 2009dc showed it had a polarization smaller than 0.3, making the large asphericity theory unlikely.\nTolman\u2013Oppenheimer\u2013Volkoff limit.\nAfter a supernova explosion, a neutron star may be left behind (except Ia type supernova explosion, which never leaves any remnants behind). These objects are even more compact than white dwarfs and are also supported, in part, by degeneracy pressure. A neutron star, however, is so massive and compressed that electrons and protons have combined to form neutrons, and the star is thus supported by neutron degeneracy pressure (as well as short-range repulsive neutron-neutron interactions mediated by the strong force) instead of electron degeneracy pressure. The limiting value for neutron star mass, analogous to the Chandrasekhar limit, is known as the Tolman\u2013Oppenheimer\u2013Volkoff limit."}
{"id": "6814", "revid": "8524693", "url": "https://en.wikipedia.org/wiki?curid=6814", "title": "Congregationalist polity", "text": "Congregationalist polity, or congregational polity, often known as congregationalism, is a system of ecclesiastical polity in which every local church congregation is independent, ecclesiastically sovereign, or \"autonomous\". Its first articulation in writing is the Cambridge Platform of 1648 in New England.\nMajor Protestant Christian traditions that employ congregationalism include Quakerism, the Baptist churches, the Congregational Methodist Church, and Congregational churches known by the \"Congregationalist\" name and having descended from the Independent Reformed wing of the Anglo-American Puritan movement of the 17th century. More recent generations have witnessed a growing number of nondenominational churches, which are often congregationalist in their governance.\nCongregationalism is distinguished from episcopal polity which is governance by a hierarchy of bishops, and is distinct from presbyterian polity in which higher assemblies of congregational representatives can exercise considerable authority over individual congregations.\nCongregationalism is not limited only to organization of Christian church congregations. The principles of congregationalism have been inherited by the Unitarian Universalist Association and the Canadian Unitarian Council. Most Jewish synagogues, many Sikh Gurdwaras, and most Islamic mosques in the US operate under congregational government, with no hierarchies.\nBasic form.\nThe term \"congregationalist polity\" describes a form of church governance that is based on the local congregation. Each local congregation is independent and self-supporting, governed by its own members. Some band into loose voluntary associations with other congregations that share similar beliefs (e.g., the Willow Creek Association and the American Unitarian Association). Others join \"conventions\", such as the Southern Baptist Convention, the National Baptist Convention or the American Baptist Churches USA (formerly the Northern Baptist Convention). In Quaker Congregationalism, monthly meetings, which are the most basic unit of administration, may be organized into larger Quarterly meetings or Yearly Meetings. Monthly, quarterly, or yearly meetings may also be associated with large \"umbrella\" associations such as Friends General Conference or Friends United Meeting. These conventions generally provide stronger ties between congregations, including some doctrinal direction and pooling of financial resources. Congregations that belong to associations and conventions are still independently governed. Most non-denominational churches are organized along congregationalist lines. Many do not see these voluntary associations as \"denominations\", because they \"believe that there is no church other than the local church, and denominations are in variance to Scripture.\"\nCongregational church.\nThe earmarks of Congregationalism can be traced back to the Pilgrim societies of the United States in the early 17th century. Congregationalism expressed the viewpoint that (1) every local church is a full realization in miniature of the entire Church of Jesus Christ; and (2) the Church, while on earth, besides the local church, can only be invisible and ideal. While other theories may insist on the truth of the former, the latter precept of congregationalism gives the entire theory a unique character among plans of church government. There is no other reference than the local congregation for the \"visible church\" in Congregationalism. And yet, the connection of all Christians is also asserted, albeit in a way that defenders of this view usually decline, often intentionally, to elaborate more clearly or consistently. This first, foundational principle by which congregationalism is guided results in confining it to operate with the consent of each gathering of believers.\nAlthough \"congregational rule\" may seem to suggest that pure democracy reigns in congregational churches, this is seldom the case. It is granted, with few exceptions (namely in some Anabaptist churches), that God has given the government of the Church into the hands of an ordained ministry. What makes congregationalism unique is its system of checks and balances, which constrains the authority of the clergy, the lay officers, and the members.\nMost importantly, the boundaries of the powers of the ministers and church officers are set by clear and constant reminders of the freedoms guaranteed by the Gospel to the laity, collectively and individually. With that freedom comes the responsibility upon each member to govern himself or herself under Christ. This requires lay people to exercise great charity and patience in debating issues with one another and to seek the glory and service of God as the foremost consideration in all of their decisions.\nThe authority of all of the people, including the officers, is limited in the local congregation by a definition of union, or a covenant, by which the terms of their cooperation together are spelled out and agreed to. This might be something as minimal as a charter specifying a handful of doctrines and behavioral expectations, or even a statement only guaranteeing specific freedoms. Or, it may be a constitution describing a comprehensive doctrinal system and specifying terms under which the local church is connected to other local churches, to which participating congregations give their assent. In congregationalism, rather uniquely, the church is understood to be a truly voluntary association.\nFinally, the congregational theory strictly forbids ministers from ruling their local churches by themselves. Not only does the minister serve by the approval of the congregation, but committees further constrain the pastor from exercising power without consent by either the particular committee, or the entire congregation. It is a contradiction of the congregational principle if a minister makes decisions concerning the congregation without the vote of these other officers.\nThe other officers may be called \"deacons\", \"elder\" or \"session\" (borrowing Presbyterian terminology), or even \"vestry\" (borrowing the Anglican term)\u00a0\u2013 it is not their label that is important to the theory, but rather their lay status and their equal vote, together with the pastor, in deciding the issues of the church. While other forms of church government are more likely to define \"tyranny\" as \"the imposition of unjust rule\", a congregationally governed church would more likely define \"tyranny\" as \"transgression of liberty\" or equivalently, \"rule by one man\". To a congregationalist, no abuse of authority is worse than the concentration of all decisive power in the hands of one ruling body, or one person.\nFollowing this sentiment, congregationalism has evolved over time to include even more participation of the congregation, more kinds of lay committees to whom various tasks are apportioned, and more decisions subject to the vote of the entire membership.\nOne of the most notable characteristics of New England (or British)-heritage Congregationalism has been its consistent leadership role in the formation of \"unions\" with other churches. Such sentiments especially grew strong in the late 19th and early 20th centuries, when ecumenism evolved out of a liberal, non-sectarian perspective on relations to other Christian groups that accompanied the relaxation of Calvinist stringencies held by earlier generations. The congregationalist theory of independence within a union has been a cornerstone of most ecumenical movements since the 18th century.\nBaptist churches.\nMost Baptists hold that no denominational or ecclesiastical organization has inherent authority over an individual Baptist church. Churches can properly relate to each other under this polity only through voluntary cooperation, never by any sort of coercion. Furthermore, this Baptist polity calls for freedom from governmental control. Exceptions to this local form of local governance include the Episcopal Baptists that have an episcopal system.\nIndependent Baptist churches have no formal organizational structure above the level of the local congregation. More generally among Baptists, a variety of parachurch agencies and evangelical educational institutions may be supported generously or not at all, depending entirely upon the local congregation's customs and predilections. Usually doctrinal conformity is held as a first consideration when a church makes a decision to grant or decline financial contributions to such agencies, which are legally external and separate from the congregations they serve. These practices also find currency among non-denominational fundamentalist or charismatic fellowships, many of which derive from Baptist origins, culturally if not theologically.\nMost Southern Baptist and National Baptist congregations, by contrast, generally relate more closely to external groups such as mission agencies and educational institutions than do those of independent persuasion. However, they adhere to a very similar ecclesiology, refusing to permit outside control or oversight of the affairs of the local church.\nChurches of Christ.\nEcclesiastical government is congregational rather than denominational. Churches of Christ purposefully have no central headquarters, councils, or other organizational structure above the local church level. Rather, the independent congregations are a network with each congregation participating at its own discretion in various means of service and fellowship with other congregations. Churches of Christ are linked by their shared commitment to restoration principles.\nCongregations are generally overseen by a plurality of elders (also known in some congregations as shepherds, bishops, or pastors) who are sometimes assisted in the administration of various works by deacons. Elders are generally seen as responsible for the spiritual welfare of the congregation, while deacons are seen as responsible for the non-spiritual needs of the church. Deacons serve under the supervision of the elders, and are often assigned to direct specific ministries. Successful service as a deacon is often seen as preparation for the eldership. Elders and deacons are chosen by the congregation based on the qualifications found in Timothy 3 and Titus 1. Congregations look for elders who have a mature enough understanding of scripture to enable them to supervise the minister and to teach, as well as to perform governance functions. In lieu of willing men who meet these qualifications, congregations are sometimes overseen by an unelected committee of the congregation's men.\nWhile the early Restoration Movement had a tradition of itinerant preachers rather than \"located Preachers\", during the 20th century a long-term, formally trained congregational minister became the norm among Churches of Christ. Ministers are understood to serve under the oversight of the elders. While the presence of a long-term professional minister has sometimes created \"significant \"de facto\" ministerial authority\" and led to conflict between the minister and the elders, the eldership has remained the \"ultimate locus of authority in the congregation\". There is a small group within the Churches of Christ which oppose a single preacher and, instead, rotate preaching duties among qualified elders (this group tends to overlap with groups which oppose Sunday School and also have only one cup to serve the Lord's Supper).\nChurches of Christ hold to the priesthood of all believers. No special titles are used for preachers or ministers that would identify them as clergy. Churches of Christ emphasize that there is no distinction between \"clergy\" and \"laity\" and that every member has a gift and a role to play in accomplishing the work of the church.\nCongregational Methodist Church.\nMethodists who disagreed with the episcopal polity of the Methodist Episcopal Church, South left their mother church to form the Congregational Methodist Church, which retains Wesleyan-Arminian theology but adopts congregationalist polity as a distinctive."}
{"id": "6816", "revid": "897817", "url": "https://en.wikipedia.org/wiki?curid=6816", "title": "Cavalry", "text": "Cavalry (from the French word \"cavalerie\", itself derived from \"cheval\" meaning \"horse\") are soldiers or warriors who fight mounted on horseback. Cavalry were historically the most mobile of the combat arms, operating as light cavalry in the roles of reconnaissance, screening, and skirmishing in many armies, or as heavy cavalry for decisive shock attacks in other armies. An individual soldier in the cavalry is known by a number of designations depending on era and tactics, such as cavalryman, horseman, trooper, cataphract, knight, hussar, uhlan, mamluk, cuirassier, lancer, dragoon, or horse archer. The designation of \"cavalry\" was not usually given to any military forces that used other animals for mounts, such as camels or elephants. Infantry who moved on horseback, but dismounted to fight on foot, were known in the early 17th to the early 18th century as \"dragoons\", a class of mounted infantry which in most armies later evolved into standard cavalry while retaining their historic designation.\nCavalry had the advantage of improved mobility, and a soldier fighting from horseback also had the advantages of greater height, speed, and inertial mass over an opponent on foot. Another element of horse mounted warfare is the psychological impact a mounted soldier can inflict on an opponent.\nThe speed, mobility, and shock value of cavalry was greatly appreciated and exploited in armed forces in the Ancient and Middle Ages; some forces were mostly cavalry, particularly in nomadic societies of Asia, notably the Huns of Attila and the later Mongol armies. In Europe, cavalry became increasingly armoured (heavy), and eventually evolving into the mounted knights of the medieval period. During the 17th century, cavalry in Europe discarded most of its armor, which was ineffective against the muskets and cannons that were coming into common use, and by the mid-18th century armor had mainly fallen into obsolescence, although some regiments retained a small thickened cuirass that offered protection against lances, sabres, and bayonets; including some protection against shot from a distance.\nIn the period between the World Wars, many cavalry units were converted into motorized infantry and mechanized infantry units, or reformed as tank troops. However, some cavalry still served during World War II, notably in the Red Army, the Mongolian People's Army, the Royal Italian Army, the Romanian Army, the Polish Land Forces, and light reconnaissance units within the Waffen SS. Most cavalry units that are horse-mounted in modern armies serve in purely ceremonial roles, or as mounted infantry in difficult terrain such as mountains or heavily forested areas. Modern usage of the term generally refers to units performing the role of reconnaissance, surveillance, and target acquisition (RSTA).\nRole of cavalry.\nIn many modern armies, the term \"cavalry\" is still often used to refer to units that are a combat arm of the armed forces which in the past filled the traditional horse-borne land combat light cavalry roles. These include scouting, skirmishing with enemy reconnaissance elements to deny them knowledge of the disposition of the main body of troops, forward security, offensive reconnaissance by combat, defensive screening of friendly forces during retrograde movement, retreat, restoration of command and control, deception, battle handover and passage of lines, relief in place, linkup, breakout operations, and raiding. The shock role, traditionally filled by heavy cavalry, is generally filled by armored units in modern warfare.\nEarly history.\nOrigins.\nBefore the Iron Age, the role of cavalry on the battlefield was largely performed by light chariots. The chariot originated with the Sintashta-Petrovka culture in Central Asia and spread by nomadic or semi-nomadic Indo-Iranians. The chariot was quickly adopted by settled peoples both as a military technology and an object of ceremonial status, especially by the pharaohs of the New Kingdom of Egypt from 1550 BC as well as the Assyrian army and Babylonian royalty.\nThe power of mobility given by mounted units was recognized early on, but was offset by the difficulty of raising large forces and by the inability of horses (then mostly small) to carry heavy armor. Nonetheless, there are indications that, from the 15th century BC onwards, horseback riding was practiced amongst the military elites of the great states of the ancient Near East, most notably those in Egypt, Assyria, the Hittite Empire, and Mycenaean Greece.\nCavalry techniques, and the rise of true cavalry, were an innovation of equestrian nomads of the Central Asian and Iranian steppe and pastoralist tribes such as the Iranic Parthians and Sarmatians.\nThe photograph above left shows Assyrian cavalry from reliefs of 865\u2013860 BC. At this time, the men had no spurs, saddles, saddle cloths, or stirrups. Fighting from the back of a horse was much more difficult than mere riding. The cavalry acted in pairs; the reins of the mounted archer were controlled by his neighbour's hand. Even at this early time, cavalry used swords, shields, spears, and bows. The sculpture implies two types of cavalry, but this might be a simplification by the artist. Later images of Assyrian cavalry show saddle cloths as primitive saddles, allowing each archer to control his own horse.\nAs early as 490 BC a breed of large horses was bred in the Nisaean plain in Media to carry men with increasing amounts of armour (Herodotus 7,40 &amp; 9,20), but large horses were still very exceptional at this time. By the fourth century BC the Chinese during the Warring States period (403\u2013221 BC) began to use cavalry against rival states, and by 331 BC when Alexander the Great defeated the Persians the use of chariots in battle was obsolete in most nations; despite a few ineffective attempts to revive scythed chariots. The last recorded use of chariots as a shock force in continental Europe was during the Battle of Telamon in 225 BC.\nHowever, chariots remained in use for ceremonial purposes such as carrying the victorious general in a Roman triumph, or for racing.\nOutside of mainland Europe, the southern Britons met Julius Caesar with chariots in 55 and 54 BC, but by the time of the Roman conquest of Britain a century later chariots were obsolete, even in Britannia. The last mention of chariot use in Britain was by the Caledonians at the Mons Graupius, in 84 AD.\nAncient Greece: city-states, Thebes, Thessaly and Macedonia.\nDuring the classical Greek period cavalry were usually limited to those citizens who could afford expensive war-horses. Three types of cavalry became common: light cavalry, whose riders, armed with javelins, could harass and skirmish; heavy cavalry, whose troopers, using lances, had the ability to close in on their opponents; and finally those whose equipment allowed them to fight either on horseback or foot. The role of horsemen did however remain secondary to that of the hoplites or heavy infantry who comprised the main strength of the citizen levies of the various city states.\nCavalry played a relatively minor role in ancient Greek city-states, with conflicts decided by massed armored infantry. However, Thebes produced Pelopidas, their first great cavalry commander, whose tactics and skills were absorbed by Phillip II of Macedon when Phillip was a guest-hostage in Thebes. Thessaly was widely known for producing competent cavalrymen, and later experiences in wars both with and against the Persians taught the Greeks the value of cavalry in skirmishing and pursuit. The Athenian author and soldier Xenophon in particular advocated the creation of a small but well-trained cavalry force; to that end, he wrote several manuals on horsemanship and cavalry operations.\nThe Macedonian Kingdom in the north, on the other hand, developed a strong cavalry force that culminated in the \"hetairoi\" (Companion cavalry) of Philip II of Macedon and Alexander the Great. In addition to these heavy cavalry, the Macedonian army also employed lighter horsemen called prodromoi for scouting and screening, as well as the Macedonian pike phalanx and various kinds of light infantry. There were also the \"Ippiko\" (or \"Horserider\"), Greek \"heavy\" cavalry, armed with kontos (or cavalry lance), and sword. These wore leather armour or mail plus a helmet. They were medium rather than heavy cavalry, meaning that they were better suited to be scouts, skirmishers, and pursuers rather than front line fighters. The effectiveness of this combination of cavalry and infantry helped to break enemy lines and was most dramatically demonstrated in Alexander's conquests of Persia, Bactria, and northwestern India.\nRoman Republic and Early Empire.\nThe cavalry in the early Roman Republic remained the preserve of the wealthy landed class known as the \"equites\"\u2014men who could afford the expense of maintaining a horse in addition to arms and armor heavier than those of the common legions. Horses were provided by the Republic and could be withdrawn if neglected or misused, together with the status of being a cavalryman.\nAs the class grew to be more of a social elite instead of a functional property-based military grouping, the Romans began to employ Italian socii for filling the ranks of their cavalry. The weakness of Roman cavalry was demonstrated by Hannibal Barca during the Second Punic War where he used his superior mounted forces to win several battles. The most notable of these was the Battle of Cannae, where he inflicted a catastrophic defeat on the Romans. At about the same time the Romans began to recruit foreign auxiliary cavalry from among Gauls, Iberians, and Numidians, the last being highly valued as mounted skirmishers and scouts (see Numidian cavalry). Julius Caesar had a high opinion of his escort of Germanic mixed cavalry, giving rise to the \"Cohortes Equitatae\". Early emperors maintained an ala of Batavian cavalry as their personal bodyguards until the unit was dismissed by Galba after the Batavian Rebellion.\nFor the most part, Roman cavalry during the early Republic functioned as an adjunct to the legionary infantry and formed only one-fifth of the standing force comprising a consular army. Except in times of major mobilisation about 1,800 horsemen were maintained, with three hundred attached to each legion. \nThe relatively low ratio of horsemen to infantry does not mean that the utility of cavalry should be underestimated, as its strategic role in scouting, skirmishing, and outpost duties was crucial to the Romans' capability to conduct operations over long distances in hostile or unfamiliar territory. On some occasions Roman cavalry also proved its ability to strike a decisive tactical blow against a weakened or unprepared enemy, such as the final charge at the Battle of Aquilonia.\nAfter defeats such as the Battle of Carrhae, the Romans learned the importance of large cavalry formations from the Parthians. \nAt the same time heavy spears and shields modelled on those favoured by the horsemen of the Greek city-states were adopted to replace the lighter weaponry of early Rome. \nThese improvements in tactics and equipment reflected those of a thousand years earlier when the first Iranians to reach the Iranian Plateau forced the Assyrians to undertake similar reform. Nonetheless, the Romans would continue to rely mainly on their heavy infantry supported by auxiliary cavalry.\nLate Roman Empire and the Migration Period.\nIn the army of the late Roman Empire, cavalry played an increasingly important role. The Spatha, the classical sword throughout most of the 1st millennium was adopted as the standard model for the Empire's cavalry forces.\nThe most widespread employment of heavy cavalry at this time was found in the forces of the Iranian empires, the Parthians and their Persian Sasanian successors. Both, but especially the former, were famed for the cataphract (fully armored cavalry armed with lances) even though the majority of their forces consisted of lighter horse archers. The West first encountered this eastern heavy cavalry during the Hellenistic period with further intensive contacts during the eight centuries of the Roman\u2013Persian Wars. At first the Parthians' mobility greatly confounded the Romans, whose armoured close-order infantry proved unable to match the speed of the Parthians. However, later the Romans would successfully adapt such heavy armor and cavalry tactics by creating their own units of cataphracts and \"clibanarii\".\nThe decline of the Roman infrastructure made it more difficult to field large infantry forces, and during the 4th and 5th centuries cavalry began to take a more dominant role on the European battlefield, also in part made possible by the appearance of new, larger breeds of horses. The replacement of the Roman saddle by variants on the Scythian model, with pommel and cantle, was also a significant factor as was the adoption of stirrups and the concomitant increase in stability of the rider's seat. Armored cataphracts began to be deployed in eastern Europe and the Near East, following the precedents established by Persian forces, as the main striking force of the armies in contrast to the earlier roles of cavalry as scouts, raiders, and outflankers.\nThe late-Roman cavalry tradition of organized units in a standing army differed fundamentally from the nobility of the Germanic invaders\u2014individual warriors who could afford to provide their own horses and equipment. While there was no direct linkage with these predecessors the early medieval knight also developed as a member of a social and martial elite, able to meet the considerable expenses required by his role from grants of land and other incomes.\nAsia.\nCentral Asia.\nXiongnu, Tujue, Avars, Kipchaks, Khitans, Mongols, Don Cossacks and the various Turkic peoples are also examples of the horse-mounted groups that managed to gain substantial successes in military conflicts with settled agrarian and urban societies, due to their strategic and tactical mobility. As European states began to assume the character of bureaucratic nation-states supporting professional standing armies, recruitment of these mounted warriors was undertaken in order to fill the strategic roles of scouts and raiders.\nThe best known instance of the continued employment of mounted tribal auxiliaries were the Cossack cavalry regiments of the Russian Empire. In Eastern Europe, and out onto the steppes, cavalry remained important much longer and dominated the scene of warfare until the early 17th century and even beyond, as the strategic mobility of cavalry was crucial for the semi-nomadic pastoralist lives that many steppe cultures led. Tibetans also had a tradition of cavalry warfare, in several military engagements with the Chinese Tang dynasty (618\u2013907 AD).\nEast Asia.\nChina.\nFurther east, the military history of China, specifically northern China, held a long tradition of intense military exchange between Han Chinese infantry forces of the settled dynastic empires and the mounted nomads or \"barbarians\" of the north. The naval history of China was centered more to the south, where mountains, rivers, and large lakes necessitated the employment of a large and well-kept navy.\nIn 307 BC, King Wuling of Zhao, the ruler of the former state of Jin, ordered his commanders and troops to adopt the trousers of the nomads as well as practice the nomads' form of mounted archery to hone their new cavalry skills.\nThe adoption of massed cavalry in China also broke the tradition of the chariot-riding Chinese aristocracy in battle, which had been in use since the ancient Shang Dynasty (c 1600\u20131050 BC). By this time large Chinese infantry-based armies of 100,000 to 200,000 troops were now buttressed with several hundred thousand mounted cavalry in support or as an effective striking force. The handheld pistol-and-trigger crossbow was invented in China in the fourth century BC; it was written by the Song dynasty scholars Zeng Gongliang, Ding Du, and Yang Weide in their book \"Wujing Zongyao\" (1044 AD) that massed missile fire by crossbowmen was the most effective defense against enemy cavalry charges.\nOn many occasions the Chinese studied nomadic cavalry tactics and applied the lessons in creating their own potent cavalry forces, while in others they simply recruited the tribal horsemen wholesale into their armies; and in yet other cases nomadic empires proved eager to enlist Chinese infantry and engineering, as in the case of the Mongol Empire and its sinicized part, the Yuan Dynasty (1279\u20131368). The Chinese recognized early on during the Han Dynasty (202 BC \u2013 220 AD) that they were at a disadvantage in lacking the number of horses the northern nomadic peoples mustered in their armies. Emperor Wu of Han (r 141\u201387 BC) went to war with the Dayuan for this reason, since the Dayuan were hoarding a massive amount of tall, strong, Central Asian bred horses in the Hellenized\u2013Greek region of Fergana (established slightly earlier by Alexander the Great). Although experiencing some defeats early on in the campaign, Emperor Wu's war from 104 BC to 102 BC succeeded in gathering the prized tribute of horses from Fergana.\nCavalry tactics in China were enhanced by the invention of the saddle-attached stirrup by at least the 4th century, as the oldest reliable depiction of a rider with paired stirrups was found in a Jin Dynasty tomb of the year 322 AD. The Chinese invention of the horse collar by the 5th century was also a great improvement from the breast harness, allowing the horse to haul greater weight without heavy burden on its skeletal structure.\nKorea.\nThe horse warfare of Korea was first started during the ancient Korean kingdom Gojoseon. Since at least the 3rd century BC, there was influence of northern nomadic peoples and Yemaek peoples on Korean warfare. By roughly the first century BC, the ancient kingdom of Buyeo also had mounted warriors. The cavalry of Goguryeo, one of the Three Kingdoms of Korea, were called \"Gaemamusa\" (\uac1c\ub9c8\ubb34\uc0ac, \u93a7\u99ac\u6b66\u58eb), and were renowned as a fearsome heavy cavalry force. King Gwanggaeto the Great often led expeditions into the Baekje, Gaya confederacy, Buyeo, Later Yan and against Japanese invaders with his cavalry.\nIn the 12th century, Jurchen tribes began to violate the Goryeo\u2013Jurchen borders, and eventually invaded Goryeo Korea. After experiencing the invasion by the Jurchen, Korean general Yun Gwan realized that Goryeo lacked efficient cavalry units. He reorganized the Goryeo military into a professional army that would contain decent and well-trained cavalry units. In 1107, the Jurchen were ultimately defeated, and surrendered to Yun Gwan. To mark the victory, General Yun built nine fortresses to the northeast of the Goryeo\u2013Jurchen borders (\ub3d9\ubd81 9\uc131, \u6771\u5317 \u4e5d\u57ce).\nJapan.\nThe ancient Japanese of the Kofun period also adopted cavalry and equine culture by the 5th century AD. The emergence of the samurai aristocracy led to the development of armoured horse archers, themselves to develop into charging lancer cavalry as gunpowder weapons rendered bows obsolete.\nAn example is Yabusame (\u6d41\u93d1\u99ac?), a type of mounted archery in traditional Japanese archery. An archer on a running horse shoots three special \"turnip-headed\" arrows successively at three wooden targets.\nThis style of archery has its origins at the beginning of the Kamakura period. Minamoto no Yoritomo became alarmed at the lack of archery skills his samurai had. He organized yabusame as a form of practice.\nCurrently, the best places to see yabusame performed are at the Tsurugaoka Hachiman-g\u016b in Kamakura and Shimogamo Shrine in Kyoto (during Aoi Matsuri in early May). It is also performed in Samukawa and on the beach at Zushi, as well as other locations.\nKasagake or Kasakake (\u7b20\u61f8, \u304b\u3055\u304c\u3051 lit. \"hat shooting\") is a type of Japanese mounted archery. In contrast to yabusame, the types of targets are various and the archer shoots without stopping the horse. While yabusame has been played as a part of formal ceremonies, kasagake has developed as a game or practice of martial arts, focusing on technical elements of horse archery.\nSouth Asia.\nIndian subcontinent.\nIn the Indian subcontinent, cavalry played a major role from the Gupta Dynasty (320\u2013600) period onwards. India has also the oldest evidence for the introduction of toe-stirrups.\nIndian literature contains numerous references to the mounted warriors of the Central Asian horse nomads, notably the Sakas, Kambojas, Yavanas, Pahlavas and Paradas. Numerous Puranic texts refer to a conflict in ancient India (16th century BC) in which the horsemen of five nations, called the \"Five Hordes\" (\"pa\u00f1ca.ganan\") or K\u1e63atriya hordes (\"K\u1e63atriya ganah\"), attacked and captured the state of Ayudhya by dethroning its Vedic King Bahu\nThe Mahabharata, Ramayana, numerous Puranas and some foreign sources attest that the Kamboja cavalry frequently played role in ancient wars. V. R. Ramachandra Dikshitar writes: \"Both the Puranas and the epics agree that the horses of the Sindhu and Kamboja regions were of the finest breed, and that the services of the Kambojas as cavalry troopers were utilised in ancient wars\". J.A.O.S. writes: \"Most famous horses are said to come either from Sindhu or Kamboja; of the latter (i.e. the Kamboja), the Indian epic Mahabharata speaks among the finest horsemen\".\nThe Mahabharata speaks of the esteemed cavalry of the Kambojas, Sakas, Yavanas and Tusharas, all of whom had participated in the Kurukshetra war under the supreme command of Kamboja ruler Sudakshin Kamboj.\nMahabharata and Vishnudharmottara Purana pay especial attention to the Kambojas, Yavansa, Gandharas etc. being \"ashva.yuddha.kushalah\" (expert cavalrymen). In the Mahabharata war, the Kamboja cavalry along with that of the Sakas, Yavanas is reported to have been enlisted by the Kuru king Duryodhana of Hastinapura.\nHerodotus (c 484 \u2013 c 425 BC) attests that the Gandarian mercenaries (i.e. \"Gandharans/Kambojans\" of Gandari Strapy of Achaemenids) from the 20th strapy of the Achaemenids were recruited in the army of emperor Xerxes I (486\u2013465 BC), which he led against the Hellas. Similarly, the \"men of the Mountain Land \" from north of Kabol-River equivalent to medieval Kohistan (Pakistan), figure in the army of Darius III against Alexander at Arbela, providing a cavalry force and 15 elephants. This obviously refers to Kamboja cavalry south of Hindukush.\nThe Kambojas were famous for their horses, as well as cavalrymen (\"asva-yuddha-Kushalah\"). On account of their supreme position in horse (Ashva) culture, they were also popularly known as Ashvakas, i.e. the \"horsemen\" and their land was known as \"Home of Horses\". They are the Assakenoi and Aspasioi of the Classical writings, and the Ashvakayanas and Ashvayanas in P\u0101\u1e47ini's Ashtadhyayi. The Assakenoi had faced Alexander with 30,000 infantry, 20,000 cavalry and 30 war elephants. Scholars have identified the Assakenoi and Aspasioi clans of Kunar and Swat valleys as a section of the Kambojas. These hardy tribes had offered stubborn resistance to Alexander (c 326 BC) during latter's campaign of the Kabul, Kunar and Swat valleys and had even extracted the praise of the Alexander's historians. These highlanders, designated as \"parvatiya Ayudhajivinah\" in P\u0101\u1e47ini's Astadhyayi, were rebellious, fiercely independent and freedom-loving cavalrymen who never easily yielded to any overlord.\nThe Sanskrit drama \"Mudra-rakashas\" by \"Visakha Dutta\" and the Jaina work \"Parishishtaparvan\" refer to Chandragupta's (c 320 BC \u2013 c 298 BC) alliance with Himalayan king \"Parvataka\". The Himalayan alliance gave Chandragupta a formidable composite army made up of the cavalry forces of the Shakas, Yavanas, Kambojas, Kiratas, Parasikas and Bahlikas as attested by Mudra-Rakashas (Mudra-Rakshasa 2). These hordes had helped Chandragupta Maurya defeat the ruler of Magadha and placed Chandragupta on the throne, thus laying the foundations of Mauryan Dynasty in Northern India.\nThe cavalry of Hunas and the Kambojas is also attested in the Raghu Vamsa epic poem of Sanskrit poet Kalidasa. Raghu of Kalidasa is believed to be Chandragupta II (\"Vikaramaditya\") (375\u2013413/15 AD), of the well-known Gupta Dynasty.\nAs late as the mediaeval era, the Kamboja cavalry had also formed part of the Gurjara-Pratihara armed forces from the eighth to the 10th centuries AD. They had come to Bengal with the Pratiharas when the latter conquered part of the province.\nAncient Kambojas organised military \"sanghas\" and shrenis (corporations) to manage their political and military affairs, as Arthashastra of Kautiliya as well as the Mahabharata record. They are described as \"Ayuddha-jivi\" or \"Shastr-opajivis\" (nations-in-arms), which also means that the Kamboja cavalry offered its military services to other nations as well. There are numerous references to Kambojas having been requisitioned as cavalry troopers in ancient wars by outside nations.\nMughal Empire.\nThe Mughal armies (\"lashkar\") were primarily a cavalry force. The elite corps were the \"ahadi\" who provided direct service to the Emperor and acted as guard cavalry. Supplementary cavalry or \"dakhilis\" were recruited, equipped and paid by the central state. This was in contrast to the \"tabinan\" horsemen who were the followers of individual noblemen. Their training and equipment varied widely but they made up the backbone of the Mughal cavalry. Finally there were tribal irregulars led by and loyal to tributary chiefs. These included Hindus, Afghans and Turks summoned for military service when their autonomous leaders were called on by the Imperial government.\nEuropean Middle Ages.\nAs the quality and availability of heavy infantry declined in Europe with the fall of the Roman Empire, heavy cavalry became more effective. Infantry that lack the cohesion and discipline of tight formations are more susceptible to being broken and scattered by shock combat\u2014the main role of heavy cavalry, which rose to become the dominant force on the European battlefield.\nAs heavy cavalry increased in importance, it became the main focus of military development. The arms and armour for heavy cavalry increased, the high-backed saddle developed, and stirrups and spurs were added, increasing the advantage of heavy cavalry even more.\nThis shift in military importance was reflected in society as well; knights took centre stage both on and off the battlefield. These are considered the \"ultimate\" in heavy cavalry: well-equipped with the best weapons, state-of-the-art armour from head to foot, leading with the lance in battle in a full-gallop, close-formation \"knightly charge\" that might prove irresistible, winning the battle almost as soon as it begun.\nBut knights remained the minority of total available combat forces; the expense of arms, armour, and horses was only affordable to a select few. While mounted men-at-arms focused on a narrow combat role of shock combat, medieval armies relied on a large variety of foot troops to fulfill all the rest (skirmishing, flank guards, scouting, holding ground, etc.). Medieval chroniclers tended to pay undue attention to the knights at the expense of the common soldiers, which led early students of military history to suppose that heavy cavalry was the only force that mattered on medieval European battlefields. But well-trained and disciplined infantry could defeat knights.\nMassed English longbowmen triumphed over French cavalry at Cr\u00e9cy, Poitiers and Agincourt, while at Gisors (1188), Bannockburn (1314), and Laupen (1339), foot-soldiers proved they could resist cavalry charges as long as they held their formation. Once the Swiss developed their pike squares for offensive as well as defensive use, infantry started to become the principal arm. This aggressive new doctrine gave the Swiss victory over a range of adversaries, and their enemies found that the only reliable way to defeat them was by the use of an even more comprehensive combined arms doctrine, as evidenced in the Battle of Marignano. The introduction of missile weapons that required less skill than the longbow, such as the crossbow and hand cannon, also helped remove the focus somewhat from cavalry elites to masses of cheap infantry equipped with easy-to-learn weapons. These missile weapons were very successfully used in the Hussite Wars, in combination with Wagenburg tactics.\nThis gradual rise in the dominance of infantry led to the adoption of dismounted tactics. From the earliest times knights and mounted men-at-arms had frequently dismounted to handle enemies they could not overcome on horseback, such as in the Battle of the Dyle (891) and the Battle of Bremule (1119), but after the 1350s this trend became more marked with the dismounted men-at-arms fighting as super-heavy infantry with two-handed swords and poleaxes. In any case, warfare in the Middle Ages tended to be dominated by raids and sieges rather than pitched battles, and mounted men-at-arms rarely had any choice other than dismounting when faced with the prospect of assaulting a fortified position.\nGreater Middle East.\nArabs.\nThe Islamic Prophet Muhammad made use of cavalry in many of his military campaigns including the Expedition of Dhu Qarad, and the expedition of Zaid ibn Haritha in al-Is which took place in September, 627 AD, fifth month of 6 AH of the Islamic calendar.\nEarly organized Arab mounted forces under the Rashidun caliphate comprised a light cavalry armed with lance and sword. Its main role was to attack the enemy flanks and rear. These relatively lightly armored horsemen formed the most effective element of the Muslim armies during the later stages of the Islamic conquest of the Levant. The best use of this lightly armed fast moving cavalry was revealed at the Battle of Yarmouk (636 AD) in which Khalid ibn Walid, knowing the skills of his horsemen, used them to turn the tables at every critical instance of the battle with their ability to engage, disengage, then turn back and attack again from the flank or rear. A strong cavalry regiment was formed by Khalid ibn Walid which included the veterans of the campaign of Iraq and Syria. Early Muslim historians have given it the name \"Mutaharrik tulai'a\"( \u0645\u062a\u062d\u0631\u0643 \u0637\u0644\u064a\u0639\u0629 ), or the Mobile guard. This was used as an advance guard and a strong striking force to route the opposing armies with its greater mobility that give it an upper hand when maneuvering against any Byzantine army. With this mobile striking force, the conquest of Syria was made easy.\nThe Battle of Talas in 751 AD was a conflict between the Arab Abbasid Caliphate and the Chinese Tang dynasty over the control of Central Asia. Chinese infantry were routed by Arab cavalry near the bank of the River Talas.\nLater Mamluks were trained as cavalry soldiers. Mamluks were to follow the dictates of al-furusiyya, a code of conduct that included values like courage and generosity but also doctrine of cavalry tactics, horsemanship, archery and treatment of wounds.\nMaghreb.\nThe Islamic Berber states of North Africa employed elite horse mounted cavalry armed with spears and following the model of the original Arab occupiers of the region. Horse-harness and weapons were manufactured locally and the six-monthly stipends for horsemen were double those of their infantry counterparts. During the 8th century Islamic conquest of Iberia large numbers of horses and riders were shipped from North Africa, to specialise in raiding and the provision of support for the massed Berber footmen of the main armies.\nMaghrebi traditions of mounted warfare eventually influenced a number of sub-Saharan African polities in the medieval era. The Esos of Ikoyi, military aristocrats of the Yoruba peoples, were a notable manifestation of this phenomenon.\nIran.\nQizilbash, were a class of Safavid militant warriors in Iran during the 15th to 18th centuries, who often fought as elite cavalry.\nRenaissance Europe.\nIronically, the rise of infantry in the early 16th century coincided with the \"golden age\" of heavy cavalry; a French or Spanish army at the beginning of the century could have up to half its numbers made up of various kinds of light and heavy cavalry, whereas in earlier medieval and later 17th-century armies the proportion of cavalry was seldom more than a quarter.\nKnighthood largely lost its military functions and became more closely tied to social and economic prestige in an increasingly capitalistic Western society. With the rise of drilled and trained infantry, the mounted men-at-arms, now sometimes called \"gendarmes\" and often part of the standing army themselves, adopted the same role as in the Hellenistic age, that of delivering a decisive blow once the battle was already engaged, either by charging the enemy in the flank or attacking their commander-in-chief.\nFrom the 1550s onwards, the use of gunpowder weapons solidified infantry's dominance of the battlefield and began to allow true mass armies to develop. This is closely related to the increase in the size of armies throughout the early modern period; heavily armored cavalrymen were expensive to raise and maintain and it took years to replace a skilled horseman or a trained horse, while arquebusiers and later musketeers could be trained and kept in the field at much lower cost, and were much easier to replace.\nThe Spanish tercio and later formations relegated cavalry to a supporting role. The pistol was specifically developed to try to bring cavalry back into the conflict, together with manoeuvres such as the caracole. The caracole was not particularly successful, however, and the charge (whether with lance, sword, or pistol) remained as the primary mode of employment for many types of European cavalry, although by this time it was delivered in much deeper formations and with greater discipline than before. The demi-lancers and the heavily armored sword-and-pistol reiters were among the types of cavalry whose heyday was in the 16th and 17th centuries, as for the Polish winged hussars, a heavy cavalry force that achieved great success against Swedes, Russians, and Turks.\n18th-century Europe and Napoleonic Wars.\nCavalry retained an important role in this age of regularization and standardization across European armies. They remained the primary choice for confronting enemy cavalry. Attacking an unbroken infantry force head-on usually resulted in failure, but extended linear infantry formations were vulnerable to flank or rear attacks. Cavalry was important at Blenheim (1704), Rossbach (1757), Marengo (1800), Eylau and Friedland (1807), remaining significant throughout the Napoleonic Wars.\nEven with the increasing prominence of infantry, cavalry still had an irreplaceable role in armies, due to their greater mobility. Their non-battle duties often included patrolling the fringes of army encampments, with standing orders to intercept suspected shirkers and deserters as well as serving as outpost pickets in advance of the main body. During battle, lighter cavalry such as hussars and uhlans might skirmish with other cavalry, attack light infantry, or charge and either capture enemy artillery or render them useless by plugging the touchholes with iron spikes. Heavier cavalry such as cuirassiers, dragoons, and carabiniers usually charged towards infantry formations or opposing cavalry in order to rout them. Both light and heavy cavalry pursued retreating enemies, the point where most battle casualties occurred.\nThe greatest cavalry charge of modern history was at the 1807 Battle of Eylau, when the entire 11,000-strong French cavalry reserve, led by Joachim Murat, launched a huge charge on and through the Russian infantry lines. Cavalry's dominating and menacing presence on the battlefield was countered by the use of infantry squares. The most notable examples are at the Battle of Quatre Bras and later at the Battle of Waterloo, the latter which the repeated charges by up to 9,000 French cavalrymen ordered by Michel Ney failed to break the British-Allied army, who had formed into squares. \nMassed infantry, especially those formed in squares were deadly to cavalry, but offered an excellent target for artillery. Once a bombardment had disordered the infantry formation, cavalry were able to rout and pursue the scattered foot soldiers. It was not until individual firearms gained accuracy and improved rates of fire that cavalry was diminished in this role as well. Even then light cavalry remained an indispensable tool for scouting, screening the army's movements, and harassing the enemy's supply lines until military aircraft supplanted them in this role in the early stages of World War I.\n19th century.\nEurope.\nBy the beginning of the 19th century, European cavalry fell into four main categories:\nThere were cavalry variations for individual nations as well: France had the \"chasseurs \u00e0 cheval\"; Prussia had the \"J\u00e4ger zu Pferde\"; Bavaria, Saxony and Austria had the \"Chevaulegers\"; and Russia had Cossacks. Britain, from the mid-18th century, had Light Dragoons as light cavalry and Dragoons, Dragoon Guards and Household Cavalry as heavy cavalry. Only after the end of the Napoleonic wars were the Household Cavalry equipped with cuirasses, and some other regiments were converted to lancers. In the United States Army prior to 1862 the cavalry were almost always dragoons. The Imperial Japanese Army had its cavalry uniformed as hussars, but they fought as dragoons.\nIn the Crimean War, the Charge of the Light Brigade and the Thin Red Line at the Battle of Balaclava showed the vulnerability of cavalry, when deployed without effective support.\nFranco-Prussian War.\nDuring the Franco-Prussian War, at the Battle of Mars-la-Tour in 1870, a Prussian cavalry brigade decisively smashed the centre of the French battle line, after skilfully concealing their approach. This event became known as Von Bredow's Death Ride after the brigade commander Adalbert von Bredow; it would be used in the following decades to argue that massed cavalry charges still had a place on the modern battlefield.\nImperial expansion.\nCavalry found a new role in colonial campaigns (irregular warfare), where modern weapons were lacking and the slow moving infantry-artillery train or fixed fortifications were often ineffective against indigenous insurgents (unless the latter offered a fight on an equal footing, as at Tel-el-Kebir, Omdurman, etc.). Cavalry \"flying columns\" proved effective, or at least cost-effective, in many campaigns\u2014although an astute native commander (like Samori in western Africa, Shamil in the Caucasus, or any of the better Boer commanders) could turn the tables and use the greater mobility of their cavalry to offset their relative lack of firepower compared with European forces.\nIn 1903 the British Indian Army maintained forty regiments of cavalry, numbering about 25,000 Indian sowars (cavalrymen), with British and Indian officers.\n Among the more famous regiments in the lineages of the modern Indian and Pakistani armies are:\nSeveral of these formations are still active, though they now are armoured formations, for example the Guides Cavalry of Pakistan.\nThe French Army maintained substantial cavalry forces in Algeria and Morocco from 1830 until the end of the Second World War. Much of the Mediterranean coastal terrain was suitable for mounted action and there was a long established culture of horsemanship amongst the Arab and Berber inhabitants. The French forces included Spahis, Chasseurs d' Afrique, Foreign Legion cavalry and mounted Goumiers. Both Spain and Italy raised cavalry regiments from amongst the indigenous horsemen of their North African territories (see regulares, Italian Spahis and savari respectively).\nImperial Germany employed mounted formations in South West Africa as part of the Schutztruppen (colonial army) garrisoning the territory.\nUnited States.\nIn the early American Civil War the regular United States Army mounted rifle, dragoon, and two existing cavalry regiments were reorganized and renamed cavalry regiments, of which there were six. Over a hundred other federal and state cavalry regiments were organized, but the infantry played a much larger role in many battles due to its larger numbers, lower cost per rifle fielded, and much easier recruitment. However, cavalry saw a role as part of screening forces and in foraging and scouting. The later phases of the war saw the Federal army developing a truly effective cavalry force fighting as scouts, raiders, and, with repeating rifles, as mounted infantry. The distinguished 1st Virginia Cavalry ranks as one of the most effectual and successful cavalry units on the Confederate side. Noted cavalry commanders included Confederate general J.E.B. Stuart, Nathan Bedford Forrest, and John Singleton Mosby (a.k.a. \"The Grey Ghost\") and on the Union side, Philip Sheridan and George Armstrong Custer.\nPost Civil War, as the volunteer armies disbanded, the regular army cavalry regiments increased in number from six to ten, among them Custer's U.S. 7th Cavalry Regiment of Little Bighorn fame, and the African-American U.S. 9th Cavalry Regiment and U.S. 10th Cavalry Regiment. The black units, along with others (both cavalry and infantry), collectively became known as the Buffalo Soldiers. According to Robert M. Utley: \nThese regiments, which rarely took the field as complete organizations, served throughout the American Indian Wars through the close of the frontier in the 1890s. Volunteer cavalry regiments like the Rough Riders consisted of horsemen such as cowboys, ranchers and other outdoorsmen, that served as a cavalry in the United States Military.\nFirst World War.\nPre-war developments.\nAt the beginning of the 20th century all armies still maintained substantial cavalry forces, although there was contention over whether their role should revert to that of mounted infantry (the historic dragoon function). Following the experience of the South African War of 1899\u20131902 (where mounted Boer citizen commandos fighting on foot from cover proved more effective than regular cavalry) the British Army withdrew lances for all but ceremonial purposes and placed a new emphasis on training for dismounted action. An Army Order dated 1909 however instructed that the six British lancer regiments then in existence resume use of this impressive but obsolete weapon for active service.\nIn 1882 the Imperial Russian Army converted all its line hussar and lancer regiments to dragoons, with an emphasis on mounted infantry training. In 1910 these regiments reverted to their historic roles, designations and uniforms.\nBy 1909 official regulations dictating the role of the Imperial German cavalry had been revised to indicate an increasing realization of the realities of modern warfare. The massive cavalry charge in three waves which had previously marked the end of annual maneuvers was discontinued and a new emphasis was placed in training on scouting, raiding and pursuit; rather than main battle involvement. The perceived importance of cavalry was however still evident, with thirteen new regiments of mounted rifles (\"Jager zu Pferde\") being raised shortly before the outbreak of war in 1914. \nIn spite of significant experience in mounted warfare in Morocco during 1908\u201314, the French cavalry remained a highly conservative institution. The traditional tactical distinctions between heavy, medium, and light cavalry branches were retained. French cuirassiers wore breastplates and plumed helmets unchanged from the Napoleonic period, during the early months of World War I. Dragoons were similarly equipped, though they did not wear cuirasses and did carry lances.\nLight cavalry were described as being \"a blaze of colour\". French cavalry of all branches were well mounted and were trained to change position and charge at full gallop. One weakness in training was that French cavalrymen seldom dismounted on the march and their horses suffered heavily from raw backs in August 1914.\nEurope 1914.\nIn August 1914 all combatant armies still retained substantial numbers of cavalry and the mobile nature of the opening battles on both Eastern and Western Fronts provided a number of instances of traditional cavalry actions, though on a smaller and more scattered scale than those of previous wars. The Imperial German cavalry, while as colourful and traditional as any in peacetime appearance, had adopted a practice of falling back on infantry support when any substantial opposition was encountered. These cautious tactics aroused derision amongst their more conservative French and Russian opponents but proved appropriate to the new nature of warfare. A single attempt by the German army, on 12 August 1914, to use six regiments of massed cavalry to cut off the Belgian field army from Antwerp foundered when they were driven back in disorder by rifle fire. The two German cavalry brigades involved lost 492 men and 843 horses in repeated charges against dismounted Belgian lancers and infantry. One of the last recorded charges by French cavalry took place on the night of 9/10 September 1914 when a squadron of the 16th Dragoons overran a German airfield at Soissons, while suffering heavy losses.\nOnce the front lines stabilised on the Western Front with the start of Trench Warfare, a combination of barbed wire, uneven muddy terrain, machine guns and rapid fire rifles proved deadly to horse mounted troops and by early 1915 most cavalry units were no longer seeing front line action. \nOn the Eastern Front a more fluid form of warfare arose from flat open terrain favorable to mounted warfare. On the outbreak of war in 1914 the bulk of the Russian cavalry was deployed at full strength in frontier garrisons and during the period that the main armies were mobilizing scouting and raiding into East Prussia and Austrian Galicia was undertaken by mounted troops trained to fight with sabre and lance in the traditional style. On 21 August 1914 the 4th Austro-Hungarian \"Kavalleriedivison\" fought a major mounted engagement at Jaroslavic with the Russian 10th Cavalry Division, in what was arguably the final historic battle to involve thousands of horsemen on both sides. While this was the last massed cavalry encounter on the Eastern Front, the absence of good roads limited the use of mechanized transport and even the technologically advanced Imperial German Army continued to deploy up to twenty-four horse-mounted divisions in the East, as late as 1917.\nEurope 1915\u201318.\nFor the remainder of the War on the Western Front cavalry had virtually no role to play. The British and French armies dismounted many of their cavalry regiments and used them in infantry and other roles: the Life Guards for example spent the last months of the War as a machine gun corps; and the Australian Light Horse served as light infantry during the Gallipoli campaign. In September 1914 cavalry comprised 9.28% of the total manpower of the British Expeditionary Force in France\u2014by July 1918 this proportion had fallen to 1.65%. As early as the first winter of the war most French cavalry regiments had dismounted a squadron each, for service in the trenches. The French cavalry numbered 102,000 in May 1915 but had been reduced to 63,000 by October 1918.\nThe German Army dismounted nearly all their cavalry in the West, maintaining only one mounted division on that front by January 1917.\nItaly entered the war in 1915 with thirty regiments of line cavalry, lancers and light horse. While employed effectively against their Austro-Hungarian counterparts during the initial offensives across the Isonzo River, the Italian mounted forces ceased to have a significant role as the front shifted into mountainous terrain. By 1916 most cavalry machine-gun sections and two complete cavalry divisions had been dismounted and seconded to the infantry.\nSome cavalry were retained as mounted troops behind the lines in anticipation of a penetration of the opposing trenches that it seemed would never come. Tanks, introduced on the Western Front by the British in September 1916 during the Battle of the Somme, had the capacity to achieve such breakthroughs but did not have the reliable range to exploit them. In their first major use at the Battle of Cambrai (1917), the plan was for a cavalry division to follow behind the tanks, however they were not able to cross a canal because a tank had broken the only bridge. While no longer the main frontline of troops, cavalry was still used throughout the war in large amounts on rare occasions for offensives, such as in the Battle of Caporetto and the Battle of Moreuil Wood. It was not until the German Army had been forced to retreat in the Hundred Days Offensive of 1918, that cavalry were again able to operate in their intended role. There was a successful charge by the British 7th Dragoon Guards on the last day of the war.\nIn the wider spaces of the Eastern Front a more fluid form of warfare continued and there was still a use for mounted troops. Some wide-ranging actions were fought, again mostly in the early months of the war. However, even here the value of cavalry was overrated and the maintenance of large mounted formations at the front by the Russian Army put a major strain on the railway system, to little strategic advantage. In February 1917 the Russian regular cavalry (exclusive of Cossacks) was reduced by nearly a third from its peak number of 200,000, as two squadrons of each regiment were dismounted and incorporated into additional infantry battalions. Their Austro-Hungarian opponents, plagued by a shortage of trained infantry, had been obliged to progressively convert most horse cavalry regiments to dismounted rifle units starting in late 1914.\nMiddle East.\nIn the Middle East, during the Sinai and Palestine Campaign mounted forces (British, Indian, Ottoman, Australian, Arab and New Zealand) retained an important strategic role both as mounted infantry and cavalry.\nIn Egypt the mounted infantry formations like the New Zealand Mounted Rifles Brigade and Australian Light Horse of ANZAC Mounted Division, operating as mounted infantry, drove German and Ottoman forces back from Romani to Magdhaba and Rafa and out of the Egyptian Sinai Peninsula in 1916.\nAfter a stalemate on the Gaza\u2014Beersheba line between March and October 1917, Beersheba was captured by the Australian Mounted Division's 4th Light Horse Brigade. Their mounted charge succeeded after a coordinated attack by the British Infantry and Yeomanry cavalry and the Australian and New Zealand Light Horse and Mounted Rifles brigades. A series of coordinated attacks by these Egyptian Expeditionary Force infantry and mounted troops were also successful at the Battle of Mughar Ridge, during which the British infantry divisions and the Desert Mounted Corps drove two Ottoman armies back to the Jaffa\u2014Jerusalem line. The infantry with mainly dismounted cavalry and mounted infantry fought in the Judean Hills to eventually almost encircle Jerusalem which was occupied shortly after.\nDuring a pause in operations necessitated by the German spring offensive in 1918 on the Western Front joint infantry and mounted infantry attacks towards Amman and Es Salt resulted in retreats back to the Jordan Valley which continued to be occupied by mounted divisions during the summer of 1918.\nThe Australian Mounted Division was armed with swords and in September, after the successful breaching of the Ottoman line on the Mediterranean coast by the British Empire infantry XXI Corps was followed by cavalry attacks by the 4th Cavalry Division, 5th Cavalry Division and Australian Mounted Divisions which almost encircled two Ottoman armies in the Judean Hills forcing their retreat. Meanwhile, Chaytor's Force of infantry and mounted infantry in ANZAC Mounted Division held the Jordan Valley, covering the right flank to later advance eastwards to capture Es Salt and Amman and half of a third Ottoman army. A subsequent pursuit by the 4th Cavalry Division and the Australian Mounted Division followed by the 5th Cavalry Division to Damascus. Armoured cars and 5th Cavalry Division lancers were continuing the pursuit of Ottoman units north of Aleppo when the Armistice of Mudros was signed by the Ottoman Empire.\nPost\u2013World War I.\nA combination of military conservatism in almost all armies and post-war financial constraints prevented the lessons of 1914\u20131918 being acted on immediately. There was a general reduction in the number of cavalry regiments in the British, French, Italian and other Western armies but it was still argued with conviction (for example in the 1922 edition of the \"Encyclop\u00e6dia Britannica\") that mounted troops had a major role to play in future warfare. The 1920s saw an interim period during which cavalry remained as a proud and conspicuous element of all major armies, though much less so than prior to 1914.\nCavalry was extensively used in the Russian Civil War and the Soviet-Polish War. The last major cavalry battle was the Battle of Komar\u00f3w in 1920, between Poland and the Russian Bolsheviks. Colonial warfare in Morocco, Syria, the Middle East and the North West Frontier of India provided some opportunities for mounted action against enemies lacking advanced weaponry.\nThe post-war German Army (Reichsheer) was permitted a large proportion of cavalry (18 regiments or 16.4% of total manpower) under the conditions of the Treaty of Versailles.\nThe British Army mechanised all cavalry regiments between 1929 and 1941, redefining their role from horse to armoured vehicles to form the Royal Armoured Corps together with the Royal Tank Regiment. The U.S. Cavalry abandoned its sabres in 1934 and commenced the conversion of its horsed regiments to mechanized cavalry, starting with the First Regiment of Cavalry in January 1933.\nDuring the 1930s the French Army experimented with integrating mounted and mechanised cavalry units into larger formations. Dragoon regiments were converted to motorised infantry (trucks and motor cycles), and cuirassiers to armoured units; while light cavalry (Chasseurs a' Cheval, Hussars and Spahis) remained as mounted sabre squadrons. The theory was that mixed forces comprising these diverse units could utilise the strengths of each according to circumstances. In practice mounted troops proved unable to keep up with fast moving mechanised units over any distance.\nThe thirty-nine cavalry regiments of the British Indian Army were reduced to twenty-one as the result of a series of amalgamations immediately following World War I. The new establishment remained unchanged until 1936 when three regiments were redesignated as permanent training units, each with six, still mounted, regiments linked to them. In 1938 the process of mechanization began with the conversion of a full cavalry brigade (two Indian regiments and one British) to armoured car and tank units. By the end of 1940 all of the Indian cavalry had been mechanized initially, in the majority of cases, to motorized infantry transported in 15cwt trucks. The last horsed regiment of the British Indian Army (other than the Viceregal Bodyguard and some Indian States Forces regiments) was the 19th King George's Own Lancers which had its final mounted parade at Rawalpindi on 28 October 1939. This unit still exists in the Pakistan Army as an armored regiment.\nWorld War II.\nWhile most armies still maintained cavalry units at the outbreak of World War II in 1939, significant mounted action was largely restricted to the Polish, Balkan, and Soviet campaigns. Rather than charge their mounts into battle, cavalry units were either used as mounted infantry (using horses to move into position and then dismounting for combat) or as reconnaissance units (especially in areas not suited to tracked or wheeled vehicles).\nPolish.\nA popular myth is that Polish cavalry armed with lances charged German tanks during the September 1939 campaign. This arose from misreporting of a single clash on 1 September near Krojanty, when two squadrons of the Polish 18th Lancers armed with sabres scattered German infantry before being caught in the open by German armoured cars.\nTwo examples illustrate how the myth developed. First, because motorised vehicles were in short supply, the Poles used horses to pull anti-tank weapons into position. Second, there were a few incidents when Polish cavalry was trapped by German tanks, and attempted to fight free. However, this did not mean that the Polish army chose to attack tanks with horse cavalry. Later, on the Eastern Front, the Red Army did deploy cavalry units effectively against the Germans.\nA more correct term would be \"mounted infantry\" instead of \"cavalry\", as horses were primarily used as a means of transportation, for which they were very suitable in view of the very poor road conditions in pre-war Poland. Another myth describes Polish cavalry as being armed with both sabres and lances; lances were used for peacetime ceremonial purposes only and the primary weapon of the Polish cavalryman in 1939 was a rifle. Individual equipment did include a sabre, probably because of well-established tradition, and in the case of a melee combat this secondary weapon would probably be more effective than a rifle and bayonet. Moreover, the Polish cavalry brigade order of battle in 1939 included, apart from the mounted soldiers themselves, light and heavy machine guns (wheeled), the Anti-tank rifle, model 35, anti-aircraft weapons, anti tank artillery such as the Bofors 37 mm, also light and scout tanks, etc. The last cavalry vs. cavalry mutual charge in Europe took place in Poland during the Battle of Krasnobr\u00f3d, when Polish and German cavalry units clashed with each other.\nThe last classical cavalry charge of the war took place on March 1, 1945 during the Battle of Schoenfeld by the 1st \"Warsaw\" Independent Cavalry Brigade. Infantry and tanks had been employed to little effect against the German position, both of which floundered in the open wetlands only to be dominated by infantry and antitank fire from the German fortifications on the forward slope of Hill 157, overlooking the wetlands. The Germans had not taken cavalry into consideration when fortifying their position which, combined with the \"Warsaw\"s swift assault, overran the German anti-tank guns and consolidated into an attack into the village itself, now supported by infantry and tanks.\nGreek.\nThe Italian invasion of Greece in October 1940 saw mounted cavalry used effectively by the Greek defenders along the mountainous frontier with Albania. Three Greek cavalry regiments (two mounted and one partially mechanized) played an important role in the Italian defeat in this difficult terrain.\nSoviet.\nThe contribution of Soviet cavalry to the development of modern military operational doctrine and its importance in defeating Nazi Germany has been eclipsed by the higher profile of tanks and airplanes. Despite the view portrayed by German propaganda, Soviet cavalry contributed significantly to the defeat of the Axis armies. Their contributions included being the most mobile troops in the early stages, when trucks and other equipment were low in quality; as well as providing cover for retreating forces.\nConsidering their relatively limited numbers, the Soviet cavalry played a significant role in giving Germany its first real defeats in the early stages of the war. The continuing potential of mounted troops was demonstrated during the Battle of Moscow, against Guderian and the powerful central German 9th Army. Cavalry were amongst the first Soviet units to complete the encirclement in the Battle of Stalingrad, thus sealing the fate of the German 6th Army. Mounted Soviet forces also played a role in the encirclement of Berlin, with some Cossack cavalry units reaching the Reichstag in April 1945. Throughout the war they performed important tasks such as the capture of bridgeheads which is considered one of the hardest jobs in battle, often doing so with inferior numbers. For instance the 8th Guards Cavalry Regiment of the 2nd Guards Cavalry Division, often fought outnumbered against the best German units.\nBy the final stages of the war only the Soviet Union was still fielding mounted units in substantial numbers, some in combined mechanized and horse units. The advantage of this approach was that in exploitation mounted infantry could keep pace with advancing tanks. Other factors favoring the retention of mounted forces included the high quality of Russian Cossacks which made about half of all cavalry; and the relative lack of roads suitable for wheeled vehicles in many parts of the Eastern Front. Another consideration was that the logistic capacity required to support very large motorized forces exceeded that necessary for mounted troops. The main usage of the Soviet cavalry involved infiltration through front lines with subsequent deep raids, which disorganized German supply lines. Another role was the pursuit of retreating enemy forces during major frontline operations and breakthroughs.\nItalian.\nThe last mounted sabre charge by Italian cavalry occurred on August 24, 1942 at Isbuscenski (Russia), when a squadron of the Savoia Cavalry Regiment charged the 812th Siberian Infantry Regiment. The remainder of the regiment, together with the Novara Lancers made a dismounted attack in an action that ended with the retreat of the Russians after heavy losses on both sides. The final Italian cavalry action occurred on October 17, 1942 in Poloj (now Croatia) by a squadron of the Alexandria Cavalry Regiment against a large group of Yugoslav partisans.\nOther Axis.\nRomanian, Hungarian and Italian cavalry were dispersed or disbanded following the retreat of the Axis forces from Russia. Germany still maintained some mounted (mixed with bicycles) SS and Cossack units until the last days of the War.\nFinnish.\nFinland used mounted troops against Russian forces effectively in forested terrain during the Continuation War. The last Finnish cavalry unit was not disbanded until 1947.\nUnited States.\nThe U.S. Army's last horse cavalry actions were fought during World War II: a) by the 26th Cavalry Regiment\u2014a small mounted regiment of Philippine Scouts which fought the Japanese during the retreat down the Bataan peninsula, until it was effectively destroyed by January 1942; and b) on captured German horses by the mounted reconnaissance section of the U.S. 10th Mountain Division in a spearhead pursuit of the German Army across the Po Valley in Italy in April 1945. The last horsed U.S. Cavalry (the Second Cavalry Division) were dismounted in March 1944.\nBritish Empire.\nAll British Army cavalry regiments had been mechanised since 1 March 1942 when the Queen's Own Yorkshire Dragoons (Yeomanry) was converted to a motorised role, following mounted service against the Vichy French in Syria the previous year. The final cavalry charge by British Empire forces occurred on 21 March 1942 when a 60 strong patrol of the Burma Frontier Force encountered Japanese infantry near Toungoo airfield in central Myanmar. The Sikh sowars of the Frontier Force cavalry, led by Captain Arthur Sandeman of The Central India Horse (21st King George V's Own Horse), charged in the old style with sabres and most were killed.\nMongolia.\nIn the early stages of World War II, mounted units of the Mongolian People's Army were involved in the Battle of Khalkhin Gol against invading Japanese forces. Soviet forces under the command of Georgy Zhukov, together with Mongolian forces, defeated the Japanese Sixth army and effectively ended the Soviet\u2013Japanese Border Wars. After the Soviet\u2013Japanese Neutrality Pact of 1941, Mongolia remained neutral throughout most of the war, but its geographical situation meant that the country served as a buffer between Japanese forces and the Soviet Union. In addition to keeping around 10% of the population under arms, Mongolia provided half a million trained horses for use by the Soviet Army. In 1945 a partially mounted Soviet-Mongolian Cavalry Mechanized Group played a supporting role on the western flank of the Soviet invasion of Manchuria. The last active service seen by cavalry units of the Mongolian Army occurred in 1946\u20131948, during border clashes between Mongolia and the Republic of China.\nPost\u2013World War II to the present day.\nWhile most modern \"cavalry\" units have some historic connection with formerly mounted troops this is not always the case. The modern Irish Defence Forces (DF) includes a \"Cavalry Corps\" equipped with armoured cars and Scorpion tracked combat reconnaissance vehicles. The DF has never included horse cavalry since its establishment in 1922 (other than a small mounted escort of Blue Hussars drawn from the Artillery Corps when required for ceremonial occasions). However, the mystique of the cavalry is such that the name has been introduced for what was always a mechanised force.\nSome engagements in late 20th and early 21st century guerrilla wars involved mounted troops, particularly against partisan or guerrilla fighters in areas with poor transport infrastructure. Such units were not used as cavalry but rather as mounted infantry. Examples occurred in Afghanistan, Portuguese Africa and Rhodesia. The French Army used existing mounted squadrons of Spahis to a limited extent for patrol work during the Algerian War (1954\u201362). The Swiss Army maintained a mounted dragoon regiment for combat purposes until 1973. The Portuguese Army used horse mounted cavalry with some success in the wars of independence in Angola and Mozambique in the 1960s and 1970s. During the 1964\u201379 Rhodesian Bush War the Rhodesian Army created an elite mounted infantry unit called Grey's Scouts to fight unconventional actions against the rebel forces of Robert Mugabe and Joshua Nkomo. The horse mounted infantry of the Scouts were effective and reportedly feared by their opponents in the rebel African forces. In the 1978 to present Afghan Civil War period there have been several instances of horse mounted combat.\nCentral and South American armies maintained mounted cavalry for longer than those of Asia, Europe, or North America. The Mexican Army included a number of horse mounted cavalry regiments as late as the mid-1990s and the Chilean Army had five such regiments in 1983 as mounted mountain troops.\nThe Soviet Army retained horse cavalry divisions until 1955. At the dissolution of the Soviet Union in 1991, there was still an independent horse mounted cavalry squadron in Kyrgyzstan.\nOperational horse cavalry.\nToday the Indian Army's 61st Cavalry is reported to be the largest existing horse-mounted cavalry unit still having operational potential. It was raised in 1951 from the amalgamated state cavalry squadrons of Gwalior, Jodhpur, and Mysore. While primarily utilised for ceremonial purposes, the regiment can be deployed for internal security or police roles if required. The 61st Cavalry and the President's Body Guard parade in full dress uniform in New Delhi each year in what is probably the largest assembly of traditional cavalry still to be seen in the world. Both the Indian and the Pakistani armies maintain armoured regiments with the titles of Lancers or Horse, dating back to the 19th century.\nAs of 2007, the Chinese People's Liberation Army employed two battalions of horse-mounted border guards in Xinjiang for border patrol purposes. PLA mounted units last saw action during border clashes with Vietnam in the 1970s and 1980s, after which most cavalry units were disbanded as part of major military downsizing in the 1980s. In the wake of the 2008 Sichuan earthquake, there were calls to rebuild the army horse inventory for disaster relief in difficult terrain. Subsequent Chinese media reports confirm that the PLA maintains operational horse cavalry at squadron strength in Xinjiang and Inner Mongolia for scouting, logistical, and border security purposes.\nThe Chilean Army still maintains a mixed armoured cavalry regiment, with elements of it acting as mounted mountain exploration troops, based in the city of Angol, being part of the III Mountain Division, and another independent exploration cavalry detachment in the town of Chaiten. The rugged mountain terrain calls for the use of special horses suited for that use.\nCeremonial horse cavalry and armored cavalry retaining traditional titles.\nCavalry or mounted gendarmerie units continue to be maintained for purely or primarily ceremonial purposes by the Algerian, Argentine, Bolivian, Brazilian, British, Bulgarian, Canadian, Chilean, Colombian, Danish, Dutch, Finnish, French, Hungarian, Indian, Italian, Jordanian, Malaysian, Moroccan, Nepalese, Nigerian, North Korean, Omani, Pakistani, Panamanian, Paraguayan, Peruvian, Polish, Portuguese, Russian, Senegalese, Spanish, Swedish, Thai, Tunisian, Turkmenistan, United States, and Venezuelan armed forces.\nA number of armoured regiments in the British Army retain the historic designations of Hussars, Dragoons, Light Dragoons, Dragoon Guards, Lancers and Yeomanry. Only the Household Cavalry (consisting of the Life Guards' mounted squadron, The Blues and Royals' mounted squadron, the State Trumpeters of The Household Cavalry and the Household Cavalry Mounted Band) are maintained for mounted (and dismounted) ceremonial duties in London.\nThe French Army still has regiments with the historic designations of Cuirassiers, Hussars, Chasseurs, Dragoons and Spahis. Only the cavalry of the Republican Guard and a ceremonial \"fanfare\" detachment of trumpeters for the cavalry/armoured branch as a whole are now mounted.\nIn the Canadian Army, a number of regular and reserve units have cavalry roots, including The Royal Canadian Hussars (Montreal), the Governor General's Horse Guards, Lord Strathcona's Horse, The British Columbia Dragoons, The Royal Canadian Dragoons, and the South Alberta Light Horse. Of these, only Lord Strathcona's Horse and the Governor General's Horse Guards maintain an official ceremonial horse-mounted cavalry troop or squadron.\nIn 2002 the Army of the Russian Federation reintroduced a ceremonial mounted squadron wearing historic uniforms.\nBoth the Australian and New Zealand armies follow the British practice of maintaining traditional titles (Light Horse or Mounted Rifles) for modern mechanised units. However, neither country retains a horse-mounted unit.\nSeveral armored units of the modern United States Army retain the designation of \"armored cavalry\". The United States also has \"air cavalry\" units equipped with helicopters. The Horse Cavalry Detachment of the U.S. Army's 1st Cavalry Division, made up of active duty soldiers, still functions as an active unit, trained to approximate the weapons, tools, equipment and techniques used by the United States Cavalry in the 1880s.\nNon-combat support roles.\nThe First Troop Philadelphia City Cavalry is a volunteer unit within the Pennsylvania Army National Guard which serves as a combat force when in federal service but acts in a mounted disaster relief role when in state service. In addition, the Parsons' Mounted Cavalry is a Reserve Officer Training Corps unit which forms part of the Corps of Cadets at Texas A&amp;M University. Valley Forge Military Academy and College also has a Mounted Company, known as D-Troop .\nSome individual U.S. states maintain cavalry units as a part of their respective state defense forces. The Maryland Defense Force includes a cavalry unit, Cavalry Troop A, which serves primarily as a ceremonial unit. The unit training includes a saber qualification course based upon the 1926 U.S. Army course. Cavalry Troop A also assists other Maryland agencies as a rural search and rescue asset. In Massachusetts, The National Lancers trace their lineage to a volunteer cavalry militia unit established in 1836 and are currently organized as an official part of the Massachusetts Organized Militia. The National Lancers maintain three units, Troops A, B, and C, which serve in a ceremonial role and assist in search and rescue missions. In July 2004, the National Lancers were ordered into active state service to guard Camp Curtis Guild during the 2004 Democratic National Convention. The Governor's Horse Guard of Connecticut maintains two companies which are trained in urban crowd control.\nLight and heavy cavalry.\nHistorically, cavalry was divided into horse archers, light cavalry, and heavy cavalry. The differences were their role in combat, the size of the mount, and how much armor was worn by the mount and rider.\nEarly light cavalry (like the auxiliaries of the Roman army) were typically used to scout and skirmish, to cut down retreating infantry, and for defeating enemy missile troops. Armoured cavalry such as the Byzantine cataphract were used as shock troops\u2014they would charge the main body of the enemy and in many cases, their actions decided the outcome of the battle, hence the later term \"battle cavalry\".\nDuring the Gunpowder Age, armored cavalry units still retained cuirasses and helmets for their protective value against sword and bayonet strikes, and the morale boost these provide to the wearers. By this time the main difference between light and heavy cavalry was their training; the former was regarded as a tool for harassment and reconnaissance, while the latter was considered best for close-order charges.\nSince the development of armored warfare, the distinction between light and heavy armor has persisted basically along the same lines. Armored cars and light tanks have adopted the reconnaissance role while medium and heavy tanks are regarded as the decisive shock troops.\nSocial status.\nFrom the beginning of civilization to the 20th century, ownership of heavy cavalry horses has been a mark of wealth amongst settled peoples. A cavalry horse involves considerable expense in breeding, training, feeding, and equipment, and has very little productive use except as a mode of transport.\nFor this reason, and because of their often decisive military role, the cavalry has typically been associated with high social status. This was most clearly seen in the feudal system, where a lord was expected to enter combat armored and on horseback and bring with him an entourage of lightly armed peasants on foot. If landlords and peasant levies came into conflict, the poorly trained footmen would be ill-equipped to defeat armored knights.\nIn later national armies, service as an officer in the cavalry was generally a badge of high social status. For instance prior to 1914 most officers of British cavalry regiments came from a socially privileged background and the considerable expenses associated with their role generally required private means, even after it became possible for officers of the line infantry regiments to live on their pay. Options open to poorer cavalry officers in the various European armies included service with less fashionable (though often highly professional) frontier or colonial units. These included the British Indian cavalry, the Russian Cossacks or the French Chasseurs d' Afrique.\nDuring the 19th and early 20th centuries most monarchies maintained a mounted cavalry element in their royal or imperial guards. These ranged from small units providing ceremonial escorts and palace guards, through to large formations intended for active service. The mounted escort of the Spanish Royal Household provided an example of the former and the twelve cavalry regiments of the Prussian Imperial Guard an example of the latter. In either case the officers of such units were likely to be drawn from the aristocracies of their respective societies.\nOn film.\nSome sense of the noise and power of a cavalry charge can be gained from the 1970 film \"Waterloo\", which featured some 2,000 cavalrymen, some of them Cossacks. It included detailed displays of the horsemanship required to manage animal and weapons in large numbers at the gallop (unlike the real battle of Waterloo, where deep mud significantly slowed the horses). The Gary Cooper movie \"They Came to Cordura\" contains a scene of a cavalry regiment deploying from march to battle line formation. A smaller-scale cavalry charge can be seen in \"\" (2003); although the finished scene has substantial computer-generated imagery, raw footage and reactions of the riders are shown in the Extended Version DVD Appendices.\nOther films that show cavalry actions include:"}
{"id": "6817", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=6817", "title": "Canonization of Saints", "text": ""}
{"id": "6818", "revid": "28481209", "url": "https://en.wikipedia.org/wiki?curid=6818", "title": "Citric acid cycle", "text": "The citric acid cycle (CAC)\u00a0\u2013 also known as the TCA cycle (tricarboxylic acid cycle) or the Krebs cycle\u00a0\u2013 is a series of chemical reactions used by all aerobic organisms to release stored energy through the oxidation of acetyl-CoA derived from carbohydrates, fats, and proteins. In addition, the cycle provides precursors of certain amino acids, as well as the reducing agent NADH, that are used in numerous other reactions. Its central importance to many biochemical pathways suggests that it was one of the earliest components of metabolism and may have originated abiogenically. Even though it is branded as a 'cycle', it is not necessary for metabolites to follow only one specific route; at least three segments of the citric acid cycle have been recognized.\nThe name of this metabolic pathway is derived from the citric acid (a tricarboxylic acid, often called citrate, as the ionized form predominates at biological pH) that is consumed and then regenerated by this sequence of reactions to complete the cycle. The cycle consumes acetate (in the form of acetyl-CoA) and water, reduces NAD+ to NADH, releasing carbon dioxide. The NADH generated by the citric acid cycle is fed into the oxidative phosphorylation (electron transport) pathway. The net result of these two closely linked pathways is the oxidation of nutrients to produce usable chemical energy in the form of ATP.\nIn eukaryotic cells, the citric acid cycle occurs in the matrix of the mitochondrion. In prokaryotic cells, such as bacteria, which lack mitochondria, the citric acid cycle reaction sequence is performed in the cytosol with the proton gradient for ATP production being across the cell's surface (plasma membrane) rather than the inner membrane of the mitochondrion. The overall yield of energy-containing compounds from the TCA cycle is three NADH, one FADH2, and one GTP.\nDiscovery.\nSeveral of the components and reactions of the citric acid cycle were established in the 1930s by the research of Albert Szent-Gy\u00f6rgyi, who received the Nobel Prize in Physiology or Medicine in 1937 specifically for his discoveries pertaining to fumaric acid, a key component of the cycle. He made this discovery by studying pigeon breast muscle. Because this tissue maintains its oxidative capacity well after breaking down in the \"Latapie\" mill and releasing in aqueous solutions, breast muscle of the pigeon was very well qualified for the study of oxidative reactions. The citric acid cycle itself was finally identified in 1937 by Hans Adolf Krebs and William Arthur Johnson while at the University of Sheffield, for which the former received the Nobel Prize for Physiology or Medicine in 1953, and for whom the cycle is sometimes named (Krebs cycle).\nOverview.\nThe citric acid cycle is a key metabolic pathway that connects carbohydrate, fat, and protein metabolism. The reactions of the cycle are carried out by eight enzymes that completely oxidize acetate (a two carbon molecule), in the form of acetyl-CoA, into two molecules each of carbon dioxide and water. Through catabolism of sugars, fats, and proteins, the two-carbon organic product acetyl-CoA (a form of acetate) is produced which enters the citric acid cycle. The reactions of the cycle also convert three equivalents of nicotinamide adenine dinucleotide (NAD+) into three equivalents of reduced NAD+ (NADH), one equivalent of flavin adenine dinucleotide (FAD) into one equivalent of FADH2, and one equivalent each of guanosine diphosphate (GDP) and inorganic phosphate (Pi) into one equivalent of guanosine triphosphate (GTP). The NADH and FADH2 generated by the citric acid cycle are, in turn, used by the oxidative phosphorylation pathway to generate energy-rich ATP.\nOne of the primary sources of acetyl-CoA is from the breakdown of sugars by glycolysis which yield pyruvate that in turn is decarboxylated by the pyruvate dehydrogenase complex generating acetyl-CoA according to the following reaction scheme:\nThe product of this reaction, acetyl-CoA, is the starting point for the citric acid cycle. Acetyl-CoA may also be obtained from the oxidation of fatty acids. Below is a schematic outline of the cycle:\nSteps.\nThere are ten basic steps in the citric acid cycle, as outlined below. The cycle is continuously supplied with new carbon in the form of acetyl-CoA, entering at step 0 in the table.\nTwo carbon atoms are oxidized to CO2, the energy from these reactions is transferred to other metabolic processes through GTP (or ATP), and as electrons in NADH and QH2. The NADH generated in the citric acid cycle may later be oxidized (donate its electrons) to drive ATP synthesis in a type of process called oxidative phosphorylation. FADH2 is covalently attached to succinate dehydrogenase, an enzyme which functions both in the CAC and the mitochondrial electron transport chain in oxidative phosphorylation. FADH2, therefore, facilitates transfer of electrons to coenzyme Q, which is the final electron acceptor of the reaction catalyzed by the succinate:ubiquinone oxidoreductase complex, also acting as an intermediate in the electron transport chain.\nMitochondria in animals, including humans, possess two succinyl-CoA synthetases: one that produces GTP from GDP, and another that produces ATP from ADP. Plants have the type that produces ATP (ADP-forming succinyl-CoA synthetase). Several of the enzymes in the cycle may be loosely associated in a multienzyme protein complex within the mitochondrial matrix.\nThe GTP that is formed by GDP-forming succinyl-CoA synthetase may be utilized by nucleoside-diphosphate kinase to form ATP (the catalyzed reaction is GTP + ADP \u2192 GDP + ATP).\nProducts.\nProducts of the first turn of the cycle are one GTP (or ATP), three NADH, one QH2 and two CO2.\nBecause two acetyl-CoA molecules are produced from each glucose molecule, two cycles are required per glucose molecule. Therefore, at the end of two cycles, the products are: two GTP, six NADH, two QH2, and four CO2.\nThe above reactions are balanced if Pi represents the H2PO4\u2212 ion, ADP and GDP the ADP2\u2212 and GDP2\u2212 ions, respectively, and ATP and GTP the ATP3\u2212 and GTP3\u2212 ions, respectively.\nThe total number of ATP molecules obtained after complete oxidation of one glucose in glycolysis, citric acid cycle, and oxidative phosphorylation is estimated to be between 30 and 38.\nEfficiency.\nThe theoretical maximum yield of ATP through oxidation of one molecule of glucose in glycolysis, citric acid cycle, and oxidative phosphorylation is 38 (assuming 3 molar equivalents of ATP per equivalent NADH and 2 ATP per UQH2). In eukaryotes, two equivalents of NADH and four equivalents of ATP are generated in glycolysis, which takes place in the cytoplasm. Transport of two of these equivalents of NADH into the mitochondria consumes two equivalents of ATP, thus reducing the net production of ATP to 36. Furthermore, inefficiencies in oxidative phosphorylation due to leakage of protons across the mitochondrial membrane and slippage of the ATP synthase/proton pump commonly reduces the ATP yield from NADH and UQH2 to less than the theoretical maximum yield. The observed yields are, therefore, closer to ~2.5 ATP per NADH and ~1.5 ATP per UQH2, further reducing the total net production of ATP to approximately 30. An assessment of the total ATP yield with newly revised proton-to-ATP ratios provides an estimate of 29.85 ATP per glucose molecule.\nVariation.\nWhile the citric acid cycle is in general highly conserved, there is significant variability in the enzymes found in different taxa (note that the diagrams on this page are specific to the mammalian pathway variant).\nSome differences exist between eukaryotes and prokaryotes. The conversion of D-\"threo\"-isocitrate to 2-oxoglutarate is catalyzed in eukaryotes by the NAD+-dependent EC 1.1.1.41, while prokaryotes employ the NADP+-dependent EC 1.1.1.42. Similarly, the conversion of (\"S\")-malate to oxaloacetate is catalyzed in eukaryotes by the NAD+-dependent EC 1.1.1.37, while most prokaryotes utilize a quinone-dependent enzyme, EC 1.1.5.4.\nA step with significant variability is the conversion of succinyl-CoA to succinate. Most organisms utilize EC 6.2.1.5, succinate\u2013CoA ligase (ADP-forming) (despite its name, the enzyme operates in the pathway in the direction of ATP formation). In mammals a GTP-forming enzyme, succinate\u2013CoA ligase (GDP-forming) (EC 6.2.1.4) also operates. The level of utilization of each isoform is tissue dependent. In some acetate-producing bacteria, such as \"Acetobacter aceti\", an entirely different enzyme catalyzes this conversion\u00a0\u2013 EC 2.8.3.18, succinyl-CoA:acetate CoA-transferase. This specialized enzyme links the TCA cycle with acetate metabolism in these organisms. Some bacteria, such as \"Helicobacter pylori\", employ yet another enzyme for this conversion\u00a0\u2013 succinyl-CoA:acetoacetate CoA-transferase (EC 2.8.3.5).\nSome variability also exists at the previous step\u00a0\u2013 the conversion of 2-oxoglutarate to succinyl-CoA. While most organisms utilize the ubiquitous NAD+-dependent 2-oxoglutarate dehydrogenase, some bacteria utilize a ferredoxin-dependent 2-oxoglutarate synthase (EC 1.2.7.3).\nOther organisms, including obligately autotrophic and methanotrophic bacteria and archaea, bypass succinyl-CoA entirely, and convert 2-oxoglutarate to succinate via succinate semialdehyde, using EC 4.1.1.71, 2-oxoglutarate decarboxylase, and EC 1.2.1.79, succinate-semialdehyde dehydrogenase.\nIn cancer, there are substantial metabolic derangements that occur to ensure the proliferation of tumor cells, and consequently metabolites can accumulate which serve to facilitate tumorigenesis, dubbed oncometabolites. Among the best characterized oncometabolites is 2-hydroxyglutarate which is produced through a heterozygous gain-of-function mutation (specifically a neomorphic one) in isocitrate dehydrogenase (IDH) (which under normal circumstances catalyzes the oxidation of isocitrate to oxalosuccinate, which then spontaneously decarboxylates to alpha-ketoglutarate, as discussed above; in this case an additional reduction step occurs after the formation of alpha-ketoglutarate via NADPH to yield 2-hydroxyglutarate), and hence IDH is considered an oncogene. Under physiological conditions, 2-hydroxyglutarate is a minor product of several metabolic pathways as an error but readily converted to alpha-ketoglutarate via hydroxyglutarate dehydrogenase enzymes (L2HGDH and D2HGDH) but does not have a known physiologic role in mammalian cells; of note, in cancer, 2-hydroxyglutarate is likely a terminal metabolite as isotope labelling experiments of colorectal cancer cell lines show that its conversion back to alpha-ketoglutarate is too low to measure. In cancer, 2-hydroxyglutarate serves as a competitive inhibitor for a number of enzymes that facilitate reactions via alpha-ketoglutarate in alpha-ketoglutarate-dependent dioxygenases. This mutation results in several important changes to the metabolism of the cell. For one thing, because there is an extra NADPH-catalyzed reduction, this can contribute to depletion of cellular stores of NADPH and also reduce levels of alpha-ketoglutarate available to the cell. In particular, the depletion of NADPH is problematic because NADPH is highly compartmentalized and cannot freely diffuse between the organelles in the cell. It is produced largely via the pentose phosphate pathway in the cytoplasm. The depletion of NADPH results in increased oxidative stress within the cell as it is a required cofactor in the production of GSH, and this oxidative stress can result in DNA damage. There are also changes on the genetic and epigenetic level through the function of histone lysine demethylases (KDMs) and ten-eleven translocation (TET) enzymes; ordinarily TETs hydroxylate 5-methylcytosines to prime them for demethylation. However, in the absence of alpha-ketoglutarate this cannot be done and there is hence hypermethylation of the cell's DNA, serving to promote epithelial-mesenchymal transition (EMT) and inhibit cellular differentiation. A similar phenomenon is observed for the Jumonji C family of KDMs which require a hydroxylation to perform demethylation at the epsilon-amino methyl group. Additionally, the inability of prolyl hydroxylases to catalyze reactions results in stabilization of hypoxia-inducible factor alpha, which is necessary to promote degradation of the latter (as under conditions of low oxygen there will not be adequate substrate for hydroxylation). This results in a pseudohypoxic phenotype in the cancer cell that promotes angiogenesis, metabolic reprogramming, cell growth, and migration.\nRegulation.\nAllosteric regulation by metabolites. The regulation of the citric acid cycle is largely determined by product inhibition and substrate availability. If the cycle were permitted to run unchecked, large amounts of metabolic energy could be wasted in overproduction of reduced coenzyme such as NADH and ATP. The major eventual substrate of the cycle is ADP which gets converted to ATP. A reduced amount of ADP causes accumulation of precursor NADH which in turn can inhibit a number of enzymes. NADH, a product of all dehydrogenases in the citric acid cycle with the exception of succinate dehydrogenase, inhibits pyruvate dehydrogenase, isocitrate dehydrogenase, \u03b1-ketoglutarate dehydrogenase, and also citrate synthase. Acetyl-coA inhibits pyruvate dehydrogenase, while succinyl-CoA inhibits alpha-ketoglutarate dehydrogenase and citrate synthase. When tested in vitro with TCA enzymes, ATP inhibits citrate synthase and \u03b1-ketoglutarate dehydrogenase; however, ATP levels do not change more than 10% in vivo between rest and vigorous exercise. There is no known allosteric mechanism that can account for large changes in reaction rate from an allosteric effector whose concentration changes less than 10%.\nCitrate is used for feedback inhibition, as it inhibits phosphofructokinase, an enzyme involved in glycolysis that catalyses formation of fructose 1,6-bisphosphate, a precursor of pyruvate. This prevents a constant high rate of flux when there is an accumulation of citrate and a decrease in substrate for the enzyme.\nRegulation by calcium. Calcium is also used as a regulator in the citric acid cycle. Calcium levels in the mitochondrial matrix can reach up to the tens of micromolar levels during cellular activation. It activates pyruvate dehydrogenase phosphatase which in turn activates the pyruvate dehydrogenase complex. Calcium also activates isocitrate dehydrogenase and \u03b1-ketoglutarate dehydrogenase. This increases the reaction rate of many of the steps in the cycle, and therefore increases flux throughout the pathway.\nTranscriptional regulation. Recent work has demonstrated an important link between intermediates of the citric acid cycle and the regulation of hypoxia-inducible factors (HIF). HIF plays a role in the regulation of oxygen homeostasis, and is a transcription factor that targets angiogenesis, vascular remodeling, glucose utilization, iron transport and apoptosis. HIF is synthesized constitutively, and hydroxylation of at least one of two critical proline residues mediates their interaction with the von Hippel Lindau E3 ubiquitin ligase complex, which targets them for rapid degradation. This reaction is catalysed by prolyl 4-hydroxylases. Fumarate and succinate have been identified as potent inhibitors of prolyl hydroxylases, thus leading to the stabilisation of HIF.\nMajor metabolic pathways converging on the citric acid cycle.\nSeveral catabolic pathways converge on the citric acid cycle. Most of these reactions add intermediates to the citric acid cycle, and are therefore known as anaplerotic reactions, from the Greek meaning to \"fill up\". These increase the amount of acetyl CoA that the cycle is able to carry, increasing the mitochondrion's capability to carry out respiration if this is otherwise a limiting factor. Processes that remove intermediates from the cycle are termed \"cataplerotic\" reactions.\nIn this section and in the next, the citric acid cycle intermediates are indicated in \"italics\" to distinguish them from other substrates and end-products.\nPyruvate molecules produced by glycolysis are actively transported across the inner mitochondrial membrane, and into the matrix. Here they can be oxidized and combined with coenzyme A to form CO2, \"acetyl-CoA\", and NADH, as in the normal cycle.\nHowever, it is also possible for pyruvate to be carboxylated by pyruvate carboxylase to form \"oxaloacetate\". This latter reaction \"fills up\" the amount of \"oxaloacetate\" in the citric acid cycle, and is therefore an anaplerotic reaction, increasing the cycle's capacity to metabolize \"acetyl-CoA\" when the tissue's energy needs (e.g. in muscle) are suddenly increased by activity.\nIn the citric acid cycle all the intermediates (e.g. \"citrate\", \"iso-citrate\", \"alpha-ketoglutarate\", \"succinate\", \"fumarate\", \"malate\", and \"oxaloacetate\") are regenerated during each turn of the cycle. Adding more of any of these intermediates to the mitochondrion therefore means that that additional amount is retained within the cycle, increasing all the other intermediates as one is converted into the other. Hence the addition of any one of them to the cycle has an anaplerotic effect, and its removal has a cataplerotic effect. These anaplerotic and cataplerotic reactions will, during the course of the cycle, increase or decrease the amount of \"oxaloacetate\" available to combine with \"acetyl-CoA\" to form \"citric acid\". This in turn increases or decreases the rate of ATP production by the mitochondrion, and thus the availability of ATP to the cell.\n\"Acetyl-CoA\", on the other hand, derived from pyruvate oxidation, or from the beta-oxidation of fatty acids, is the only fuel to enter the citric acid cycle. With each turn of the cycle one molecule of \"acetyl-CoA\" is consumed for every molecule of \"oxaloacetate\" present in the mitochondrial matrix, and is never regenerated. It is the oxidation of the acetate portion of \"acetyl-CoA\" that produces CO2 and water, with the energy of O2 thus released captured in the form of ATP. The three steps of beta-oxidation resemble the steps that occur in the production of oxaloacetate from succinate in the TCA cycle. Acyl-CoA is oxidized to trans-Enoyl-CoA while FAD is reduced to FADH2, which is similar to the oxidation of succinate to fumarate. Following, trans-Enoyl-CoA is hydrated across the double bond to beta-hydroxyacyl-CoA, just like fumarate is hydrated to malate. Lastly, beta-hydroxyacyl-CoA is oxidized to beta-ketoacyl-CoA while NAD+ is reduced to NADH, which follows the same process as the oxidation of malate to oxaloacetate.\nIn the liver, the carboxylation of cytosolic pyruvate into intra-mitochondrial \"oxaloacetate\" is an early step in the gluconeogenic pathway which converts lactate and de-aminated alanine into glucose, under the influence of high levels of glucagon and/or epinephrine in the blood. Here the addition of \"oxaloacetate\" to the mitochondrion does not have a net anaplerotic effect, as another citric acid cycle intermediate (\"malate\") is immediately removed from the mitochondrion to be converted into cytosolic oxaloacetate, which is ultimately converted into glucose, in a process that is almost the reverse of glycolysis.\nIn protein catabolism, proteins are broken down by proteases into their constituent amino acids. Their carbon skeletons (i.e. the de-aminated amino acids) may either enter the citric acid cycle as intermediates (e.g. \"alpha-ketoglutarate\" derived from glutamate or glutamine), having an anaplerotic effect on the cycle, or, in the case of leucine, isoleucine, lysine, phenylalanine, tryptophan, and tyrosine, they are converted into \"acetyl-CoA\" which can be burned to CO2 and water, or used to form ketone bodies, which too can only be burned in tissues other than the liver where they are formed, or excreted via the urine or breath. These latter amino acids are therefore termed \"ketogenic\" amino acids, whereas those that enter the citric acid cycle as intermediates can only be cataplerotically removed by entering the gluconeogenic pathway via \"malate\" which is transported out of the mitochondrion to be converted into cytosolic oxaloacetate and ultimately into glucose. These are the so-called \"glucogenic\" amino acids. De-aminated alanine, cysteine, glycine, serine, and threonine are converted to pyruvate and can consequently either enter the citric acid cycle as \"oxaloacetate\" (an anaplerotic reaction) or as \"acetyl-CoA\" to be disposed of as CO2 and water.\nIn fat catabolism, triglycerides are hydrolyzed to break them into fatty acids and glycerol. In the liver the glycerol can be converted into glucose via dihydroxyacetone phosphate and glyceraldehyde-3-phosphate by way of gluconeogenesis. In many tissues, especially heart and skeletal muscle tissue, fatty acids are broken down through a process known as beta oxidation, which results in the production of mitochondrial \"acetyl-CoA\", which can be used in the citric acid cycle. Beta oxidation of fatty acids with an odd number of methylene bridges produces propionyl-CoA, which is then converted into \"succinyl-CoA\" and fed into the citric acid cycle as an anaplerotic intermediate.\nThe total energy gained from the complete breakdown of one (six-carbon) molecule of glucose by glycolysis, the formation of 2 \"acetyl-CoA\" molecules, their catabolism in the citric acid cycle, and oxidative phosphorylation equals about 30 ATP molecules, in eukaryotes. The number of ATP molecules derived from the beta oxidation of a 6 carbon segment of a fatty acid chain, and the subsequent oxidation of the resulting 3 molecules of \"acetyl-CoA\" is 40.\nCitric acid cycle intermediates serve as substrates for biosynthetic processes.\nIn this subheading, as in the previous one, the TCA intermediates are identified by \"italics\".\nSeveral of the citric acid cycle intermediates are used for the synthesis of important compounds, which will have significant cataplerotic effects on the cycle.\n\"Acetyl-CoA\" cannot be transported out of the mitochondrion. To obtain cytosolic acetyl-CoA, \"citrate\" is removed from the citric acid cycle and carried across the inner mitochondrial membrane into the cytosol. There it is cleaved by ATP citrate lyase into acetyl-CoA and oxaloacetate. The oxaloacetate is returned to mitochondrion as \"malate\" (and then converted back into \"oxaloacetate\" to transfer more \"acetyl-CoA\" out of the mitochondrion). The cytosolic acetyl-CoA is used for fatty acid synthesis and the production of cholesterol. Cholesterol can, in turn, be used to synthesize the steroid hormones, bile salts, and vitamin D.\nThe carbon skeletons of many non-essential amino acids are made from citric acid cycle intermediates. To turn them into amino acids the alpha keto-acids formed from the citric acid cycle intermediates have to acquire their amino groups from glutamate in a transamination reaction, in which pyridoxal phosphate is a cofactor. In this reaction the glutamate is converted into \"alpha-ketoglutarate\", which is a citric acid cycle intermediate. The intermediates that can provide the carbon skeletons for amino acid synthesis are \"oxaloacetate\" which forms aspartate and asparagine; and \"alpha-ketoglutarate\" which forms glutamine, proline, and arginine.\nOf these amino acids, aspartate and glutamine are used, together with carbon and nitrogen atoms from other sources, to form the purines that are used as the bases in DNA and RNA, as well as in ATP, AMP, GTP, NAD, FAD and CoA.\nThe pyrimidines are partly assembled from aspartate (derived from \"oxaloacetate\"). The pyrimidines, thymine, cytosine and uracil, form the complementary bases to the purine bases in DNA and RNA, and are also components of CTP, UMP, UDP and UTP.\nThe majority of the carbon atoms in the porphyrins come from the citric acid cycle intermediate, \"succinyl-CoA\". These molecules are an important component of the hemoproteins, such as hemoglobin, myoglobin and various cytochromes.\nDuring gluconeogenesis mitochondrial \"oxaloacetate\" is reduced to \"malate\" which is then transported out of the mitochondrion, to be oxidized back to oxaloacetate in the cytosol. Cytosolic oxaloacetate is then decarboxylated to phosphoenolpyruvate by phosphoenolpyruvate carboxykinase, which is the rate limiting step in the conversion of nearly all the gluconeogenic precursors (such as the glucogenic amino acids and lactate) into glucose by the liver and kidney.\nBecause the citric acid cycle is involved in both catabolic and anabolic processes, it is known as an amphibolic pathway.\nEvan M.W.Duo\nGlucose feeds the TCA cycle via circulating lactate.\nThe metabolic role of lactate is well recognized as a fuel for tissues and tumors. In the classical Cori cycle, muscles produce lactate which is then taken up by the liver for gluconeogenesis. New studies suggest that lactate can be used as a source of carbon for the TCA cycle.\nEvolution.\nIt is believed that components of the citric acid cycle were derived from anaerobic bacteria, and that the TCA cycle itself may have evolved more than once. Theoretically, several alternatives to the TCA cycle exist; however, the TCA cycle appears to be the most efficient. If several TCA alternatives had evolved independently, they all appear to have converged to the TCA cycle."}
{"id": "6821", "revid": "40025788", "url": "https://en.wikipedia.org/wiki?curid=6821", "title": "Military engineering vehicle", "text": "A military engineering vehicle is a vehicle built for the construction work or for the transportation of combat engineers on the battlefield. These vehicles may be modified civilian equipment (such as the armoured bulldozers that many nations field) or purpose-built military vehicles (such as the AVRE). The first appearance of such vehicles coincided with the appearance of the first tanks, these vehicles were modified Mark V tanks for bridging and mine clearance. Modern \"military engineering vehicles\" are expected to fulfill numerous roles, as such they undertake numerous forms, examples of roles include; bulldozers, cranes, graders, excavators, dump trucks, breaching vehicles, bridging vehicles, military ferries, amphibious crossing vehicles, and Combat engineer section carriers. \nHistory.\nWorld War One.\nA Heavy RE tank was developed shortly after World War I by Major Giffard LeQuesne Martel RE. This vehicle was a modified Mark V tank. Two support functions for these Engineer Tanks were developed: bridging and mine clearance. The bridging component involved an assault bridge, designed by Major Charles Inglis RE, called the Canal Lock Bridge, which had sufficient length to span a canal lock. Major Martel mated the bridge with the tank and used hydraulic power generated by the tank's engine to maneuver the bridge into place. For mine clearance the tanks were equipped with 2 ton rollers.\n1918-1939.\nBetween the wars various experimental bridging tanks were used to test a series of methods for bridging obstacles and developed by the Experimental Bridging Establishment (EBE). Captain SG Galpin RE conceived a prototype Light Tank Mk V to test the Scissors Assault Bridge. This concept was realised by Captain SA Stewart RE with significant input from a Mr DM Delany, a scientific civil servant in the employ of the EBE. MB Wild &amp; Co, Birmingham, also developed a bridge that could span gaps of 26 feet using a complex system of steel wire ropes and a traveling jib, where the front section was projected and then attached to the rear section prior to launching the bridge. This system had to be abandoned due to lack of success in getting it to work, however the idea was later used successfully on the Beaver Bridge Laying Tank.\nEarly World War Two.\nOnce World War Two had begun, the development of armoured vehicles for use by engineers in the field was accelerated under Delaney's direction. The EBE rapidly developed an assault bridge carried on a modified Covenanter tank capable of deploying a 24-ton tracked load capacity bridge (Class 24) that could span gaps of 30 feet. However, it did not see service in the British armed forces, and all vehicles were passed onto Allied forces such as Australia and Czechoslovakia.\nA Class 30 design superseded the Class 24 with no real re-design, simply the substitution of the Covenanter tank with a suitably modified Valentine.\nAs tanks in the war got heavier, a new bridge capable of supporting them was developed. A heavily modified Churchill used a single-piece bridge mounted on a turret-less tank and was able to lay the bridge in 90 seconds; this bridge was able to carry a 60-ton tracked or 40-ton wheeled load.\nLate World War 2: Hobart's 'Funnies' and D-Day.\nHobart's Funnies were a number of unusually modified tanks operated during the Second World War by the 79th Armoured Division of the British Army or by specialists from the Royal Engineers. They were designed in light of problems that more standard tanks experienced during the amphibious Dieppe Raid, so that the new models would be able to overcome the problems of the planned Invasion of Normandy. These tanks played a major part on the Commonwealth beaches during the landings. They were forerunners of the modern combat engineering vehicle and were named after their commander, Major General Percy Hobart.\nHobart's unusual, specialized tanks, nicknamed \"funnies\", included:\nIn U.S. Forces, Sherman tanks were also fitted with dozer blades, and anti-mine roller devices were developed, enabling engineering operations and providing similar capabilities.\nPost war.\nPost war, the value of the combat engineering vehicles had been proven, and armoured multi-role engineering vehicles have been added to the majority of armoured forces.\nTypes.\nCivilian and militarized heavy equipment.\nMilitary engineering can employ a wide variety of heavy equipment in the same or similar ways to how this equipment is used outside the military. Bulldozers, cranes, graders, excavators, dump trucks, loaders, and backhoes all see extensive use by military engineers.\nMilitary engineers may also use civilian heavy equipment which was modified for military applications. Typically, this involves adding armour for protection from battlefield hazards such as artillery, unexploded ordnance, mines, and small arms fire. Often this protection is provided by armour plates and steel jackets. Some examples of armoured civilian heavy equipment are the IDF Caterpillar D9, American D7 TPK, Canadian D6 armoured bulldozer, cranes, graders, excavators, and M35 2-1/2 ton cargo truck.\nMilitarized heavy equipment may also take on the form of traditional civilian equipment designed and built to unique military specifications. These vehicles typically sacrifice some depth of capability from civilian models in order to gain greater speed and independence from prime movers. Examples of this type of vehicle include high speed backhoes such as the Australian Army's High Mobility Engineering Vehicle (HMEV) from Thales or the Canadian Army's Multi-Purpose Engineer Vehicle (MPEV) from Arva.\n\"The main article for civilian heavy equipment is:\" Heavy equipment (construction)\nArmoured engineering vehicle.\nTypically based on the platform of a main battle tank, these vehicles go by different names depending upon the country of use or manufacture. In the US the term \"combat engineer vehicle (CEV)\" is used, in the UK the terms \"Armoured Vehicle Royal Engineers (AVRE)\" or Armoured Repair and Recovery Vehicle (ARRV) are used, while in Canada and other commonwealth nations the term \"armoured engineer vehicle (AEV)\" is used. There is no set template for what such a vehicle will look like, yet likely features include a large dozer blade or mine ploughs, a large caliber demolition cannon, augers, winches, excavator arms and cranes or lifting booms.\nThese vehicles are designed to directly conduct obstacle breaching operations and to conduct other earth-moving and engineering work on the battlefield. Good examples of this type of vehicle include the UK Trojan AVRE, the Russian IMR, and the US M728 Combat Engineer Vehicle. Although the term \"armoured engineer vehicle\" is used specifically to describe these multi-purpose tank based engineering vehicles, that term is also used more generically in British and Commonwealth militaries to describe all heavy tank based engineering vehicles used in the support of mechanized forces. Thus, \"armoured engineer vehicle\" used generically would refer to AEV, AVLB, Assault Breachers, and so on.\nArmoured earth mover.\nLighter and less multi-functional than the CEVs or AEVs described above, these vehicles are designed to conduct earth-moving work on the battlefield. These vehicles have greater high speed mobility than traditional heavy equipment and are protected against the effects of blast and fragmentation. Good examples are the American M9 ACE and the UK FV180 Combat Engineer Tractor.\nBreaching vehicle.\nThese vehicles are equipped with mechanical or other means for the breaching of man made obstacles. Common types of breaching vehicles include mechanical flails, mine plough vehicles, and mine roller vehicles. In some cases, these vehicles will also mount Mine-clearing line charges. Breaching vehicles may be either converted armoured fighting vehicles or purpose built vehicles. In larger militaries, converted AFV are likely to be used as \"assault breachers\" while the breached obstacle is still covered by enemy observation and fire, and then purpose built breaching vehicles will create additional lanes for following forces.\nGood examples of breaching vehicles include the USMC M1 Assault Breacher Vehicle, the UK Aardvark JSFU, and the Singaporean Trailblazer.\nBridging vehicles.\nSeveral types of military bridging vehicles have been developed. An armoured vehicle-launched bridge (AVLB) is typically a modified tank hull converted to carry a bridge into battle in order to support crossing ditches, small waterways, or other gap obstacles.\nAnother type of bridging vehicle is the truck launched bridge. The Soviet TMM bridging truck could carry and launch a 10-meter bridge that could be daisy-chained with other TMM bridges to cross larger obstacles. More recent developments have seen the conversion of AVLB and truck launched bridge with launching systems that can be mounted on either tank or truck for bridges that are capable of supporting heavy main battle tanks.\nEarlier examples of bridging vehicles include a type in which a converted tank hull is the bridge. On these vehicles, the hull deck comprises the main portion of the tread way while ramps extend from the front and rear of the vehicle to allow other vehicles to climb over the bridging vehicle and cross obstacles. An example of this type of armoured bridging vehicle was the Churchill Ark used in the Second World War.\nCombat engineer section carriers.\nAnother type of CEVs are armoured fighting vehicles which are used to transport sappers (combat engineers) and can be fitted with a bulldozer's blade and other mine-breaching devices. They are often used as APCs because of their carrying ability and heavy protection. They are usually armed with machine guns and grenade launchers and usually tracked to provide enough tractive force to push blades and rakes. Some examples are the U.S. M113 APC, IDF Puma, Nagmachon, Husky, and U.S. M1132 ESV (a Stryker variant).\nMilitary ferries and amphibious crossing vehicles.\nOne of the major tasks of military engineering is crossing major rivers. Several military engineering vehicles have been developed in various nations to achieve this task. One of the more common types is the amphibious ferry such as the M3 Amphibious Rig. These vehicles are self-propelled on land, they can transform into raft type ferries when in the water, and often multiple vehicles can connect to form larger rafts or floating bridges. Other types of military ferries, such as the Soviet \"Plavayushij Transportyor - Srednyj\", are able to load while still on land and transport other vehicles cross country and over water.\nIn addition to amphibious crossing vehicles, military engineers may also employ several types of boats. Military assault boats are small boats propelled by oars or an outboard motor and used to ferry dismounted infantry across water.\nTank-based combat engineering vehicles.\nMost CEVs are armoured fighting vehicles that may be based on a tank chassis and have special attachments in order to breach obstacles. Such attachments may include dozer blades, mine rollers, cranes etc. An example of an engineering vehicle of this kind is a bridgelaying tank, which replaces the turret with a segmented hydraulic bridge. The Hobart's Funnies of the Second World War were a wide variety of armoured vehicles for combat engineering tasks. They were allocated to the initial beachhead assaults by the British and Commonwealth forces in the D-Day landings\nChurchill tank.\nThe British Churchill tank because of its good cross-country performance and capacious interior with side hatches became the most adapted with modifications, the base unit being the AVRE carrying a large demolition gun."}
{"id": "6822", "revid": "22150306", "url": "https://en.wikipedia.org/wiki?curid=6822", "title": "Catalonia", "text": "Catalonia (; ; Aranese Occitan: \"Catalonha\" ; ) is an autonomous community in the northeastern corner of Spain, designated as a \"nationality\" by its Statute of Autonomy.\nCatalonia consists of four provinces: Barcelona, Girona, Lleida, and Tarragona. The capital and largest city, Barcelona is the second-most populated municipality in Spain and the fifth-most populous urban area in the European Union. It comprises most of the former Principality of Catalonia (with the remainder Roussillon now part of France's Pyr\u00e9n\u00e9es-Orientales). It is bordered by France (Occitanie) and Andorra to the north, the Mediterranean Sea to the east, and the Spanish autonomous communities of Aragon to the west and Valencia to the south. The official languages are Catalan, Spanish, and the Aranese dialect of Occitan.\nIn the late 8th century, various counties across the eastern Pyrenees were established by the Frankish kingdom as a defensive barrier against Muslim invasions. In the 10th century the County of Barcelona became progressively independent. In 1137, Barcelona and the Kingdom of Aragon were united by marriage under the Crown of Aragon. Within the Crown, the Catalan counties adopted a common polity, the Principality of Catalonia, developing its own institutional system, such as Courts, Generalitat and constitutions, becoming the base for the Crown's Mediterranean trade and expansionism. In the later Middle Ages, Catalan literature flourished. In 1469, the king of Aragon and the queen of Castile were married and ruled their realms together, retaining all of their distinct institutions and legislation.\nDuring the Franco-Spanish War (1635\u20131659), Catalonia revolted (1640\u20131652) against a large and burdensome presence of the royal army, being briefly proclaimed a republic under French protection, until it was largely reconquered by the Spanish army. By the Treaty of the Pyrenees (1659), the northern parts of Catalonia, mostly the Roussillon, were ceded to France. During the War of the Spanish Succession (1701\u20131714), the Crown of Aragon sided against the Bourbon Philip V of Spain; following Catalan defeat on 11 September 1714, Philip V imposed a unifying administration across Spain, enacting the Nueva Planta decrees which, like in the other realms of the Crown of Aragon, suppressed the Catalan institutions and rights. This led to the eclipse of Catalan as a language of government and literature, replaced by Spanish. Throughout the 18th century, Catalonia experienced economic growth.\nIn the 19th century, Catalonia was severely affected by the Napoleonic and Carlist Wars. In the second third of the century, it experienced industrialisation. As wealth from the industrial expansion grew, it saw a cultural renaissance coupled with incipient nationalism while several workers movements appeared. With the establishment of the Second Spanish Republic (1931\u20131939), the Generalitat was restored as a Catalan autonomous government. After the Spanish Civil War, the Francoist dictatorship enacted repressive measures, abolishing Catalan self-government and banning the official use of the Catalan language. After a period of autarky, from the late 1950s through to the 1970s Catalonia saw rapid economic growth, drawing many workers from across Spain, making Barcelona one of Europe's largest industrial metropolitan areas and turning Catalonia into a major tourist destination. During the Spanish transition to democracy (1975\u20131982), Catalonia regained self-government and is now one of the most economically dynamic communities of Spain. \nSince the 2010s there has been growing support for Catalan independence. On 27 October 2017, the Catalan Parliament unilaterally declared independence following a disputed referendum. The Spanish Senate voted in favour of enforcing direct rule by removing the Catalan government and calling a snap regional election. The Spanish Supreme Court imprisoned seven former ministers of the Catalan government on charges of rebellion and misuse of public funds, while several others\u2014including then-President, Carles Puigdemont\u2014fled to other European countries.\nEtymology and pronunciation.\nThe name Catalonia \u2014 ; , spelled \"Cathalonia\" \u2014 began to be used for the homeland of the Catalans (\"Cathalanenses\") in the late 11th century and was probably used before as a territorial reference to the group of counties that comprised part of the March of Gothia and the March of Hispania under the control of the Count of Barcelona and his relatives. The origin of the name \"Catalunya\" is subject to diverse interpretations because of a lack of evidence.\nOne theory suggests that \"Catalunya\" derives from the name \"Gothia\" (or \"Gauthia\") \"Launia\" (\"Land of the Goths\"), since the origins of the Catalan counts, lords and people were found in the March of Gothia, known as \"Gothia\", whence \"Gothland\" &gt; &gt; &gt; &gt; \"Catalonia\" theoretically derived. During the Middle Ages, Byzantine chroniclers claimed that \"Catalania\" derives from the local medley of Goths with Alans, initially constituting a \"Goth-Alania\".\nOther less plausible or recent theories suggest:\nIn English, \"Catalonia\" is pronounced . The native name, \"Catalunya\", is pronounced in Central Catalan, the most widely spoken variety, whose pronunciation is considered standard. The Spanish name is \"Catalu\u00f1a\" (), and the Aranese name is \"Catalonha\" ().\nHistory.\nPrehistory.\nThe first known human settlements in what is now Catalonia were at the beginning of the Middle Paleolithic. The oldest known trace of human occupation is a mandible found in Banyoles, described by some sources as pre-Neanderthal some 200,000 years old; other sources suggest it to be only about one third that old. From the next prehistoric era, the Epipalaeolithic or Mesolithic, important remains survive, the greater part dated between 8000 and 5000\u00a0BC, such as those of Sant Gregori (Falset) and el Filador (Margalef de Montsant). The most important sites from these eras, all excavated in the region of Moian\u00e8s, are the Balma del Gai (Epipaleolithic) and the Balma de l'Espluga (late Epipaleolithic and Early Neolithic).\nThe Neolithic era began in Catalonia around 5000 BC, although the population was slower to develop fixed settlements than in other places, thanks to the abundance of woods, which allowed the continuation of a fundamentally hunter-gatherer culture. An example of such settlements would be La Draga, an \"early Neolithic village which dates from the end of the 6th millennium BC.\"\nThe Chalcolithic period developed in Catalonia between 2500 and 1800 BC, with the beginning of the construction of copper objects. The Bronze Age occurred between 1800 and 700 BC. There are few remnants of this era, but there were some known settlements in the low Segre zone. The Bronze Age coincided with the arrival of the Indo-Europeans through the Urnfield Culture, whose successive waves of migration began around 1200 BC, and they were responsible for the creation of the first proto-urban settlements. Around the middle of the 7th century BC, the Iron Age arrived in Catalonia.\nPre-Roman and Roman period.\nIn pre-Roman times, the area that is now called Catalonia in the north-east of Iberian Peninsula \u2013 like the rest of the Mediterranean side of the peninsula \u2013 was populated by the Iberians. The Iberians of this area \u2013 the Ilergetes, Indigetes and Lacetani (Cerretains) \u2013 also maintained relations with the peoples of the Mediterranean. Some urban agglomerations became relevant, including Ilerda (Lleida) inland, Hibera (perhaps Amposta or Tortosa) or Indika (Ullastret). Coastal trading colonies were established by the ancient Greeks, who settled around the Gulf of Roses, in Emporion (Emp\u00faries) and Roses in the 8th century BC. The Carthaginians briefly ruled the territory in the course of the Second Punic War and traded with the surrounding Iberian population.\nAfter the Carthaginian defeat by the Roman Republic, the north-east of Iberia became the first to come under Roman rule and became part of Hispania, the westernmost part of the Roman Empire. Tarraco (modern Tarragona) was one of the most important Roman cities in Hispania and the capital of the province of Tarraconensis. Other important cities of the Roman period are Ilerda (Lleida), Dertosa (Tortosa), Gerunda (Girona) as well as the ports of Empuri\u00e6 (former Emporion) and Barcino (Barcelona). As for the rest of Hispania, Latin law was granted to all cities under the reign of Vespasian (69-79 AD), while Roman citizenship was granted to all free men of the empire by the Edict of Caracalla in 212 AD (Tarraco, the capital, was already a colony of Roman law since 45 BC). It was a rich agricultural province (olive oil, vine, wheat), and the first centuries of the Empire saw the construction of roads (the most important being the Via Augusta, parallel to Mediterranean coastline) and infrastructure like aqueducts.\nConversion to Christianity, attested in the 3rd century, was completed in urban areas in the 4th century. Although Hispania remained under Roman rule and did not fall under the rule of Vandals, Swabians and Alans in the 5th century, the main cities suffered frequent sacking and some deurbanization.\nMiddle Ages.\nAfter the fall of the Western Roman Empire, the area was conquered by the Visigoths and was ruled as part of the Visigothic Kingdom for almost two and a half centuries. In 718, it came under Muslim control and became part of Al-Andalus, a province of the Umayyad Caliphate. From the conquest of Roussillon in 760, to the conquest of Barcelona in 801, the Frankish empire took control of the area between Septimania and the Llobregat river from the Muslims and created heavily militarised, self-governing counties. These counties formed part of the historiographically known as the Gothic and Hispanic marches, a buffer zone in the south of the Frankish empire in the former province of Septimania and in the northeast of the Iberian Peninsula, to act as a defensive barrier for the Frankish empire against further Muslim invasions from Al-Andalus.\nThese counties came under the rule of the counts of Barcelona, who were Frankish vassals nominated by the emperor of the Franks, to whom they were feudatories (801\u2013988). The earliest known use of the name \"Catalonia\" for these counties dates to 1117. At the end of the 9th century, the Count of Barcelona Wilfred the Hairy made his title hereditary and founded the dynasty of the House of Barcelona, which ruled Catalonia until 1410.\nIn 988 Borrell II, Count of Barcelona, did not recognise the new French king Hugh Capet as his king, evidencing the loss of dependency from Frankish rule and confirming his successors (from Ramon Borrell I to Ramon Berenguer IV) as independent of the Capetian crown whom they regarded as usurpers of the Carolingian Frankish realm. At the beginning of eleventh century the Catalan counties suffered an important process of feudalisation, partially controlled by the church's sponsored Peace and Truce Assemblies and by the negotiation skills of the Count of Barcelona Ramon Berenguer I, which began the codification of feudal law in the written Usages of Barcelona, becoming the basis of the Catalan law. In 1137, Ramon Berenguer IV, Count of Barcelona decided to accept King Ramiro II of Aragon's proposal to marry Queen Petronila, establishing the dynastic union of the County of Barcelona with the Kingdom of Aragon, creating the Crown of Aragon and making the Catalan counties that were united under the county of Barcelona into a principality of the Aragonese Crown.\nIn 1258, by means of the Treaty of Corbeil, James I of Aragon King of Aragon and Count of Barcelona, king of Mallorca and of Valencia, renounced his family rights and dominions in Occitania and recognised the king of France as heir of the Carolingian Dynasty. The king of France, Louis IX, formally relinquished his claims of feudal lordship over all the Catalan counties, except the County of Foix, despite the opposition of the king of Aragon and count of Barcelona. This treaty confirmed, from French point of view, the independence of the Catalan counties established and exercised during the previous three centuries, but also meant the irremediable separation between the geographical areas of Catalonia and Languedoc.\nAs a coastal territory, Catalonia became the base of the Aragonese Crown's maritime forces, which spread the power of the Aragonese Crown in the Mediterranean, and made Barcelona into a powerful and wealthy city. In the period of 1164\u20131410, new territories, the Kingdom of Valencia, the Kingdom of Majorca, Sardinia, the Kingdom of Sicily, Corsica, and, briefly, the Duchies of Athens and Neopatras, were incorporated into the dynastic domains of the House of Aragon. The expansion was accompanied by a great development of the Catalan trade, creating an extensive trade network across the Mediterranean which competed with those of the maritime republics of Genoa and Venice.\nAt the same time, the Principality of Catalonia developed a complex institutional and political system based in the concept of a pact between the estates of the realm and the king. Laws had to be approved in the General Court of Catalonia, one of the first parliamentary bodies of Europe that banned the royal power to create legislation unilaterally (since 1283). The Courts were composed of the three Estates, were presided over by the king of Aragon, and approved the constitutions, which created a compilation of rights for the citizenship of the Principality. In order to collect general taxes, the Courts of 1359 established a permanent representative of deputies position, called the Deputation of the General (and later usually known as Generalitat), which gained political power over the next centuries.\nThe domains of the Aragonese Crown were severely affected by the Black Death pandemic and by later outbreaks of the plague. Between 1347 and 1497 Catalonia lost 37 percent of its population. In 1410, King Martin I died without surviving descendants. Under the Compromise of Caspe, Ferdinand from the Castilian House of Trast\u00e1mara received the Crown of Aragon as Ferdinand I of Aragon. During the reign of his son, John II, social and political tensions caused the Catalan Civil War (1462\u20131472).\nModern era.\nFerdinand II of Aragon, the grandson of Ferdinand I, and Queen Isabella I of Castile were married in 1469, later taking the title the Catholic Monarchs; subsequently, this event was seen by historiographers as the dawn of a unified Spain. At this time, though united by marriage, the Crowns of Castile and Aragon maintained distinct territories, each keeping its own traditional institutions, parliaments, laws and currency. Castile commissioned expeditions to the Americas and benefited from the riches acquired in the Spanish colonisation of the Americas, but, in time, also carried the main burden of military expenses of the united Spanish kingdoms. After Isabella's death, Ferdinand II personally ruled both kingdoms.\nBy virtue of descent from his maternal grandparents, Ferdinand II of Aragon and Isabella I of Castile, in 1516 Charles I of Spain became the first king to rule the Crowns of Castile and Aragon simultaneously by his own right. Following the death of his paternal (House of Habsburg) grandfather, Maximilian I, Holy Roman Emperor, he was also elected Charles V, Holy Roman Emperor, in 1519.\nOver the next few centuries, the Principality of Catalonia was generally on the losing side of a series of wars that led steadily to an increased centralization of power in Spain. Despite this fact, between the 16th and 18th centuries, the participation of the political community in the local and the general Catalan government grew, while the kings remained absent and its constitutional system continued to consolidate. Tensions between Catalan institutions and the Monarchy began to arise. The large and burdensome presence of the Spanish royal army in the Principality due to the Franco-Spanish War led to an uprising of peasants, provoking the Reapers' War (1640\u20131652), which saw Catalonia rebel (briefly as a republic led by the chairman of the Generalitat, Pau Claris) with French help against the Spanish Crown for overstepping Catalonia's rights during the Thirty Years' War. Within a brief period France took full control of Catalonia. Most of Catalonia was reconquered by the Spanish Monarchy but Catalan rights were recognised. Roussillon was lost to France by the Treaty of the Pyrenees (1659).\nThe most significant conflict concerning the governing monarchy was the War of the Spanish Succession, which began when the childless Charles II of Spain, the last Spanish Habsburg, died without an heir in 1700. Charles II had chosen Philip V of Spain from the French House of Bourbon. Catalonia, like other territories that formed the Crown of Aragon, rose up in support of the Austrian Habsburg pretender Charles VI, Holy Roman Emperor, in his claim for the Spanish throne as Charles III of Spain. The fight between the houses of Bourbon and Habsburg for the Spanish Crown split Spain and Europe.\nThe fall of Barcelona on 11 September 1714 to the Bourbon king Philip V militarily ended the Habsburg claim to the Spanish Crown, which became legal fact in the Treaty of Utrecht. Philip felt that he had been betrayed by the Catalan Courts, as it had initially sworn its loyalty to him when he had presided over it in 1701. In retaliation for the betrayal, and inspired by the French absolutist style of government, the first Bourbon king introduced the Nueva Planta decrees, that incorporated the lands of the Crown of Aragon, including the Principality of Catalonia, as provinces under the Crown of Castile in 1716, terminating their separate institutions, laws and rights, as well as their politics, within a united kingdom of Spain. From the second third of 18th century onwards Catalonia carried out a successful process of proto-industrialization, reinforced in the late quarter of the century when Castile's trade monopoly with American colonies ended.\nIndustrialisation, Republic and autonomy.\nAt the beginning of the nineteenth century, Catalonia was severely affected by the Napoleonic Wars. In 1808, it was occupied by French troops; the resistance against the occupation eventually developed into the Peninsular War. The rejection to French dominion was institutionalized with the creation of \"juntas\" (councils) who, remaining loyal to the Bourbons, exercised the sovereignty and representation of the territory due to the disappearance of the old institutions. Napoleon took direct control of Catalonia to establish order, creating the Government of Catalonia under the rule of Marshall Augereau, and making Catalan briefly an official language again. Between 1812 and 1814, Catalonia was annexed to France and organized as four d\u00e9partements. The French troops evacuated Catalan territory at the end of 1814. After the Bourbon restoration in Spain and the death of the absolutist king Ferdinand VII, Carlist Wars erupted against the new born liberal state of Isabella II. Catalonia was divided, the coast and most industrialized areas support liberalism, while many inland areas were in the hands of Carlists, as the last ones proposed to reestablish the institutional systems suppressed in the Nueva Planta decrees in all the ancient realms of the Crown of Aragon.\nIn the second third of the 19th century, it became an industrial center. This process was boosted by, amongst other things, national (although the policy of the Spanish government during those times changed many times between free trade and protectionism) and the conditions of proto-industrialization of the prior two centuries of the Catalan urban areas and its countryside. Along the century, textile industry flourished in urban areas and in the countryside, usually in the form of company towns. To this day it remains one of the most industrialised areas of Spain. In 1832 it was inaugurated in Barcelona the factory Bonaplata, the first of the country which worked with steam engine. During those years, Barcelona was the focus of important revolutionary uprisings, called \"bullangues\", causing a difficult relation between many sectors of Catalan society and the central government and, in Catalonia, a republican current began to develop; also, inevitably, many Catalans favored a more federal Spain. Meanwhile, the Catalan language saw a cultural renaissance (the \"Renaixen\u00e7a\") at popular and bourgeois level. After the fall of the First Spanish Republic and the restoration of the Bourbon dynasty (1874), Catalan nationalism grew in importance.\nThe Anarchists had been active throughout the early 20th century, founding the CNT trade union and achieving one of the first eight-hour workday in Europe in 1919. Growing resentment of conscription and of the military culminated in the Tragic Week in Barcelona in 1909. In the first third of the 20th century, Catalonia gained and lost varying degrees of autonomy several times. In 1914, the four Catalan provinces were authorized to create a Commonwealth (Catalan: \"Mancomunitat de Catalunya\"), without any legislative power or specific autonomy which carried out an ambitious program of modernization, but it was disbanded in 1925 by the dictatorship of Primo de Rivera (1923-1930). During the last steps of the Dictatorship, Barcelona celebrated the 1929 International Exposition, while Spain began to suffer an economic crisis.\nAfter the fall of the dictator and a brief proclamation of the Catalan Republic during the events which led to the proclamation of the Second Spanish Republic (1931-1939), it received its first Statute of Autonomy from the Spanish Republic's Parliament, establishing an autonomous body, the Generalitat of Catalonia, which included a parliament, a government and a court of appeal, and the left-wing independentist leader Francesc Maci\u00e0 was elected its first president. The governments of the Republican Generalitat, led by the Republican Left of Catalonia (ERC) members Francesc Maci\u00e0 (1931-1933) and Llu\u00eds Companys (1933-1940) made efforts to implement an advanced and progressive social agenda, despite the internal difficulties. This period was marked by political unrest, the effects of the economic crisis and their social repercussions. The Statute of Autonomy was suspended in 1934, due to the Events of 6 October in Barcelona, as a response to the accession of right-wing Spanish nationalist party CEDA to the government of the Republic, considered close to fascism.\nAfter the electoral victory of the Popular Front in February 1936, the Government of Catalonia was pardoned and the self-government restored.\nSpanish Civil War (1936\u20131939) and Franco's rule (1939\u20131975).\nThe defeat of the military rebellion against the Republican government in Barcelona placed Catalonia firmly in the Republican side of the Spanish Civil War. During the war, there were two rival powers in Catalonia: the de jure power of the Generalitat and the de facto power of the armed popular militias. Violent confrontations between the workers' parties (CNT-FAI and POUM against the PSUC) culminated in the defeat of the first ones in 1937. The situation resolved itself progressively in favor of the Generalitat, but at the same time the Generalitat was partially losing its autonomous power within Republican Spain. In 1938 Franco's troops broke the Republican territory in two, isolating Catalonia from the rest of the Republic. The defeat of the Republican army in the Battle of the Ebro led in 1938 and 1939 to the occupation of Catalonia by Franco's forces.\nThe defeat of the Spanish Republic in the Spanish Civil War brought to power the dictatorship of Francisco Franco, whose first ten-year rule was particularly violent, autocratic, and repressive both in a political, cultural, social, and economical sense. In Catalonia, any kind of public activities associated with Catalan nationalism, republicanism, anarchism, socialism, liberalism, democracy or communism, including the publication of books on those subjects or simply discussion of them in open meetings, was banned. Franco's regime banned the use of Catalan in government-run institutions and during public events, and also the Catalan institutions of self-government were abolished. The pro-Republic of Spain president of Catalonia, Llu\u00eds Companys, was taken to Spain from his exile in the German-occupied France, and was tortured and executed in the Montju\u00efc Castle of Barcelona for the crime of 'military rebellion'.\nDuring later stages of Francoist Spain, certain folkloric and religious celebrations in Catalan resumed and were tolerated. Use of Catalan in the mass media had been forbidden, but was permitted from the early 1950s in the theatre. Despite the ban during the first years and the difficulties of the next period, publishing in Catalan continued throughout his rule.\nThe years after the war were extremely hard. Catalonia, like many other parts of Spain, had been devastated by the war. Recovery from the war damage was slow and made more difficult by the international trade embargo and the autarkic politics of Franco's regime. By the late 1950s the region had recovered its pre-war economic levels and in the 1960s was the second fastest growing economy in the world in what became known as the Spanish miracle. During this period there was a spectacular growth of industry and tourism in Catalonia that drew large numbers of workers to the region from across Spain and made the area around Barcelona into one of Europe's largest industrial metropolitan areas.\nTransition and democratic period (1975\u2013present).\nAfter Franco's death in 1975, Catalonia voted for the adoption of a democratic Spanish Constitution in 1978, in which Catalonia recovered political and cultural autonomy, restoring the Generalitat (exiled since the end of the Civil War in 1939) in 1977 and adopting a new Statute of Autonomy in 1979. First election to the Parliament of Catalonia under this Statute gave the Catalan presidency to Jordi Pujol, a position he would hold until 2003. During this time, he also led Converg\u00e8ncia i Uni\u00f3 (CiU), a center-right Catalan nationalist electoral coalition. Throughout the 1980s and 1990s, the institutions of Catalan autonomy continued to develop, among them an autonomous police force (\"Mossos d'Esquadra\", in 1983), and the broadcasting network Televisi\u00f3 de Catalunya and its first channel TV3, created in 1983. Today, Catalonia is one of the most economically dynamic communities of Spain. The Catalan capital and largest city, Barcelona, is a major international cultural centre and a major tourist destination. In 1992, Barcelona hosted the Summer Olympic Games.\nIn November 2003, elections to the Parliament of Catalonia gave the government to a left-wing catalanist coalition formed by the Socialists' Party of Catalonia (PSC-PSOE), Republican Left of Catalonia (ERC) and Initiative for Catalonia Greens (ICV), and the socialist Pasqual Maragall was appointed president. The new government redacted a new version of the Statute of Autonomy, which consolidated and extended certain aspects of self-government.\nThe new Statute of Autonomy of Catalonia, approved after a referendum in 2006, was contested by important sectors of the Spanish society, especially by the conservative People's Party, which sent the law to the Constitutional Court of Spain. In 2010, the Court declared non-valid some of the articles that established an autonomous Catalan system of Justice, improved aspects of the financing, a new territorial division, the status of Catalan language or the symbolical declaration of Catalonia as a nation. This decision was severely contested by large sectors of Catalan society, which increased the demands of independence.\nIndependence movement.\nA controversial independence referendum was held in Catalonia on 1 October 2017, using a disputed voting process. It was declared illegal and suspended by the Constitutional Court of Spain, because it breached the 1978 Constitution. Subsequent developments saw, on 27 October 2017, a symbolic declaration of independence by the Parliament of Catalonia, the enforcement of direct rule by the Spanish government through the use of Article 155 of the Constitution, the dismissal of the Executive Council and the dissolution of the Parliament, with a snap regional election called for 21 December 2017, which ended with a victory of pro-independence parties. Former President Carles Puigdemont and five former cabinet ministers fled Spain and took refuge in other European countries (such as Belgium, in Puigdemont's case), whereas nine other cabinet members, including vice-president Oriol Junqueras, were sentenced to prison under various charges of rebellion, sedition, and misuse of public funds. Quim Torra became the 131st President of the Government of Catalonia on 17 May 2018, after the Spanish courts blocked three other candidates.\nIn 2018, the Assemblea Nacional Catalana joined the Unrepresented Nations and Peoples Organization (UNPO) on behalf of Catalonia.\nOn 14 October 2019, the Spanish Supreme court sentenced several Catalan political leaders involved in organizing a referendum on Catalonia's independence from Spain were convicted on charges ranging from sedition to misuse of public funds, with sentences ranging from 9 to 13 years in prison. This decision sparked demonstrations around Catalonia.\nGeography.\nClimate.\nThe climate of Catalonia is diverse. The populated areas lying by the coast in Tarragona, Barcelona and Girona provinces feature a Hot-summer Mediterranean climate (K\u00f6ppen \"Csa\"). The inland part (including the Lleida province and the inner part of Barcelona province) show a mostly Mediterranean climate (K\u00f6ppen \"Csa\"). The Pyrenean peaks have a continental (K\u00f6ppen \"D\") or even Alpine climate (K\u00f6ppen \"ET\") at the highest summits, while the valleys have a maritime or oceanic climate sub-type (K\u00f6ppen \"Cfb\").\nIn the Mediterranean area, summers are dry and hot with sea breezes, and the maximum temperature is around . Winter is cool or slightly cold depending on the location. It snows frequently in the Pyrenees, and it occasionally snows at lower altitudes, even by the coastline. Spring and autumn are typically the rainiest seasons, except for the Pyrenean valleys, where summer is typically stormy.\nThe inland part of Catalonia is hotter and drier in summer. Temperature may reach , some days even . Nights are cooler there than at the coast, with the temperature of around . Fog is not uncommon in valleys and plains; it can be especially persistent, with freezing drizzle episodes and subzero temperatures during winter, mainly along the Ebro and Segre valleys and in Plain of Vic.\nTopography.\nCatalonia has a marked geographical diversity, considering the relatively small size of its territory. The geography is conditioned by the Mediterranean coast, with of coastline, and large relief units of the Pyrenees to the north. The Catalan territory is divided into three main geomorphological units:\nThe Catalan Pyrenees represent almost half in length of the Pyrenees, as it extends more than . Traditionally differentiated the Axial Pyrenees (the main part) and the Pre-Pyrenees (southern from the Axial) which are mountainous formations parallel to the main mountain ranges but with lower altitudes, less steep and a different geological formation. The highest mountain of Catalonia, located north of the comarca of Pallars Sobir\u00e0 is the Pica d'Estats (3,143\u00a0m), followed by the Puigpedr\u00f3s (2,914\u00a0m). The Serra del Cad\u00ed comprises the highest peaks in the Pre-Pyrenees and forms the southern boundary of the Cerdanya valley.\nThe Central Catalan Depression is a plain located between the Pyrenees and Pre-Coastal Mountains. Elevation ranges from . The plains and the water that descend from the Pyrenees have made it fertile territory for agriculture and numerous irrigation canals have been built. Another major plain is the Empord\u00e0, located in the northeast.\nThe Catalan Mediterranean system is based on two ranges running roughly parallel to the coast (southwest\u2013northeast), called the Coastal and the Pre-Coastal Ranges. The Coastal Range is both the shorter and the lower of the two, while the Pre-Coastal is greater in both length and elevation. Areas within the Pre-Coastal Range include Montserrat, Montseny and the Ports de Tortosa-Beseit. Lowlands alternate with the Costal and Pre-Costal Ranges. The Coastal Lowland is located to the East of the Coastal Range between it and the coast, while the Pre-Coastal Lowlands are located inland, between the Costal and Pre-Costal Ranges, and includes the Vall\u00e8s and Pened\u00e8s plains.\nFlora and fauna.\nCatalonia is a showcase of European landscapes on a small scale. Just over hosting a variety of substrates, soils, climates, directions, altitudes and distances to the sea. The area is of great ecological diversity and a remarkable wealth of landscapes, habitats and species.\nThe fauna of Catalonia comprises a minority of animals endemic to the region and a majority of non-native animals. Much of Catalonia enjoys a Mediterranean climate (except mountain areas), which makes many of the animals that live there adapted to Mediterranean ecosystems. Of mammals, there are plentiful wild boar, red foxes, as well as roe deer and in the Pyrenees, the Pyrenean chamois. Other large species such as the bear have been recently reintroduced.\nWaters of Balearic Sea are rich in biodiversity, and even the megafaunas of ocean; various type of whales (such as fin, sperm, and pilot) and dolphins live within the area.\nHydrography.\nMost of Catalonia belongs to the Mediterranean Basin. The Catalan hydrographic network consists of two important basins, the one of the Ebro and the one that comprises the internal basins of Catalonia (respectively covering 46.84% and 51.43% of the territory), all of them flow to the Mediterranean. Furthermore, there is the Garona river basin that flows to the Atlantic Ocean, but it only covers 1.73% of the Catalan territory.\nThe hydrographic network can be divided in two sectors, an occidental slope or Ebro river slope and one oriental slope constituted by minor rivers that flow to the Mediterranean along the Catalan coast. The first slope provides an average of per year, while the second only provides an average of /year. The difference is due to the big contribution of the Ebro river, from which the Segre is an important tributary. Moreover, in Catalonia there is a relative wealth of groundwaters, although there is inequality between \"comarques\", given the complex geological structure of the territory. In the Pyrenees there are many small lakes, remnants of the ice age. The biggest are the lake of Banyoles and the recently recovered lake of Ivars.\nThe Catalan coast is almost rectilinear, with a length of and few landforms\u2014the most relevant are the Cap de Creus and the Gulf of Roses to the north and the Ebro Delta to the south. The Catalan Coastal Range hugs the coastline, and it is split into two segments, one between L'Estartit and the town of Blanes (the Costa Brava), and the other at the south, at the Costes del Garraf.\nThe principal rivers in Catalonia are the Ter, Llobregat, and the Ebro (Catalan: ), all of which run into the Mediterranean.\nAnthropic pressure and protection of nature.\nThe majority of Catalan population is concentrated in 30% of the territory, mainly in the coastal plains. Intensive agriculture, livestock farming and industrial activities have been accompanied by a massive tourist influx (more than 20\u00a0million annual visitors), a rate of urbanization and even of major metropolisation which has led to a strong urban sprawl: two thirds of Catalans live in the urban area of Barcelona, while the proportion of urban land increased from 4.2% in 1993 to 6.2% in 2009, a growth of 48.6% in sixteen years, complemented with a dense network of transport infrastructure. This is accompanied by a certain agricultural abandonment (decrease of 15% of all areas cultivated in Catalonia between 1993 and 2009) and a global threat to natural environment. Human activities have also put some animal species at risk, or even led to their disappearance from the territory, like the gray wolf and probably the brown bear of the Pyrenees. The pressure created by this model of life means that the country's ecological footprint exceeds its administrative area.\nFaced with this problems, Catalan authorities initiated several measures whose purpose is to protect natural ecosystems. Thus, in 1990, the Catalan government created the Nature Conservation Council (Catalan: ), an advisory body with the aim to study, protect and manage the natural environments and landscapes of Catalonia. In addition, the Generalitat has carried out the Plan of Spaces of Natural Interest ( or PEIN) in 1992 while eighteen Natural Spaces of Special Protection ( or ENPE) have been instituted.\nThere's a National Park, Aig\u00fcestortes i Estany de Sant Maurici; fourteen Natural Parks, Alt Pirineu, Aiguamolls de l'Empord\u00e0, Cad\u00ed-Moixer\u00f3, Cap de Creus, Sources of Ter and Freser, Collserola, Ebro Delta, Ports, Montgr\u00ed, Medes Islands and Baix Ter, Montseny, Montserrat, Sant Lloren\u00e7 del Munt and l'Obac, Serra de Montsant and the Garrotxa Volcanic Zone; as well as three Natural Places of National Interest ( or PNIN), the Pedraforca, the Poblet Forest and the Alb\u00e8res.\nPolitics.\nAfter Franco's death in 1975 and the adoption of a democratic constitution in Spain in 1978, Catalonia recovered and extended the powers that it had gained in the Statute of Autonomy of 1932 but lost with the fall of the Second Spanish Republic at the end of the Spanish Civil War in 1939.\nThis autonomous community has gradually achieved more autonomy since the approval of the Spanish Constitution of 1978. The Generalitat holds exclusive jurisdiction in education, health, culture, environment, communications, transportation, commerce, public safety and local government, and only shares jurisdiction with the Spanish government in justice. In all, some analysts argue that formally the current system grants Catalonia with \"more self-government than almost any other corner in Europe\".\nThe support for Catalan nationalism ranges from a demand for further autonomy and the federalisation of Spain to the desire for independence from the rest of Spain, expressed by Catalan independentists. The first survey following the Constitutional Court ruling that cut back elements of the 2006 Statute of Autonomy, published by \"La Vanguardia\" on 18 July 2010, found that 46% of the voters would support independence in a referendum. In February of the same year, a poll by the Open University of Catalonia gave more or less the same results. Other polls have shown lower support for independence, ranging from 40 to 49%. Although it is established in the whole of the territory, support for independence is significantly higher in the hinterland and the northeast, away from the more populated coastal areas such as Barcelona.\nSince 2011 when the question started to be regularly surveyed by the governmental Center for Public Opinion Studies (CEO), support for Catalan independence has been on the rise. According to the CEO opinion poll from July 2016, 47.7% of Catalans would vote for independence and 42.4% against it while, about the question of preferences, according to the CEO opinion poll from March 2016, a 57.2 claim to be \"absolutely\" or \"fairly\" in favour of independence. Other polls have shown lower support for independence, ranging from 40 to 49%. Other polls show more variable results, according with the Spanish CIS, as of December 2016, 47% of Catalans rejected independence and 45% supported it.\nIn hundreds of non-binding local referendums on independence, organised across Catalonia from 13 September 2009, a large majority voted for independence, although critics argued that the polls were mostly held in pro-independence areas. In December 2009, 94% of those voting backed independence from Spain, on a turn-out of 25%. The final local referendum was held in Barcelona, in April 2011. On 11 September 2012, a pro-independence march pulled in a crowd of between 600,000 (according to the Spanish Government), 1.5\u00a0million (according to the Gu\u00e0rdia Urbana de Barcelona), and 2\u00a0million (according to its promoters); whereas poll results revealed that half the population of Catalonia supported secession from Spain.\nTwo major factors were Spain's Constitutional Court's 2010 decision to declare part of the 2006 Statute of Autonomy of Catalonia unconstitutional, as well as the fact that Catalonia contributes 19.49% of the central government's tax revenue, but only receives 14.03% of central government's spending.\nParties that consider themselves either Catalan nationalist or independentist have been present in all Catalan governments since 1980. The largest Catalan nationalist party, Convergence and Union, ruled Catalonia from 1980 to 2003, and returned to power in the 2010 election. Between 2003 and 2010, a leftist coalition, composed by the Catalan Socialists' Party, the pro-independence Republican Left of Catalonia and the leftist-environmentalist Initiative for Catalonia-Greens, implemented policies that widened Catalan autonomy.\nIn the 25 November 2012 Catalan parliamentary election, sovereigntist parties supporting a secession referendum gathered 59.01% of the votes and held 87 of the 135 seats in the Catalan Parliament. Parties supporting independence from the rest of Spain obtained 49.12% of the votes and a majority of 74 seats.\nArtur Mas, then the president of Catalonia, organised early elections that took place on 27 September 2015. In these elections, Converg\u00e8ncia and Esquerra Republicana decided to join, and they presented themselves under the coalition named \"Junts pel S\u00ed\" (in Catalan, \"Together for Yes\"). \"Junts pel S\u00ed\" won 62 seats and was the most voted party, and CUP (Candidatura d'Unitat Popular, a far-left and independentist party) won another 10, so the sum of all the independentist forces/parties was 72 seats, reaching an absolute majority, but not in number of individual votes, comprising 47,74% of the total.\nStatute of Autonomy.\nThe Statute of Autonomy of Catalonia is the fundamental organic law, second only to the Spanish Constitution from which the Statute originates.\nIn the Spanish Constitution of 1978 Catalonia, along with the Basque Country and Galicia, was defined as a \"nationality\". The same constitution gave Catalonia the automatic right to autonomy, which resulted in the Statute of Autonomy of Catalonia of 1979.\nBoth the 1979 Statute of Autonomy and the current one, approved in 2006, state that \"Catalonia, as a nationality, exercises its self-government constituted as an Autonomous Community in accordance with the Constitution and with the Statute of Autonomy of Catalonia, which is its basic institutional law, always under the law in Spain\".\nThe Preamble of the 2006 Statute of Autonomy of Catalonia states that the Parliament of Catalonia has defined Catalonia as a nation, but that \"the Spanish Constitution recognizes Catalonia's national reality as a nationality\". While the Statute was approved by and sanctioned by both the Catalan and Spanish parliaments, and later by referendum in Catalonia, it has been subject to a legal challenge by the surrounding autonomous communities of Aragon, Balearic Islands and Valencia, as well as by the conservative People's Party. The objections are based on various issues such as disputed cultural heritage but, especially, on the Statute's alleged breaches of the principle of \"solidarity between regions\" in fiscal and educational matters enshrined by the Constitution.\nSpain's Constitutional Court assessed the disputed articles and on 28 June 2010, issued its judgment on the principal allegation of unconstitutionality presented by the People's Party in 2006. The judgment granted clear passage to 182 articles of the 223 that make up the fundamental text. The court approved 73 of the 114 articles that the People's Party had contested, while declaring 14 articles unconstitutional in whole or in part and imposing a restrictive interpretation on 27 others. The court accepted the specific provision that described Catalonia as a \"nation\", however ruled that it was a historical and cultural term with no legal weight, and that Spain remained the only nation recognised by the constitution.\nGovernment and law.\nThe Catalan Statute of Autonomy establishes that Catalonia is organised politically through the Generalitat of Catalonia (in Catalan: ), conformed by the Parliament, the Presidency of the Generalitat, the Government or Executive Council and the other institutions created by the Parliament, among them the Ombudsman (), the Office of Auditors () or the Council for Statutory Guarantees ()\nLegislature.\nThe Parliament of Catalonia (in Catalan: ) is the legislative body of the Generalitat and represents the citizens of Catalonia. It is elected every four years by universal suffrage, and it has powers to legislate in different matters such as education, health, culture, internal institutional and territorial organization, election and control of the president of the Generalitat and the Government, budget and other affairs, according with the Statute of Autonomy. The last Catalan election was held on 21 December 2017, and its current president is Roger Torrent, incumbent since January 2018.\nPresidency.\nThe president of the Generalitat of Catalonia (in Catalan: ) is the highest representative of Catalonia, and is also responsible of leading the government's action. Since the restoration of the Generalitat on the return of democracy in Spain, the presidents of Catalonia have been Josep Tarradellas (1977\u20131980, president in exile since 1954), Jordi Pujol (1980\u20132003), Pasqual Maragall (2003\u20132006), Jos\u00e9 Montilla (2006\u20132010), Artur Mas (2010\u20132016), Carles Puigdemont (2016\u20132017) and, after the imposition of direct rule from Madrid, Quim Torra (2018\u20132020) and Pere Aragon\u00e8s (2020-).\nExecutive.\nThe Executive Council (in Catalan: ) or Government (), is the body responsible of the government of the Generalitat, it holds executive and regulatory power. It comprises the president of the Generalitat, the First Minister (or the Vice President) and the Ministers (). Its seat is the Palau de la Generalitat, in Barcelona.\nSecurity forces and Justice.\nCatalonia has its own police force, the (officially called ), whose origins date back to the 18th century. Since 1980 they have been under the command of the Generalitat, and since 1994 they have expanded in number in order to replace the national Civil Guard and National Police Corps, which report directly to the Homeland Department of Spain. The national bodies retain personnel within Catalonia to exercise functions of national scope such as overseeing ports, airports, coasts, international borders, custom offices, the identification of documents and arms control, immigration control, terrorism prevention, arms trafficking prevention, amongst others.\nMost of the justice system is administered by national judicial institutions, the highest body and last judicial instance in the Catalan jurisdiction, integrating the Spanish judiciary, is the High Court of Justice of Catalonia. The criminal justice system is uniform throughout Spain, while civil law is administered separately within Catalonia. The civil laws that are subject to autonomous legislation have been codified in the Civil Code of Catalonia () since 2002.\nNavarre, the Basque Country and Catalonia are the Spanish communities with the highest degree of autonomy in terms of law enforcement.\nAdministrative divisions.\nCatalonia is organised territorially into provinces, further subdivided into comarques and municipalities. The 2006 Statute of Autonomy of Catalonia establishes the administrative organisation of three local authorities: vegueries, comarques, and municipalities.\nProvinces.\nCatalonia is divided administratively into four provinces, the governing body of which is the Provincial Deputation (, ). The four provinces and their populations are:\nComarques.\nComarques (singular: \"comarca\") are entities composed by the municipalities to manage their responsibilities and services. The current regional division has its roots in a decree of the Generalitat de Catalunya of 1936, in effect until 1939, when it was suppressed by Franco. In 1987 the Government adopted the territorial division again and in 1988 three new comarques were added (Alta Ribagor\u00e7a, Pla d'Urgell and Pla de l'Estany), and in 2015 was created another comarca, the Moian\u00e8s. At present there are 41. Every comarca is administered by a comarcal council ().\nThe Val d'Aran (Aran Valley), until 2015 considered as a comarca, is officially defined today as \"unique territorial entity\", has a special status and its autonomous government is named .\nMunicipalities.\nThere are at present 948 municipalities () in Catalonia. Each municipality is run by a council () elected every four years by the residents in local elections. The council consists of a number of members () depending on population, who elect the mayor ( or ). Its seat is the town hall (, or ).\nVegueries.\nThe \"vegueria\" is a new type of division defined as a specific territorial area for the exercise of government and inter-local cooperation with legal personality. The current Statute of Autonomy states vegueries are intended to supersede provinces in Catalonia, and take over many of functions of the comarques.\nThe territorial plan of Catalonia () provided six general functional areas, but was amended by Law 24/2001, of 31 December, recognizing the Alt Pirineu i Aran as a new functional area differentiated of Ponent. On 14 July 2010 the Catalan Parliament approved the creation of the functional area of the Pened\u00e8s.\nEconomy.\nA highly industrialized land, the nominal GDP of Catalonia in 2018 was \u20ac228\u00a0billion (second after the community of Madrid, \u20ac230\u00a0billion) and the per capita GDP was \u20ac30,426 ($32,888), behind Madrid (\u20ac35,041), the Basque Country (\u20ac33,223), and Navarre (\u20ac31,389). That year, the GDP growth was 2.3%. In recent years, and increasingly following the unilateral declaration of independence in 2017, there has been a negative net relocation rate of companies based in Catalonia moving to other autonomous communities of Spain. From the 2017 independence referendum until the end of 2018, for example, Catalonia lost 5454 companies to other parts of Spain (mainly Madrid), 2359 only in 2018, gaining 467 new ones from the rest of the country during 2018.\nCatalonia's long-term credit rating is BB (Non-Investment Grade) according to Standard &amp; Poor's, Ba2 (Non-Investment Grade) according to Moody's, and BBB- (Low Investment Grade) according to Fitch Ratings. Catalonia's rating is tied for worst with between 1 and 5 other autonomous communities of Spain, depending on the rating agency.\n The city of Barcelona occupies the eighth position as the best world city to live, work, research and visit in 2021, according to the report \"The World's Best Cities 2021\", prepared by Resonance Consultancy and released this Sunday, 3 January, on Barcelona's town hall .\nThe Catalan capital, despite the current moment of crisis, is also one of the European bases of \"reference for start-ups\" and the fifth city in the world to establish one of these companies, behind London, Berlin, Paris and Amsterdam, according to the Eu-Starts-Up 2020 study.\nBarcelona is behind London, New York, Paris, Moscow, Tokyo, Dubai and Singapore and ahead of Los Angeles and Madrid. \nIn the context of the financial crisis of 2007\u20132008, Catalonia was expected to suffer a recession amounting to almost a 2% contraction of its regional GDP in 2009. Catalonia's debt in 2012 was the highest of all Spain's autonomous communities, reaching \u20ac13,476\u00a0million, i.e. 38% of the total debt of the 17 autonomous communities, but in recent years its economy recovered a positive evolution and the GDP grew a 3.3% in 2015.\nCatalonia is amongst the List of country subdivisions by GDP over 100 billion US dollars and is a member of the Four Motors for Europe organisation.\nThe distribution of sectors is as follows:\nThe main tourist destinations in Catalonia are the city of Barcelona, the beaches of the Costa Brava in Girona, the beaches of the Costa del Maresme and Costa del Garraf from Malgrat de Mar to Vilanova i la Geltr\u00fa and the Costa Daurada in Tarragona. In the High Pyrenees there are several ski resorts, near Lleida. On 1 November 2012, Catalonia started charging a tourist tax. The revenue is used to promote tourism, and to maintain and upgrade tourism-related infrastructure.\nMany savings banks were based in Catalonia before the independence referendum of 2017, with 10 of the 46 Spanish savings banks having headquarters in the region at that time. This list included Europe's premier savings bank, La Caixa, who, on 7 October 2017, a week after the referendum, moved its headquarters to Palma de Mallorca, in the Balearic Islands and CaixaBank to Valencia, in the Valencian Community. The first private bank in Catalonia, Banc Sabadell, ranked fourth among all Spanish private banks, also moved its headquarters to Alicante, in the Valencian Community.\nThe stock market of Barcelona, which in 2016 had a volume of around \u20ac152\u00a0billion, is the second largest of Spain after Madrid, and Fira de Barcelona organizes international exhibitions and congresses to do with different sectors of the economy.\nThe main economic cost for the Catalan families is the purchase of a home. According to data from the Society of Appraisal on 31 December 2005 Catalonia is, after Madrid, the second most expensive region in Spain for housing: 3,397\u00a0\u20ac/m2 on average (see Spanish property bubble).\nUnemployment.\nThe unemployment rate stood at 10.5% in 2019 and was lower than the national average.\nTransport.\nAirports.\nAirports in Catalonia are owned and operated by Aena (a Spanish Government entity) except two airports in Lleida which are operated by Aeroports de Catalunya (an entity belonging to the Government of Catalonia).\nPorts.\nSince the Middle Ages, Catalonia has been well integrated into international maritime networks. The port of Barcelona (owned and operated by , a Spanish Government entity) is an industrial, commercial and tourist port of worldwide importance. With 1,950,000 TEUs in 2015, it is the first container port in Catalonia, the third in Spain after Valencia and Algeciras in Andalusia, the 9th in the Mediterranean Sea, the 14th in Europe and the 68th in the world. It is sixth largest cruise port in the world, the first in Europe and the Mediterranean with 2,364,292 passengers in 2014. The ports of Tarragona (owned and operated by Puertos del Estado) in the southwest and Palam\u00f3s near Girona at northeast are much more modest. The port of Palam\u00f3s and the other ports in Catalonia (26) are operated and administered by , a Catalan Government entity.\nThe development of these infrastructures, resulting from the topography and history of the Catalan territory, responds strongly to the administrative and political organization of this autonomous community.\nRoads.\nThere are of roads throughout Catalonia.\nThe principal highways are \u00a0AP-7\u00a0 () and \u00a0A-7\u00a0 (). They follow the coast from the French border to Valencia, Murcia and Andalusia. The main roads generally radiate from Barcelona. The \u00a0AP-2\u00a0 () and \u00a0A-2\u00a0 () connect inland and onward to Madrid.\nOther major roads are:\nPublic-own roads in Catalonia are either managed by the autonomous government of Catalonia (e.g., \u00a0C-\u00a0 roads) or the Spanish government (e.g., \u00a0AP-\u00a0, \u00a0A-\u00a0, \u00a0N-\u00a0 roads).\nRailways.\nCatalonia saw the first railway construction in the Iberian Peninsula in 1848, linking Barcelona with Matar\u00f3. Given the topography most lines radiate from Barcelona. The city has both suburban and inter-city services. The main east coast line runs through the province connecting with the SNCF (French Railways) at Portbou on the coast.\nThere are two publicly owned railway companies operating in Catalonia: the Catalan FGC that operates commuter and regional services, and the Spanish national RENFE that operates long-distance and high-speed rail services (AVE and Avant) and the main commuter and regional service , administered by the Catalan government since 2010.\nHigh-speed rail (AVE) services from Madrid currently reach Lleida, Tarragona and Barcelona. The official opening between Barcelona and Madrid took place 20 February 2008. The journey between Barcelona and Madrid now takes about two-and-a-half hours. A connection to the French high-speed TGV network has been completed (called the Perpignan\u2013Barcelona high-speed rail line) and the Spanish AVE service began commercial services on the line 9 January 2013, later offering services to Marseille on their high speed network. This was shortly followed by the commencement of commercial service by the French TGV on 17 January 2013, leading to an average travel time on the Paris-Barcelona TGV route of 7h 42m. This new line passes through Girona and Figueres with a tunnel through the Pyrenees.\nDemographics.\nAs of 2017, the official population of Catalonia was 7,522,596. 1,194,947 residents did not have Spanish citizenship, accounting for about 16% of the population.\nThe Urban Region of Barcelona includes 5,217,864 people and covers an area of . The metropolitan area of the Urban Region includes cities such as L'Hospitalet de Llobregat, Sabadell, Terrassa, Badalona, Santa Coloma de Gramenet and Cornell\u00e0 de Llobregat.\nIn 1900, the population of Catalonia was 1,966,382 people and in 1970 it was 5,122,567. The sizeable increase of the population was due to the demographic boom in Spain during the 60s and early 70s as well as in consequence of large-scale internal migration from the rural economically weak regions to its more prospering industrial cities. In Catalonia that wave of internal migration arrived from several regions of Spain, especially from Andalusia, Murcia and Extremadura.\nImmigrants from other countries settled in Catalonia since the 1990s; a large percentage comes from Africa, Latin America and Eastern Europe, and smaller numbers from Asia and Southern Europe, often settling in urban centers such as Barcelona and industrial areas. In 2017, Catalonia had 940,497 foreign residents (11.9% of the total population) with non-Spanish ID cards, without including those who acquired the Spanish citizenship.\nReligion.\nHistorically, all the Catalan population was Christian, specifically Catholic, but since the 1980s there has been a trend of decline of Christianity and parallel growth of irreligion (including stances of atheism and agnosticism) and other religions. According to the most recent study sponsored by the government of Catalonia, as of 2020, 62.3% of the Catalans identify as Christians (up from 61.9% in 2016 and 56.5% in 2014) of whom 53.0% Catholics, 7.0% Protestants and Evangelicals, 1.3% Orthodox Christians and 1.0% Jehovah's Witnesses. At the same time, 18.6% of the population identify as atheists, 8.8% as agnostics, 4.3% as Muslims, and a further 3.4% as being of other religions.\nLanguages.\nAccording to the linguistic census held by the Government of Catalonia in 2013, Spanish is the most spoken language in Catalonia (46.53% claim Spanish as \"their own language\"), followed by Catalan (37.26% claim Catalan as \"their own language\"). In everyday use, 11.95% of the population claim to use both languages equally, whereas 45.92% mainly use Spanish and 35.54% mainly use Catalan. There is a significant difference between the Barcelona metropolitan area (and, to a lesser extent, the Tarragona area), where Spanish is more spoken than Catalan, and the more rural and small town areas, where Catalan clearly prevails over Spanish.\nOriginating in the historic territory of Catalonia, Catalan has enjoyed special status since the approval of the Statute of Autonomy of 1979 which declares it to be \"Catalonia's own language\", a term which signifies a language given special legal status within a Spanish territory, or which is historically spoken within a given region. The other languages with official status in Catalonia are Spanish, which has official status throughout Spain, and Aranese Occitan, which is spoken in Val d'Aran.\nSince the Statute of Autonomy of 1979, Aranese (a Gascon dialect of Occitan) has also been official and subject to special protection in Val d'Aran. This small area of 7,000 inhabitants was the only place where a dialect of Occitan had received full official status. Then, on 9 August 2006, when the new Statute came into force, Occitan became official throughout Catalonia. Occitan is the mother tongue of 22.4% of the population of Val d'Aran, which has attracted heavy immigration from other Spanish regions to work in the service industry. Catalan Sign Language is also officially recognised.\nAlthough not considered an \"official language\" in the same way as Catalan, Spanish, and Occitan, the Catalan Sign Language, with about 18,000 users in Catalonia, is granted official recognition and support: \"The public authorities shall guarantee the use of Catalan sign language and conditions of equality for deaf people who choose to use this language, which shall be the subject of education, protection and respect.\"\nAs was the case since the ascent of the Bourbon dynasty to the throne of Spain after the War of the Spanish Succession, and with the exception of the short period of the Second Spanish Republic, under Francoist Spain Catalan was banned from schools and all other official use, so that for example families were not allowed to officially register children with Catalan names. Although never completely banned, Catalan language publishing was severely restricted during the early 1940s, with only religious texts and small-run self-published texts being released. Some books were published clandestinely or circumvented the restrictions by showing publishing dates prior to 1936. This policy was changed in 1946, when restricted publishing in Catalan resumed.\nRural\u2013urban migration originating in other parts of Spain also reduced the social use of Catalan in urban areas and increased the use of Spanish. Lately, a similar sociolinguistic phenomenon has occurred with foreign immigration. Catalan cultural activity increased in the 1960s and the teaching of Catalan began thanks to the initiative of associations such as \u00d2mnium Cultural.\nAfter the end of Francoist Spain, the newly established self-governing democratic institutions in Catalonia embarked on a long-term language policy to recover the use of Catalan and has, since 1983, enforced laws which attempt to protect and extend the use of Catalan. This policy, known as the \"linguistic normalisation\" ( in Catalan, in Spanish) has been supported by the vast majority of Catalan political parties through the last thirty years. Some groups consider these efforts a way to discourage the use of Spanish, whereas some others, including the Catalan government and the European Union consider the policies respectful, or even as an example which \"should be disseminated throughout the Union\".\nToday, Catalan is the main language of the Catalan autonomous government and the other public institutions that fall under its jurisdiction. Basic public education is given basically in Catalan, but also there are some hours per week of Spanish medium instruction. Although businesses are required by law to display all information (e.g. menus, posters) at least in Catalan, this not systematically enforced. There is no obligation to display this information in either Occitan or Spanish, although there is no restriction on doing so in these or other languages. The use of fines was introduced in a 1997 linguistic law that aims to increase the public use of Catalan and defend the rights of Catalan speakers. On the other hand, the Spanish Constitution does not recognize equal language rights for national minorities since it enshrined Spanish as the only official language of the state, the knowledge of which being compulsory. Numerous laws regarding for instance the labelling of pharmaceutical products, make in effect Spanish the only language of compulsory use. \nThe law ensures that both Catalan and Spanish \u2013 being official languages \u2013 can be used by the citizens without prejudice in all public and private activities. The Generalitat uses Catalan in its communications and notifications addressed to the general population, but citizens can also receive information from the Generalitat in Spanish if they so desire. Debates in the Catalan Parliament take place almost exclusively in Catalan and the Catalan public television broadcasts programs basically in Catalan.\nDue to the intense immigration which Spain in general and Catalonia in particular experienced in the first decade of the 21st century, many foreign languages are spoken in various cultural communities in Catalonia, of which Rif-Berber, Moroccan Arabic, Romanian and Urdu are the most common ones.\nIn Catalonia, there is a high social and political consensus on the language policies favoring Catalan, also among Spanish speakers and speakers of other languages. However, some of these policies have been criticised for trying to promote Catalan by imposing fines on businesses. For example, following the passage of the law on Catalan cinema in March 2010, which established that half of the movies shown in Catalan cinemas had to be in Catalan, a general strike of 75% of the cinemas took place. The Catalan government gave in and dropped the clause that forced 50% of the movies to be dubbed or subtitled in Catalan before the law came to effect. On the other hand, organisations such as Plataforma per la Llengua reported different violations of the linguistic rights of the Catalan speakers in Catalonia and the other Catalan-speaking territories in Spain, most of them caused by the institutions of the Spanish government in these territories.\nThe Catalan language policy has been challenged by some political parties in the Catalan Parliament. Citizens, currently the main opposition party, has been one of the most consistent critics of the Catalan language policy within Catalonia. The Catalan branch of the People's Party has a more ambiguous position on the issue: on one hand, it demands a bilingual Catalan\u2013Spanish education and a more balanced language policy that would defend Catalan without favoring it over Spanish, whereas on the other hand, a few local PP politicians have supported in their municipalities measures privileging Catalan over Spanish and it has defended some aspects of the official language policies, sometimes against the positions of its colleagues from other parts of Spain.\nCulture.\nArt and architecture.\nCatalonia has given to the world many important figures in the area of the art. Catalan painters internationally known are, among others, Salvador Dal\u00ed, Joan Mir\u00f3 and Antoni T\u00e0pies. Closely linked with the Catalan pictorial atmosphere, Pablo Picasso lived in Barcelona during his youth, training them as an artist and creating the movement of cubism. Other important artists are Claudi Lorenzale for the medieval Romanticism that marked the artistic Renaixen\u00e7a, Mari\u00e0 Fortuny for the Romanticism and Catalan Orientalism of the nineteenth century, Ramon Casas or Santiago Rusi\u00f1ol, main representatives of the pictorial current of Catalan modernism from the end of the nineteenth century to the beginning of the twentieth century, Josep Maria Sert for early 20th-century Noucentisme, or Josep Maria Subirachs for expressionist or abstract sculpture and painting of the late twentieth century.\nThe most important painting museums of Catalonia are the Teatre-Museu Dal\u00ed in Figueres, the National Art Museum of Catalonia (MNAC), Picasso Museum, Fundaci\u00f3 Antoni T\u00e0pies, Joan Mir\u00f3 Foundation, the Barcelona Museum of Contemporary Art (MACBA), the Centre of Contemporary Culture of Barcelona (CCCB) and the CaixaForum.\nIn the field of architecture were developed and adapted to Catalonia different artistic styles prevalent in Europe, leaving footprints in many churches, monasteries and cathedrals, of Romanesque (the best examples of which are located in the northern half of the territory) and Gothic styles. The Gothic developed in Barcelona and its area of influence is known as Catalan Gothic, with some particular characteristics. The church of Santa Maria del Mar is an example of this kind of style. During the Middle Ages, many fortified castles were built by feudal nobles to mark their powers.\nThere are some examples of Renaissance (such as the Palau de la Generalitat), Baroque and Neoclassical architectures. In the late nineteenth century Modernism (Art Nouveau) appeared as the national art. The world-renowned Catalan architects of this style are Antoni Gaud\u00ed, Llu\u00eds Dom\u00e8nech i Montaner and Josep Puig i Cadafalch. Thanks to the urban expansion of Barcelona during the last decades of the century and the first ones of the next, many buildings of the Eixample are modernists. In the field of architectural rationalism, which turned especially relevant in Catalonia during the Republican era (1931-1939) highlighting Josep Llu\u00eds Sert and Josep Torres i Clav\u00e9, members of the GATCPAC and, in contemporany architecture, Ricardo Bofill and Enric Miralles.\nMonuments and World Heritage Sites.\nThere are several UNESCO World Heritage Sites in Catalonia:\nLiterature.\nThe oldest surviving literary use of the Catalan language is considered to be the religious text known as Homilies d'Organy\u00e0, written either in late 11th or early 12th century.\nThere are two historical moments of splendor of Catalan literature. The first begins with the historiographic chronicles of the 13th century (chronicles written between the thirteenth and fourteenth centuries narrating the deeds of the monarchs and leading figures of the Crown of Aragon) and the subsequent Golden Age of the 14th and 15th centuries. After that period, between the 16th and 19th centuries the Romantic historiography defined this era as the , considered as the \"decadent\" period in Catalan literature because of a general falling into disuse of the vernacular language in cultural contexts and lack of patronage among the nobility.\nThe second moment of splendor began in the 19th century with the cultural and political (Renaissance) represented by writers and poets such as Jacint Verdaguer, V\u00edctor Catal\u00e0 (pseudonym of Caterina Albert i Parad\u00eds), Narc\u00eds Oller, Joan Maragall and \u00c0ngel Guimer\u00e0. During the 20th century, avant-garde movements developed, initiated by the Generation of '14 (called Noucentisme in Catalonia), represented by Eugeni d'Ors, Joan Salvat-Papasseit, Josep Carner, Carles Riba, J.V. Foix and others. During the dictatorship of Primo de Rivera, the Civil War (Generation of '36) and the Francoist period, Catalan literature was maintained despite the repression against the Catalan language, being often produced in exile. The most outstanding authors of this period are Salvador Espriu, Josep Pla, Josep Maria de Sagarra (the latter three being considered as the main responsible of the renewal of Catalan prose), Merc\u00e8 Rodoreda, Joan Oliver Sallar\u00e8s or \"Pere Quart\", Pere Calders, Gabriel Ferrater, Manuel de Pedrolo, Agust\u00ed Bartra or Miquel Mart\u00ed i Pol. In addition, several foreign writers who fought in the framework of the International Brigades then recount their experiences of fighting in their works, historical or fictional, with for example \"Homage to Catalonia\" of the British George Orwell in 1938 or in 1962 and \"The Georgics\" in 1981 by Frenchman Claude Simon.\nAfter the transition to democracy (1975\u20131978) and the restoration of the Generalitat (1977), literary life and the editorial market have returned to normality and literary production in Catalan is being bolstered with a number of language policies intended to protect Catalan culture. Besides the aforementioned authors, other relevant 20th-century writers of the Francoist and democracy periods include Joan Brossa, Agust\u00ed Bartra, Manuel de Pedrolo, Pere Calders or Quim Monz\u00f3.\nAna Mar\u00eda Matute, Jaime Gil de Biedma, Manuel V\u00e1zquez Montalb\u00e1n and Juan Goytisolo are among the most prominent Catalan writers in the Spanish language since the democratic restoration in Spain.\nFestivals and public holidays.\nCastells are one of the main manifestations of Catalan popular culture. The activity consists in constructing human towers by competing (teams). This practice originated in Valls, on the region of the Camp de Tarragona, during the 18th century, and later it was extended along the next two centuries to the rest of the territory. The tradition of els Castells i els Castellers was declared Masterpiece of the Oral and Intangible Heritage of Humanity by UNESCO in 2010.\nIn main celebrations, other elements of the Catalan popular culture are also usually present: parades with (giants), bigheads, stick-dancers and musicians, and the , where devils and monsters dance and spray showers of sparks using firecrackers. Another traditional celebration in Catalonia is , declared a Masterpiece of the Oral and Intangible Heritage of Humanity by the UNESCO on 25 November 2005.\nChristmas in Catalonia lasts two days, plus Christmas Eve. On the 25th, Christmas is celebrated, followed by a similar feast on the 26, called Sant Esteve (Saint Steve's Day). This allows families to visit and dine with different sectors of the extended family, or get together with friends on the second day.\nOne of the most deeply-rooted and curious Christmas traditions is the popular figure of the , consisting of an (often hollow) log with a face painted on it and often two little front legs appended, usually wearing a Catalan hat and scarf. Note that the word has nothing to do with the Spanish word \"t\u00edo\", meaning uncle. \"Ti\u00f3\" means log in Catalan. The log is sometimes \"found in the woods\" (in an event staged for children) and then adopted and taken home, where it is fed and cared for during a month or so. On Christmas Day or on Christmas Eve, a game is played where children march around the house singing a song requesting the log to poop, then they tap the log gently with a stick, as if a magic wand, to make it poop, and lo and behold, as if through magic, it poops candy, and sometimes other small gifts. Usually the larger or main gifts are brought by the Three Kings on 6 January, and the ti\u00f3 only brings small things.\nAnother custom is to make a (nativity scene) in the home or in shop windows, the latter sometimes competing in originality or shear size and detail. Churches often host exhibits of numerous dioramas by nativity scene makers, or a single nativity scene they put out, and town halls generally put out a nativity scene in the central square. In Barcelona, every year, the main nativity scene is designed by different artists, and often ends up being an interesting, post-modern or conceptual and strange creation. In the home, the nativity scene often consists of strips of cork bark to represent cliffs or mountains in the background, moss as grass in the foreground, some wood chips or other as dirt, and aluminum foil for rivers and lakes. The traditional figurines often included are the three wise men on camels or horses, which are moved every day or so to go closer to the manger, a star with a long tail in the background to lead people to the spot, the annunciation with shepherds having a meal and an angel appearing (hanging from something), a washer lady washing clothes in the pond, sheep, ducks, people carrying packages on their backs, a donkey driver with a load of twigs, and atrezzo such as a starry sky, miniature towns placed in the distance, either Oriental-styled or local-looking, a bridge over the river, trees, etc.\nOne of the most astonishing and sui-generis figurines traditionally placed in the nativity scene, to the great glee of children, is the , a person depicted in the act of defecating. This figurine is hidden in some corner of the nativity scene and the game is to detect it. Of course, churches forgo this figurine, and the main nativity scene of Barcelona, for instance, likewise does not feature it. The caganer is so popular it has, together with the ti\u00f3, long been a major part of the Christmas markets, where they come in the guise of your favorite politicians or other famous people, as well as the traditional figures of a Catalan farmer. People often buy a figurine of a caganer in the guise of a famous person they are actually fond of, contrary to what one would imagine, though sometimes people buy a caganer in the guise of someone they dislike, although this means they have to look at them in the home...\nAnother (extended) Christmas tradition is the celebration of the Epiphany on 6 January, which is called \"Reis\", meaning Three Kings Day. This is every important in Catalonia and the Catalan-speaking areas, and families go to watch major parades on the eve of the Epiphany, where they can greet the kings and watch them pass by in pomp and circumstance, on floats and preceded and followed by pages, musicians, dancers, etc. They often give the kings letters with their gift requests, which are collected by the pages. On the next day, the children find the gifts the three kings brought for them.\nIn addition to traditional local Catalan culture, traditions from other parts of Spain can be found as a result of migration from other regions, for instance the celebration of the Andalusian in Catalonia.\nOn 28 July 2010, second only after the Canary Islands, Catalonia became another Spanish territory to forbid bullfighting. The ban, which went into effect on 1 January 2012, had originated in a popular petition supported by over 180,000 signatures.\nMusic and dance.\nThe sardana is considered to be the most characteristic Catalan folk dance, interpreted to the rhythm of tambor\u00ed, tible and tenora (from the oboe family), trumpet, tromb\u00f3 (trombone), fiscorn (family of bugles) and contrabaix with three strings played by a cobla, and are danced in a circle dance. Other tunes and dances of the traditional music are the contrap\u00e0s (obsolete today), ball de bastons (the \"dance of sticks\"), the moixiganga, the goigs (popular songs), the galops or the jota in the southern part. The havaneres are characteristic in some marine localities of the Costa Brava, especially during the summer months when these songs are sung outdoors accompanied by a of burned rum.\nArt music was first developed, up to the nineteenth century and, as in much of Europe, in a liturgical setting, particularly marked by the Escolania de Montserrat. The main Western musical trends have marked these productions, medieval monodies or polyphonies, with the work of Abbot Oliba in the eleventh century or the compilation Llibre Vermell de Montserrat (\"Red Book of Montserrat\") from the fourteenth century. Through the Renaissance there were authors such as Pere Albert Vila, Joan Brudieu or the two Mateu Fletxa (\"The Old\" and \"The Young\"). Baroque had composers like Joan Cererols. The Romantic music was represented by composers such as Fernando Sor, Josep Anselm Clav\u00e9 (father of choir movement in Catalonia and responsible of the music folk reviving) or Felip Pedrell.\nModernisme also expressed in musical terms from the end of the 19th century onwards, mixing folkloric and post-romantic influences, through the works of Isaac Alb\u00e9niz and Enric Granados. The avant-garde spirit initiated by the modernists is prolonged throughout the twentieth century, thanks to the activities of the Orfe\u00f3 Catal\u00e0, a choral society founded in 1891, with its monumental concert hall, the Palau de la M\u00fasica Catalana in Catalan, built by Llu\u00eds Dom\u00e8nech i Montaner from 1905 to 1908, the Barcelona Symphony Orchestra created in 1944 and composers, conductors and musicians engaged against the Francoism like Robert Gerhard, Eduard Toldr\u00e0 and Pau Casals.\nPerformances of opera, mostly imported from Italy, began in the 18th century, but some native operas were written as well, including the ones by Dom\u00e8nec Terradellas, Carles Baguer, Ramon Carles, Isaac Alb\u00e9niz and Enric Granados. The Barcelona main opera house, Gran Teatre del Liceu (opened in 1847), remains one of the most important in Spain, hosting one of the most prestigious music schools in Barcelona, the Conservatori Superior de M\u00fasica del Liceu. Several lyrical artists trained by this institution gained international renown during the 20th century, such as Victoria de los \u00c1ngeles, Montserrat Caball\u00e9, Giacomo Aragall and Josep Carreras.\nCellist Pau Casals is admired as an outstanding player. Other popular musical styles were born in the second half of the 20th century such as Nova Can\u00e7\u00f3 from the 1960s with Llu\u00eds Llach and the group Els Setze Jutges, the Catalan rumba in the 1960s with Peret, Catalan Rock from the late 1970s with La Banda Trapera del R\u00edo and Decibelios for Punk Rock, Sau, Els Pets, Sopa de Cabra or Lax'n'Busto for pop rock or Sangtra\u00eft for hard rock, electropop since the 1990s with OBK and indie pop from the 1990s.\nMedia and cinema.\nCatalonia is the autonomous community, along with Madrid, that has the most media (TV, Magazines, Newspapers etc.). In Catalonia there is a wide variety of local and comarcal media. With the restoration of democracy, many newspapers and magazines, until then in the hands of the Franco government, were recovered in order to convert them into free and democratic media, while local radios and televisions were implemented.\nTelevisi\u00f3 de Catalunya, which broadcasts entirely in the Catalan language, is the main Catalan public TV. It has five channels: TV3, El 33, Super3, 3/24, Esport3 and TV3CAT. In 2018, TV3 became the first television channel to be the most viewed one for nine consecutive years in Catalonia. State televisions that broadcast in Catalonia in Spanish language include Televisi\u00f3n Espa\u00f1ola (with few emissions in Catalan), Antena 3, Cuatro, Telecinco, and La Sexta. Other smaller Catalan television channels include; 8TV (owned by Grup God\u00f3), Bar\u00e7a TV and the local televisions, the greatest exponent of which is , the TV channel of Barcelona, which also broadcasts in Catalan.\nThe two main Catalan newspapers of general information are \"El Peri\u00f3dico de Catalunya\" and \"La Vanguardia\", both with editions in Catalan and Spanish. Catalan only published newspapers include \"Ara\" and \"El Punt Avui\" (from the fusion of \"El Punt\" and \"Avui\" in 2011), as well as most part of the local press. The Spanish newspapers, such as \"El Pa\u00eds\", \"El Mundo\" or \"La Raz\u00f3n\", can be also acquired.\nCatalonia has a long tradition of use of radio, the first regular radio broadcast in the country was from R\u00e0dio Barcelona in 1924. Today, the public Catalunya R\u00e0dio (owned by Catalan Media Corporation) and the private RAC 1 (belonging to Grup God\u00f3) are the two main radios of Catalonia, both in Catalan.\nRegarding the cinema, after the democratic transition, three styles have dominated since then. First, auteur cinema, in the continuity of the Barcelona School, emphasizes experimentation and form, while focusing on developing social and political themes. Worn first by Josep Maria Forn or Bigas Luna, then by Marc Recha, Jaime Rosales and Albert Serra, this genre has achieved some international recognition. Then, the documentary became another genre particularly representative of contemporary Catalan cinema, boosted by Joaquim Jord\u00e0 i Catal\u00e0 and Jos\u00e9 Luis Guer\u00edn. Later, horror films and thrillers have also emerged as a specialty of the Catalan film industry, thanks in particular to the vitality of the Sitges Film Festival, created in 1968. Several directors have gained worldwide renown thanks to this genre, starting with Jaume Balaguer\u00f3 and his series \"REC\" (co-directed with Valencian Paco Plaza), Juan Antonio Bayona and \"El Orfanato\" or Jaume Collet-Serra with \"Orphan\", \"Unknown\" and \"Non-Stop\".\nCatalan actors have shot for Spanish and international productions, such as Sergi L\u00f3pez.\nThe Museum of Cinema - Tom\u00e0s Mallol Collection (Museu del Cinema - Col.lecci\u00f3 Tom\u00e0s Mallol in Catalan) of Girona is home of important permanent exhibitions of cinema and pre-cinema objects. Other important institutions for the promotion of cinema are the Gaud\u00ed Awards (Premis Gaud\u00ed in Catalan, which replaced from 2009 Barcelona Film Awards themselves created in 2002), serving as equivalent for Catalonia to the Spanish Goya or French C\u00e9sar.\nPhilosophy.\n is a form of ancestral Catalan wisdom or sensibleness. It involves well-pondered perception of situations, level-headedness, awareness, integrity, and right action. Many Catalans consider seny something unique to their culture, is based on a set of ancestral local customs stemming from the scale of values and social norms of their society.\nSport.\nSport has a distinct importance in Catalan life and culture since the beginning of the 20th century and consequently, has a well developed sport infrastructure. The main sports are football, basketball, handball, rink hockey, tennis and motorsport.\nDespite the fact that the most popular sports are represented outside by the Spanish national teams, Catalonia can officially play as itself in some others, like korfball, futsal or rugby league. Most of Catalan Sports Federations have a long tradition and some of them participated in the foundation of international sports federations, as the Catalan Federation of Rugby, that was one of the founder members of the F\u00e9d\u00e9ration Internationale de Rugby Amateur (FIRA) in 1934. The majority of Catalan sport federations are part of the Sports Federation Union of Catalonia (Catalan: ), founded in 1933.\nThe Catalan Football Federation also periodically fields a national team against international opposition, organizing friendly matches. In the recent years they have played with Bulgaria, Argentina, Brazil, Basque Country, Colombia, Nigeria, Cape Verde and Tunisia. The biggest football clubs are FC Barcelona (also known as Bar\u00e7a), who have won five European Cups (UEFA Champions League), and RCD Espanyol, who have twice been runner-up of the UEFA Cup. Both play in La Liga.\nThe Catalan waterpolo is one of the main powers of the Iberian Peninsula. The Catalans won triumphs in waterpolo competitions at European and world level by club (the Barcelona was champion of Europe in 1981/82 and the Catalonia in 1994/95) and national team (one gold and one silver in Olympic Games and World Championships). It also has many international synchronized swimming champions.\nMotorsport has a long tradition in Catalonia, which involving many people, with some world champions and several competitions organized since the beginning of the 20th century. The Circuit de Catalunya, built in 1991, is one of the main motorsport venues, holding the Catalan motorcycle Grand Prix, the Spanish F1 Grand Prix, a DTM race, and several other races.\nCatalonia hosted many relevant international sport events, such as the 1992 Summer Olympics in Barcelona, and also the 1955 Mediterranean Games, the 2013 World Aquatics Championships or the 2018 Mediterranean Games. It held annually the fourth-oldest still-existing cycling stage race in the world, the Volta a Catalunya (Tour of Catalonia).\nSymbols.\nCatalonia has its own representative and distinctive national symbols such as:\nCuisine.\nCatalan gastronomy has a long culinary tradition. Various local food recipes have been described in documents dating from the fifteenth century. As with all the cuisines of the Mediterranean, Catatonian dishes make abundant use of fish, seafood, olive oil, bread and vegetables. Regional specialties include the (bread with tomato), which consists of bread (sometimes toasted), and tomato seasoned with olive oil and salt. Often the dish is accompanied with any number of sausages (cured botifarres, fuet, iberic ham, etc.), ham or cheeses. Others dishes include the , , (fish stew), and a dessert, Catalan cream.\nCatalan vineyards also have several wines, such as: Priorat, Montsant, Pened\u00e8s and Empord\u00e0. There is also a sparkling wine, the cava.\nCatalonia is internationally recognized for its fine dining. Three of The World's 50 Best Restaurants are in Catalonia, and four restaurants have three Michelin stars, including restaurants like El Bulli or El Celler de Can Roca, both of which regularly dominate international rankings of restaurants."}
{"id": "6823", "revid": "39152912", "url": "https://en.wikipedia.org/wiki?curid=6823", "title": "Konstantinos Kanaris", "text": "Konstantinos Kanaris, also anglicised as Constantine Kanaris or Canaris (; c. 17902 September 1877), was a Greek admiral, Prime Minister, and a hero of the Greek War of Independence.\nBiography.\nEarly life.\nKonstantinos Kanaris was born and grew up on the island of Psara, close to the island of Chios, in the Aegean. The exact year of his birth is unknown. Official records of the Hellenic Navy indicate 1795, however, modern Greek historians consider 1790 or 1793 to be more probable.\nHe was left an orphan at a young age. Having to support himself, he chose to become a seaman like most members of his family since the beginning of the 18th century. He was subsequently hired as a boy on the brig of his uncle Dimitris Bourekas.\nMilitary career.\nKanaris gained his fame during the Greek War of Independence (1821\u20131829). Unlike most other prominent figures of the War, he had never been initiated into the \"Filiki Eteria\" (Society of Friends), which played a significant role in the uprising against the Ottoman Empire, primarily by secret recruitment of supporters against the Turkish rule.\nBy early 1821, the movement had gained enough support to launch a revolution. This seems to have inspired Kanaris, who was in Odessa at the time. He returned to the island of Psara in haste and was present when it joined the uprising on 10 April 1821.\nThe island formed its own fleet and the famed seamen of Psara, already known for their well-equipped ships and successful combats against sea pirates, proved to be highly effective in naval warfare. Kanaris soon distinguished himself as a fire ship captain.\nAt Chios, on the moonless night of 6\u20137 June 1822, forces under his command destroyed the flagship of the Ottoman admiral Nasuhzade Ali Pasha in revenge for the Chios massacre. The admiral was holding a \"Bayram\" celebration, allowing Kanaris and his men to position their fire ship without being noticed. When the flagship's powder store caught fire, all men aboard were instantly killed. The Turkish casualties comprised men, both naval officers and common sailors, as well as Nasuhzade Ali Pasha himself.\nKanaris led another successful attack against the Ottoman fleet at Tenedos in November 1822. He was famously said to have encouraged himself by murmuring \"Konstant\u00ed, you are going to die\" every time he was approaching a Turkish warship on the fire boat he was about to detonate.\nThe Ottoman fleet captured Psara on 21 June 1824. A part of the population, including Kanaris, managed to flee the island, but those who didn't were either sold into slavery or slaughtered. After the destruction of his home island, he continued to lead attacks against Turkish forces. In August 1824, he engaged in naval combats in the Dodecanese.\nThe following year, Kanaris led the Greek raid on Alexandria, a daring attempt to destroy the Egyptian fleet with fire ships that might have been successful if the wind had not failed just after the Greek ships entered Alexandria harbour.\nAfter the end of the War and the independence of Greece, Kanaris became an officer of the new Greek Navy, reaching the rank of admiral, and became a prominent politician.\nPolitical career.\nKonstantinos Kanaris was one of the few with the personal confidence of Ioannis Kapodistrias, the first Head of State of independent Greece. After the assassination of Kapodistrias on 9 October 1831, he retired to the island of Syros.\nDuring the reign of King Otto I, Kanaris served as Minister in various governments and then as Prime Minister in the provisional government (16 February30 March 1844). He served a second term (15 October 184812 December 1849), and as Navy Minister in Alexandros Mavrokordatos' 1854 cabinet.\nIn 1862, he was among the rare War of Independence veterans who took part in the bloodless insurrection that deposed the increasingly unpopular King Otto I and led to the election of Prince William of Denmark as King George I of Greece. During his reign, Kanaris served as a Prime Minister for a third term (6 March16 April 1864), fourth term (26 July 186426 February 1865) and fifth and last term (7 June2 September 1877).\nKanaris died on 2 September 1877 whilst still serving in office as Prime Minister. Following his death his government remained in power until 14 September 1877 without agreeing on a replacement at its head. He was buried in the First Cemetery of Athens, where most Greek prime ministers and celebrated figures are also buried. After his death he was honoured as a national hero.\nFamily.\nIn 1817, Konstantinos Kanaris married Despoina Maniatis, from a historical family of Psara. They had seven children:\nWilhelm Canaris, a German Admiral, speculated that he might be a descendant of Konstantinos Kanaris. An official genealogical family history that was researched in 1938 showed however, that he was of Italian descent and not related to the Kanaris family from Greece.\nHonours.\nEponyms.\nTo honour Kanaris, the following ships of the Hellenic Navy have been named after him:\nExternal links.\n \n \n \n \n "}
{"id": "6824", "revid": "4796325", "url": "https://en.wikipedia.org/wiki?curid=6824", "title": "Carl Sagan", "text": "Carl Edward Sagan (; November 9, 1934December 20, 1996) was an American astronomer, planetary scientist, cosmologist, astrophysicist, astrobiologist, author, and science communicator. His best known scientific contribution is research on extraterrestrial life, including experimental demonstration of the production of amino acids from basic chemicals by radiation. Sagan assembled the first physical messages sent into space: the Pioneer plaque and the Voyager Golden Record, universal messages that could potentially be understood by any extraterrestrial intelligence that might find them. Sagan argued the now-accepted hypothesis that the high surface temperatures of Venus can be attributed to and calculated using the greenhouse effect.\nInitially an associate professor at Harvard and later at Cornell, from 1976 to his death, he was the David Duncan Professor of Astronomy and Space Sciences at the latter. Sagan published more than 600 scientific papers and articles and was author, co-author or editor of more than 20 books. He wrote many popular science books, such as \"The Dragons of Eden\", Cosmos, \"Broca's Brain\" and \"Pale Blue Dot\", and narrated and co-wrote the award-winning 1980 television series \"\". The most widely watched series in the history of American public television, \"Cosmos\" has been seen by at least 500 million people across 60 different countries. The book \"Cosmos\" was published to accompany the series. He also wrote the science fiction novel \"Contact\", the basis for a 1997 film of the same name. His papers, containing 595,000 items, are archived at The Library of Congress.\nSagan advocated scientific skeptical inquiry and the scientific method, pioneered exobiology and promoted the Search for Extra-Terrestrial Intelligence (SETI). He spent most of his career as a professor of astronomy at Cornell University, where he directed the Laboratory for Planetary Studies. Sagan and his works received numerous awards and honors, including the NASA Distinguished Public Service Medal, the National Academy of Sciences Public Welfare Medal, the Pulitzer Prize for General Non-Fiction for his book \"The Dragons of Eden\", and, regarding \"Cosmos: A Personal Voyage\", two Emmy Awards, the Peabody Award, and the Hugo Award. He married three times and had five children. After suffering from myelodysplasia, Sagan died of pneumonia at the age of 62, on December 20, 1996.\nEarly life and education.\nCarl Sagan was born in the Bensonhurst neighborhood of Brooklyn, New York on November 9, 1934. His father, Samuel Sagan, was an immigrant garment worker from Kamianets-Podilskyi, then in the Russian Empire, in today's Ukraine. His mother, Rachel Molly Gruber, was a housewife from New York. Carl was named in honor of Rachel's biological mother, Chaiya Clara, in Sagan's words, \"the mother she never knew\", because she passed while giving birth to her second child. Samuel remarried to a woman named Rose. According to Carl, Carol (his sister) \"never accepted Rose as her mother. She knew she wasn't her birth mother... She was a rather rebellious child and young adult ... `emancipated woman,' we'd call her now.\"\nThe family lived in a modest apartment near the Atlantic Ocean, in Bensonhurst, a Brooklyn neighborhood. According to Sagan, they were Reform Jews, the most liberal of North American Judaism's four main groups. Carl and his sister agreed that their father was not especially religious, but that their mother \"definitely believed in God, and was active in the temple; ... and served only kosher meat\". During the depths of the Depression, his father worked as a theater usher.\nAccording to biographer Keay Davidson, Sagan's \"inner war\" was a result of his close relationship with both of his parents, who were in many ways \"opposites\". Sagan traced his later analytical urges to his mother, a woman who had been extremely poor as a child in New York City during World War I and the 1920s. As a young woman, she had held her own intellectual ambitions, but they were frustrated by social restrictions: her poverty, her status as a woman and a wife, and her Jewish ethnicity. Davidson notes that she therefore \"worshipped her only son, Carl. He would fulfill her unfulfilled dreams.\"\nHowever, he claimed that his sense of wonder came from his father, who in his free time gave apples to the poor or helped soothe labor-management tensions within New York's garment industry. Although he was awed by Carl's intellectual abilities, he took his son's inquisitiveness in stride and saw it as part of his growing up. In his later years as a writer and scientist, Sagan would often draw on his childhood memories to illustrate scientific points, as he did in his book \"Shadows of Forgotten Ancestors\". Sagan describes his parents' influence on his later thinking:\nSagan recalls that one of his most defining moments was when his parents took him to the 1939 New York World's Fair when he was four years old. The exhibits became a turning point in his life. He later recalled the moving map of the \"America of Tomorrow\" exhibit: \"It showed beautiful highways and cloverleaves and little General Motors cars all carrying people to skyscrapers, buildings with lovely spires, flying buttresses\u2014and it looked great!\" At other exhibits, he remembered how a flashlight that shone on a photoelectric cell created a crackling sound, and how the sound from a tuning fork became a wave on an oscilloscope. He also witnessed the future media technology that would replace radio: television. Sagan wrote:\nHe also saw one of the Fair's most publicized events, the burial of a time capsule at Flushing Meadows, which contained mementos of the 1930s to be recovered by Earth's descendants in a future millennium. \"The time capsule thrilled Carl\", writes Davidson. As an adult, Sagan and his colleagues would create similar time capsules\u2014capsules that would be sent out into the galaxy; these were the Pioneer plaque and the \"Voyager Golden Record\" pr\u00e9cis, all of which were spinoffs of Sagan's memories of the World's Fair.\nDuring World War\u00a0II Sagan's family worried about the fate of their European relatives. Sagan, however, was generally unaware of the details of the ongoing war. He wrote, \"Sure, we had relatives who were caught up in the Holocaust. Hitler was not a popular fellow in our household... But on the other hand, I was fairly insulated from the horrors of the war.\" His sister, Carol, said that their mother \"above all wanted to protect Carl... She had an extraordinarily difficult time dealing with World War\u00a0II and the Holocaust.\" Sagan's book \"The Demon-Haunted World\" (1996) included his memories of this conflicted period, when his family dealt with the realities of the war in Europe but tried to prevent it from undermining his optimistic spirit.\nInquisitiveness about nature.\nSoon after entering elementary school he began to express a strong inquisitiveness about nature. Sagan recalled taking his first trips to the public library alone, at the age of five, when his mother got him a library card. He wanted to learn what stars were, since none of his friends or their parents could give him a clear answer:\nAt about age six or seven, he and a close friend took trips to the American Museum of Natural History across the East River in Manhattan. While there, they went to the Hayden Planetarium and walked around the museum's exhibits of space objects, such as meteorites, and displays of dinosaurs and animals in natural settings. Sagan writes about those visits:\nHis parents helped nurture his growing interest in science by buying him chemistry sets and reading materials. His interest in space, however, was his primary focus, especially after reading science fiction stories by writers such as H. G. Wells and Edgar Rice Burroughs, which stirred his imagination about life on other planets such as Mars. According to biographer Ray Spangenburg, these early years as Sagan tried to understand the mysteries of the planets became a \"driving force in his life, a continual spark to his intellect, and a quest that would never be forgotten\".\nIn 1947 he discovered \"Astounding Science Fiction\" magazine, which introduced him to more hard science fiction speculations than those in Burroughs's novels. That same year inaugurated the \"flying saucer\" mass hysteria with the young Carl suspecting that the \"discs\" might be alien spaceships.\nHigh-school years.\nSagan had lived in Bensonhurst, where he went to David A. Boody Junior High School. He had his bar mitzvah in Bensonhurst when he turned 13. The following year, 1948, his family moved to the nearby town of Rahway, New Jersey, for his father's work, where Sagan then entered Rahway High School. He graduated in 1951. Rahway was an older industrial town, and the Sagans were among its few Jewish families.\nSagan was a straight-A student but was bored due to unchallenging classes and uninspiring teachers. His teachers realized this and tried to convince his parents to send him to a private school, the administrator telling them, \"This kid ought to go to a school for gifted children, he has something really remarkable.\" However, his parents could not afford it.\nSagan was made president of the school's chemistry club, and at home he set up his own laboratory. He taught himself about molecules by making cardboard cutouts to help him visualize how molecules were formed: \"I found that about as interesting as doing [chemical] experiments\", he said. Sagan remained mostly interested in astronomy as a hobby, and in his junior year made it a career goal after he learned that astronomers were paid for doing what he always enjoyed: \"That was a splendid day\u2014when I began to suspect that if I tried hard I could do astronomy full-time, not just part-time.\"\nBefore the end of high school, he entered an essay contest in which he posed the question of whether human contact with advanced life forms from another planet might be as disastrous for people on Earth as it was for Native Americans when they first had contact with Europeans. The subject was considered controversial, but his rhetorical skill won over the judges, and they awarded him first prize. By graduation, his classmates had voted him \"most likely to succeed\" and put him in line to be valedictorian.\nUniversity education.\nSagan attended the University of Chicago, which was one of the few colleges he applied to that would, despite his excellent high-school grades, consider admitting a 16-year-old. Its chancellor, Robert Maynard Hutchins, had recently retooled the undergraduate College of the University of Chicago into an \"ideal meritocracy\" built on Great Books, Socratic dialogue, comprehensive examinations and early entrance to college with no age requirement. The school also employed a number of the nation's leading scientists, including Enrico Fermi and Edward Teller, along with operating the famous Yerkes Observatory.\nDuring his time as an honors program undergraduate, Sagan worked in the laboratory of the geneticist H. J. Muller and wrote a thesis on the origins of life with physical chemist Harold Urey. Sagan joined the Ryerson Astronomical Society, received a B.A. degree in laughingly self-proclaimed \"nothing\" with general and special honors in 1954, and a B.S. degree in physics in 1955. He went on to earn a M.S. degree in physics in 1956, before earning a Ph.D. degree in 1960 with his thesis \"Physical Studies of Planets\" submitted to the Department of Astronomy and Astrophysics.\nHe used the summer months of his graduate studies to work with his dissertation director, planetary scientist Gerard Kuiper, as well as physicist George Gamow and chemist Melvin Calvin. The title of Sagan's dissertation reflects his shared interests with Kuiper, who throughout the 1950s had been president of the International Astronomical Union's commission on \"Physical Studies of Planets and Satellites\". In 1958, the two worked on the classified military Project A119, the secret Air Force plan to detonate a nuclear warhead on the Moon.\nSagan had a Top Secret clearance at the U.S. Air Force and a Secret clearance with NASA. While working on his doctoral dissertation, Sagan revealed US Government classified titles of two Project A119 papers when he applied for a University of California, Berkeley scholarship in 1959. The leak was not publicly revealed until 1999, when it was published in the journal \"Nature\". A follow-up letter to the journal by project leader Leonard Reiffel confirmed Sagan's security leak.\nCareer and research.\nFrom 1960 to 1962 Sagan was a Miller Fellow at the University of California, Berkeley. Meanwhile, he published an article in 1961 in the journal \"Science\" on the atmosphere of Venus, while also working with NASA's Mariner 2 team, and served as a \"Planetary Sciences Consultant\" to the RAND Corporation.\nAfter the publication of Sagan's \"Science\" article, in 1961 Harvard University astronomers Fred Whipple and Donald Menzel offered Sagan the opportunity to give a colloquium at Harvard and subsequently offered him a lecturer position at the institution. Sagan instead asked to be made an assistant professor, and eventually Whipple and Menzel were able to convince Harvard to offer Sagan the assistant professor position he requested. Sagan lectured, performed research, and advised graduate students at the institution from 1963 until 1968, as well as working at the Smithsonian Astrophysical Observatory, also located in Cambridge, Massachusetts.\nIn 1968, Sagan was denied tenure at Harvard. He later indicated that the decision was very much unexpected. The tenure denial has been blamed on several factors, including that he focused his interests too broadly across a number of areas (while the norm in academia is to become a renowned expert in a narrow specialty), and perhaps because of his well-publicized scientific advocacy, which some scientists perceived as borrowing the ideas of others for little more than self-promotion. An advisor from his years as an undergraduate student, Harold Urey, wrote a letter to the tenure committee recommending strongly against tenure for Sagan.\nLong before the ill-fated tenure process, Cornell University astronomer Thomas Gold had courted Sagan to move to Ithaca, New York, and join the faculty at Cornell. Following the denial of tenure from Harvard, Sagan accepted Gold's offer and remained a faculty member at Cornell for nearly 30 years until his death in 1996. Unlike Harvard, the smaller and more laid-back astronomy department at Cornell welcomed Sagan's growing celebrity status. Following two years as an associate professor, Sagan became a full professor at Cornell in 1970 and directed the Laboratory for Planetary Studies there. From 1972 to 1981, he was associate director of the Center for Radiophysics and Space Research (CRSR) at Cornell. In 1976, he became the David Duncan Professor of Astronomy and Space Sciences, a position he held for the remainder of his life.\nSagan was associated with the U.S. space program from its inception. From the 1950s onward, he worked as an advisor to NASA, where one of his duties included briefing the Apollo astronauts before their flights to the Moon. Sagan contributed to many of the robotic spacecraft missions that explored the Solar System, arranging experiments on many of the expeditions. Sagan assembled the first physical message that was sent into space: a gold-plated plaque, attached to the space probe \"Pioneer\u00a010\", launched in 1972. \"Pioneer\u00a011\", also carrying another copy of the plaque, was launched the following year. He continued to refine his designs; the most elaborate message he helped to develop and assemble was the Voyager Golden Record, which was sent out with the Voyager space probes in 1977. Sagan often challenged the decisions to fund the Space Shuttle and the International Space Station at the expense of further robotic missions.\nScientific achievements.\nFormer student David Morrison described Sagan as \"an 'idea person' and a master of intuitive physical arguments and 'back of the envelope' calculations\", and Gerard Kuiper said that \"Some persons work best in specializing on a major program in the laboratory; others are best in liaison between sciences. Dr. Sagan belongs in the latter group.\"\nSagan's contributions were central to the discovery of the high surface temperatures of the planet Venus. In the early 1960s no one knew for certain the basic conditions of Venus' surface, and Sagan listed the possibilities in a report later depicted for popularization in a Time Life book \"Planets\". His own view was that Venus was dry and very hot as opposed to the balmy paradise others had imagined. He had investigated radio waves from Venus and concluded that there was a surface temperature of . As a visiting scientist to NASA's Jet Propulsion Laboratory, he contributed to the first Mariner missions to Venus, working on the design and management of the project. Mariner 2 confirmed his conclusions on the surface conditions of Venus in 1962.\nSagan was among the first to hypothesize that Saturn's moon Titan might possess oceans of liquid compounds on its surface and that Jupiter's moon Europa might possess subsurface oceans of water. This would make Europa potentially habitable. Europa's subsurface ocean of water was later indirectly confirmed by the spacecraft \"Galileo\". The mystery of Titan's reddish haze was also solved with Sagan's help. The reddish haze was revealed to be due to complex organic molecules constantly raining down onto Titan's surface.\nSagan further contributed insights regarding the atmospheres of Venus and Jupiter, as well as seasonal changes on Mars. He also perceived global warming as a growing, man-made danger and likened it to the natural development of Venus into a hot, life-hostile planet through a kind of runaway greenhouse effect. Sagan and his Cornell colleague Edwin Ernest Salpeter speculated about life in Jupiter's clouds, given the planet's dense atmospheric composition rich in organic molecules. He studied the observed color variations on Mars' surface and concluded that they were not seasonal or vegetational changes as most believed, but shifts in surface dust caused by windstorms.\nSagan is also known for his research on the possibilities of extraterrestrial life, including experimental demonstration of the production of amino acids from basic chemicals by radiation.\nHe is also the 1994 recipient of the Public Welfare Medal, the highest award of the National Academy of Sciences for \"distinguished contributions in the application of science to the public welfare\". He was denied membership in the Academy, reportedly because his media activities made him unpopular with many other scientists.\n, Sagan is the most cited SETI scientist and one of the most cited planetary scientists.\n\"Cosmos\": popularizing science on TV.\nIn 1980 Sagan co-wrote and narrated the award-winning 13-part PBS television series \"\", which became the most widely watched series in the history of American public television until 1990. The show has been seen by at least 500 million people across 60 countries. The book, \"Cosmos\", written by Sagan, was published to accompany the series.\nBecause of his earlier popularity as a science writer from his best-selling books, including \"The Dragons of Eden\", which won him a Pulitzer Prize in 1977, he was asked to write and narrate the show. It was targeted to a general audience of viewers, whom Sagan felt had lost interest in science, partly due to a stifled educational system.\nEach of the 13 episodes was created to focus on a particular subject or person, thereby demonstrating the synergy of the universe. They covered a wide range of scientific subjects including the origin of life and a perspective of humans' place on Earth.\nThe show won an Emmy, along with a Peabody Award, and transformed Sagan from an obscure astronomer into a pop-culture icon. \"Time\" magazine ran a cover story about Sagan soon after the show broadcast, referring to him as \"creator, chief writer and host-narrator of the show\". In 2000, \"Cosmos\" was released on a remastered set of DVDs.\n\"Billions and billions\".\nSagan was invited to frequent appearances on \"The Tonight Show Starring Johnny Carson\".\nAfter \"Cosmos\" aired, he became associated with the catchphrase \"billions and billions\", although he never actually used the phrase in the \"Cosmos\" series. He rather used the term \"billions \"upon\" billions\". Carson, however, would sometimes use the phrase during his parodies of Sagan.\nAs a humorous tribute to Sagan and his association with the catchphrase \"billions and billions\", a \"sagan\" has been defined as a unit of measurement equivalent to a very large number\u00a0\u2013 technically at least four billion (two billion plus two billion)\u00a0\u2013 of anything.\nScientific and critical thinking advocacy.\nSagan's ability to convey his ideas allowed many people to understand the cosmos better\u2014simultaneously emphasizing the value and worthiness of the human race, and the relative insignificance of the Earth in comparison to the Universe. He delivered the 1977 series of Royal Institution Christmas Lectures in London.\nSagan was a proponent of the search for extraterrestrial life. He urged the scientific community to listen with radio telescopes for signals from potential intelligent extraterrestrial life-forms. Sagan was so persuasive that by 1982 he was able to get a petition advocating SETI published in the journal \"Science\", signed by 70 scientists, including seven Nobel Prize winners. This signaled a tremendous increase in the respectability of a then-controversial field. Sagan also helped Frank Drake write the Arecibo message, a radio message beamed into space from the Arecibo radio telescope on November 16, 1974, aimed at informing potential extraterrestrials about Earth.\nSagan was chief technology officer of the professional planetary research journal \"Icarus\" for 12 years. He co-founded The Planetary Society and was a member of the SETI Institute Board of Trustees. Sagan served as Chairman of the Division for Planetary Science of the American Astronomical Society, as President of the Planetology Section of the American Geophysical Union, and as Chairman of the Astronomy Section of the American Association for the Advancement of Science (AAAS).\nAt the height of the Cold War, Sagan became involved in nuclear disarmament efforts by promoting hypotheses on the effects of nuclear war, when Paul Crutzen's \"Twilight at Noon\" concept suggested that a substantial nuclear exchange could trigger a nuclear twilight and upset the delicate balance of life on Earth by cooling the surface. In 1983 he was one of five authors\u2014the \"S\"\u2014in the follow-up \"TTAPS\" model (as the research article came to be known), which contained the first use of the term \"nuclear winter\", which his colleague Richard P. Turco had coined. In 1984 he co-authored the book \"\" and in 1990 the book \"A Path Where No Man Thought: Nuclear Winter and the End of the Arms Race\", which explains the nuclear-winter hypothesis and advocates nuclear disarmament. Sagan received a great deal of skepticism and disdain for the use of media to disseminate a very uncertain hypothesis. A personal correspondence with nuclear physicist Edward Teller around 1983 began amicably, with Teller expressing support for continued research to ascertain the credibility of the winter hypothesis. However, Sagan and Teller's correspondence would ultimately result in Teller writing: \"A propagandist is one who uses incomplete information to produce maximum persuasion. I can compliment you on being, indeed, an excellent propagandist, remembering that a propagandist is the better the less he appears to be one\". Biographers of Sagan would also comment that from a scientific viewpoint, nuclear winter was a low point for Sagan, although, politically speaking, it popularized his image amongst the public.\nThe adult Sagan remained a fan of science fiction, although disliking stories that were not realistic (such as ignoring the inverse-square law) or, he said, did not include \"thoughtful pursuit of alternative futures\". He wrote books to popularize science, such as \"Cosmos\", which reflected and expanded upon some of the themes of \"A Personal Voyage\" and became the best-selling science book ever published in English; \"The Dragons of Eden: Speculations on the Evolution of Human Intelligence\", which won a Pulitzer Prize; and \"Broca's Brain: Reflections on the Romance of Science\". Sagan also wrote the best-selling science fiction novel \"Contact\" in 1985, based on a film treatment he wrote with his wife, Ann Druyan, in 1979, but he did not live to see the book's 1997 motion-picture adaptation, which starred Jodie Foster and won the 1998 Hugo Award for Best Dramatic Presentation.\nSagan wrote a sequel to \"Cosmos\", \"Pale Blue Dot: A Vision of the Human Future in Space\", which was selected as a notable book of 1995 by \"The New York Times\". He appeared on PBS's \"Charlie Rose\" program in January 1995. Sagan also wrote the introduction for Stephen Hawking's bestseller \"A Brief History of Time\". Sagan was also known for his popularization of science, his efforts to increase scientific understanding among the general public, and his positions in favor of scientific skepticism and against pseudoscience, such as his debunking of the Betty and Barney Hill abduction. To mark the tenth anniversary of Sagan's death, David Morrison, a former student of Sagan, recalled \"Sagan's immense contributions to planetary research, the public understanding of science, and the skeptical movement\" in \"Skeptical Inquirer\".\nFollowing Saddam Hussein's threats to light Kuwait's oil wells on fire in response to any physical challenge to Iraqi control of the oil assets, Sagan together with his \"TTAPS\" colleagues and Paul Crutzen, warned in January 1991 in \"The Baltimore Sun\" and \"Wilmington Morning Star\" newspapers that if the fires were left to burn over a period of several months, enough smoke from the 600 or so 1991 Kuwaiti oil fires \"might get so high as to disrupt agriculture in much of South Asia\u00a0...\" and that this possibility should \"affect the war plans\"; these claims were also the subject of a televised debate between Sagan and physicist Fred Singer on January 22, aired on the ABC News program \"Nightline\". In the televised debate, Sagan argued that the effects of the smoke would be similar to the effects of a nuclear winter, with Singer arguing to the contrary. After the debate, the fires burnt for many months before extinguishing efforts were complete. The results of the smoke did not produce continental-sized cooling. Sagan later conceded in \"The Demon-Haunted World\" that the prediction did not turn out to be correct: \"it \"was\" pitch black at noon and temperatures dropped 4\u20136\u00a0\u00b0C over the Persian Gulf, but not much smoke reached stratospheric altitudes and Asia was spared\".\nIn his later years Sagan advocated the creation of an organized search for asteroids/near-Earth objects (NEOs) that might impact the Earth but to forestall or postpone developing the technological methods that would be needed to defend against them. He argued that all of the numerous methods proposed to alter the orbit of an asteroid, including the employment of nuclear detonations, created a deflection dilemma: if the ability to deflect an asteroid away from the Earth exists, then one would also have the ability to divert a non-threatening object towards Earth, creating an immensely destructive weapon. In a 1994 paper he co-authored, he ridiculed a 3-day long \"Near-Earth Object Interception Workshop\" held by Los Alamos National Laboratory (LANL) in 1993 that did not, \"even in passing\" state that such interception and deflection technologies could have these \"ancillary dangers\".\nSagan remained hopeful that the natural NEO impact threat and the intrinsically double-edged essence of the methods to prevent these threats would serve as a \"new and potent motivation to maturing international relations\". Later acknowledging that, with sufficient international oversight, in the future a \"work our way up\" approach to implementing nuclear explosive deflection methods could be fielded, and when sufficient knowledge was gained, to use them to aid in mining asteroids. His interest in the use of nuclear detonations in space grew out of his work in 1958 for the Armour Research Foundation's Project A119, concerning the possibility of detonating a nuclear device on the lunar surface.\nSagan was a critic of Plato, having said of the ancient Greek philosopher: \"Science and mathematics were to be removed from the hands of the merchants and the artisans. This tendency found its most effective advocate in a follower of Pythagoras named Plato\" and\nHe (Plato) believed that ideas were far more real than the natural world. He advised the astronomers not to waste their time observing the stars and planets. It was better, he believed, just to think about them. Plato expressed hostility to observation and experiment. He taught contempt for the real world and disdain for the practical application of scientific knowledge. Plato's followers succeeded in extinguishing the light of science and experiment that had been kindled by Democritus and the other Ionians.\nSagan popularized a set of tools for skeptical thinking first coined by friend Arthur Felberbaum called the \"baloney detection kit\".\nPopularizing science.\nSpeaking about his activities in popularizing science, Sagan said that there were at least two reasons for scientists to share the purposes of science and its contemporary state. Simple self-interest was one: much of the funding for science came from the public, and the public therefore had the right to know how the money was being spent. If scientists increased public admiration for science, there was a good chance of having more public supporters. The other reason was the excitement of communicating one's own excitement about science to others.\nFollowing the success of \"Cosmos\", Sagan set up his own publishing firm, Cosmos Store, in order to publish science books for the general public. It was not successful.\nCriticisms.\nWhile Sagan was widely adored by the general public, his reputation in the scientific community was more polarized. Critics sometimes characterized his work as fanciful, non-rigorous, and self-aggrandizing, and others complained in his later years that he neglected his role as a faculty member to foster his celebrity status.\nOne of Sagan's harshest critics, Harold Urey, felt that Sagan was getting too much publicity for a scientist and was treating some scientific theories too casually. Urey and Sagan were said to have different philosophies of science, according to Davidson. While Urey was an \"old-time empiricist\" who avoided theorizing about the unknown, Sagan was by contrast willing to speculate openly about such matters. Fred Whipple wanted Harvard to keep Sagan there, but learned that because Urey was a Nobel laureate, his opinion was an important factor in Harvard denying Sagan tenure.\nSagan's Harvard friend Lester Grinspoon also stated: \"I know Harvard well enough to know there are people there who certainly do not like people who are outspoken.\" Grinspoon added:\nSome, like Urey, later came to realize that Sagan's popular brand of scientific advocacy was beneficial to the science as a whole. Urey especially liked Sagan's 1977 book \"The Dragons of Eden\" and wrote Sagan with his opinion: \"I like it very much and am amazed that someone like you has such an intimate knowledge of the various features of the problem... I congratulate you... You are a man of many talents.\"\nSagan was accused of borrowing some ideas of others for his own benefit and countered these claims by explaining that the misappropriation was an unfortunate side effect of his role as a science communicator and explainer, and that he attempted to give proper credit whenever possible.\nSocial concerns.\nSagan believed that the Drake equation, on substitution of reasonable estimates, suggested that a large number of extraterrestrial civilizations would form, but that the lack of evidence of such civilizations highlighted by the Fermi paradox suggests technological civilizations tend to self-destruct. This stimulated his interest in identifying and publicizing ways that humanity could destroy itself, with the hope of avoiding such a cataclysm and eventually becoming a spacefaring species. Sagan's deep concern regarding the potential destruction of human civilization in a nuclear holocaust was conveyed in a memorable cinematic sequence in the final episode of \"Cosmos\", called \"Who Speaks for Earth?\" Sagan had already resigned from the Air Force Scientific Advisory Board's UFO investigating Condon Committee and voluntarily surrendered his top-secret clearance in protest over the Vietnam War. Following his marriage to his third wife (novelist Ann Druyan) in June 1981, Sagan became more politically active\u2014particularly in opposing escalation of the nuclear arms race under President Ronald Reagan.\nIn March 1983, Reagan announced the Strategic Defense Initiative\u2014a multibillion-dollar project to develop a comprehensive defense against attack by nuclear missiles, which was quickly dubbed the \"Star Wars\" program. Sagan spoke out against the project, arguing that it was technically impossible to develop a system with the level of perfection required, and far more expensive to build such a system than it would be for an enemy to defeat it through decoys and other means\u2014and that its construction would seriously destabilize the \"nuclear balance\" between the United States and the Soviet Union, making further progress toward nuclear disarmament impossible.\nWhen Soviet leader Mikhail Gorbachev declared a unilateral moratorium on the testing of nuclear weapons, which would begin on August 6, 1985\u2014the 40th\u00a0anniversary of the atomic bombing of Hiroshima\u2014the Reagan administration dismissed the dramatic move as nothing more than propaganda and refused to follow suit. In response, US anti-nuclear and peace activists staged a series of protest actions at the Nevada Test Site, beginning on Easter Sunday in 1986 and continuing through 1987. Hundreds of people in the \"Nevada Desert Experience\" group were arrested, including Sagan, who was arrested on two separate occasions as he climbed over a chain-link fence at the test site during the underground Operation Charioteer and United States's Musketeer nuclear test series of detonations.\nSagan was also a vocal advocate of the controversial notion of testosterone poisoning, arguing in 1992 that human males could become gripped by an \"unusually severe [case of] testosterone poisoning\" and this could compel them to become genocidal. In his review of Moondance magazine writer Daniela Gioseffi's 1990 book \"Women on War\", he argues that females are the only half of humanity \"untainted by testosterone poisoning\". One chapter of his 1993 book \"Shadows of Forgotten Ancestors\" is dedicated to testosterone and its alleged poisonous effects.\nIn 1989, Carl Sagan was interviewed by Ted Turner whether he believed in socialism and responded that: \"I'm not sure what a socialist is. But I believe the government has a responsibility to care for the people... I'm talking about making the people self-reliant.\"\nPersonal life and beliefs.\nSagan was married three times. In 1957, he married biologist Lynn Margulis. The couple had two children, Jeremy and Dorion Sagan. After Sagan and Margulis divorced, he married artist Linda Salzman in 1968 and they also had a child together, Nick Sagan. During these marriages, Carl Sagan focused heavily on his career, a factor which may have contributed to Sagan's first divorce. In 1981, Sagan married author Ann Druyan and they later had two children, Alexandra (known as Sasha) and Samuel Sagan. Carl Sagan and Druyan remained married until his death in 1996.\nWhile teaching at Cornell, he lived in an Egyptian revival house in Ithaca perched on the edge of a cliff that had formerly been the headquarters of a Cornell secret society. While there he drove a purple 1970 Porsche 911 with the license plate PHOBOS. He also owned an orange Porsche 914.\nIn 2019, Carl Sagan's daughter Sasha Sagan released \"For Small Creatures Such as We: Rituals for Finding Meaning in our Unlikely World\", which depicts life with her parents and her father's death when she was fourteen. Building on a theme in her father's work, Sasha Sagan argues in \"For Small Creatures Such as We\" that skepticism does not imply pessimism.\nSagan was acquainted with the science fiction fandom through his friendship with Isaac Asimov, and he spoke at the Nebula Awards ceremony in 1969. Asimov described Sagan as one of only two people he ever met whose intellect surpassed his own. The other, he claimed, was the computer scientist and artificial intelligence expert Marvin Minsky.\nNaturalism.\nSagan wrote frequently about religion and the relationship between religion and science, expressing his skepticism about the conventional conceptualization of God as a sapient being. For example: Some people think God is an outsized, light-skinned male with a long white beard, sitting on a throne somewhere up there in the sky, busily tallying the fall of every sparrow. Others\u2014for example Baruch Spinoza and Albert Einstein\u2014considered God to be essentially the sum total of the physical laws which describe the universe. I do not know of any compelling evidence for anthropomorphic patriarchs controlling human destiny from some hidden celestial vantage point, but it would be madness to deny the existence of physical laws.\nIn another description of his view on the concept of God, Sagan wrote: The idea that God is an oversized white male with a flowing beard who sits in the sky and tallies the fall of every sparrow is ludicrous. But if by God one means the set of physical laws that govern the universe, then clearly there is such a God. This God is emotionally unsatisfying\u00a0... it does not make much sense to pray to the law of gravity.\nOn atheism, Sagan commented in 1981: An atheist is someone who is certain that God does not exist, someone who has compelling evidence against the existence of God. I know of no such compelling evidence. Because God can be relegated to remote times and places and to ultimate causes, we would have to know a great deal more about the universe than we do now to be sure that no such God exists. To be certain of the existence of God and to be certain of the nonexistence of God seem to me to be the confident extremes in a subject so riddled with doubt and uncertainty as to inspire very little confidence indeed.\nSagan also commented on Christianity and the Jefferson Bible, stating \"My long-time view about Christianity is that it represents an amalgam of two seemingly immiscible parts, the religion of Jesus and the religion of Paul. Thomas Jefferson attempted to excise the Pauline parts of the New Testament. There wasn't much left when he was done, but it was an inspiring document.\"\nRegarding spirituality and its relationship with science, Sagan stated: 'Spirit' comes from the Latin word 'to breathe'. What we breathe is air, which is certainly matter, however thin. Despite usage to the contrary, there is no necessary implication in the word 'spiritual' that we are talking of anything other than matter (including the matter of which the brain is made), or anything\noutside the realm of science. On occasion, I will feel free to use the word. Science is not only compatible with spirituality; it is a profound source of spirituality. When we recognize our place in an immensity of light-years and in the passage of ages, when we grasp the intricacy, beauty, and subtlety of life, then that soaring feeling, that sense of elation and humility combined, is surely spiritual.\nAn environmental appeal, \"Preserving and Cherishing the Earth\", signed by Sagan with other noted scientists in January 1990, stated that \"The historical record makes clear that religious teaching, example, and leadership are powerfully able to influence personal conduct and commitment... Thus, there is a vital role for religion and science.\"\nIn reply to a question in 1996 about his religious beliefs, Sagan answered, \"I'm agnostic.\" Sagan maintained that the idea of a creator God of the Universe was difficult to prove or disprove and that the only conceivable scientific discovery that could challenge it would be an infinitely old universe. Sagan's views on religion have been interpreted as a form of pantheism comparable to Einstein's belief in Spinoza's God. His son, Dorion Sagan said, \"My father believed in the God of Spinoza and Einstein, God not behind nature but as nature, equivalent to it.\" His last wife, Ann Druyan, stated: When my husband died, because he was so famous and known for not being a believer, many people would come up to me\u2014it still sometimes happens\u2014and ask me if Carl changed at the end and converted to a belief in an afterlife. They also frequently ask me if I think I will see him again. Carl faced his death with unflagging courage and never sought refuge in illusions. The tragedy was that we knew we would never see each other again. I don't ever expect to be reunited with Carl.\nIn 2006, Ann Druyan edited Sagan's 1985 Glasgow \"Gifford Lectures in Natural Theology\" into a book, \"\", in which he elaborates on his views of divinity in the natural world.\nSagan is also widely regarded as a freethinker or skeptic; one of his most famous quotations, in \"Cosmos\", was, \"Extraordinary claims require extraordinary evidence\" (called the \"Sagan standard\" by some). This was based on a nearly identical statement by fellow founder of the Committee for the Scientific Investigation of Claims of the Paranormal, Marcello Truzzi, \"An extraordinary claim requires extraordinary proof.\" This idea had been earlier aphorized in Th\u00e9odore Flournoy's work \"From India to the Planet Mars\" (1899) from a longer quote by Pierre-Simon Laplace (1749\u20131827), a French mathematician and astronomer, as the Principle of Laplace: \"The weight of the evidence should be proportioned to the strangeness of the facts.\"\nLate in his life, Sagan's books elaborated on his naturalistic view of the world. In \"The Demon-Haunted World\", he presented tools for testing arguments and detecting fallacious or fraudulent ones, essentially advocating wide use of critical thinking and the scientific method. The compilation \"Billions and Billions: Thoughts on Life and Death at the Brink of the Millennium\", published in 1997 after Sagan's death, contains essays written by Sagan, such as his views on abortion, as well as an account by his widow, Ann Druyan, of his death in relation to his having been an agnostic and freethinker.\nSagan warned against humans' tendency towards anthropocentrism. He was the faculty adviser for the Cornell Students for the Ethical Treatment of Animals. In the \"Cosmos\" chapter \"Blues For a Red Planet\", Sagan wrote, \"If there is life on Mars, I believe we should do nothing with Mars. Mars then belongs to the Martians, even if the Martians are only microbes.\"\nMarijuana advocacy.\nSagan was a user and advocate of marijuana. Under the pseudonym \"Mr.\u00a0X\", he contributed an essay about smoking cannabis to the 1971 book \"Marihuana Reconsidered\". The essay explained that marijuana use had helped to inspire some of Sagan's works and enhance sensual and intellectual experiences. After Sagan's death, his friend Lester Grinspoon disclosed this information to Sagan's biographer, Keay Davidson. The publishing of the biography, \"Carl Sagan: A Life\", in 1999 brought media attention to this aspect of Sagan's life. Not long after his death, his widow Ann Druyan went on to preside over the board of directors of the National Organization for the Reform of Marijuana Laws (NORML), a non-profit organization dedicated to reforming cannabis laws.\nIn 1994, engineers at Apple Computer code-named the Power Macintosh\u00a07100 \"Carl Sagan\" in the hope that Apple would make \"billions and billions\" with the sale of the PowerMac\u00a07100. The name was only used internally, but Sagan was concerned that it would become a product endorsement and sent Apple a cease-and-desist letter. Apple complied, but engineers retaliated by changing the internal codename to \"BHA\" for \"Butt-Head Astronomer\". Sagan then sued Apple for libel in federal court. The court granted Apple's motion to dismiss Sagan's claims and opined in dicta that a reader aware of the context would understand Apple was \"clearly attempting to retaliate in a humorous and satirical way\", and that \"It strains reason to conclude that Defendant was attempting to criticize Plaintiff's reputation or competency as an astronomer. One does not seriously attack the expertise of a scientist using the undefined phrase 'butt-head'.\" Sagan then sued for Apple's original use of his name and likeness, but again lost. Sagan appealed the ruling. In November 1995, an out-of-court settlement was reached and Apple's office of trademarks and patents released a conciliatory statement that \"Apple has always had great respect for Dr.\u00a0Sagan. It was never Apple's intention to cause Dr.\u00a0Sagan or his family any embarrassment or concern.\" Apple's third and final code name for the project was \"LAW\", short for \"Lawyers are Wimps\".\nSagan briefly served as an adviser on Stanley Kubrick's film \"\". Sagan proposed that the film suggest, rather than depict, extraterrestrial superintelligence.\nUFOs.\nIn 1947, the year that inaugurated the \"flying saucer\" craze, the young Sagan suspected the \"discs\" might be alien spaceships.\nSagan's interest in UFO reports prompted him on August 3, 1952, to write a letter to U.S.\u00a0Secretary of State Dean Acheson to ask how the United States would respond if flying saucers turned out to be extraterrestrial. He later had several conversations on the subject in 1964 with Jacques Vall\u00e9e. Though quite skeptical of any extraordinary answer to the UFO question, Sagan thought scientists should study the phenomenon, at least because there was widespread public interest in UFO reports.\nStuart Appelle notes that Sagan \"wrote frequently on what he perceived as the logical and empirical fallacies regarding UFOs and the abduction experience. Sagan rejected an extraterrestrial explanation for the phenomenon but felt there were both empirical and pedagogical benefits for examining UFO reports and that the subject was, therefore, a legitimate topic of study.\"\nIn 1966 Sagan was a member of the Ad\u00a0Hoc Committee to Review Project Blue Book, the U.S.\u00a0Air Force's UFO investigation project. The committee concluded Blue Book had been lacking as a scientific study, and recommended a university-based project to give the UFO phenomenon closer scientific scrutiny. The result was the Condon Committee (1966\u201368), led by physicist Edward Condon, and in their final report they formally concluded that UFOs, regardless of what any of them actually were, did not behave in a manner consistent with a threat to national security.\nSociologist Ron Westrum writes that \"The high point of Sagan's treatment of the UFO question was the AAAS' symposium in 1969. A wide range of educated opinions on the subject were offered by participants, including not only proponents such as James McDonald and J.\u00a0Allen Hynek but also skeptics like astronomers William Hartmann and Donald Menzel. The roster of speakers was balanced, and it is to Sagan's credit that this event was presented in spite of pressure from Edward Condon.\" With physicist Thornton Page, Sagan edited the lectures and discussions given at the symposium; these were published in 1972 as \"UFO's: A Scientific Debate\". Some of Sagan's many books examine UFOs (as did one episode of \"Cosmos\") and he claimed a religious undercurrent to the phenomenon.\nSagan again revealed his views on interstellar travel in his 1980 \"Cosmos\" series. In one of his last written works, Sagan argued that the chances of extraterrestrial spacecraft visiting Earth are vanishingly small. However, Sagan did think it plausible that Cold War concerns contributed to governments misleading their citizens about UFOs, and wrote that \"some UFO reports and analyses, and perhaps voluminous files, have been made inaccessible to the public which pays the bills\u00a0... It's time for the files to be declassified and made generally available.\" He cautioned against jumping to conclusions about suppressed UFO data and stressed that there was no strong evidence that aliens were visiting the Earth either in the past or present.\n\"Sagan's paradox\".\nSagan's contribution to the 1969 AAAS symposium was an attack on the belief that UFOs are piloted by extraterrestrial beings. Applying several logical assumptions (see Drake equation), Sagan calculated the possible number of advanced civilizations capable of interstellar travel to be about one million. He projected that any civilization wishing to check on all the others on a regular basis of, say, once a year would have to launch 10,000 spacecraft annually. Not only does that seem like an unreasonable number of launchings, but it would take all the material in one percent of the universe's stars to produce all the spaceships needed for all the civilizations to seek each other out.\nTo argue that the Earth was being chosen for regular visitations, Sagan said, one would have to assume that the planet is somehow unique, and that assumption \"goes exactly against the idea that there are lots of civilizations around. Because if there are then our sort of civilization must be pretty common. And if we're not pretty common then there aren't going to be many civilizations advanced enough to send visitors\".\nThis argument, which some called Sagan's paradox, helped to establish a new school of thought, namely the belief that extraterrestrial life exists, but it has nothing to do with UFOs. The new belief had a salutary effect on UFO studies. It helped separate researchers who wanted to distinguish UFOs from those who wanted to identify their pilots and it gave scientists opportunities to search the universe for intelligent life unencumbered by the stigma associated with UFOs.\nDeath.\nAfter suffering from myelodysplasia for two years and receiving three bone marrow transplants from his sister, Sagan died from pneumonia at the age of 62, at the Fred Hutchinson Cancer Research Center in Seattle, Washington, on December 20, 1996. His burial took place at Lake View Cemetery in Ithaca, New York.\nAwards and honors.\nPosthumous recognition.\nThe 1997 film \"Contact\", based on Sagan's only novel of the same name and finished after his death, ends with the dedication \"For Carl\". His photo can also be seen in the film.\nIn 1997 the Sagan Planet Walk was opened in Ithaca, New York. It is a walking-scale model of the Solar System, extending 1.2\u00a0km from the center of The Commons in downtown Ithaca to the Sciencenter, a hands-on museum. The exhibition was created in memory of Carl Sagan, who was an Ithaca resident and Cornell Professor. Professor Sagan had been a founding member of the museum's advisory board.\nThe landing site of the unmanned \"Mars Pathfinder\" spacecraft was renamed the Carl Sagan Memorial Station on July 5, 1997. Asteroid 2709\u00a0Sagan is named in his honor, as is the Carl Sagan Institute for the search of habitable planets.\nSagan's son, Nick Sagan, wrote several episodes in the \"Star Trek\" franchise. In an episode of \"\" entitled \"Terra Prime\", a quick shot is shown of the relic rover \"Sojourner\", part of the \"Mars Pathfinder\" mission, placed by a historical marker at Carl Sagan Memorial Station on the Martian surface. The marker displays a quote from Sagan: \"Whatever the reason you're on Mars, I'm glad you're there, and I wish I was with you.\" Sagan's student Steve Squyres led the team that landed the rovers \"Spirit\" and \"Opportunity\" successfully on Mars in 2004.\nOn November 9, 2001, on what would have been Sagan's 67th birthday, the Ames Research Center dedicated the site for the Carl Sagan Center for the Study of Life in the Cosmos. \"Carl was an incredible visionary, and now his legacy can be preserved and advanced by a 21st\u00a0century research and education laboratory committed to enhancing our understanding of life in the universe and furthering the cause of space exploration for all time\", said NASA Administrator Daniel Goldin. Ann Druyan was at the center as it opened its doors on October 22, 2006.\nSagan has at least three awards named in his honor:\nAugust 2007 the Independent Investigations Group (IIG) awarded Sagan posthumously a Lifetime Achievement Award. This honor has also been awarded to Harry Houdini and James Randi.\nIn September 2008, a musical compositor Benn Jordan released his album \"Pale Blue Dot\" as a tribute to Carl Sagan's life.\nBeginning in 2009, a musical project known as Symphony of Science sampled several excerpts of Sagan from his series \"Cosmos\" and remixed them to electronic music. To date, the videos have received over 21\u00a0million views worldwide on YouTube.\nThe 2014 Swedish science fiction short film \"Wanderers\" uses excerpts of Sagan's narration of his book \"Pale Blue Dot\", played over digitally-created visuals of humanity's possible future expansion into outer space.\nIn February 2015, the Finnish-based symphonic metal band Nightwish released the song \"Sagan\" as a non-album bonus track for their single \"\u00c9lan\". The song, written by the band's songwriter/composer/keyboardist Tuomas Holopainen, is an homage to the life and work of the late Carl Sagan.\nIn August 2015, it was announced that a biopic of Sagan's life was being planned by Warner Bros.\nOn October 21, 2019, the Carl Sagan and Ann Druyan Theater was opened at the Center for Inquiry West in Los Angeles.\nReferences.\nFootnotes\nCitations\nExternal links.\n \n[[Category:Carl Sagan| ]]\n[[Category:1934 births]]\n[[Category:1996 deaths]]\n[[Category:20th-century American novelists]]\n[[Category:20th-century American scientists]]\n[[Category:20th-century astronomers]]\n[[Category:American agnostics]]\n[[Category:American anti\u2013Vietnam War activists]]\n[[Category:American anti\u2013nuclear weapons activists]]\n[[Category:American astronomers]]\n[[Category:American astrophysicists]]\n[[Category:American cannabis activists]]\n[[Category:American humanists]]\n[[Category:American male non-fiction writers]]\n[[Category:American male novelists]]\n[[Category:American naturalists]]\n[[Category:American nature writers]]\n[[Category:American pacifists]]\n[[Category:American people of Russian-Jewish descent]]\n[[Category:American people of Ukrainian-Jewish descent]]\n[[Category:American science fiction writers]]\n[[Category:American science writers]]\n[[Category:American skeptics]]\n[[Category:American social commentators]]\n[[Category:American UFO writers]]\n[[Category:Astrobiologists]]\n[[Category:Astrochemists]]\n[[Category:Burials in New York (state)]]\n[[Category:Cornell University faculty]]\n[[Category:Cosmologists]]\n[[Category:Critics of alternative medicine]]\n[[Category:Critics of creationism]]\n[[Category:Critics of parapsychology]]\n[[Category:Critics of religions]]\n[[Category:Cultural critics]]\n[[Category:Deaths from pneumonia]]\n[[Category:Harvard University faculty]]\n[[Category:Infectious disease deaths in Washington (state)]]\n[[Category:Interstellar messages]]\n[[Category:Jewish activists]]\n[[Category:Jewish agnostics]]\n[[Category:Jewish American scientists]]\n[[Category:Jewish astronomers]]\n[[Category:Jewish skeptics]]\n[[Category:Members of the American Philosophical Society]]\n[[Category:Novelists from New York (state)]]\n[[Category:Pantheists]]\n[[Category:People associated with the American Museum of Natural History]]\n[[Category:People from Bensonhurst, Brooklyn]]\n[[Category:Planetary scientists]]\n[[Category:Presidents of The Planetary Society]]\n[[Category:Pulitzer Prize for General Non-Fiction winners]]\n[[Category:Rahway High School alumni]]\n[[Category:Royal Institution Christmas Lectures]]\n[[Category:Sagan family]]\n[[Category:Science communicators]]\n[[Category:Scientists from New York (state)]]\n[[Category:Search for extraterrestrial intelligence]]\n[[Category:Secular humanists]]\n[[Category:Social critics]]\n[[Category:Space advocates]]\n[[Category:Spinozists]]\n[[Category:University of California, Berkeley fellows]]\n[[Category:University of Chicago alumni]]\n[[Category:Writers from Brooklyn]]\n[[Category:Writers about religion and science]]\n[[Category:20th-century naturalists]]\n[[Category:Fellows of the American Physical Society]]\n[[Category:Articles containing video clips]]"}
{"id": "6826", "revid": "10049", "url": "https://en.wikipedia.org/wiki?curid=6826", "title": "Cases of anthrax", "text": ""}
{"id": "6827", "revid": "603343", "url": "https://en.wikipedia.org/wiki?curid=6827", "title": "Cuban Missile Crisis", "text": "The Cuban Missile Crisis, also known as the October Crisis of 1962 (), the Caribbean Crisis (), or the Missile Scare, was a 1 month, 4 day (16 October \u2013 20 November 1962) confrontation between the United States and the Soviet Union which escalated into an international crisis when American deployments of missiles in Italy and Turkey were matched by Soviet deployments of similar ballistic missiles in Cuba. Despite the short time frame, the Cuban Missile Crisis remains a defining moment in U.S. national security and nuclear war preparation. The confrontation is often considered the closest the Cold War came to escalating into a full-scale nuclear war. \nIn response to the presence of American Jupiter ballistic missiles in Italy and Turkey, and the failed Bay of Pigs Invasion of 1961, Soviet First Secretary Nikita Khrushchev agreed to Cuba's request to place nuclear missiles on the island to deter a future invasion. An agreement was reached during a secret meeting between Khrushchev and Cuban Prime Minister Fidel Castro in July 1962, and construction of a number of missile launch facilities started later that summer.\nMeanwhile, the 1962 United States elections were under way, and the White House denied charges for months that it was ignoring dangerous Soviet missiles from Florida. The missile preparations were confirmed when an Air Force U-2 spy plane produced clear photographic evidence of medium-range R-12 (NATO code name SS-4) and intermediate-range R-14 (NATO code name SS-5) ballistic missile facilities.\nWhen this was reported to President John F. Kennedy he then convened a meeting of the nine members of the National Security Council and five other key advisers in a group that became known as the Executive Committee of the National Security Council (EXCOMM). During this meeting, President Kennedy was originally advised to carry out an air strike on Cuban soil in order to compromise Soviet missile supplies, followed by an invasion of the Cuban mainland. After careful consideration, President Kennedy chose a less aggressive course of action in fear of declaration of war. After consultation with them, Kennedy ordered a naval blockade on October 22 to prevent further missiles from reaching Cuba. By declaring a quarantine rather than a blockade, the United States was able to avoid a further conflict. This quarantine fell short of a traditional blockade and so avoided the implications of a state of war. The US announced it would not permit offensive weapons to be delivered to Cuba and demanded that the weapons already in Cuba be dismantled and returned to the Soviet Union.\nAfter several days of tense negotiations, an agreement was reached between Kennedy and Khrushchev. Publicly, the Soviets would dismantle their offensive weapons in Cuba and return them to the Soviet Union, subject to United Nations verification, in exchange for a US public declaration and agreement to not invade Cuba again. Secretly, the United States agreed that it would dismantle all of the Jupiter MRBMs, which had been deployed in Turkey against the Soviet Union. There has been debate on whether or not Italy was included in the agreement as well. While the Soviets dismantled their missiles, some Soviet bombers remained in Cuba, forcing the Naval quarantine to stay in place until November 20 of that year.\nWhen all offensive missiles and the Ilyushin Il-28 light bombers had been withdrawn from Cuba, the blockade was formally ended on November 20, 1962. The negotiations between the United States and the Soviet Union pointed out the necessity of a quick, clear, and direct communication line between the two Superpowers. As a result, the Moscow\u2013Washington hotline was established. A series of agreements later reduced US\u2013Soviet tensions for several years until both parties eventually resumed expanding their nuclear arsenals.\nBackground.\nCuba and Berlin Wall.\nWith the end of World War II and the start of the Cold War, the United States had grown concerned about the expansion of communism. A Latin American country openly allying with the Soviet Union was regarded by the US as unacceptable. It would, for example, defy the Monroe Doctrine, a US policy limiting US involvement in European colonies and European affairs but holding that the Western Hemisphere was in the US sphere of influence.\nThe Kennedy administration had been publicly embarrassed by the failed Bay of Pigs Invasion in April 1961, which had been launched under President John F. Kennedy by CIA-trained forces of Cuban exiles. Afterward, former President Dwight Eisenhower told Kennedy that \"the failure of the Bay of Pigs will embolden the Soviets to do something that they would otherwise not do.\" The half-hearted invasion left Soviet first secretary Nikita Khrushchev and his advisers with the impression that Kennedy was indecisive and, as one Soviet adviser wrote, \"too young, intellectual, not prepared well for decision making in crisis situations... too intelligent and too weak\". US covert operations against Cuba continued in 1961 with the unsuccessful Operation Mongoose.\nIn addition, Khrushchev's impression of Kennedy's weaknesses was confirmed by the President's response during the Berlin Crisis of 1961, particularly to the building of the Berlin Wall. Speaking to Soviet officials in the aftermath of the crisis, Khrushchev asserted, \"I know for certain that Kennedy doesn't have a strong background, nor, generally speaking, does he have the courage to stand up to a serious challenge.\" He also told his son Sergei that on Cuba, Kennedy \"would make a fuss, make more of a fuss, and then agree\".\nIn January 1962, US Army General Edward Lansdale described plans to overthrow the Cuban government in a top-secret report (partially declassified 1989), addressed to Kennedy and officials involved with Operation Mongoose. CIA agents or \"pathfinders\" from the Special Activities Division were to be infiltrated into Cuba to carry out sabotage and organization, including radio broadcasts. In February 1962, the US launched an embargo against Cuba, and Lansdale presented a 26-page, top-secret timetable for implementation of the overthrow of the Cuban government, mandating guerrilla operations to begin in August and September. \"Open revolt and overthrow of the Communist regime\" would occur in the first two weeks of October.\nMissile gap.\nWhen Kennedy ran for president in 1960, one of his key election issues was an alleged \"missile gap\" with the Soviets leading. Actually, the US at that time \"led\" the Soviets by a wide margin that would only increase. In 1961, the Soviets had only four intercontinental ballistic missiles (R-7 Semyorka). By October 1962, they may have had a few dozen, with some intelligence estimates as high as 75.\nThe US, on the other hand, had 170 ICBMs and was quickly building more. It also had eight - and ballistic missile submarines, with the capability to launch 16 Polaris missiles, each with a range of . Khrushchev increased the perception of a missile gap when he loudly boasted to the world that the Soviets were building missiles \"like sausages\" but Soviet missiles' numbers and capabilities were nowhere close to his assertions. The Soviet Union had medium-range ballistic missiles in quantity, about 700 of them, but they were very unreliable and inaccurate. The US had a considerable advantage in total number of nuclear warheads (27,000 against 3,600) and in the technology required for their accurate delivery. The US also led in missile defensive capabilities, naval and air power; but the Soviets had a 2\u20131 advantage in conventional ground forces, more pronounced in field guns and tanks, particularly in the European theatre.\nSoviet deployment of missiles in Cuba.\nJustification.\nIn May 1962, Soviet First Secretary Nikita Khrushchev was persuaded by the idea of countering the US's growing lead in developing and deploying strategic missiles by placing Soviet intermediate-range nuclear missiles in Cuba, despite the misgivings of the Soviet Ambassador in Havana, Alexandr Ivanovich Alexeyev, who argued that Castro would not accept the deployment of the missiles. Khrushchev faced a strategic situation in which the US was perceived to have a \"splendid first strike\" capability that put the Soviet Union at a huge disadvantage. In 1962, the Soviets had only 20 ICBMs capable of delivering nuclear warheads to the US from inside the Soviet Union. The poor accuracy and reliability of the missiles raised serious doubts about their effectiveness. A newer, more reliable generation of ICBMs would become operational only after 1965.\nTherefore, Soviet nuclear capability in 1962 placed less emphasis on ICBMs than on medium and intermediate-range ballistic missiles (MRBMs and IRBMs). The missiles could hit American allies and most of Alaska from Soviet territory but not the Contiguous United States. Graham Allison, the director of Harvard University's Belfer Center for Science and International Affairs, points out, \"The Soviet Union could not right the nuclear imbalance by deploying new ICBMs on its own soil. In order to meet the threat it faced in 1962, 1963, and 1964, it had very few options. Moving existing nuclear weapons to locations from which they could reach American targets was one.\"\nA second reason that Soviet missiles were deployed to Cuba was because Khrushchev wanted to bring West Berlin, controlled by the American, British and French within Communist East Germany, into the Soviet orbit. The East Germans and Soviets considered western control over a portion of Berlin a grave threat to East Germany. Khrushchev made West Berlin the central battlefield of the Cold War. Khrushchev believed that if the US did nothing over the missile deployments in Cuba, he could muscle the West out of Berlin using said missiles as a deterrent to western countermeasures in Berlin. If the US tried to bargain with the Soviets after it became aware of the missiles, Khrushchev could demand trading the missiles for West Berlin. Since Berlin was strategically more important than Cuba, the trade would be a win for Khrushchev, as Kennedy recognised: \"The advantage is, from Khrushchev's point of view, he takes a great chance but there are quite some rewards to it.\"\nThirdly, from the perspective of the Soviet Union and of Cuba, it seemed that the United States wanted to increase its presence in Cuba. With actions including the attempt to expel Cuba from the Organization of American States, placing economic sanctions on the nation, directly invading it in addition to conducting secret operations on containing communism and Cuba, it was assumed that America was trying to overrun Cuba. As a result, to try and prevent this, the USSR would place missiles in Cuba and neutralise the threat. This would ultimately serve to secure Cuba against attack and keep the country in the Socialist Bloc.\nAnother major reason why Khrushchev planned to place missiles on Cuba undetected was to \"level the playing field\" with the evident American nuclear threat. America had the upper hand as they could launch from Turkey and destroy the USSR before they would have a chance to react. After the transmission of nuclear missiles, Khrushchev had finally established mutually assured destruction, meaning that if the U.S. decided to launch a nuclear strike against the USSR, the latter would react by launching a retaliatory nuclear strike against the U.S.\nAdditionally, placing nuclear missiles on Cuba was a way for the USSR to show their support for Cuba and support the Cuban people who viewed the United States as a threatening force, as the latter had become their ally after the Cuban Revolution of 1959. According to Khrushchev, the Soviet Union's motives were \"aimed at allowing Cuba to live peacefully and develop as its people desire\".\nDeployment.\nIn early 1962, a group of Soviet military and missile construction specialists accompanied an agricultural delegation to Havana. They obtained a meeting with Cuban prime minister Fidel Castro. The Cuban leadership had a strong expectation that the US would invade Cuba again and enthusiastically approved the idea of installing nuclear missiles in Cuba. According to another source, Castro objected to the missiles' deployment that would have made him look like a Soviet puppet, but he was persuaded that missiles in Cuba would be an irritant to the US and help the interests of the entire socialist camp. Also, the deployment would include short-range tactical weapons (with a range of 40\u00a0km, usable only against naval vessels) that would provide a \"nuclear umbrella\" for attacks upon the island.\nBy May, Khrushchev and Castro agreed to place strategic nuclear missiles secretly in Cuba. Like Castro, Khrushchev felt that a US invasion of Cuba was imminent and that to lose Cuba would do great harm to the communists, especially in Latin America. He said he wanted to confront the Americans \"with more than words... the logical answer was missiles\". The Soviets maintained their tight secrecy, writing their plans longhand, which were approved by Marshal of the Soviet Union Rodion Malinovsky on July 4 and Khrushchev on July 7.\nFrom the very beginning, the Soviets' operation entailed elaborate denial and deception, known as \"maskirovka\". All the planning and preparation for transporting and deploying the missiles were carried out in the utmost secrecy, with only a very few told the exact nature of the mission. Even the troops detailed for the mission were given misdirection by being told that they were headed for a cold region and being outfitted with ski boots, fleece-lined parkas, and other winter equipment. The Soviet code-name was Operation Anadyr. The Anadyr River flows into the Bering Sea, and Anadyr is also the capital of Chukotsky District and a bomber base in the far eastern region. All the measures were meant to conceal the program from both internal and external audiences.\nSpecialists in missile construction under the guise of \"machine operators\", \"irrigation specialists\", and \"agricultural specialists\" arrived in July. A total of 43,000 foreign troops would ultimately be brought in. Chief Marshal of Artillery Sergei Biryuzov, Head of the Soviet Rocket Forces, led a survey team that visited Cuba. He told Khrushchev that the missiles would be concealed and camouflaged by palm trees.\nThe Cuban leadership was further upset when on September 20, the US Senate approved Joint Resolution 230, which expressed the US was determined \"to prevent in Cuba the creation or use of an externally-supported military capability endangering the security of the United States\". On the same day, the US announced a major military exercise in the Caribbean, PHIBRIGLEX-62, which Cuba denounced as a deliberate provocation and proof that the US planned to invade Cuba.\nThe Soviet leadership believed, based on its perception of Kennedy's lack of confidence during the Bay of Pigs Invasion, that he would avoid confrontation and accept the missiles as a . On September 11, the Soviet Union publicly warned that a US attack on Cuba or on Soviet ships that were carrying supplies to the island would mean war. The Soviets continued the \"Maskirovka\" program to conceal their actions in Cuba. They repeatedly denied that the weapons being brought into Cuba were offensive in nature. On September 7, Soviet Ambassador to the United States Anatoly Dobrynin assured United States Ambassador to the United Nations Adlai Stevenson that the Soviet Union was supplying only defensive weapons to Cuba. On September 11, the Telegraph Agency of the Soviet Union (TASS: \"Telegrafnoe Agentstvo Sovetskogo Soyuza\") announced that the Soviet Union had no need or intention to introduce offensive nuclear missiles into Cuba. On October 13, Dobrynin was questioned by former Undersecretary of State Chester Bowles about whether the Soviets planned to put offensive weapons in Cuba. He denied any such plans. On October 17, Soviet embassy official Georgy Bolshakov brought President Kennedy a personal message from Khrushchev reassuring him that \"under no circumstances would surface-to-surface missiles be sent to Cuba.\"\nAs early as August 1962, the US suspected the Soviets of building missile facilities in Cuba. During that month, its intelligence services gathered information about sightings by ground observers of Russian-built MiG-21 fighters and Il-28 light bombers. U-2 spy planes found S-75 Dvina (NATO designation \"SA-2\") surface-to-air missile sites at eight different locations. CIA director John A. McCone was suspicious. Sending antiaircraft missiles into Cuba, he reasoned, \"made sense only if Moscow intended to use them to shield a base for ballistic missiles aimed at the United States\". On August 10, he wrote a memo to Kennedy in which he guessed that the Soviets were preparing to introduce ballistic missiles into Cuba.\nWith important Congressional elections scheduled for November, the crisis became enmeshed in American politics. On August 31, Senator Kenneth Keating (R-New York) warned on the Senate floor that the Soviet Union was \"in all probability\" constructing a missile base in Cuba. He charged the Kennedy administration with covering up a major threat to the US, thereby starting the crisis. He may have received this initial \"remarkably accurate\" information from his friend, former congresswoman and ambassador Clare Boothe Luce, who in turn received it from Cuban exiles. A later confirming source for Keating's information possibly was the West German ambassador to Cuba, who had received information from dissidents inside Cuba that Soviet troops had arrived in Cuba in early August and were seen working \"in all probability on or near a missile base\" and who passed this information to Keating on a trip to Washington in early October. Air Force General Curtis LeMay presented a pre-invasion bombing plan to Kennedy in September, and spy flights and minor military harassment from US forces at Guantanamo Bay Naval Base were the subject of continual Cuban diplomatic complaints to the US government.\nThe first consignment of R-12 missiles arrived on the night of September 8, followed by a second on September 16. The R-12 was a medium-range ballistic missile, capable of carrying a thermonuclear warhead. It was a single-stage, road-transportable, surface-launched, storable liquid propellant fuelled missile that could deliver a megaton-class nuclear weapon. The Soviets were building nine sites\u2014six for R-12 medium-range missiles (NATO designation \"SS-4 Sandal\") with an effective range of and three for R-14 intermediate-range ballistic missiles (NATO designation \"SS-5 Skean\") with a maximum range of .\nOn October 7, Cuban President Osvaldo Dortic\u00f3s Torrado spoke at the UN General Assembly: \"If... we are attacked, we will defend ourselves. I repeat, we have sufficient means with which to defend ourselves; we have indeed our inevitable weapons, the weapons, which we would have preferred not to acquire, and which we do not wish to employ.\" On October 10 in another Senate speech Sen. Keating reaffirmed his earlier warning of August 31 and stated that, \"Construction has begun on at least a half dozen launching sites for intermediate range tactical missiles.\"\nMissiles reported.\nThe missiles in Cuba allowed the Soviets to effectively target most of the Continental US. The planned arsenal was forty launchers. The Cuban populace readily noticed the arrival and deployment of the missiles and hundreds of reports reached Miami. US intelligence received countless reports, many of dubious quality or even laughable, most of which could be dismissed as describing defensive missiles.\nOnly five reports bothered the analysts. They described large trucks passing through towns at night that were carrying very long canvas-covered cylindrical objects that could not make turns through towns without backing up and manoeuvring. Defensive missiles could turn. The reports could not be satisfactorily dismissed.\nAerial confirmation.\nThe United States had been sending U-2 surveillance over Cuba since the failed Bay of Pigs Invasion. The first issue that led to a pause in reconnaissance flights took place on August 30, when a U-2 operated by the US Air Force's Strategic Air Command flew over Sakhalin Island in the Soviet Far East by mistake. The Soviets lodged a protest and the US apologised. Nine days later, a Taiwanese-operated U-2 was lost over western China to an SA-2 surface-to-air missile. US officials were worried that one of the Cuban or Soviet SAMs in Cuba might shoot down a CIA U-2, initiating another international incident. In a meeting with members of the Committee on Overhead Reconnaissance (COMOR) on September 10, Secretary of State Dean Rusk and National Security Advisor McGeorge Bundy heavily restricted further U-2 flights over Cuban airspace. The resulting lack of coverage over the island for the next five weeks became known to historians as the \"Photo Gap\". No significant U-2 coverage was achieved over the interior of the island. US officials attempted to use a Corona photo-reconnaissance satellite to obtain coverage over reported Soviet military deployments, but imagery acquired over western Cuba by a Corona KH-4 mission on October 1 was heavily covered by clouds and haze and failed to provide any usable intelligence. At the end of September, Navy reconnaissance aircraft photographed the Soviet ship \"Kasimov\", with large crates on its deck the size and shape of Il-28 jet bomber fuselages.\nIn September 1962, analysts from the Defense Intelligence Agency (DIA) noticed that Cuban surface-to-air missile sites were arranged in a pattern similar to those used by the Soviet Union to protect its ICBM bases, leading DIA to lobby for the resumption of U-2 flights over the island. Although in the past the flights had been conducted by the CIA, pressure from the Defense Department led to that authority being transferred to the Air Force. Following the loss of a CIA U-2 over the Soviet Union in May 1960, it was thought that if another U-2 were shot down, an Air Force aircraft arguably being used for a legitimate military purpose would be easier to explain than a CIA flight.\nWhen the reconnaissance missions were reauthorized on October 9, poor weather kept the planes from flying. The US first obtained U-2 photographic evidence of the missiles on October 14, when a U-2 flight piloted by Major Richard Heyser took 928 pictures on a path selected by DIA analysts, capturing images of what turned out to be an SS-4 construction site at San Crist\u00f3bal, Pinar del R\u00edo Province (now in Artemisa Province), in western Cuba.\nPresident notified.\nOn October 15, the CIA's National Photographic Interpretation Center (NPIC) reviewed the U-2 photographs and identified objects that they interpreted as medium range ballistic missiles. This identification was made, in part, on the strength of reporting provided by Oleg Penkovsky, a double agent in the GRU working for CIA and MI6. Although he provided no direct reports of the Soviet missile deployments to Cuba, technical and doctrinal details of Soviet missile regiments that had been provided by Penkovsky in the months and years prior to the Crisis helped NPIC analysts correctly identify the missiles on U-2 imagery.\nThat evening, the CIA notified the Department of State and at 8:30\u00a0pm EDT, Bundy chose to wait until the next morning to tell the President. McNamara was briefed at midnight. The next morning, Bundy met with Kennedy and showed him the U-2 photographs and briefed him on the CIA's analysis of the images. At 6:30\u00a0pm EDT, Kennedy convened a meeting of the nine members of the National Security Council and five other key advisers, in a group he formally named the Executive Committee of the National Security Council (EXCOMM) after the fact on October 22 by the National Security Action Memorandum 196. Without informing the members of EXCOMM, President Kennedy tape recorded all of their proceedings, and Sheldon M. Stern, head of the Kennedy library transcribed some of them.\nOn October 16, President Kennedy notified Robert Kennedy that he was convinced Russia was placing missiles in Cuba and it was a legitimate threat. This officially made the threat of nuclear destruction by two world superpowers a reality. Robert Kennedy responded by contacting the Soviet Ambassador, Anatoly Dobrynin. Robert Kennedy expressed his \"concern about what was happening\" and Dobrynin \"was instructed by Soviet Chairman Nikita S. Khrushchev to assure President Kennedy that there would be no ground-to-ground missiles or offensive weapons placed in Cuba\". Khrushchev further assured Kennedy that the Soviet Union had no intention of \"disrupting the relationship of our two countries\" despite the photo evidence presented before President Kennedy.\nResponses considered.\nThe US had no plan in place because its intelligence had been convinced that the Soviets would never install nuclear missiles in Cuba. EXCOMM, of which Vice President Lyndon B. Johnson was a member, quickly discussed several possible courses of action:\nThe Joint Chiefs of Staff unanimously agreed that a full-scale attack and invasion was the only solution. They believed that the Soviets would not attempt to stop the US from conquering Cuba. Kennedy was skeptical:\nKennedy concluded that attacking Cuba by air would signal the Soviets to presume \"a clear line\" to conquer Berlin. Kennedy also believed that US allies would think of the country as \"trigger-happy cowboys\" who lost Berlin because they could not peacefully resolve the Cuban situation.\nThe EXCOMM then discussed the effect on the strategic balance of power, both political and military. The Joint Chiefs of Staff believed that the missiles would seriously alter the military balance, but McNamara disagreed. An extra 40, he reasoned, would make little difference to the overall strategic balance. The US already had approximately 5,000 strategic warheads, but the Soviet Union had only 300. McNamara concluded that the Soviets having 340 would not therefore substantially alter the strategic balance. In 1990, he reiterated that \"it made \"no\" difference... The military balance wasn't changed. I didn't believe it then, and I don't believe it now.\"\nThe EXCOMM agreed that the missiles would affect the \"political\" balance. Kennedy had explicitly promised the American people less than a month before the crisis that \"if Cuba should possess a capacity to carry out offensive actions against the United States... the United States would act.\" Also, credibility among US allies and people would be damaged if the Soviet Union appeared to redress the strategic balance by placing missiles in Cuba. Kennedy explained after the crisis that \"it would have politically changed the balance of power. It would have appeared to, and appearances contribute to reality.\"\nOn October 18, Kennedy met with Soviet Minister of Foreign Affairs, Andrei Gromyko, who claimed the weapons were for defensive purposes only. Not wanting to expose what he already knew and to avoid panicking the American public, Kennedy did not reveal that he was already aware of the missile buildup. By October 19, frequent U-2 spy flights showed four operational sites.\nOperational plans.\nTwo Operational Plans (OPLAN) were considered. OPLAN 316 envisioned a full invasion of Cuba by Army and Marine units, supported by the Navy following Air Force and naval airstrikes. Army units in the US would have had trouble fielding mechanised and logistical assets, and the US Navy could not supply enough amphibious shipping to transport even a modest armoured contingent from the Army.\nOPLAN 312, primarily an Air Force and Navy carrier operation, was designed with enough flexibility to do anything from engaging individual missile sites to providing air support for OPLAN 316's ground forces.\nBlockade.\nKennedy met with members of EXCOMM and other top advisers throughout October 21, considering two remaining options: an air strike primarily against the Cuban missile bases or a naval blockade of Cuba. A full-scale invasion was not the administration's first option. McNamara supported the naval blockade as a strong but limited military action that left the US in control. The term \"blockade\" was problematic. According to international law, a blockade is an act of war, but the Kennedy administration did not think that the Soviets would be provoked to attack by a mere blockade. Additionally, legal experts at the State Department and Justice Department concluded that a declaration of war could be avoided if another legal justification, based on the Rio Treaty for defence of the Western Hemisphere, was obtained from a resolution by a two-thirds vote from the members of the Organization of American States (OAS).\nAdmiral Anderson, Chief of Naval Operations wrote a position paper that helped Kennedy to differentiate between what they termed a \"quarantine\" of offensive weapons and a blockade of all materials, claiming that a classic blockade was not the original intention. Since it would take place in international waters, Kennedy obtained the approval of the OAS for military action under the hemispheric defence provisions of the Rio Treaty:\nOn October 19, the EXCOMM formed separate working groups to examine the air strike and blockade options, and by the afternoon most support in the EXCOMM shifted to the blockade option. Reservations about the plan continued to be voiced as late as the October 21, the paramount concern being that once the blockade was put into effect, the Soviets would rush to complete some of the missiles. Consequently, the US could find itself bombing operational missiles if the blockade failed to force Khrushchev to remove the missiles already on the island.\nSpeech to the nation.\nAt 3:00\u00a0pm EDT on October 22, President Kennedy formally established the Executive Committee (EXCOMM) with National Security Action Memorandum (NSAM) 196. At 5:00\u00a0pm, he met with Congressional leaders who contentiously opposed a blockade and demanded a stronger response. In Moscow, Ambassador Foy D. Kohler briefed Khrushchev on the pending blockade and Kennedy's speech to the nation. Ambassadors around the world gave notice to non-Eastern Bloc leaders. Before the speech, US delegations met with Canadian Prime Minister John Diefenbaker, British Prime Minister Harold Macmillan, West German Chancellor Konrad Adenauer, French President Charles de Gaulle and Secretary-General of the Organization of American States, Jos\u00e9 Antonio Mora to brief them on the US intelligence and their proposed response. All were supportive of the US position. Over the course of the crisis, Kennedy had daily telephone conversations with Macmillan, who was publicly supportive of US actions.\nShortly before his speech, Kennedy called former President Dwight Eisenhower. Kennedy's conversation with the former president also revealed that the two were consulting during the Cuban Missile Crisis. The two also anticipated that Khrushchev would respond to the Western world in a manner that was similar to his response during the Suez Crisis and would possibly wind up trading off Berlin.\nOn October 22 at 7:00\u00a0pm EDT, Kennedy delivered a nationwide televised address on all of the major networks announcing the discovery of the missiles. He noted:\nKennedy described the administration's plan:\nDuring the speech, a directive went out to all US forces worldwide, placing them on DEFCON 3. The heavy cruiser was designated flagship for the blockade, with as \"Newport News\"s destroyer escort.\nCrisis deepens.\nOn October 23, at 11:24\u00a0am EDT, a cable, drafted by George Wildman Ball to the US Ambassador in Turkey and NATO, notified them that they were considering making an offer to withdraw what the US knew to be nearly-obsolete missiles from Italy and Turkey, in exchange for the Soviet withdrawal from Cuba. Turkish officials replied that they would \"deeply resent\" any trade involving the US missile presence in their country. Two days later, on the morning of October 25, American journalist Walter Lippmann proposed the same thing in his syndicated column. Castro reaffirmed Cuba's right to self-defense and said that all of its weapons were defensive and Cuba would not allow an inspection.\nInternational response.\nThree days after Kennedy's speech, the Chinese \"People's Daily\" announced that \"650,000,000 Chinese men and women were standing by the Cuban people.\" In West Germany, newspapers supported the US response by contrasting it with the weak American actions in the region during the preceding months. They also expressed some fear that the Soviets might retaliate in Berlin. In France on October 23, the crisis made the front page of all the daily newspapers. The next day, an editorial in \"Le Monde\" expressed doubt about the authenticity of the CIA's photographic evidence. Two days later, after a visit by a high-ranking CIA agent, the newspaper accepted the validity of the photographs. Also in France, in the October 29 issue of \"Le Figaro\", Raymond Aron wrote in support of the American response. On October 24, Pope John XXIII sent a message to the Soviet embassy in Rome to be transmitted to the Kremlin in which he voiced his concern for peace. In this message he stated, \"We beg all governments not to remain deaf to this cry of humanity. That they do all that is in their power to save peace.\"\nSoviet broadcast and communications.\nThe crisis was continuing unabated, and in the evening of October 24, the Soviet news agency TASS broadcast a telegram from Khrushchev to Kennedy in which Khrushchev warned that the United States' \"outright piracy\" would lead to war. That was followed at 9:24\u00a0pm by a telegram from Khrushchev to Kennedy, which was received at 10:52\u00a0pm EDT. Khrushchev stated, \"if you weigh the present situation with a cool head without giving way to passion, you will understand that the Soviet Union cannot afford not to decline the despotic demands of the USA\" and that the Soviet Union views the blockade as \"an act of aggression\" and their ships will be instructed to ignore it. After October 23, Soviet communications with the USA increasingly showed indications of having been rushed. Undoubtedly a product of pressure, it was not uncommon for Khrushchev to repeat himself and send messages lacking simple editing. With President Kennedy making his aggressive intentions of a possible air-strike followed by an invasion on Cuba known, Khrushchev rapidly sought a diplomatic compromise. Communications between the two super-powers had entered into a unique and revolutionary period; with the newly developed threat of mutual destruction through the deployment of nuclear weapons, diplomacy now demonstrated how power and coercion could dominate negotiations.\nUS alert level raised.\nThe US requested an emergency meeting of the United Nations Security Council on October 25. US Ambassador to the United Nations Adlai Stevenson confronted Soviet Ambassador Valerian Zorin in an emergency meeting of the Security Council, challenging him to admit the existence of the missiles. Ambassador Zorin refused to answer. The next day at 10:00\u00a0pm EDT, the US raised the readiness level of SAC forces to DEFCON 2. For the only confirmed time in US history, B-52 bombers went on continuous airborne alert, and B-47 medium bombers were dispersed to various military and civilian airfields and made ready to take off, fully equipped, on 15\u00a0minutes' notice. One eighth of SAC's 1,436 bombers were on airborne alert, and some 145 intercontinental ballistic missiles stood on ready alert, some of which targeted Cuba, and Air Defense Command (ADC) redeployed 161 nuclear-armed interceptors to 16 dispersal fields within nine hours, with one third maintaining 15-minute alert status. Twenty-three nuclear-armed B-52s were sent to orbit points within striking distance of the Soviet Union so that it would believe that the US was serious. Jack J. Catton later estimated that about 80 percent of SAC's planes were ready for launch during the crisis; David A. Burchinal recalled that, by contrast:\nBy October 22, Tactical Air Command (TAC) had 511 fighters plus supporting tankers and reconnaissance aircraft deployed to face Cuba on one-hour alert status. TAC and the Military Air Transport Service had problems. The concentration of aircraft in Florida strained command and support echelons, which faced critical undermanning in security, armaments, and communications; the absence of initial authorization for war-reserve stocks of conventional munitions forced TAC to scrounge; and the lack of airlift assets to support a major airborne drop necessitated the call-up of 24 Reserve squadrons.\nOn October 25 at 1:45\u00a0am EDT, Kennedy responded to Khrushchev's telegram by stating that the US was forced into action after receiving repeated assurances that no offensive missiles were being placed in Cuba, and when the assurances proved to be false, the deployment \"required the responses I have announced... I hope that your government will take necessary action to permit a restoration of the earlier situation.\"\nBlockade challenged.\nAt 7:15\u00a0am EDT on October 25, and attempted to intercept \"Bucharest\" but failed to do so. Fairly certain that the tanker did not contain any military material, the US allowed it through the blockade. Later that day, at 5:43\u00a0pm, the commander of the blockade effort ordered the destroyer to intercept and board the Lebanese freighter \"Marucla\". That took place the next day, and \"Marucla\" was cleared through the blockade after its cargo was checked.\nAt 5:00\u00a0pm EDT on October 25, William Clements announced that the missiles in Cuba were still actively being worked on. That report was later verified by a CIA report that suggested there had been no slowdown at all. In response, Kennedy issued Security Action Memorandum 199, authorizing the loading of nuclear weapons onto aircraft under the command of SACEUR, which had the duty of carrying out first air strikes on the Soviet Union. Kennedy claimed that the blockade had succeeded when the USSR turned back fourteen ships presumably carrying offensive weapons. The first indication of this came from a report from the British GCHQ sent to the White House Situation Room containing intercepted communications from Soviet ships reporting their positions. On October 24, \"Kislovodsk,\" a Soviet cargo ship, reported a position north-east of where it had been 24 hours earlier indicating it had \"discontinued\" its voyage and turned back towards the Baltic. The next day, reports showed more ships originally bound for Cuba had altered their course.\nRaising the stakes.\nThe next morning, October 26, Kennedy informed the EXCOMM that he believed only an invasion would remove the missiles from Cuba. He was persuaded to give the matter time and continue with both military and diplomatic pressure. He agreed and ordered the low-level flights over the island to be increased from two per day to once every two hours. He also ordered a crash program to institute a new civil government in Cuba if an invasion went ahead.\nAt this point, the crisis was ostensibly at a stalemate. The Soviets had shown no indication that they would back down and had made public media and private inter-governmental statements to that effect. The US had no reason to believe otherwise and was in the early stages of preparing for an invasion, along with a nuclear strike on the Soviet Union if it responded militarily, which was assumed. Kennedy had no intention of keeping these plans a secret; with an array of Cuban and Soviet spies forever present, Khrushchev was quickly made aware of this looming danger.\nThe implicit threat of air strikes on Cuba followed by invasion allowed the United States to exert pressure in future talks. It was the possibility of military action that played an influential role in accelerating Khrushchev's proposal for a compromise. Throughout the closing stages of October, Soviet communications to the United States indicated increasing defensiveness. Khrushchev's increasing tendency to use poorly phrased and ambiguous communications throughout the compromise negotiations conversely increased United States confidence and clarity in messaging. Leading Soviet figures consistently failed to mention that only the Cuban government could agree to inspections of the territory and continually made arrangements relating to Cuba without the knowledge of Fidel Castro himself. According to Dean Rusk, Khrushchev \"blinked\", he began to panic from the consequences of his own plan and this was reflected in the tone of Soviet messages. This allowed the US to largely dominate negotiations in late October.\nSecret negotiations.\nAt 1:00\u00a0pm EDT on October 26, John A. Scali of ABC News had lunch with Aleksandr Fomin, the cover name of Alexander Feklisov, the KGB station chief in Washington, at Fomin's request. Following the instructions of the Politburo of the CPSU, Fomin noted, \"War seems about to break out.\" He asked Scali to use his contacts to talk to his \"high-level friends\" at the State Department to see if the US would be interested in a diplomatic solution. He suggested that the language of the deal would contain an assurance from the Soviet Union to remove the weapons under UN supervision and that Castro would publicly announce that he would not accept such weapons again in exchange for a public statement by the US that it would not invade Cuba. The US responded by asking the Brazilian government to pass a message to Castro that the US would be \"unlikely to invade\" if the missiles were removed.\nOn October 26 at 6:00\u00a0pm EDT, the State Department started receiving a message that appeared to be written personally by Khrushchev. It was Saturday at 2:00\u00a0am in Moscow. The long letter took several minutes to arrive, and it took translators additional time to translate and transcribe it.\nRobert F. Kennedy described the letter as \"very long and emotional\". Khrushchev reiterated the basic outline that had been stated to Scali earlier in the day: \"I propose: we, for our part, will declare that our ships bound for Cuba are not carrying any armaments. You will declare that the United States will not invade Cuba with its troops and will not support any other forces which might intend to invade Cuba. Then the necessity of the presence of our military specialists in Cuba will disappear.\" At 6:45\u00a0pm EDT, news of Fomin's offer to Scali was finally heard and was interpreted as a \"set up\" for the arrival of Khrushchev's letter. The letter was then considered official and accurate although it was later learned that Fomin was almost certainly operating of his own accord without official backing. Additional study of the letter was ordered and continued into the night.\nCrisis continues.\nCastro, on the other hand, was convinced that an invasion of Cuba was soon at hand, and on October 26, he sent a telegram to Khrushchev that appeared to call for a pre-emptive nuclear strike on the US in case of attack. In a 2010 interview, Castro expressed regret about his earlier stance on first use: \"After I've seen what I've seen, and knowing what I know now, it wasn't worth it at all.\" Castro also ordered all anti-aircraft weapons in Cuba to fire on any US aircraft: the orders had been to fire only on groups of two or more. At 6:00\u00a0am EDT on October 27, the CIA delivered a memo reporting that three of the four missile sites at San Cristobal and the two sites at Sagua la Grande appeared to be fully operational. It also noted that the Cuban military continued to organise for action but was under order not to initiate action unless attacked.\nAt 9:00\u00a0am EDT on October 27, Radio Moscow began broadcasting a message from Khrushchev. Contrary to the letter of the night before, the message offered a new trade: the missiles on Cuba would be removed in exchange for the removal of the Jupiter missiles from Italy and Turkey. At 10:00\u00a0am EDT, the executive committee met again to discuss the situation and came to the conclusion that the change in the message was because of internal debate between Khrushchev and other party officials in the Kremlin. Kennedy realised that he would be in an \"insupportable position if this becomes Khrushchev's proposal\" because the missiles in Turkey were not militarily useful and were being removed anyway and \"It's gonna \u2013 to any man at the United Nations or any other rational man, it will look like a very fair trade.\" Bundy explained why Khrushchev's public acquiescence could not be considered: \"The current threat to peace is not in Turkey, it is in Cuba.\"\nMcNamara noted that another tanker, the \"Grozny\", was about out and should be intercepted. He also noted that they had not made the Soviets aware of the blockade line and suggested relaying that information to them via U Thant at the United Nations.\nWhile the meeting progressed, at 11:03\u00a0am EDT a new message began to arrive from Khrushchev. The message stated, in part:\n\"You are disturbed over Cuba. You say that this disturbs you because it is ninety-nine miles by sea from the coast of the United States of America. But... you have placed destructive missile weapons, which you call offensive, in Italy and Turkey, literally next to us... I therefore make this proposal: We are willing to remove from Cuba the means which you regard as offensive... Your representatives will make a declaration to the effect that the United States... will remove its analogous means from Turkey... and after that, persons entrusted by the United Nations Security Council could inspect on the spot the fulfillment of the pledges made.\"\nThe executive committee continued to meet through the day.\nThroughout the crisis, Turkey had repeatedly stated that it would be upset if the Jupiter missiles were removed. Italy's Prime Minister Amintore Fanfani, who was also Foreign Minister \"ad interim\", offered to allow withdrawal of the missiles deployed in Apulia as a bargaining chip. He gave the message to one of his most trusted friends, Ettore Bernabei, the general manager of RAI-TV, to convey to Arthur M. Schlesinger Jr. Bernabei was in New York to attend an international conference on satellite TV broadcasting. Unknown to the Soviets, the US regarded the Jupiter missiles as obsolete and already supplanted by the Polaris nuclear ballistic submarine missiles.\nOn the morning of October 27, a U-2F (the third CIA U-2A, modified for air-to-air refuelling) piloted by USAF Major Rudolf Anderson, departed its forward operating location at McCoy AFB, Florida. At approximately 12:00\u00a0pm EDT, the aircraft was struck by an SA-2 surface-to-air missile launched from Cuba. The aircraft was shot down, and Anderson was killed. The stress in negotiations between the Soviets and the US intensified; it was only later believed that the decision to fire the missile was made locally by an undetermined Soviet commander, acting on his own authority. Later that day, at about 3:41\u00a0pm EDT, several US Navy RF-8A Crusader aircraft, on low-level photo-reconnaissance missions, were fired upon.\nOn October 28, 1962, Khrushchev told his son Sergei that the shooting down of Anderson's U-2 was by the \"Cuban military at the direction of Raul Castro\".\nAt 4:00\u00a0pm EDT, Kennedy recalled members of EXCOMM to the White House and ordered that a message should immediately be sent to U Thant asking the Soviets to suspend work on the missiles while negotiations were carried out. During the meeting, General Maxwell Taylor delivered the news that the U-2 had been shot down. Kennedy had earlier claimed he would order an attack on such sites if fired upon, but he decided to not act unless another attack was made. Forty years later, McNamara said:\nEllsberg said that Robert Kennedy (RFK) told him in 1964 that after the U-2 was shot down and the pilot killed, he (RFK) told Soviet ambassador Dobrynin, \"You have drawn first blood ... . [T]he president had decided against advice ... not to respond militarily to that attack, but he [Dobrynin] should know that if another plane was shot at, ... we would take out all the SAMs and antiaircraft ... . And that would almost surely be followed by an invasion.\"\nDrafting response.\nEmissaries sent by both Kennedy and Khrushchev agreed to meet at the Yenching Palace Chinese restaurant in the Cleveland Park neighbourhood of Washington, DC, on Saturday evening, October 27. Kennedy suggested to take Khrushchev's offer to trade away the missiles. Unknown to most members of the EXCOMM, but with the support of his brother the president, Robert Kennedy had been meeting with the Soviet Ambassador Dobrynin in Washington to discover whether the intentions were genuine. The EXCOMM was generally against the proposal because it would undermine NATO's authority, and the Turkish government had repeatedly stated it was against any such trade.\nAs the meeting progressed, a new plan emerged, and Kennedy was slowly persuaded. The new plan called for him to ignore the latest message and instead to return to Khrushchev's earlier one. Kennedy was initially hesitant, feeling that Khrushchev would no longer accept the deal because a new one had been offered, but Llewellyn Thompson argued that it was still possible. White House Special Counsel and Adviser Ted Sorensen and Robert Kennedy left the meeting and returned 45\u00a0minutes later, with a draft letter to that effect. The President made several changes, had it typed, and sent it.\nAfter the EXCOMM meeting, a smaller meeting continued in the Oval Office. The group argued that the letter should be underscored with an oral message to Dobrynin that stated that if the missiles were not withdrawn, military action would be used to remove them. Rusk added one proviso that no part of the language of the deal would mention Turkey, but there would be an understanding that the missiles would be removed \"voluntarily\" in the immediate aftermath. The president agreed, and the message was sent.\nAt Rusk's request, Fomin and Scali met again. Scali asked why the two letters from Khrushchev were so different, and Fomin claimed it was because of \"poor communications\". Scali replied that the claim was not credible and shouted that he thought it was a \"stinking double cross\". He went on to claim that an invasion was only hours away, and Fomin stated that a response to the US message was expected from Khrushchev shortly and urged Scali to tell the State Department that no treachery was intended. Scali said that he did not think anyone would believe him, but he agreed to deliver the message. The two went their separate ways, and Scali immediately typed out a memo for the EXCOMM.\nWithin the US establishment, it was well understood that ignoring the second offer and returning to the first put Khrushchev in a terrible position. Military preparations continued, and all active duty Air Force personnel were recalled to their bases for possible action. Robert Kennedy later recalled the mood: \"We had not abandoned all hope, but what hope there was now rested with Khrushchev's revising his course within the next few hours. It was a hope, not an expectation. The expectation was military confrontation by Tuesday (October 30), and possibly tomorrow (October 29) ...\"\nAt 8:05\u00a0pm EDT, the letter drafted earlier in the day was delivered. The message read, \"As I read your letter, the key elements of your proposals\u2014which seem generally acceptable as I understand them\u2014are as follows: 1) You would agree to remove these weapons systems from Cuba under appropriate United Nations observation and supervision; and undertake, with suitable safe-guards, to halt the further introduction of such weapon systems into Cuba. 2) We, on our part, would agree\u2014upon the establishment of adequate arrangements through the United Nations, to ensure the carrying out and continuation of these commitments (a) to remove promptly the quarantine measures now in effect and (b) to give assurances against the invasion of Cuba.\" The letter was also released directly to the press to ensure it could not be \"delayed\". With the letter delivered, a deal was on the table. As Robert Kennedy noted, there was little expectation it would be accepted. At 9:00\u00a0pm EDT, the EXCOMM met again to review the actions for the following day. Plans were drawn up for air strikes on the missile sites as well as other economic targets, notably petroleum storage. McNamara stated that they had to \"have two things ready: a government for Cuba, because we're going to need one; and secondly, plans for how to respond to the Soviet Union in Europe, because sure as hell they're going to do something there\".\nAt 12:12\u00a0am EDT, on October 27, the US informed its NATO allies that \"the situation is growing shorter... the United States may find it necessary within a very short time in its interest and that of its fellow nations in the Western Hemisphere to take whatever military action may be necessary.\" To add to the concern, at 6:00\u00a0am, the CIA reported that all missiles in Cuba were ready for action.\nOn October 27, Khrushchev also received a letter from Castro, what is now known as the Armageddon Letter (dated the day before), which was interpreted as urging the use of nuclear force in the event of an attack on Cuba: \"I believe the imperialists' aggressiveness is extremely dangerous and if they actually carry out the brutal act of invading Cuba in violation of international law and morality, that would be the moment to eliminate such danger forever through an act of clear legitimate defense, however harsh and terrible the solution would be,\" Castro wrote.\nAverted nuclear launch.\nLater that same day, what the White House later called \"Black Saturday\", the US Navy dropped a series of \"signalling\" depth charges (practice depth charges the size of hand grenades) on a Soviet submarine () at the blockade line, unaware that it was armed with a nuclear-tipped torpedo with orders that allowed it to be used if the submarine was damaged by depth charges or surface fire. As the submarine was too deep to monitor any radio traffic, the captain of the \"B-59\", Valentin Grigorievitch Savitsky, decided that a war might already have started and wanted to launch a nuclear torpedo. The decision to launch these required agreement from all three officers on board, but one of them, Vasily Arkhipov, objected and so the nuclear launch was narrowly averted.\nOn the same day a U-2 spy plane made an accidental, unauthorised ninety-minute overflight of the Soviet Union's far eastern coast. The Soviets responded by scrambling MiG fighters from Wrangel Island; in turn, the Americans launched F-102 fighters armed with nuclear air-to-air missiles over the Bering Sea.\nCrisis ends.\nOn Saturday, October 27, after much deliberation between the Soviet Union and Kennedy's cabinet, Kennedy secretly agreed to remove all missiles set in Turkey and possibly southern Italy, the former on the border of the Soviet Union, in exchange for Khrushchev removing all missiles in Cuba. There is some dispute as to whether removing the missiles from Italy was part of the secret agreement. Khrushchev wrote in his memoirs that it was, and when the crisis had ended McNamara gave the order to dismantle the missiles in both Italy and Turkey.\nAt this point, Khrushchev knew things the US did not: First, that the shooting down of the U-2 by a Soviet missile violated direct orders from Moscow, and Cuban antiaircraft fire against other US reconnaissance aircraft also violated direct orders from Khrushchev to Castro. Second, the Soviets already had 162 nuclear warheads on Cuba that the US did not then believe were there. Third, the Soviets and Cubans on the island would almost certainly have responded to an invasion by using those nuclear weapons, even though Castro believed that every human in Cuba would likely die as a result. Khrushchev also knew but may not have considered the fact that he had submarines armed with nuclear weapons that the US Navy may not have known about.\nKhrushchev knew he was losing control. President Kennedy had been told in early 1961 that a nuclear war would likely kill a third of humanity, with most or all of those deaths concentrated in the US, the USSR, Europe and China; Khrushchev may well have received similar reports from his military.\nWith this background, when Khrushchev heard Kennedy's threats relayed by Robert Kennedy to Soviet Ambassador Dobrynin, he immediately drafted his acceptance of Kennedy's latest terms from his dacha without involving the Politburo, as he had previously, and had them immediately broadcast over Radio Moscow, which he believed the US would hear. In that broadcast at 9:00\u00a0am EST, on October 28, Khrushchev stated that \"the Soviet government, in addition to previously issued instructions on the cessation of further work at the building sites for the weapons, has issued a new order on the dismantling of the weapons which you describe as 'offensive' and their crating and return to the Soviet Union.\" At 10:00\u00a0am, October 28, Kennedy first learned of Khrushchev's solution to the crisis with the US removing the 15 Jupiters in Turkey and the Soviets would remove the rockets from Cuba. Khrushchev had made the offer in a public statement for the world to hear. Despite almost solid opposition from his senior advisers, Kennedy quickly embraced the Soviet offer. \"This is a pretty good play of his,\" Kennedy said, according to a tape recording that he made secretly of the Cabinet Room meeting. Kennedy had deployed the Jupiters in March of the year, causing a stream of angry outbursts from Khrushchev. \"Most people will think this is a rather even trade and we ought to take advantage of it,\" Kennedy said. Vice President Lyndon Johnson was the first to endorse the missile swap but others continued to oppose the offer. Finally, Kennedy ended the debate. \"We can't very well invade Cuba with all its toil and blood,\" Kennedy said, \"when we could have gotten them out by making a deal on the same missiles on Turkey. If that's part of the record, then you don't have a very good war.\"\nKennedy immediately responded to Khrushchev's letter, issuing a statement calling it \"an important and constructive contribution to peace\". He continued this with a formal letter:\nKennedy's planned statement would also contain suggestions he had received from his adviser Schlesinger Jr. in a \"Memorandum for the President\" describing the \"Post Mortem on Cuba\".\nKennedy's Oval Office telephone conversation with Eisenhower soon after Khrushchev's message arrived revealed that the President was planning to use the Cuban Missile Crisis to escalate tensions with Khrushchev and in the long run, Cuba as well. The President also claimed that he thought the crisis would result in direct military confrontations in Berlin by the end of the next month. He also claimed in his conversation with Eisenhower that the Soviet leader had offered to withdraw from Cuba in exchange for the withdrawal of missiles from Turkey and that while the Kennedy Administration had agreed not to invade Cuba, they were only in process of determining Khrushchev's offer to withdraw from Turkey.\nWhen former US President Harry Truman called President Kennedy the day of Khrushchev's offer, the President informed him that his Administration had rejected the Soviet leader's offer to withdraw missiles from Turkey and was planning on using the Soviet setback in Cuba to escalate tensions in Berlin.\nThe US continued the blockade; in the following days, aerial reconnaissance proved that the Soviets were making progress in removing the missile systems. The 42 missiles and their support equipment were loaded onto eight Soviet ships. On November 2, 1962, Kennedy addressed the US via radio and television broadcasts regarding the dismantlement process of the Soviet R-12 missile bases located in the Caribbean region. The ships left Cuba on November 5 to 9. The US made a final visual check as each of the ships passed the blockade line. Further diplomatic efforts were required to remove the Soviet Il-28 bombers, and they were loaded on three Soviet ships on December 5 and 6. Concurrent with the Soviet commitment on the Il-28s, the US government announced the end of the blockade from 6:45\u00a0pm EST on November 20, 1962. \nAt the time when the Kennedy administration thought that the Cuban Missile Crisis was resolved, nuclear tactical rockets stayed in Cuba since they were not part of the Kennedy-Khrushchev understandings and the Americans did not know about them. The Soviets changed their minds, fearing possible future Cuban militant steps, and on November 22, 1962, Deputy Premier of the Soviet Union Anastas Mikoyan told Castro that the rockets with the nuclear warheads were being removed as well.\nIn his negotiations with the Soviet Ambassador Anatoly Dobrynin, Robert Kennedy informally proposed that the Jupiter missiles in Turkey would be removed \"within a short time after this crisis was over\". Under an operation code-named \"Operation Pot Pie,\" the removal of the Jupiters from Italy and Turkey began on 1 April and was completed by 24 April 1963. The initial plans were to recycle the missiles for use in other programs, but NASA and the USAF were not interested in retaining the missile hardware. The missile bodies were destroyed on site, warheads, guidance packages, and launching equipment worth $14 million were returned to the United States.\nThe practical effect of the Kennedy-Khrushchev Pact was that the US would remove their rockets from Italy and Turkey and that the Soviets had no intention of resorting to nuclear war if they were out-gunned by the US. Because the withdrawal of the Jupiter missiles from NATO bases in Italy and Turkey was not made public at the time, Khrushchev appeared to have lost the conflict and become weakened. The perception was that Kennedy had won the contest between the superpowers and that Khrushchev had been humiliated. Both Kennedy and Khrushchev took every step to avoid full conflict despite pressures from their respective governments. Khrushchev held power for another two years.\nNuclear forces.\nBy the time of the crisis in October 1962, the total number of nuclear weapons in the stockpiles of each country numbered approximately 26,400 for the United States and 3,300 for the Soviet Union. At the peak of the crisis, the U.S. had some 3,500 nuclear weapons ready to be used on command with a combined yield of approximately 6,300 megatons. The Soviets had considerably less strategic firepower at their disposal (some 300\u2013320 bombs and warheads), lacking submarine-based weapons in a position to threaten the U.S. mainland and having most of their intercontinental delivery systems based on bombers that would have difficulty penetrating North American air defence systems. The U.S. had approximately 4,375 nuclear weapons deployed in Europe, most of which were tactical weapons such as nuclear artillery, with around 450 of them for ballistic missiles, cruise missiles, and aircraft; the Soviets had more than 550 similar weapons in Europe.\nAftermath.\nSoviet leadership.\nThe enormity of how close the world came to thermonuclear war impelled Khrushchev to propose a far-reaching easing of tensions with the US. In a letter to President Kennedy dated October 30, 1962, Khrushchev outlined a range of bold initiatives to forestall the possibility of a further nuclear crisis, including proposing a non-aggression treaty between the North Atlantic Treaty Organization (NATO) and the Warsaw Pact or even disbanding these military blocs, a treaty to cease all nuclear weapons testing and even the elimination of all nuclear weapons, resolution of the hot-button issue of Germany by both East and West formally accepting the existence of West Germany and East Germany, and US recognition of the government of mainland China. The letter invited counter-proposals and further exploration of these and other issues through peaceful negotiations. Khrushchev invited Norman Cousins, the editor of a major US periodical and an anti-nuclear weapons activist, to serve as liaison with President Kennedy, and Cousins met with Khrushchev for four hours in December 1962.\nKennedy's response to Khrushchev's proposals was lukewarm but Kennedy expressed to Cousins that he felt constrained in exploring these issues due to pressure from hardliners in the US national security apparatus. The US and the USSR did shortly thereafter agree on a treaty banning atmospheric testing of nuclear weapons, known as the \"Partial Nuclear Test Ban Treaty\".\nFurther after the crisis, the US and the Soviet Union created the Moscow\u2013Washington hotline, a direct communications link between Moscow and Washington. The purpose was to have a way that the leaders of the two Cold War countries could communicate directly to solve such a crisis.\nThe compromise embarrassed Khrushchev and the Soviet Union because the withdrawal of US missiles from Italy and Turkey was a secret deal between Kennedy and Khrushchev. Khrushchev went to Kennedy as he thought that the crisis was getting out of hand, but the Soviets were seen as retreating from circumstances that they had started.\nKhrushchev's fall from power two years later was in part because of the Soviet Politburo's embarrassment at both Khrushchev's eventual concessions to the US and this ineptitude in precipitating the crisis in the first place. According to Dobrynin, the top Soviet leadership took the Cuban outcome as \"a blow to its prestige bordering on humiliation\".\nCuban leadership.\nCuba perceived the outcome as a betrayal by the Soviets, as decisions on how to resolve the crisis had been made exclusively by Kennedy and Khrushchev. Castro was especially upset that certain issues of interest to Cuba, such as the status of the US Naval Base in Guant\u00e1namo, were not addressed. That caused Cuban\u2013Soviet relations to deteriorate for years to come.\nUS leadership.\nThe worldwide US Forces DEFCON 3 status was returned to DEFCON 4 on November 20, 1962. General Curtis LeMay told the President that the resolution of the crisis was the \"greatest defeat in our history\"; his was a minority position. He had pressed for an immediate invasion of Cuba as soon as the crisis began and still favoured invading Cuba even after the Soviets had withdrawn their missiles. Twenty-five years later, LeMay still believed that \"We could have gotten not only the missiles out of Cuba, we could have gotten the Communists out of Cuba at that time.\"\nAt least four contingency strikes were armed and launched from Florida against Cuban airfields and suspected missile sites in 1963 and 1964, although all were diverted to the Pinecastle Range Complex after the planes passed Andros island. Critics, including Seymour Melman, and Seymour Hersh suggested that the Cuban Missile Crisis encouraged the United States' use of military means, such as the case in the later Vietnam War.\nHuman casualties.\nU-2 pilot Anderson's body was returned to the US and was buried with full military honours in South Carolina. He was the first recipient of the newly created Air Force Cross, which was awarded posthumously. Although Anderson was the only combatant fatality during the crisis, 11 crew members of three reconnaissance Boeing RB-47 Stratojets of the 55th Strategic Reconnaissance Wing were also killed in crashes during the period between September 27 and November 11, 1962. Seven crew died when a Military Air Transport Service Boeing C-135B Stratolifter delivering ammunition to Guantanamo Bay Naval Base stalled and crashed on approach on October 23.\nLater revelations.\nSchlesinger, a historian and adviser to Kennedy, told National Public Radio in an interview on October 16, 2002 that Castro did not want the missiles, but Khrushchev pressured Castro to accept them. Castro was not completely happy with the idea, but the Cuban National Directorate of the Revolution accepted them, both to protect Cuba against US attack and to aid the Soviet Union. Schlesinger believed that when the missiles were withdrawn, Castro was more angry with Khrushchev than with Kennedy because Khrushchev had not consulted Castro before deciding to remove them. Although Castro was infuriated by Khrushchev, he planned on striking the US with remaining missiles if an invasion of the island occurred.\nIn early 1992, it was confirmed that Soviet forces in Cuba had already received tactical nuclear warheads for their artillery rockets and Il-28 bombers when the crisis broke. Castro stated that he would have recommended their use if the US invaded despite Cuba being destroyed.\nArguably, the most dangerous moment in the crisis was not recognised until the Cuban Missile Crisis Havana conference, in October 2002. Attended by many of the veterans of the crisis, they all learned that on October 27, 1962, had tracked and dropped signalling depth charges (the size of hand grenades) on , a Soviet Project 641 (NATO designation ) submarine. Unknown to the US, it was armed with a 15-kiloton nuclear torpedo. Running out of air, the Soviet submarine was surrounded by American warships and desperately needed to surface. An argument broke out among three officers aboard \"B-59\", including submarine captain Valentin Savitsky, political officer Ivan Semonovich Maslennikov, and Deputy brigade commander Captain 2nd rank (US Navy Commander rank equivalent) Vasily Arkhipov. An exhausted Savitsky became furious and ordered that the nuclear torpedo on board be made combat ready. Accounts differ about whether Arkhipov convinced Savitsky not to make the attack or whether Savitsky himself finally concluded that the only reasonable choice left open to him was to come to the surface. During the conference, McNamara stated that nuclear war had come much closer than people had thought. Thomas Blanton, director of the National Security Archive, said, \"A guy called Vasili Arkhipov saved the world.\"\nFifty years after the crisis, Graham T. Allison wrote:\nBBC journalist Joe Matthews published the story, on October 13, 2012, behind the 100 tactical nuclear warheads mentioned by Graham Allison in the excerpt above. Khrushchev feared that Castro's hurt pride and widespread Cuban indignation over the concessions he had made to Kennedy might lead to a breakdown of the agreement between the Soviet Union and the US. To prevent that, Khrushchev decided to offer to give Cuba more than 100 tactical nuclear weapons that had been shipped to Cuba along with the long-range missiles but, crucially, had escaped the notice of US intelligence. Khrushchev determined that because the Americans had not listed the missiles on their list of demands, keeping them in Cuba would be in the Soviet Union's interests.\nAnastas Mikoyan was tasked with the negotiations with Castro over the missile transfer deal that was designed to prevent a breakdown in the relations between Cuba and the Soviet Union. While in Havana, Mikoyan witnessed the mood swings and paranoia of Castro, who was convinced that Moscow had made the agreement with the US at the expense of Cuba's defence. Mikoyan, on his own initiative, decided that Castro and his military not be given control of weapons with an explosive force equal to 100 Hiroshima-sized bombs under any circumstances. He defused the seemingly intractable situation, which risked re-escalating the crisis, on November 22, 1962. During a tense, four-hour meeting, Mikoyan convinced Castro that despite Moscow's desire to help, it would be in breach of an unpublished Soviet law, which did not actually exist, to transfer the missiles permanently into Cuban hands and provide them with an independent nuclear deterrent. Castro was forced to give way and, much to the relief of Khrushchev and the rest of the Soviet government, the tactical nuclear weapons were crated and returned by sea to the Soviet Union during December 1962.\nIn popular culture.\nThe American popular media, especially television, made frequent use of the events of the missile crisis and both fictional and documentary forms. Jim Willis includes the Crisis as one of the 100 \"media moments that changed America\". Sheldon Stern finds that a half century later there are still many \"misconceptions, half-truths, and outright lies\" that have shaped media versions of what happened in the White House during those harrowing two weeks.\nHistorian William Cohn argued in a 1976 article that television programs are typically the main source used by the American public to know about and interpret the past. According to Cold War historian Andrei Kozovoi, the Soviet media proved somewhat disorganised as it was unable to generate a coherent popular history. Khrushchev lost power and was airbrushed out of the story. Cuba was no longer portrayed as a heroic David against the American Goliath. One contradiction that pervaded the Soviet media campaign was between the pacifistic rhetoric of the peace movement that emphasises the horrors of nuclear war and the militancy of the need to prepare Soviets for war against American aggression."}
{"id": "6828", "revid": "12512572", "url": "https://en.wikipedia.org/wiki?curid=6828", "title": "Aquilegia", "text": "Aquilegia (common names: granny's bonnet, columbine) is a genus of about 60\u201370 species of perennial plants that are found in meadows, woodlands, and at higher altitudes throughout the Northern Hemisphere, known for the spurred petals of their flowers.\nEtymology.\nThe genus name \"Aquilegia\" is derived from the Latin word for eagle (\"aquila\"), because of the shape of the flower petals, which are said to resemble an eagle's claw. The common name \"columbine\" comes from the Latin for \"dove\", due to the resemblance of the inverted flower to five doves clustered together.\nDescription.\nPerennial herbs, with woody, erect stock, roots forming thick rhizomes. The basal leaves are compound, 1\u20133 ternate, blades 3-lobed -partite, and lobes lobulate and obtuse. The cauline leaves are similar to the basal ones, while the upper ones are bract like. \nThe hermaphrodite (bisexual) flowers are terminal to stem and branches. They are usually pentamerous (with five spreading perianth petaloid sepal segments). Five tubular honey-leaves are semi erect with a flat limb and spurred or saccate at the base. The spur is directed backwards and secretes nectar. Stamens are numerous (often more than 50) in whorls of 5, the innermost being scarious staminodes. There are ten membranaceous intrastaminal scales. There are five pistils and the Carpels are free.\nThe fruit has several (five to 15) follicles which are semi erect and slightly connate downwards. These hold many seeds and are formed at the end of the pistils. The nectar is mainly consumed by long-beaked birds such as hummingbirds. Almost all \"Aquilegia\" species have a ring of staminodia around the base of the stigma, which may help protect against insects. Chromosome number is x=7.\nRelatives.\nColumbines are closely related to plants in the genera \"Actaea\" (baneberries) and \"Aconitum\" (wolfsbanes/monkshoods), which like \"Aquilegia\" produce cardiogenic toxins.\nInsects.\nThey are used as food plants by some Lepidoptera (butterfly and moth) caterpillars. These are mainly of noctuid moths \u2013 noted for feeding on many poisonous plants without harm \u2013 such as cabbage moth (\"Mamestra brassicae\"), dot moth (\"Melanchra persicariae\") and mouse moth (\"Amphipyra tragopoginis\"). the engrailed (\"Ectropis crepuscularia\"), a geometer moth, also uses columbine as a larval food plant. The larvae of the \"Papaipema leucostigma\" also feed on columbine.\nPlants in the genus \"Aquilegia\" are a major food source for \"Bombus hortorum\", a species of bumblebee. Specifically, they have been found to forage on species of \"Aquilegia vulgaris\" in Belgium and \"Aquilegia chrysantha\" in North America and Belgium. The bees do not show any preference in color of the flowers.\nCultivation.\nColumbine is a hardy perennial, which propagates by seed. It will grow to a height of 15 to 20\u00a0inches. It will grow in full sun; however, it prefers growing in partial shade and well drained soil, and is able to tolerate average soils and dry soil conditions. Columbine is rated at hardiness zone 3 in the United States so does not require mulching or protection in the winter.\nLarge numbers of hybrids are available for the garden, since the European \"A. vulgaris\" was hybridized with other European and North American varieties.\n \"Aquilegia\" species are very interfertile, and will self-sow. Some varieties are short-lived so are better treated as biennials. \nThe British National Collection of \"Aquilegia\"s was held by Mrs Carrie Thomas at Killay near Swansea. Some time during or before 2014 the collection started to succumb to Aquilegia Downy Mildew \"Peronospora aquilegiicola\" which was at the time an emerging disease to which the plants had no resistance. By 2018 the entire collection had been lost. Aquilegia can be grown from seeds or rhizomes.\nUses.\nThe flowers of various species of columbine were consumed in moderation by Native Americans as a condiment with other fresh greens, and are reported to be very sweet, and safe if consumed in small quantities. The plant's seeds and roots, however, are highly poisonous and contain cardiogenic toxins which cause both severe gastroenteritis and heart palpitations if consumed as food. Native Americans used very small amounts of \"Aquilegia\" root as a treatment for ulcers. However, the medical use of this plant is better avoided due to its high toxicity; columbine poisonings may be fatal.\nAn acute toxicity test in mice has demonstrated that ethanol extract mixed with isocytisoside, the main flavonoid compound from the leaves and stems of \"Aquilegia vulgaris\", can be classified as non-toxic, since a dose of 3000\u00a0mg/kg did not cause mortality.\nCulture.\nThe Colorado blue columbine (\"A. coerulea\") is the official state flower of Colorado (see also Columbine, Colorado).\nEvolution.\nColumbines have been important in the study of evolution. It was found that the Sierra columbine (\"A. pubescens\") and crimson columbine (\"A. formosa\") each has adapted specifically to a pollinator. Bees and hummingbirds are the visitors to \"A. formosa\", while hawkmoths would only visit \"A. pubescens\" when given a choice. Such a \"pollination syndrome\", being due to flower color and orientation controlled by their genetics, ensures reproductive isolation and can be a cause of speciation.\n\"Aquilegia\" petals show an enormous range of petal spur length diversity ranging from a centimeter to the 15\u00a0cm spurs of \"Aquilegia longissima\". Selection from pollinator shifts is suggested to have driven these changes in nectar spur length. \nIt was shown that this spur length diversity is achieved solely through changing cell shape, not cell number or cell size. This suggests that a simple microscopic change can result in a dramatic evolutionarily relevant morphological change.\nSpecies.\nColumbine species include:"}
{"id": "6829", "revid": "6908984", "url": "https://en.wikipedia.org/wiki?curid=6829", "title": "Cache (computing)", "text": "In computing, a cache ( , or in Australian English) is a hardware or software component that stores data so that future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation or a copy of data stored elsewhere. A \"cache hit\" occurs when the requested data can be found in a cache, while a \"cache miss\" occurs when it cannot. Cache hits are served by reading data from the cache, which is faster than recomputing a result or reading from a slower data store; thus, the more requests that can be served from the cache, the faster the system performs.\nTo be cost-effective and to enable efficient use of data, caches must be relatively small. Nevertheless, caches have proven themselves in many areas of computing, because typical computer applications access data with a high degree of locality of reference. Such access patterns exhibit temporal locality, where data is requested that has been recently requested already, and spatial locality, where data is requested that is stored physically close to data that has already been requested.\nMotivation.\nThere is an inherent trade-off between size and speed (given that a larger resource implies greater physical distances) but also a tradeoff between expensive, premium technologies (such as SRAM) vs cheaper, easily mass-produced commodities (such as DRAM or hard disks).\nThe buffering provided by a cache benefits both latency and throughput (bandwidth):\nLatency.\nA larger resource incurs a significant latency for access e.g. it can take hundreds of clock cycles for a modern 4\u00a0GHz processor to reach DRAM. This is mitigated by reading in large chunks, in the hope that subsequent reads will be from nearby locations. Prediction or explicit prefetching might also guess where future reads will come from and make requests ahead of time; if done correctly the latency is bypassed altogether.\nThroughput.\nThe use of a cache also allows for higher throughput from the underlying resource, by assembling multiple fine grain transfers into larger, more efficient requests. In the case of DRAM circuits, this might be served by having a wider data bus. For example, consider a program accessing bytes in a 32-bit address space, but being served by a 128-bit off-chip data bus; individual uncached byte accesses would allow only 1/16th of the total bandwidth to be used, and 80% of the data movement would be memory addresses instead of data itself. Reading larger chunks reduces the fraction of bandwidth required for transmitting address information.\nOperation.\nHardware implements cache as a block of memory for temporary storage of data likely to be used again. Central processing units (CPUs) and hard disk drives (HDDs) frequently use a cache, as do web browsers and web servers.\nA cache is made up of a pool of entries. Each entry has associated \"data\", which is a copy of the same data in some \"backing store\". Each entry also has a \"tag\", which specifies the identity of the data in the backing store of which the entry is a copy. Tagging allows simultaneous cache-oriented algorithms to function in multilayered fashion without differential relay interference.\nWhen the cache client (a CPU, web browser, operating system) needs to access data presumed to exist in the backing store, it first checks the cache. If an entry can be found with a tag matching that of the desired data, the data in the entry is used instead. This situation is known as a cache hit. For example, a web browser program might check its local cache on disk to see if it has a local copy of the contents of a web page at a particular URL. In this example, the URL is the tag, and the content of the web page is the data. The percentage of accesses that result in cache hits is known as the hit rate or hit ratio of the cache.\nThe alternative situation, when the cache is checked and found not to contain any entry with the desired tag, is known as a cache miss. This requires a more expensive access of data from the backing store. Once the requested data is retrieved, it is typically copied into the cache, ready for the next access.\nDuring a cache miss, some other previously existing cache entry is removed in order to make room for the newly retrieved data. The heuristic used to select the entry to replace is known as the replacement policy. One popular replacement policy, \"least recently used\" (LRU), replaces the oldest entry, the entry that was accessed less recently than any other entry (see cache algorithm). More efficient caching algorithms compute the use-hit frequency against the size of the stored contents, as well as the latencies and throughputs for both the cache and the backing store. This works well for larger amounts of data, longer latencies, and slower throughputs, such as that experienced with hard drives and networks, but is not efficient for use within a CPU cache.\nWriting policies.\nWhen a system writes data to cache, it must at some point write that data to the backing store as well. The timing of this write is controlled by what is known as the \"write policy\". There are two basic writing approaches:\nA write-back cache is more complex to implement, since it needs to track which of its locations have been written over, and mark them as \"dirty\" for later writing to the backing store. The data in these locations are written back to the backing store only when they are evicted from the cache, an effect referred to as a \"lazy write\". For this reason, a read miss in a write-back cache (which requires a block to be replaced by another) will often require two memory accesses to service: one to write the replaced data from the cache back to the store, and then one to retrieve the needed data.\nOther policies may also trigger data write-back. The client may make many changes to data in the cache, and then explicitly notify the cache to write back the data.\nSince no data is returned to the requester on write operations, a decision needs to be made on write misses, whether or not data would be loaded into the cache.\nThis is defined by these two approaches:\nBoth write-through and write-back policies can use either of these write-miss policies, but usually they are paired in this way:\nEntities other than the cache may change the data in the backing store, in which case the copy in the cache may become out-of-date or \"stale\". Alternatively, when the client updates the data in the cache, copies of those data in other caches will become stale. Communication protocols between the cache managers which keep the data consistent are known as coherency protocols.\nExamples of hardware caches.\nCPU cache.\nSmall memories on or close to the CPU can operate faster than the much larger main memory. Most CPUs since the 1980s have used one or more caches, sometimes in cascaded levels; modern high-end embedded, desktop and server microprocessors may have as many as six types of cache (between levels and functions). Examples of caches with a specific function are the D-cache and I-cache and the translation lookaside buffer for the MMU.\nGPU cache.\nEarlier graphics processing units (GPUs) often had limited read-only texture caches, and introduced Morton order swizzled textures to improve 2D cache coherency. Cache misses would drastically affect performance, e.g. if mipmapping was not used. Caching was important to leverage 32-bit (and wider) transfers for texture data that was often as little as 4\u00a0bits per pixel, indexed in complex patterns by arbitrary UV coordinates and perspective transformations in inverse texture mapping.\nAs GPUs advanced (especially with GPGPU compute shaders) they have developed progressively larger and increasingly general caches, including instruction caches for shaders, exhibiting increasingly common functionality with CPU caches. For example, GT200 architecture GPUs did not feature an L2 cache, while the Fermi GPU has 768\u00a0KB of last-level cache, the Kepler GPU has 1536\u00a0KB of last-level cache, and the Maxwell GPU has 2048\u00a0KB of last-level cache. These caches have grown to handle synchronisation primitives between threads and atomic operations, and interface with a CPU-style MMU.\nDSPs.\nDigital signal processors have similarly generalised over the years. Earlier designs used scratchpad memory fed by DMA, but modern DSPs such as Qualcomm Hexagon often include a very similar set of caches to a CPU (e.g. Modified Harvard architecture with shared L2, split L1 I-cache and D-cache).\nTranslation lookaside buffer.\nA memory management unit (MMU) that fetches page table entries from main memory has a specialized cache, used for recording the results of virtual address to physical address translations. This specialized cache is called a translation lookaside buffer (TLB).\nIn-network cache.\nInformation-centric networking.\nInformation-centric networking (ICN) is an approach to evolve the Internet infrastructure away from a host-centric paradigm, based on perpetual connectivity and the end-to-end principle, to a network architecture in which the focal point is identified information (or content or data). Due to the inherent caching capability of the nodes in an ICN, it can be viewed as a loosely connected network of caches, which has unique requirements of caching policies. However, ubiquitous content caching introduces the challenge to content protection against unauthorized access, which requires extra care and solutions.\nUnlike proxy servers, in ICN the cache is a network-level solution. Therefore, it has rapidly changing cache states and higher request arrival rates; moreover, smaller cache sizes further impose a different kind of requirements on the content eviction policies. In particular, eviction policies for ICN should be fast and lightweight. Various cache replication and eviction schemes for different ICN architectures and applications have been proposed.\nPolicies.\nTime aware least recently used (TLRU).\nThe Time aware Least Recently Used (TLRU) is a variant of LRU designed for the situation where the stored contents in cache have a valid life time. The algorithm is suitable in network cache applications, such as Information-centric networking (ICN), Content Delivery Networks (CDNs) and distributed networks in general. TLRU introduces a new term: TTU (Time to Use). TTU is a time stamp of a content/page which stipulates the usability time for the content based on the locality of the content and the content publisher announcement. Owing to this locality based time stamp, TTU provides more control to the local administrator to regulate in network storage.\nIn the TLRU algorithm, when a piece of content arrives, a cache node calculates the local TTU value based on the TTU value assigned by the content publisher. The local TTU value is calculated by using a locally defined function. Once the local TTU value is calculated the replacement of content is performed on a subset of the total content stored in cache node. The TLRU ensures that less popular and small life content should be replaced with the incoming content.\nLeast frequent recently used (LFRU).\nThe Least Frequent Recently Used (LFRU) cache replacement scheme combines the benefits of LFU and LRU schemes. LFRU is suitable for 'in network' cache applications, such as Information-centric networking (ICN), Content Delivery Networks (CDNs) and distributed networks in general. In LFRU, the cache is divided into two partitions called privileged and unprivileged partitions. The privileged partition can be defined as a protected partition. If content is highly popular, it is pushed into the privileged partition. Replacement of the privileged partition is done as follows: LFRU evicts content from the unprivileged partition, pushes content from privileged partition to unprivileged partition, and finally inserts new content into the privileged partition. In the above procedure the LRU is used for the privileged partition and an approximated LFU (ALFU) scheme is used for the unprivileged partition, hence the abbreviation LFRU.\nThe basic idea is to filter out the locally popular contents with ALFU scheme and push the popular contents to one of the privileged partition.\nSoftware caches.\nDisk cache.\nWhile CPU caches are generally managed entirely by hardware, a variety of software manages other caches. The page cache in main memory, which is an example of disk cache, is managed by the operating system kernel.\nWhile the disk buffer, which is an integrated part of the hard disk drive, is sometimes misleadingly referred to as \"disk cache\", its main functions are write sequencing and read prefetching. Repeated cache hits are relatively rare, due to the small size of the buffer in comparison to the drive's capacity. However, high-end disk controllers often have their own on-board cache of the hard disk drive's data blocks.\nFinally, a fast local hard disk drive can also cache information held on even slower data storage devices, such as remote servers (web cache) or local tape drives or optical jukeboxes; such a scheme is the main concept of hierarchical storage management. Also, fast flash-based solid-state drives (SSDs) can be used as caches for slower rotational-media hard disk drives, working together as hybrid drives or solid-state hybrid drives (SSHDs).\nWeb cache.\nWeb browsers and web proxy servers employ web caches to store previous responses from web servers, such as web pages and images. Web caches reduce the amount of information that needs to be transmitted across the network, as information previously stored in the cache can often be re-used. This reduces bandwidth and processing requirements of the web server, and helps to improve responsiveness for users of the web.\nWeb browsers employ a built-in web cache, but some Internet service providers (ISPs) or organizations also use a caching proxy server, which is a web cache that is shared among all users of that network.\nAnother form of cache is P2P caching, where the files most sought for by peer-to-peer applications are stored in an ISP cache to accelerate P2P transfers. Similarly, decentralised equivalents exist, which allow communities to perform the same task for P2P traffic, for example, Corelli.\nMemoization.\nA cache can store data that is computed on demand rather than retrieved from a backing store. Memoization is an optimization technique that stores the results of resource-consuming function calls within a lookup table, allowing subsequent calls to reuse the stored results and avoid repeated computation. It is related to the dynamic programming algorithm design methodology, which can also be thought of as a means of caching.\nOther caches.\nThe BIND DNS daemon caches a mapping of domain names to IP addresses, as does a resolver library.\nWrite-through operation is common when operating over unreliable networks (like an Ethernet LAN), because of the enormous complexity of the coherency protocol required between multiple write-back caches when communication is unreliable. For instance, web page caches and client-side network file system caches (like those in NFS or SMB) are typically read-only or write-through specifically to keep the network protocol simple and reliable.\nSearch engines also frequently make web pages they have indexed available from their cache. For example, Google provides a \"Cached\" link next to each search result. This can prove useful when web pages from a web server are temporarily or permanently inaccessible.\nAnother type of caching is storing computed results that will likely be needed again, or memoization. For example, ccache is a program that caches the output of the compilation, in order to speed up later compilation runs.\nDatabase caching can substantially improve the throughput of database applications, for example in the processing of indexes, data dictionaries, and frequently used subsets of data.\nA distributed cache uses networked hosts to provide scalability, reliability and performance to the application. The hosts can be co-located or spread over different geographical regions.\nBuffer vs. cache.\nThe semantics of a \"buffer\" and a \"cache\" are not totally different; even so, there are fundamental differences in intent between the process of caching and the process of buffering.\nFundamentally, caching realizes a performance increase for transfers of data that is being repeatedly transferred. While a caching system may realize a performance increase upon the initial (typically write) transfer of a data item, this performance increase is due to buffering occurring within the caching system.\nWith read caches, a data item must have been fetched from its residing location at least once in order for subsequent reads of the data item to realize a performance increase by virtue of being able to be fetched from the cache's (faster) intermediate storage rather than the data's residing location. With write caches, a performance increase of writing a data item may be realized upon the first write of the data item by virtue of the data item immediately being stored in the cache's intermediate storage, deferring the transfer of the data item to its residing storage at a later stage or else occurring as a background process. Contrary to strict buffering, a caching process must adhere to a (potentially distributed) cache coherency protocol in order to maintain consistency between the cache's intermediate storage and the location where the data resides. Buffering, on the other hand,\nWith typical caching implementations, a data item that is read or written for the first time is effectively being buffered; and in the case of a write, mostly realizing a performance increase for the application from where the write originated. Additionally, the portion of a caching protocol where individual writes are deferred to a batch of writes is a form of buffering. The portion of a caching protocol where individual reads are deferred to a batch of reads is also a form of buffering, although this form may negatively impact the performance of at least the initial reads (even though it may positively impact the performance of the sum of the individual reads). In practice, caching almost always involves some form of buffering, while strict buffering does not involve caching.\nA buffer is a temporary memory location that is traditionally used because CPU instructions cannot directly address data stored in peripheral devices. Thus, addressable memory is used as an intermediate stage. Additionally, such a buffer may be feasible when a large block of data is assembled or disassembled (as required by a storage device), or when data may be delivered in a different order than that in which it is produced. Also, a whole buffer of data is usually transferred sequentially (for example to hard disk), so buffering itself sometimes increases transfer performance or reduces the variation or jitter of the transfer's latency as opposed to caching where the intent is to reduce the latency. These benefits are present even if the buffered data are written to the buffer once and read from the buffer once.\nA cache also increases transfer performance. A part of the increase similarly comes from the possibility that multiple small transfers will combine into one large block. But the main performance-gain occurs because there is a good chance that the same data will be read from cache multiple times, or that written data will soon be read. A cache's sole purpose is to reduce accesses to the underlying slower storage. Cache is also usually an abstraction layer that is designed to be invisible from the perspective of neighboring layers."}
{"id": "6830", "revid": "180623", "url": "https://en.wikipedia.org/wiki?curid=6830", "title": "Columbus, Indiana", "text": "Columbus is a city in and the county seat of Bartholomew County, Indiana, United States. The population was 44,061 at the 2010 census. The relatively small city has provided a unique place for noted Modern architecture and public art, commissioning numerous works since the mid-20th century; the annual program Exhibit Columbus celebrates this legacy. Located about south of Indianapolis, on the east fork of the White River, it is the state's 20th-largest city. It is the principal city of the Columbus, Indiana metropolitan statistical area, which encompasses all of Bartholomew County. Columbus is the birthplace of former Indiana Governor and former Vice President of the United States, Mike Pence.\n\"National Geographic Traveler\" ranked Columbus 11th on its historic destinations list in late 2008, describing the city as \"authentic, unique, and unspoiled.\" Columbus won the national contest \"America in Bloom\" in 2006, and in 2004 it was named as one of \"The Ten Most Playful Towns\" by \"Nick Jr. Family Magazine\". The July 2005 edition of \"GQ\" magazine, Columbus was named as one of the \"62 Reasons to Love Your Country\". Columbus is the headquarters of the engine company Cummins, Inc.\nHistory.\nThe land developed as Columbus was bought by General John Tipton and Luke Bonesteel in 1820. Tipton built a log cabin on Mount Tipton, a small hill overlooking White River and the surrounding flat, heavily forested and swampy valley. It held wetlands of the river. The town was first known as Tiptona, named in honor of Tipton. The town's name was changed to Columbus on March 20, 1821. Many people believe General Tipton was upset by the name change, but no evidence exists to prove this. Nonetheless, he decided to leave the newly founded town and did not return. He was later appointed as the highway commissioner for the State of Indiana and was assigned to building a highway from Indianapolis, Indiana to Louisville, Kentucky. When the road reached Columbus, Tipton constructed the first bypass road ever built; it detoured south around the west side of Columbus en route to Seymour.\nJoseph McKinney was the first to plot the town of Columbus, but no date was recorded.\nLocal history books for years said that the land on which Columbus sits was donated by General Tipton. But in 2003, Historic Columbus Indiana acquired a deed showing that General Tipton sold the land.\nA ferry was established below the confluence of the Flatrock and Driftwood rivers, which form the White River. A village of three or four log cabins developed around the ferry landing, and a store was added in 1821. Later that year, Bartholomew County was organized by an act of the State Legislature and named to honor the famous Hoosier militiaman, General Joseph Bartholomew. Columbus was incorporated on June 28, 1864.\nThe first railroad in Indiana was constructed to Columbus from Madison, Indiana in 1844. This eventually became the Madison branch of the Pennsylvania Railroad. The railroad fostered the growth of the community into one of the largest in Indiana, and three more railroads reached the city by 1850.\nColumbus is host to the oldest theater in Indiana, The Crump Theatre, which was built in 1889 by John Crump. Today the building is included within the Columbus Historic District. Before it closed permanently in 2010, it was an all-ages venue with occasional musical performances. Columbus was host to the oldest continually operated bookstore in Indiana, Cummins Bookstore, which began operations in 1892. It closed in late 2007.\nThe Irwin Union Bank building was built in 1954. It was designated as a National Historic Landmark by the National Park Service in 2001 in recognition of its unique architecture. The building consists of a one-story bank structure adjacent to a three-story office annex. A portion of the office annex was built along with the banking hall in 1954. The remaining larger portion, designed by Kevin Roche John Dinkeloo and Associates, was built in 1973. Eero Saarinen designed the bank building with its glazed hall to be set off against the blank background of its three-story brick annex. Two steel and glass vestibule connectors lead from the north side of this structure to the annex. The building was designed to distance the Irwin Union Bank from traditional banking architecture, which mostly echoed imposing, neoclassical style buildings of brick or stone. Tellers were behind iron bars and removed from their customers. Saarinen worked to develop a building that would welcome customers rather than intimidate them.\nEconomy.\nColumbus has been home to many manufacturing companies, including Noblitt-Sparks Industries (which built radios under the Arvin brand in the 1930s) and Arvin Industries, now Meritor, Inc. After merging with Meritor Automotive on July 10, 2000, the headquarters of the newly created ArvinMeritor Industries was established in Troy, Michigan, the home of parent company, Rockwell International. It was announced in February 2011 that the company name would revert to Meritor, Inc. Cummins, Inc. is by far the region's largest employer, and the Infotech Park accounts for a sizable number of research jobs in Columbus proper. Just south of Columbus are the North American headquarters of Toyota Material Handling, U.S.A., Inc., the world's largest material handling (forklift) manufacturer. Other notable industries include architecture, a discipline for which Columbus is famous worldwide. The late J. Irwin Miller (then president and chairman of Cummins Engine Company) launched the Cummins Foundation, a charitable program that helps subsidize a large number of architectural projects throughout the city by up-and-coming engineers and architects.\nEarly in the 20th century, Columbus also was home to a number of pioneering car manufacturers, including Reeves, which produced the unusual four-axle Octoauto and the twin rear-axle Sextoauto, both around 1911.\nNearly 19,000 workers commute into the city from the surrounding townships and villages. In recent years city officials have explored ways to revitalize the city. They recognize the value of J. Irwin Miller's support of architectural excellence in the mid-20th century, when the Cummins Foundation made it a mecca of modern architecture. Economic development, widespread beautification innovations, various tax incentives, and increased law enforcement have helped Columbus overcome what some considered a slump during the 1980s and 1990s.\nIn addition to the Columbus Historic District and Irwin Union Bank, the city has numerous buildings listed on the National Register of Historic Places, including seven National Historic Landmarks of modernist architecture: Bartholomew County Courthouse, Columbus City Hall, First Baptist Church, First Christian Church, Haw Creek Leather Company, Mabel McDowell Elementary School, McEwen-Samuels-Marr House, McKinley School, Miller House, North Christian Church, and The Republic Newspaper Office.\nGeography.\nColumbus is located at (39.213998, \u221285.911056). The Driftwood and Flatrock Rivers converge at Columbus to form the East Fork of the White River.\nAccording to the 2010 census, Columbus has a total area of , of which (or 98.62%) is land and (or 1.38%) is water.\nDemographics.\n2010 census.\nAs of the census of 2010, there were 44,061 people, 17,787 households, and 11,506 families residing in the city. The population density was . There were 19,700 housing units at an average density of . The racial makeup of the city was 86.9% White, 2.7% African American, 0.2% Native American, 5.6% Asian, 0.1% Pacific Islander, 2.5% from other races, and 2.0% from two or more races. Hispanic or Latino of any race were 5.8% of the population.\nThere were 17,787 households, of which 33.5% had children under the age of 18 living with them, 48.5% were married couples living together, 11.7% had a female householder with no husband present, 4.5% had a male householder with no wife present, and 35.3% were non-families. 29.7% of all households were made up of individuals, and 11.5% had someone living alone who was 65 years of age or older. The average household size was 2.43 and the average family size was 3.00.\nThe median age in the city was 37.1 years. 25.2% of residents were under the age of 18; 8.1% were between the ages of 18 and 24; 27.3% were from 25 to 44; 24.9% were from 45 to 64; and 14.4% were 65 years of age or older. The gender makeup of the city was 48.4% male and 51.6% female.\n2000 census.\nAs of the census of 2000, there were 39,059 people, 15,985 households, and 10,566 families residing in the city. The population density was 1,505.3 people per square mile (581.1/km). There were 17,162 housing units at an average density of 661.4 per square mile (255.3/km). The racial makeup of the city was 91.32% White, 2.71% Black or African American, 0.13% Native American, 3.23% Asian, 0.05% Pacific Islander, 1.39% from other races, and 1.19% from two or more races. 2.81% of the population were Hispanic or Latino of any race.\nThere were 15,985 households, out of which 31.8% had children under the age of 18 living with them, 51.9% were married couples living together, 11.0% had a female householder with no husband present, and 33.9% were non-families. 29.1% of all households were composed of individuals, and 10.7% had someone living alone who was 65 years of age or older. The average household size was 2.39, and the average family size was 2.94.\nIn the city, the population was spread out, with 25.7% under the age of 18, 8.0% from 18 to 24 years, 29.5% from 25 to 44 years, 23.0% from 45 to 64 years, and 13.7% over the age of 65. The median age was 36 years. There were 92.8 males for every 100 females and 89.6 males for every 100 females over age 18.\nThe median income for a household in the city was $41,723, and the median income for a family was $52,296. Males had a median income of $40,367 versus $24,446 for females, and the per capita income was $22,055. About 6.5% of families and 8.1% of the population were below the poverty line, including 9.7% of those under age 18 and 8.8% of those age 65 or over.\nArts and culture.\nColumbus is a city known for its modern architecture and public art. J. Irwin Miller, 2nd CEO and a nephew of a co-founder of Cummins Inc., the Columbus-headquartered diesel engine manufacturer, instituted a program in which the Cummins Foundation paid the architects' fees, provided the client selected a firm from a list compiled by the foundation. The plan was initiated with public schools and was so successful that the foundation decided to offer such design support to other non-profit and civic organizations. The high number of notable public buildings and public art in the Columbus area, designed by such individuals as Eero Saarinen, I.M. Pei, Robert Venturi, Cesar Pelli, and Richard Meier, led to Columbus earning the nickname \"Athens on the Prairie.\"\nSeven buildings, constructed between 1942 and 1965, are National Historic Landmarks, and approximately 60 other buildings sustain the Bartholomew County seat's reputation as a showcase of modern architecture. National Public Radio once devoted an article to the town's architecture.\nIn 2015, Landmark Columbus was created as a program of Heritage Fund - The Community Foundation of Bartholomew county.\nExhibit Columbus.\nIn May 2016, Landmark Columbus launched Exhibit Columbus as a way to continue the ambitious traditions of the past into the future. Exhibit Columbus features annual programming that alternates between symposium and exhibition years.\nSports.\nColumbus High School was home to footwear pioneer Chuck Taylor, who played basketball in Columbus before setting out to promote his now famous shoes and the sport of basketball before being inducted into the Naismith Memorial Basketball Hall of Fame.\nTwo local high schools compete within the state in various sports. Columbus North and Columbus East both have competitive athletics and have many notable athletes that go on to compete in college and beyond. Columbus North High School houses one of the largest high school gyms in the United States. CNHS vs CEHS\nIndiana Diesels of the Premier Basketball League play their home games at the gymnasium at Ceraland Park, with plans to move to a proposed downtown sports complex in the near future. Columbus also boasts a roller derby league, the Terrorz of Tiny Towns. Established in 2010, this league hosts weekly practices at Columbus Skateland. The town also has two cricket teams, both which play under the name of Columbus Indiana Cricket Club; their home ground is at Ceraland Park.\nParks and recreation.\nColumbus boasts over of parks and green space and over 20 miles of People Trails. These amenities, in addition to several athletic and community facilities, including Donner Aquatic Center, Lincoln Park Softball Complex, Hamilton Center Ice Arena, Clifty Park, Foundation for Youth/Columbus Gymnastics Center and The Commons, are managed and maintained by the Columbus Parks and Recreation Department.\nGovernment.\nColumbus uses the Mayor-Council form of government. The council consists of seven members. Five are elected from one of five wards the other two are elected at-large. The Mayor is elected in a citywide vote. The current mayor is Jim Lienhoop.\nTransportation.\nRoads and highways.\nThe north-south US Route 31 has been diverted to the northeastern part of the city. Interstate 65 bypasses Columbus to the west. Indiana Route 46 runs-east-west through the southern section of the city.\nRailroads.\nFreight rail service is provided by the Louisville and Indiana Railroad (LIRC). The LIRC line runs in a north-south orientation along the western edge of Columbus.\nThe Pennsylvania Railroad's \"Kentuckyian\" (Chicago-Louisville) made stops in the city until 1968. The PRR and its successor, the Penn Central, ran the Florida-bound \"South Wind\" up to 1971.\nAirport.\nColumbus is served by the Columbus Municipal Airport (KBAK). It is located approximately north of Columbus. The airport handles approximately 40,500 operations per year, with roughly 87% general aviation, 4% air taxi, 8% military and &lt;1% commercial service. The airport has two concrete runways; a 6,401 foot runway with approved ILS and GPS approaches (Runway 5-23) and a 5,001 foot crosswind runway, also with GPS approaches, (Runway 14-32).\nThe nearest commercial airport which currently has scheduled airline service is Indianapolis International Airport (IND), located approximately northwest of Columbus. Louisville Muhammad Ali International Airport and Cincinnati/Northern Kentucky International Airport are to the south and to the southeast, respectively.\nNotable people.\nThis is a list of notable people who were born in, or who currently live, or have lived in Columbus.\nEducation.\nThe Bartholomew Consolidated School Corporation (BCSC) is the local school district. High schools include:\nColumbus has a public library, a branch of the Bartholomew County Public Library.\nSecondary education includes Indiana University \u2013 Purdue University Columbus (IUPUC), an Ivy Tech campus, Purdue Polytechnic and an Indiana Wesleyan University education center."}
{"id": "6834", "revid": "40993790", "url": "https://en.wikipedia.org/wiki?curid=6834", "title": "List of computer scientists", "text": "This is a list of computer scientists, people who do work in computer science, in particular researchers and authors.\nSome persons notable as programmers are included here because they work in research as well as program. A few of these people pre-date the invention of the digital computer; they are now regarded as computer scientists because their work can be seen as leading to the invention of the computer. Others are mathematicians whose work falls within what would now be called theoretical computer science, such as complexity theory and algorithmic information theory."}
{"id": "6835", "revid": "24043204", "url": "https://en.wikipedia.org/wiki?curid=6835", "title": "Coracinus capensis", "text": ""}
{"id": "6839", "revid": "7903804", "url": "https://en.wikipedia.org/wiki?curid=6839", "title": "Reaction kinetics in uniform supersonic flow", "text": "Reaction kinetics in uniform supersonic flow (, CRESU ) is an experiment investigating chemical reactions taking place at very low temperatures.\nThe technique involves the expansion of a gas or mixture of gases through a de Laval nozzle from a high pressure reservoir into a vacuum chamber. As it expands, the nozzle collimates the gas into a uniform supersonic beam that is essentially collision free and has a temperature that, in the centre of mass frame, can be significantly below that of the reservoir gas. Each nozzle produces a characteristic temperature. This way, any temperature between room temperature and about 10K can be achieved.\nApparatus.\nThere are relatively few CRESU apparatuses in existence for the simple reason that the gas throughput and pumping requirements are huge, which makes them expensive to run. Two of the leading centres have been the University of Rennes (France) and the University of Birmingham (UK). A more recent development has been a pulsed version of the CRESU, which requires far less gas and therefore smaller pumps.\nKinetics.\nMost species have a negligible vapour pressure at such low temperatures and this means that they quickly condense on the sides of the apparatus. Essentially, the CRESU technique provides a \"wall-less flow tube,\" which allows the kinetics of gas phase reactions to be investigated at much lower temperatures than otherwise possible.\nChemical kinetics experiments can then be carried out in a pump-probe fashion using a laser to initiate the reaction (for example by preparing one of the reagents by photolysis of a precursor), followed by observation of that same species (for example by laser-induced fluorescence) after a known time delay. The fluorescence signal is captured by a photomultiplier a known distance downstream of the de Laval nozzle. The time delay can be varied up to the maximum corresponding to the flow time over that known distance. By studying how quickly the reagent species disappears in the presence of differing concentrations of a (usually stable) co-reagent species the reaction rate constant at the low temperature of the CRESU flow can be determined.\nReactions studied by the CRESU technique typically have no significant activation energy barrier. In the case of neutral-neutral reactions (i.e., not involving any charged species, ions), these type of barrier-free reactions usually involve free radical species such as molecular oxygen (O2), the cyanide radical (CN) or the hydroxyl radical (OH). The energetic driving force for these reactions is typically an attractive long range intermolecular potential.\nCRESU experiments have been used to show deviations from Arrhenius kinetics at low temperatures: as the temperature is reduced, the rate constant actually increases. They can explain why chemistry is so prevalent in the interstellar medium, where many different polyatomic species have been detected (by radio astronomy)."}
{"id": "6840", "revid": "3938795", "url": "https://en.wikipedia.org/wiki?curid=6840", "title": "Cygwin", "text": "Cygwin ( ) is a POSIX-compatible programming and runtime environment that runs natively on Microsoft Windows. Under Cygwin, source code designed for Unix-like operating systems may be compiled with minimal modification and executed.\nThe Cygwin installation directory has a directory layout that is similar to the root file system of Unix-like systems, with familiar directories, such as /bin, /home, /etc, /usr, /var. Cygwin installs with hundreds of command-line tools and other programs commonly found on a Unix-like system. Additionally, many applications may be installed from a packaging system. The terminal emulator Mintty is the default command-line interface provided to interact with the environment.\nCygwin provides native integration of Windows-based applications. Thus it is possible to launch Windows applications from the Cygwin environment, as well as to use Cygwin tools and applications within the Windows operating context.\nCygwin consists of two parts: a dynamic-link library (DLL) as an API compatibility layer in the form of a C standard library providing a substantial part of the POSIX API functionality, and an extensive collection of software tools and applications that provide a Unix-like look and feel.\nCygwin is free and open-source software, released under the GNU Lesser General Public License version 3. It was originally developed by Cygnus Solutions, which was later acquired by Red Hat (now part of IBM), to port the Linux toolchain to Win32, including the GNU Compiler Suite. Rather than rewrite the tools to use the Win32 runtime environment, Cygwin implemented a POSIX compatible environment in form of a dynamic-link library (DLL).\nDescription.\nThe Cygwin environment is provided in two versions; the full 64-bit version and a stripped down 32-bit version that is slowly being phased out. Cygwin consists of a library that implements the POSIX system call API in terms of Windows system calls, a GNU development toolchain (including GCC and GDB) to allow software development, and running of a large number of application programs equivalent to those on Unix systems. Programmers have ported many Unix, GNU, BSD and Linux programs and packages to Cygwin, including the X Window System, K Desktop Environment 3, GNOME, Apache, and TeX. Cygwin permits installing inetd, syslogd, sshd, Apache, and other daemons as standard Windows services, allowing Microsoft Windows systems to emulate Unix and Linux servers.\nCygwin programs are installed by running Cygwin's \"setup\" program, which downloads the necessary program and feature package files from repositories on the Internet. As mentioned, there are two versions of this setup program, one for 32-bit versions of the Cygwin DLL, and corresponding applications, and one for 64-bit versions. Setup can install, update, and remove programs and their source code packages. A complete installation will take in excess of 90\u00a0GB of hard disk space, but usable configurations may require as little as 1 or 2\u00a0GB.\nEfforts to reconcile concepts that differ between Unix and Windows systems include:\nThe version of gcc that comes with Cygwin has various extensions for creating Windows DLLs, specifying whether a program is a windowing or console-mode program, adding resources, etc. Support for compiling programs that do not require the POSIX compatibility layer provided by the Cygwin DLL used to be included in the default codice_13, but is provided by cross-compilers contributed by the MinGW-w64 project.\nCygwin is used heavily for porting many popular pieces of software to the Windows platform. It is used to compile Sun Java, LibreOffice, and even web server software like Lighttpd and Hiawatha.\nThe Cygwin API library is licensed under the GNU Lesser General Public License version 3 (or later) with an exception to allow linking to any free and open-source software whose license conforms to the Open Source Definition (less strict than the Free Software Definition).\nHistory.\nCygwin began in 1995 as a project of Steve Chamberlain, a Cygnus engineer who observed that Windows NT and 95 used COFF as their object file format, and that GNU already included support for x86 and COFF, and the C library newlib. He thought it would be possible to retarget GCC and produce a cross compiler generating executables that could run on Windows. This proved practical and a prototype was quickly developed.\nThe next step was to attempt to bootstrap the compiler on a Windows system, requiring sufficient emulation of Unix to let the GNU configure shell script run. A Bourne shell-compatible command interpreter, such as bash, was needed and in turn a fork system call emulation and standard input/output. Windows includes similar functionality, so the Cygwin library just needed to provide a POSIX-compatible application programming interface (API) and properly translate calls and manage private versions of data, such as file descriptors.\nInitially, Cygwin was called gnuwin32 (not to be confused with the current GnuWin32 project). The name was changed to Cygwin32 to emphasize Cygnus' role in creating it. When Microsoft registered the trademark Win32, the 32 was dropped to simply become Cygwin.\nBy 1996, other engineers had joined in, because it was clear that Cygwin would be a useful way to provide Cygnus' embedded tools hosted on Windows systems (the previous strategy had been to use DJGPP). It was especially attractive because it was possible to do a three-way cross-compile, for instance to use a hefty Sun Microsystems workstation to build, say, a Windows-x-MIPS cross-compiler, which was faster than using the PC at the time. In 1999, Cygnus offered Cygwin 1.0 as a commercial product of interest in its own right although subsequent versions have not been released, instead relying on continued open source releases.\nGeoffrey Noer was the project lead from 1996 to 1999. Christopher Faylor was the project lead from 1999 to mid-2014. Corinna Vinschen became co-lead since 2004 when Faylor left Red Hat and has been lead since mid-2014, when Faylor withdrew from active participation in the project.\nFeatures.\nCygwin's base package selection is fairly small (about 100\u00a0MB), containing little more than the bash (interactive user) and dash (installation) shells and the core file and text manipulation utilities expected of a Unix command line. Additional packages are available as optional installs from within Cygwin's package manager (\"setup-x86.exe\" \u2013 32bit &amp; \"setup-x86_64.exe\" \u2013 64bit). These include (among many others):\nThe Cygwin/X project contributes an implementation of the X Window System that allows graphical Unix programs to display their user interfaces on the Windows desktop. This can be used with both local and remote programs. Cygwin/X supports over 500 packages including major X window managers, desktop environments, and applications, for example:\nIn addition to the low-level Xlib/XCB libraries for developing X applications, Cygwin also ships with various higher-level and cross-platform GUI frameworks, including GTK+ and Qt.\nThe Cygwin Ports project provided many additional packages that were not available in the Cygwin distribution itself. Examples included GNOME and K Desktop Environment 3 as well as the MySQL database and the PHP scripting language. Most ports have been adopted by volunteer maintainers as Cygwin packages, and Cygwin Ports are no longer maintained. "}
{"id": "6841", "revid": "86247", "url": "https://en.wikipedia.org/wiki?curid=6841", "title": "Communists", "text": ""}
{"id": "6844", "revid": "9092818", "url": "https://en.wikipedia.org/wiki?curid=6844", "title": "Conspiracy theories", "text": ""}
{"id": "6845", "revid": "14026582", "url": "https://en.wikipedia.org/wiki?curid=6845", "title": "Corinth", "text": "Corinth ( ; , ) is the successor to an ancient city, and is a former municipality in Corinthia, Peloponnese, which is located in south-central Greece. Since the 2011 local government reform, it has been part of the municipality of Corinth, of which it is the seat and a municipal unit. It is the capital of Corinthia.\nIt was founded as Nea Korinthos (), or New Corinth, in 1858 after an earthquake destroyed the existing settlement of Corinth, which had developed in and around the site of ancient Corinth.\nGeography.\nLocated about west of Athens, Corinth is surrounded by the coastal townlets of (clockwise) Lechaio, Isthmia, Kechries, and the inland townlets of Examilia and the archaeological site and village of ancient Corinth. Natural features around the city include the narrow coastal plain of Vocha, the Corinthian Gulf, the Isthmus of Corinth cut by its canal, the Saronic Gulf, the Oneia Mountains, and the monolithic rock of Acrocorinth, where the medieval acropolis was built.\nHistory.\nCorinth derives its name from Ancient Corinth, a city-state of antiquity. The site was occupied from before 3000 BC. Historical references begin with the early 8th century BC, when Corinth began to develop as a commercial center. Between the 8th and 7th centuries, the Bacchiad family ruled Corinth. Cypselus overthrew the Bacchiad family, and between 657 and 550 BC, he and his son Periander ruled Corinth as the Tyrants. \nIn about 550 BC, an oligarchical government seized power. This government allied with Sparta within the Peloponnesian League, and Corinth participated in the Persian Wars and Peloponnesian War as an ally of Sparta. After Sparta's victory in the Peloponnesian war, the two allies fell out with one another, and Corinth pursued an independent policy in the various wars of the early 4th century BC. After the Macedonian conquest of Greece, the Acrocorinth was the seat of a Macedonian garrison until 243 BC, when the city was liberated and joined the Achaean League. Nearly a century later, in 146 BC, Corinth was captured and was completely destroyed by the Roman army.\nAs a newly rebuilt Roman colony in 44 BC, Corinth flourished and became the administrative capital of the Roman province of Achaea.\nIn 1858, the old city, now known as Ancient Corinth (\u0391\u03c1\u03c7\u03b1\u03af\u03b1 \u039a\u03cc\u03c1\u03b9\u03bd\u03b8\u03bf\u03c2, \"Archaia Korinthos\"), located south-west of the modern city, was totally destroyed by a magnitude 6.5 earthquake. New Corinth (\"Nea Korinthos\") was then built to the north-east of it, on the coast of the Gulf of Corinth. In 1928, a magnitude 6.3 earthquake devastated the new city, which was then rebuilt on the same site. In 1933, there was a great fire, and the new city was rebuilt again.\nDemographics.\nThe Municipality of Corinth (\u0394\u03ae\u03bc\u03bf\u03c2 \u039a\u03bf\u03c1\u03b9\u03bd\u03b8\u03af\u03c9\u03bd) had a population of 58,192 according to the 2011 census, the second most populous municipality in the Peloponnese Region after Kalamata. The municipal unit of Corinth had 38,132 inhabitants, of which Corinth itself had 30,176 inhabitants, placing it in third place behind Kalamata and Tripoli among the cities of the Peloponnese Region.\nThe municipal unit of Corinth (\u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03ae \u03b5\u03bd\u03cc\u03c4\u03b7\u03c4\u03b1 \u039a\u03bf\u03c1\u03b9\u03bd\u03b8\u03af\u03c9\u03bd) includes apart from Corinth proper the town of Archaia Korinthos (2,198 inhabitants in 2011), the town of Examilia (2,905 inhabitants), and the smaller settlements of Xylokeriza (1,316 inhabitants) and Solomos (817 inhabitants). The municipal unit has an area of 102.187\u00a0km2.\nEconomy.\nIndustry.\nCorinth is a major industrial hub at a national level. The Corinth Refinery is one of the largest oil refining industrial complexes in Europe. Ceramic tiles, copper cables, gums, gypsum, leather, marble, meat products, medical equipment, mineral water and beverages, petroleum products, and salt are produced nearby. , a period of deindustrialization commenced as a large pipework complex, a textile factory and a meat packing facility diminished their operations.\nTransport.\nRoads.\nCorinth is a major road hub. The A7 toll motorway for Tripoli and Kalamata, (and Sparta via A71 toll), branches off the A8/European route E94 toll motorway from Athens at Corinth. Corinth is the main entry point to the Peloponnesian peninsula, the southernmost area of continental Greece.\nBus.\nKTEL Korinthias provides intercity bus service in the peninsula and to Athens via the Isthmos station southeast of the city center. Local bus service is also available.\nRailways.\nThe metre gauge railway from Athens and Pireaeus reached Corinth in 1884. This station closed to regular public transport in 2007. In 2005, two years prior, the city was connected to the Proastiakos/Suburban, the Athens suburban rail network, following the completion of the new Corinth railway station. The journey from Athens to Corinth is estimated to approx. 55 minutes so it is really convenient to choose a hotel in Corinth and commute to Athens for sightseeing. Train station is 5 minutes by car from the city center and parking is available for free.\nPort.\nThe port of Corinth, located north of the city centre and close to the northwest entrance of the Corinth Canal, at 37 56.0\u2019 N / 22 56.0\u2019 E, serves the local needs of industry and agriculture. It is mainly a cargo exporting facility.\nIt is an artificial harbour (depth approximately , protected by a concrete mole (length approximately 930 metres, width 100 metres, mole surface 93,000 m2). A new pier finished in the late 1980s doubled the capacity of the port. The reinforced mole protects anchored vessels from strong northern winds.\nWithin the port operates a customs office facility and a Hellenic Coast Guard post. Sea traffic is limited to trade in the export of local produce, mainly citrus fruits, grapes, marble, aggregates and some domestic imports. The port operates as a contingency facility for general cargo ships, bulk carriers and ROROs, in case of strikes at Piraeus port.\nFerries.\nThere was formerly a ferry link to Catania, Sicily and Genoa in Italy.\nCanal.\nThe Corinth Canal, carrying ship traffic between the western Mediterranean Sea and the Aegean Sea, is about east of the city, cutting through the Isthmus of Corinth that connects the Peloponnesian peninsula to the Greek mainland, thus effectively making the former an island. The builders dug the canal through the Isthmus at sea level; no locks are employed. It is in length and only wide at its base, making it impassable for most modern ships. It now has little economic importance.\nThe canal was mooted in classical times and an abortive effort was made to build it in the 1st century AD. Julius Caesar and Caligula both considered digging the canal but died before starting the construction. The emperor Nero was the first to attempt to construct the canal. The Roman workforce responsible for the initial digging consisted of 6,000 Jewish prisoners of war. Modern construction started in 1882, after Greece gained independence from the Ottoman Empire, but was hampered by geological and financial problems that bankrupted the original builders. It was completed in 1893, but due to the canal's narrowness, navigational problems and periodic closures to repair landslips from its steep walls, it failed to attract the level of traffic anticipated by its operators. It is now used mainly for tourist traffic.\nSport.\nThe city's association football team is Korinthos F.C. (\"\u03a0.\u0391.E. \u039a\u03cc\u03c1\u03b9\u03bd\u03b8\u03bf\u03c2\"), established in 1999 after the merger of Pankorinthian Football Club (\"\u03a0\u03b1\u03b3\u03ba\u03bf\u03c1\u03b9\u03bd\u03b8\u03b9\u03b1\u03ba\u03cc\u03c2\") and Corinth Football Club (\"\u039a\u03cc\u03c1\u03b9\u03bd\u03b8\u03bf\u03c2\"). During the 2006\u20132007 season, the team played in the Greek Fourth Division's Regional Group 7. The team went undefeated that season and it earned the top spot. This granted the team a promotion to the Gamma Ethnik\u00ed (Third Division) for the 2007\u20132008 season. For the 2008\u20132009 season, Korinthos F.C. competed in the Gamma Ethniki (Third Division) southern grouping.\nTwin towns/sister cities.\nCorinth is twinned with:\nOther locations named after Corinth.\nDue to its ancient history and the presence of St. Paul the Apostle in Corinth some locations all over the world have been named Corinth."}
{"id": "6846", "revid": "7770027", "url": "https://en.wikipedia.org/wiki?curid=6846", "title": "Colossae", "text": "Colossae (; Greek: \u039a\u03bf\u03bb\u03bf\u03c3\u03c3\u03b1\u03af) was an ancient city of Phrygia in Asia Minor, and one of the most celebrated cities of southern Anatolia (modern Turkey). The Epistle to the Colossians, an early Christian text which identifies its author as Paul the Apostle, is addressed to the church in Colossae. A significant city from the 5th century BC onwards, it had dwindled in importance by the time of Paul, but was notable for the existence of its local angel cult. It was part of the Roman \u2013 and then Byzantine \u2013 province of Phrygia Pacatiana, before being destroyed in 1192/3 and its population relocating to nearby Chonae (Chonai, modern day Honaz).\nLocation and geography.\nColossae was located in Phrygia, in Asia Minor. It was located 15\u00a0km southeast of Laodicea on the road through the Lycus Valley near the Lycus River at the foot of Mt. Cadmus, the highest mountain in Turkey's western Aegean Region, and between the cities Sardeis and Celaenae, and southeast of the ancient city of Hierapolis. At Colossae, Herodotus describes how, \"the river Lycos falls into an opening of the earth and disappears from view, and then after an interval of about five furlongs it comes up to view again, and this river also flows into the Maiander.\" Despite a treacherously ambiguous cartography and history, Colossae has been clearly distinguished in modern research from nearby \"Chonai\" (\u03a7\u1ff6\u03bd\u03b1\u03b9), now called Honaz, with what remains of the buried ruins of Colossae (\"the mound\") lying 3\u00a0km to the north of Honaz.\nOrigin and etymology of place name.\nThe medieval poet Manuel Philes, incorrectly, imagined that the name \"Colossae\" was connected to the Colossus of Rhodes. More recently, in an interpretation which ties Colossae to an Indo-European root that happens to be shared with the word \"kolossos\", Jean-Pierre Vernant has connected the name to the idea of setting up a sacred space or shrine. Another proposal relates the name to the Greek \"kolazo\", \"to punish\". Others believe the name derives from the manufacture of its famous dyed wool, or \"colossinus\".\nHistory.\nBefore the Pauline period.\nThe first mention of the city may be in a 17th-century BC Hittite inscription, which speaks of a city called Huwalu\u0161ija, which some archeologists believe refer to early Colossae. The Fifth Century geographer Herodotus first mentions Colossae by name and as a \"great city in Phrygia\", which accommodates the Persian King Xerxes I while en route to wage war against the Greeks - showing the city had already reached a certain level of wealth and size by this time. \nWriting in the 5th century BC, Xenophon refers to Colossae as \"a populous city, wealthy and of considerable magnitude\". It was famous for its wool trade. Strabo notes that the city drew great revenue from the flocks, and that the wool of Colossae gave its name to colour \"colossinus\".\nIn 396 BC, Colossae was the site of the execution of the rebellious Persian satrap Tissaphernes who was lured there and slain by an agent of the party of Cyrus the Younger.\nPauline period.\nAlthough during the Hellenistic period, the town was of some mercantile importance, by the 1st century it had dwindled greatly in size and significance. Paul's letter to the Colossians points to the existence of an early Christian community. The town was known for its fusion of religious influences (syncretism), which included Jewish, Gnostic, and pagan influences that in the first century AD were described as an angel-cult. This unorthodox cult venerated the archangel Michael who is said to have caused a curative spring to gush from a fissure in the Earth.\nThe canonical biblical text Epistle to the Colossians is addressed to the Christian community in Colossae. The epistle has traditionally been attributed to Paul the Apostle due to its autobiographical salutation and style, but some modern critical scholars now believe it to be written by another author some time after Paul's death. It is believed that one aim of the letter was to address the challenges that the Colossian community faced in its context of the syncretistic Gnostic religions that were developing in Asia Minor.\nAccording to the Epistle to the Colossians, Epaphras seems to have been a person of some importance in the Christian community in Colossae, and tradition presents him as its first bishop. The epistle also seems to imply that Paul had never visited the city, because it only speaks of him having \"heard\" of the Colossians' faith, and in the Epistle to Philemon Paul tells Philemon of his hope to visit Colossae upon being freed from prison. Tradition also gives Philemon as the second bishop of the see.\nThe city was decimated by an earthquake in the 60s AD, and was rebuilt independent of the support of Rome.\nThe Apostolic Constitutions list Philemon as a Bishop of Colossae. On the other hand, the Catholic Encyclopedia considers Philemon doubtful.\nThe first historically documented bishop is Epiphanius, who was not personally at the Council of Chalcedon, but whose metropolitan bishop Nunechius of Laodicea, the capital of the Roman province of Phrygia Pacatiana signed the acts on his behalf.\nByzantine period and decline.\nThe city's fame and renowned status continued into the Byzantine period, and in 858, it was distinguished as a Metropolitan See. The Byzantines also built the church of St. Michael in the vicinity of Colossae, one of the largest church buildings in the Middle East. Nevertheless, sources suggest that the town may have decreased in size or may even been completely abandoned due to Arab invasions in the seventh and eighth centuries, forcing the population to flee to resettle in the nearby city of Chonai (modern day Honaz).\nColossae's famous church was destroyed in 1192/3 during the Byzantine civil wars. It was a suffragan diocese of Laodicea in Phyrigia Pacatiane but was replaced in the Byzantine period by the Chonae settlement on higher ground\nModern study and archeology.\nAs of 2019, Colossae has never been excavated, as most archeological attention has been focused on nearby Laodicea and Hierapolis, though plans are reported for an Australian-led expedition to the site. The present site exhibits a biconical acropolis almost 100 feet high, and encompasses an area of almost 22 acres. On the eastern slope there sits a theater which probably seated around 5,000 people, suggesting a total population of 25,000 - 30,000 people. The theater was probably built during the Roman period, and may be near an agora that abuts the \"Cardo Maximus\", or the city's main north-south road. Ceramic finds around the theater confirm the city's early occupation in the third and second millennia BC. Northeast of the tell, and most likely outside the city walls, a necropolis displays Hellenistic tombs with two main styles of burial: one with an antecedent room connected to an inner chamber, and tumuli, or underground chambers accessed by stairs leading to the entrance. Outside the tell there are also remains of sections of columns that may have marked a processional way or the \"cardo\". Today, the remains of one column marks the location where locals believe a church once stood, possibly that of St. Michael. Near the Lycus River, there is evidence that water channels had been cut out of the rock with a complex of pipes and sluice gates to divert water for bathing and for agricultural and industrial purposes.\nModern legacy.\nThe holiness and healing properties associated with the waters of Colossae during the Byzantine Era continue to this day, particularly at a pool fed by the Lycus River at the G\u00f6z picnic grounds west of Colossae at the foot of Mt. Cadmus. Locals consider the water to be therapeutic."}
{"id": "6847", "revid": "212624", "url": "https://en.wikipedia.org/wiki?curid=6847", "title": "Colossians", "text": ""}
{"id": "6848", "revid": "6046894", "url": "https://en.wikipedia.org/wiki?curid=6848", "title": "Charge of the Goddess", "text": "The Charge of the Goddess (or Charge of the Star Goddess) is an inspirational text often used in the neopagan religion of Wicca. The Charge of the Goddess is recited during most rituals in which the Wiccan priest/priestess is expected to represent, and/or embody, the Goddess within the sacred circle, and is often spoken by the High Priest/Priestess after the ritual of Drawing Down the Moon.\nThe Charge is the promise of the Goddess (who is embodied by the high priestess) to all witches that she will teach and guide them. It has been called \"perhaps the most important single theological document in the neo-Pagan movement\". It is used not only in Wicca, but as part of the foundational documents of the Reclaiming tradition of witchcraft co-founded by Starhawk.\nSeveral versions of the Charge exist, though they all have the same basic premise, that of a set of instructions given by the Great Goddess to her worshippers. The earliest version is that compiled by Gerald Gardner. This version, titled \"Leviter Veslis\" or \"Lift Up the Veil\", includes material paraphrased from works by Aleister Crowley, primarily from Liber AL (The Book of the Law, particularly from Ch 1, spoken by Nuit, the Star Goddess), and from Liber LXV (The Book of the Heart Girt with a Serpent) and from Crowley's essay \"The Law of Liberty\", thus linking modern Wicca to the cosmology and revelations of Thelema. It has been shown that Gerald Gardner's book collection included a copy of Crowley's \"The Blue Equinox\" (1919) which includes all of the Crowley quotations transferred by Gardner to the Charge of the Goddess.\nThere are also two versions written by Doreen Valiente in the mid-1950s, after her 1953 Wiccan initiation. The first was a poetic paraphrase which eliminated almost all the material derived from Leland and Crowley. The second was a prose version which is contained within the traditional Gardnerian Book of Shadows and more closely resembles Gardner's \"Leviter Veslis\" version of 1949.\nSeveral different versions of a Wiccan Charge of the God have since been created to mirror and accompany the Charge of the Goddess.\nThemes.\nThe opening paragraph names a collection of goddesses, some derived from Greek or Roman mythology, others from Celtic or Arthurian legends, affirming a belief that these various figures represent a single Great Mother:\nThis theme echoes the ancient Roman belief that the Goddess Isis was known by ten thousand names and also that the Goddess still worshipped today by Wiccans and other neopagans is known under many guises but is in fact one universal divinity.\nThe second paragraph is largely derived and paraphrased from the words that Aradia, the messianic daughter of Diana, speaks to her followers in Charles Godfrey Leland's 1899 book \"Aradia, or the Gospel of the Witches\" (London: David Nutt; various reprints). The third paragraph is largely written by Doreen Valiente, with a significant content of phrases loosely from \"The Book of the Law\" and \"The Book of the Heart Girt with the Serpent\" by Aleister Crowley.\nThe charge affirms that \"all\" acts of love and pleasure are sacred to the Goddess, e.g.:\nHistory.\nAncient precedents.\nIn book eleven, chapter 47 of Apuleius's \"The Golden Ass\", Isis delivers what Ceisiwr Serith calls \"essentially a charge of a goddess\". This is rather different from the modern version known in Wicca, though they have the same premise, that of the rules given by a great Mother Goddess to her faithful.\nThe Charge of the Goddess is also known under the title \"Leviter Veslis\". This has been identified by the historian Ronald Hutton, cited in an article by Roger Dearnsley \"The Influence of Aleister Crowley on \"Ye Bok of Ye Art Magical\", as a piece of medieval ecclesiastical Latin used to mean \"lifting the veil.\" However, Hutton's interpretation does not reflect the Latin grammar as it currently stands. It may represent Gardner's attempt to write \"Levetur Velis\", which has the literal meaning of \"Let the veil be lifted.\" This expression would, by coincidence or design, grammatically echo the famous \"fiat lux\" (\"Gen. 1:3\") of the Latin Vulgate.\nOrigins.\nThe earliest known Wiccan version is found in a document dating from the late 1940s, Gerald Gardner's ritual notebook titled \"Ye Bok of Ye Art Magical\". The oldest identifiable source contained in this version is the final line, which is traceable to the 17th-century \"Centrum Naturae Concentratum\" of Alipili (or Ali Puli). This version also draws extensively from Charles Godfrey Leland's \"Aradia, or the Gospel of the Witches\" (1899) and other modern sources, particularly from the works of Aleister Crowley.\nIt is believed to have been compiled by Gerald Gardner or possibly another member of the New Forest coven. Gardner intended his version to be a theological statement justifying the Gardnerian sequence of initiations. Like the Charge found in Freemasonry, where the charge is a set of instructions read to a candidate standing in a temple, the Charge of the Goddess was intended to be read immediately before an initiation.\nValiente felt that the influence of Crowley on the Charge was too obvious, and she did not want \"the Craft\" (a common term for Wicca) associated with Crowley. Gardner invited her to rewrite the Charge. She proceeded to do so, her first version being into verse.\nThe initial verse version by Doreen Valiente consisted of eight verses, the second of which was:\nValiente was unhappy with this version, saying that \"people seemed to have some difficulty with this, because of the various goddess-names which they found hard to pronounce\", and so she rewrote it as a prose version, much of which differs from her initial version, and is more akin to Gardner's version. This prose version has since been modified and reproduced widely by other authors."}
{"id": "6849", "revid": "222130", "url": "https://en.wikipedia.org/wiki?curid=6849", "title": "Cy Young", "text": "Denton True \"Cy\" Young (March 29, 1867 \u2013 November 4, 1955) was an American Major League Baseball (MLB) pitcher. Born in Gilmore, Ohio, he worked on his family's farm as a youth before starting his professional baseball career. Young entered the major leagues in 1890 with the National League's Cleveland Spiders and pitched for them until 1898. He was then transferred to the St. Louis Cardinals franchise. In 1901, Young jumped to the American League and played for the Boston Red Sox franchise until 1908, helping them win the 1903 World Series. He finished his career with the Cleveland Naps and Boston Rustlers, retiring in 1911.\nYoung was one of the hardest-throwing pitchers in the game early in his career. After his speed diminished, he relied more on his control and remained effective into his forties. By the time Young retired, he had established numerous pitching records, some of which have stood for over a century. He holds MLB records for the most career wins, with 511, along with most career innings pitched, games started, and complete games. He led his league in wins during five seasons and pitched three no-hitters, including a 1904 perfect game.\nYoung was elected to the National Baseball Hall of Fame in 1937. In 1956, one year after his death, the Cy Young Award was created to honor the best pitcher in each league for each season.\nEarly life.\nCy Young was the oldest child born to Nancy (Mottmiller) and McKinzie Young, Jr., and was christened Denton True Young. He was of part German descent. The couple had four more children: Jesse Carlton, Alonzo, Ella, and Anthony. When the couple married, McKinzie's father gave him the of farm land he owned. Young was born in Gilmore, a tiny farming community located in Washington Township, Tuscarawas County, Ohio. \nHe was raised on one of the local farms and went by the name Dent Young in his early years. Young was also known as \"Farmer Young\" and \"Farmboy Young\". Young stopped his formal education after he completed the sixth grade so he could help out on the family's farm. In 1885, Young moved with his father to Nebraska, and in the summer of 1887, they returned to Gilmore.\nYoung played for many amateur baseball leagues during his youth, including a semi-professional Carrollton team in 1888. Young pitched and played second base. The first box score known containing the name Young came from that season. In that game, Young played first base and had three hits in three at-bats. After the season, Young received an offer to play for the minor league Canton team, which started Young's professional career.\nProfessional baseball career.\nMinor leagues.\nYoung began his professional career in 1889 with the Canton, Ohio, team of the Tri-State League, a professional minor league. During his tryout, Young impressed the scouts, recalling years later, \"I almost tore the boards off the grandstand with my fast ball.\" Cy Young's nickname came from the fences that he had destroyed using his fastball. The fences looked like a cyclone had hit them. Reporters later shortened the name to \"Cy\", which became the nickname Young used for the rest of his life. During Young's one year with the Canton team, he won 15 games and lost 15.\nFranchises in the National League, the major professional baseball league at the time, wanted the best players available to them. Therefore, in 1890, Young signed with the Cleveland Spiders, a team which had moved from the American Association to the National League the previous year.\nCleveland Spiders.\nOn August 6, 1890, Young's major league debut, he pitched a three-hit 8\u20131 victory over the Chicago Colts. While Young was on the Spiders, Chief Zimmer was his catcher more often than any other player. Bill James, a baseball statistician, estimated that Zimmer caught Young in more games than any other battery in baseball history.\nEarly on, Young established himself as one of the harder-throwing pitchers in the game. Bill James wrote that Zimmer often put a piece of beefsteak inside his baseball glove to protect his catching hand from Young's fastball. In the absence of radar guns, however, it is impossible to say just how hard Young actually threw. Young continued to perform at a high level during the 1890 season. On the last day of the season, Young won both games of a doubleheader. In the first weeks of Young's career, Cap Anson, the player-manager of the Chicago Colts spotted Young's ability. Anson told Spiders manager Gus Schmelz, \"He's too green to do your club much good, but I believe if I taught him what I know, I might make a pitcher out of him in a couple of years. He's not worth it now, but I'm willing to give you $1,000 ($ today) for him.\" Schmelz replied, \"Cap, you can keep your thousand and we'll keep the rube.\"\nTwo years after Young's debut, the National League moved the pitcher's position back by . Since 1881, pitchers had pitched within a \"box\" whose front line was from home base, and since 1887 they had been compelled to toe the back line of the box when delivering the ball. The back line was away from home. In 1893, was added to the back line, yielding the modern pitching distance of . In the book \"The Neyer/James Guide to Pitchers\", sports journalist Rob Neyer wrote that the speed with which pitchers like Cy Young, Amos Rusie, and Jouett Meekin threw was the impetus that caused the move.\nThe 1892 regular season was a success for Young, who led the National League in wins (36), ERA (1.93), and shutouts (9). Just as many contemporary Minor League Baseball leagues operate today, the National League was using a split season format during the 1892 season. The Boston Beaneaters won the first-half title, and the Spiders won the second-half title, with a best-of-nine series determining the league champion. Despite the Spiders' second half run, the Beaneaters swept the series, five games to none. Young pitched three complete games in the series, but lost two decisions. He also threw a complete game shutout, but the game ended in a scoreless tie.\nThe Spiders faced the Baltimore Orioles in the Temple Cup, a precursor to the World Series, in 1895. Young won three games in the series and Cleveland won the Cup, four games to one. It was around this time that Young added what he called a \"slow ball\" to his pitching repertoire to reduce stress on his arm. The pitch today is called a changeup.\nIn 1896, Young lost a no-hitter with two outs in the ninth inning when Ed Delahanty of the Philadelphia Phillies hit a single. On September 18, 1897, Young pitched the first no-hitter of his career in a game against the Cincinnati Reds. Although Young did not walk a batter, the Spiders committed four errors while on defense. One of the errors had originally been ruled a hit, but the Cleveland third baseman sent a note to the press box after the eighth inning, saying he had made an error, and the ruling was changed. Young later said that, despite his teammate's gesture, he considered the game to be a one-hitter.\nShift to St. Louis.\nPrior to the 1899 season, Frank Robison, the Spiders owner, bought the St. Louis Browns, thus owning two clubs simultaneously. The Browns were renamed the \"Perfectos\", and restocked with Cleveland talent. Just weeks before the season opener, most of the better Spiders players were transferred to St. Louis, including three future Hall of Famers: Young, Jesse Burkett, and Bobby Wallace. The roster maneuvers failed to create a powerhouse Perfectos team, as St. Louis finished fifth in both 1899 and 1900. Meanwhile, the depleted Spiders lost 134 games, the most in MLB history, before folding. Young spent two years with St. Louis, which is where he found his favorite catcher, Lou Criger. The two men were teammates for a decade.\nMove to Boston of the American League.\nIn 1901, the rival American League declared major league status and set about raiding National League rosters. Young left St. Louis and joined the American League's Boston Americans for a $3,500 contract ($ today). Young would remain with the Boston team until 1909. In his first year in the American League, Young was dominant. Pitching to Criger, who had also jumped to Boston, Young led the league in wins, strikeouts, and ERA, thus earning the colloquial AL Triple Crown for pitchers. Young won almost 42% of his team's games in 1901, accounting for 33 of his team's 79 wins. In February 1902, before the start of the baseball season, Young served as a pitching coach at Harvard University. The sixth-grade graduate instructing Harvard students delighted Boston newspapers. The following year, Young coached at Mercer University during the spring. The team went on to win the Georgia state championship in 1903, 1904, and 1905.\nThe Boston Americans played the Pittsburgh Pirates in the first modern World Series in 1903. Young, who started Game One against the visiting Pirates, thus threw the first pitch in modern World Series history. The Pirates scored four runs in that first inning, and Young lost the game. Young performed better in subsequent games, winning his next two starts. He also drove in three runs in Game Five. Young finished the series with a 2\u20131 record and a 1.85 ERA in four appearances, and Boston defeated Pittsburgh, five games to three games.\nAfter one-hitting Boston on May 2, 1904, Philadelphia Athletics pitcher Rube Waddell taunted Young to face him so that he could repeat his performance against Boston's ace. Three days later, Young pitched a perfect game against Waddell and the Athletics. It was the first perfect game in American League history. Waddell was the 27th and last batter, and when he flied out, Young shouted, \"How do you like that, you hayseed?\"\nWaddell had picked an inauspicious time to issue his challenge. Young's perfect game was the centerpiece of a pitching streak. Young set major league records for the most consecutive scoreless innings pitched and the most consecutive innings without allowing a hit; the latter record still stands at 25.1 innings, or 76 hitless batters. Even after allowing a hit, Young's scoreless streak reached a then-record 45 shutout innings. Before Young, only two pitchers had thrown perfect games. This occurred in 1880, when Lee Richmond and John Montgomery Ward pitched perfect games within five days of each other, although under somewhat different rules: the front edge of the pitcher's box was only from home base (the modern release point is about farther away); walks required eight balls; and pitchers were obliged to throw side-armed. Young's perfect game was the first under the modern rules established in 1893. One year later, on July 4, 1905, Rube Waddell beat Young and the Americans, 4\u20132, in a 20-inning matchup. Young pitched 13 consecutive scoreless innings before he gave up a pair of unearned runs in the final inning. Young did not walk a batter and was later quoted: \"For my part, I think it was the greatest game of ball I ever took part in.\" In 1907, Young and Waddell faced off in a scoreless 13-inning tie.\nIn 1908, Young pitched the third no-hitter of his career. Three months past his 41st birthday, Cy Young was the oldest pitcher to record a no-hitter, a record which would stand 82 years until 43-year-old Nolan Ryan surpassed the feat. Only a walk kept Young from his second perfect game. After that runner was caught stealing, no other batter reached base. At this time, Young was the second-oldest player in either league. In another game one month before his no-hitter, he allowed just one single while facing 28 batters. On August 13, 1908, the league celebrated \"Cy Young Day\". No American League games were played on that day, and a group of All-Stars from the league's other teams gathered in Boston to play against Young and the Red Sox. When the season ended, he posted a 1.26 ERA, which gave him not only the lowest in his career, but also gave him a major league record of being the oldest pitcher with 150+ innings pitched to post a season ERA under 1.50.\nCleveland Naps and retirement.\nYoung was traded back to Cleveland, the place where he played over half his career, before the 1909 season, to the Cleveland Naps of the American League. The following season, 1910, he won his 500th career game on July 19 against Washington. He split 1911, his final year, between the Naps and the Boston Rustlers. On September 22, 1911, Young shut out the Pittsburgh Pirates, 1\u20130, for his last career victory. In his final start two weeks later, the last eight batters of Young's career combined to hit a triple, four singles, and three doubles. By the time of his retirement, Young's control had faltered. He had also gained weight. In two of his last three years, he was the oldest player in the league.\nCareer accomplishments.\nYoung established numerous pitching records, some of which have stood for over a century. Young compiled 511 wins, which is the most in major league history and 94 ahead of Walter Johnson, second on the list. At the time of Young's retirement, Pud Galvin had the second most career wins with 364. In addition to wins, Young still holds the major league records for most career innings pitched (7,356), most career games started (815), and most complete games (749). He also retired with 316 losses, the most in MLB history. Young's career record for strikeouts was broken by Johnson in 1921. Young's 76 career shutouts are fourth all-time.\nYoung led his league in wins five times (1892, 1895, and 1901\u20131903), finishing second twice. His career high was 36 in 1892. He won at least 30 games in a season five times. He had 15 seasons with 20 or more wins, two more than the runners-up, Christy Mathewson and Warren Spahn. Young won two ERA titles during his career, in 1892 (1.93) and in 1901 (1.62), and was three times the runner-up. Young's earned run average was below 2.00 six times, but this was not uncommon during the dead-ball era. Although Young threw over 400 innings in each of his first four full seasons, he did not lead his league until 1902. He had 40 or more complete games nine times. Young also led his league in strikeouts twice (with 140 in 1896, and 158 in 1901), and in shutouts seven times. Young led his league in fewest walks per nine innings fourteen times and finished second one season. Only twice in his 22-year career did Young finish lower than 5th in the category. Although the WHIP ratio was not calculated until well after Young's death, Young was the retroactive league leader in this category seven times and was second or third another seven times. Young is tied with Roger Clemens for the most career wins by a Boston Red Sox pitcher. They each won 192 games while with the franchise. In addition, Young pitched three no-hitters, including the third perfect game in baseball history, first in baseball's \"modern era\".\nYoung also was an above average hitting pitcher in his career. He posted a .210 batting average (623-for-2960) with 325 runs, 18 home runs, 290 RBI and drew 81 bases on balls. From 1891 through 1905, he drove in 10 or more runs for 15 straight seasons, with a high of 28 RBI in 1896.\nPitching style.\nParticularly after his fastball slowed, Young relied upon his control. Young was once quoted as saying, \"Some may have thought it was essential to know how to curve a ball before anything else. Experience, to my mind, teaches to the contrary. Any young player who has good control will become a successful curve pitcher long before the pitcher who is endeavoring to master both curves and control at the same time. The curve is merely an accessory to control.\" In addition to his exceptional control, Young was also a workhorse who avoided injury, partlydue to him being able to pitch in different arm positions (Overhand, three-quarters, sidearm and even submarine) . For nineteen consecutive years, from 1891 through 1909, Young was in his league's top ten for innings pitched; in fourteen of the seasons, he was in the top five. Not until 1900, a decade into his career, did Young pitch two consecutive incomplete games. By habit, Young restricted his practice throws in spring training. \"I figured the old arm had just so many throws in it\", said Young, \"and there wasn't any use wasting them.\" Young once described his approach before a game:\nI never warmed up ten, fifteen minutes before a game like most pitchers do. I'd loosen up, three, four minutes. Five at the outside. And I never went to the bullpen. Oh, I'd relieve all right, plenty of times, but I went right from the bench to the box, and I'd take a few warm-up pitches and be ready. Then I had good control. I aimed to make the batter hit the ball, and I threw as few pitches as possible. That's why I was able to work every other day.\nLater life.\nIn 1910, it was reported that Young was a vegetarian. Beginning in 1912, Young lived and worked on his farm. In 1913, he served as manager of the Cleveland Green Sox of the Federal League, which was at the time an outlaw league. However, he never worked in baseball after that.\nIn 1916, he ran for county treasurer in Tuscarawas County, Ohio. \nYoung's wife, Roba, whom he had known since childhood, died in 1933. After she died, Young tried several jobs, and eventually moved in with friends John and Ruth Benedum and did odd jobs for them. Young took part in many baseball events after his retirement. In 1937, 26 years after he retired from baseball, Young was inducted into the Baseball Hall of Fame. He was among the first to donate mementos to the Hall.\nBy 1940, Young's only source of income was stock dividends of $300 per year ($ today). On November 4, 1955, Young died on the Benedums' farm at the age of 88. He was buried in Peoli, Ohio.\nLegacy.\nYoung's career is seen as a bridge from baseball's earliest days to its modern era; he pitched against stars such as Cap Anson, already an established player when the National League was first formed in 1876, as well as against Eddie Collins, who played until 1930. When Young's career began, pitchers delivered the baseball underhand and fouls were not counted as strikes. The pitcher's mound was not moved back to its present position of until Young's fourth season; he did not wear a glove until his sixth season.\nYoung was elected to the National Baseball Hall of Fame in 1937. In 1956, about one year after Young's death, the Cy Young Award was created to honor the best pitcher in Major League Baseball for each season. The first award was given to Brooklyn's Don Newcombe. Originally, it was a single award covering all of baseball. The honor was divided into two Cy Young Awards in 1967, one for each league.\nOn September 23, 1993, a statue dedicated to him was unveiled by Northeastern University on the site of the Red Sox's original stadium, the Huntington Avenue Grounds. It was there that Young had pitched the first game of the 1903 World Series, as well as the first perfect game in the modern era of baseball. A home plate-shaped plaque next to the statue reads:\nOn October 1, 1903 the first modern World Series between the American League champion Boston Pilgrims (later known as the Red Sox) and the National League champion Pittsburgh Pirates was played on this site. General admission tickets were fifty cents. The Pilgrims, led by twenty-eight game winner Cy Young, trailed the series three games to one but then swept four consecutive victories to win the championship five games to three.\nIn 1999, 88 years after his final major league appearance and 44 years after his death, editors at \"The Sporting News\" ranked Young 14th on their list of \"Baseball's 100 Greatest Players\". That same year, baseball fans named him to the Major League Baseball All-Century Team."}
{"id": "6851", "revid": "34532625", "url": "https://en.wikipedia.org/wiki?curid=6851", "title": "Coronation Street", "text": "Coronation Street (often referred to as Corrie) is a British soap opera created by Granada Television and shown on ITV since 9 December 1960. The programme typically centres around the residents of Coronation Street \u2013 a cobbled, terraced street in Weatherfield, a fictional town based on inner-city Salford.\nOriginally broadcast twice weekly, the series began airing six times a week in 2016. The programme was conceived by scriptwriter Tony Warren and entered production at Granada Television in Manchester in 1960. Warren's initial proposal was rejected by the station's founder Sidney Bernstein, but he was persuaded by producer Harry Elton to produce the programme for 13 pilot episodes, and the show has since become a significant part of British culture.\n\"Coronation Street\" is made by ITV Granada at MediaCityUK and shown in all ITV regions, as well as internationally. On 17 September 2010, it became the world's longest-running television soap opera and was listed in the \"Guinness World Records\" (by years run). Initially influenced by the conventions of kitchen sink realism, \"Coronation Street\" is noted for its depiction of a down-to-earth, working-class community, combined with light-hearted humour and strong characters. The show currently averages around six million viewers per episode. The show premiered its 10,000th episode on 7 February 2020, and celebrated its 60th anniversary later that year.\nHistory.\n1960s.\nThe first episode was aired on 9 December 1960 at 7\u00a0pm, and was not initially a critical success; \"Daily Mirror\" columnist Ken Irwin claimed the series would only last three weeks. Granada Television had commissioned only 13 episodes, and some inside the company doubted the show would last beyond its planned production run. Despite the criticism, viewers were immediately drawn into the serial, won over by \"Coronation Street\"s ordinary characters. The programme also made use of Northern English language and dialect; affectionate local terms like \"eh, chuck?\", \"nowt\" (, from \"nought\", meaning \"nothing\"), and \"by 'eck!\" became widely heard on British television for the first time.\nEarly episodes told the story of student Ken Barlow (William Roache), who had won a place at university, and thus found his working-class background\u2014as well as his parents, Frank (Frank Pemberton) and Ida (Noel Dyson)\u2014something of an embarrassment. The character was one of the few to have experienced life outside of Coronation Street. In some ways this predicts the growth of globalisation, and the decline of similar communities. In an episode from 1961, Barlow declares: \"You can't go on just thinking about your own street these days. We're living with people on the other side of the world. There's more to worry about than Elsie Tanner (Pat Phoenix) and her boyfriends.\" Roache is the only remaining member of the original cast, which makes him the longest-serving actor in \"Coronation Street\", and in British and global soap history.\nAt the centre of many early stories, there was Ena Sharples (Violet Carson), caretaker of the Glad Tidings Mission Hall, and her friends: timid Minnie Caldwell (Margot Bryant), and bespectacled Martha Longhurst (Lynne Carol). The trio were likened to the Greek chorus, and the three witches in William Shakespeare's \"Macbeth\", as they would sit in the snug bar of The Rovers Return Inn, passing judgement over family, neighbours and frequently each other. Headstrong Ena often clashed with Elsie Tanner (Pat Phoenix), whom she believed espoused a dauntlessly loose set of morals. Elsie resented Ena's interference and gossip, which most of the time had little basis in reality.\nIn April 1961, Jed Stone (Kenneth Cope) made his first appearance and returned the following year in 1962. He left in 1963, but returned three years later in 1966. He left again and then returned 42 years later in 2008.\nIn March 1961, \"Coronation Street\" reached No. 1 in the television ratings and remained there for the rest of the year. Earlier in 1961, a Television Audience Measurement (TAM) showed that 75% of available viewers (15\u00a0million) tuned into \"Corrie\", and by 1964 the programme had over 20\u00a0million regular viewers, with ratings peaking on 2 December 1964, at 21.36\u00a0million viewers.\nStorylines throughout the decade included Elsie's mystery poison-pen letter, the 1962 marriage of Ken and Valerie Tatlock (Anne Reid), the death of Martha Longhurst in 1964, the birth of the Barlow twins in 1965, Elsie Tanner's wedding to Steve Tanner (Paul Maxwell) and a train crashing from the viaduct (both in 1967), Steve Tanner's murder in 1968, and a coach crash in 1969.\nIn spite of rising popularity with viewers, \"Coronation Street\" was criticised by some for its outdated portrayal of the urban working class, and its representation of a community that was a nostalgic fantasy. After the first episode in 1960, the \"Daily Mirror\" printed: \"The programme is doomed from the outset\u00a0... For there is little reality in this new serial, which apparently, we have to suffer twice a week.\" By 1967, critics were suggesting that the programme no longer reflected life in 1960s Britain, but reflected how life was in the \"1950s\". Granada hurried to update the programme, with the hope of introducing more issue-driven stories, including Lucille Hewitt (Jennifer Moss) becoming addicted to drugs, Jerry Booth (Graham Haberfield) being in a storyline about homosexuality, Emily Nugent (Eileen Derbyshire) having an out-of-wedlock child, and introducing a black family, but all of these ideas were dropped for fear of upsetting viewers.\n1970s.\nThe show's production team was tested when many core cast members left the programme in the early 1970s. When Arthur Leslie died suddenly in 1970, his character, Rovers' landlord Jack Walker, died with him. Anne Reid quit as Valerie Barlow; her character was killed off in 1971, electrocuting herself with a faulty hairdryer. Ratings reached a low of eight million in February 1973, when Pat Phoenix quit as Elsie Tanner and Doris Speed (haughty landlady Annie Walker) took two months' leave due to bereavement. The audience of ITV's other flagship soap opera \"Crossroads\" increased markedly at this time, as its established cast, such as Meg Richardson (Noele Gordon), grew in popularity. These sudden departures forced the writing team to quickly develop characters who had previously stood in the background. The roles of Bet Lynch (Julie Goodyear), Deirdre Hunt (Anne Kirkbride), Rita Littlewood (Barbara Knox), Mavis Riley (Thelma Barlow) and Ivy Tildsley (Lynne Perrie) were built up between 1972 and 1973 (with Perrie's character being renamed to the better-known \"Tilsley\"), and characters such as Gail Potter (Helen Worth), Blanche Hunt (Patricia Cutts/Maggie Jones), and Vera Duckworth (Liz Dawn) first appearing in 1974. These characters would remain at the centre of the programme for many years.\nComic storylines had been popular in the series in the 1960s, but had become sparse during the early 1970s. These were re-introduced by new producer Bill Podmore who joined the series in 1976. He had worked on Granada comedy productions prior to his appointment. Stan (Bernard Youens) and Hilda Ogden (Jean Alexander) were often at the centre of overtly funny storylines, with other comic characters including Eddie Yeats (Geoffrey Hughes), Fred Gee (Fred Feast), and Jack Duckworth (Bill Tarmey) all making their first appearances during the decade.\nIn 1976, Pat Phoenix returned to her role as Elsie Tanner and, after a spate of ill health (including a stroke in 1974 where she was written out of the show for 10 months), Violet Carson returned on a more regular basis as Ena. \"Coronation Street's\" stalwart cast slotted back into the programme alongside the newcomers, examining new relationships between characters of different ages and backgrounds: Eddie Yeats became the Ogdens' lodger, Gail Potter and Suzie Birchall (Cheryl Murray) moved in with Elsie, Mike Baldwin (Johnny Briggs) arrived in 1976 as the tough factory boss, and Annie Walker reigned at the Rovers with her trio of staff: Bet Lynch, Fred Gee and Betty Turpin (Betty Driver).\nStorylines throughout the decade included a warehouse fire in 1975, the birth of Tracy Langton in 1977, the murder of Ernest Bishop (Stephen Hancock) in 1978, a lorry crashing into the Rovers Return in 1979, and the marriage of Gail to Brian Tilsley (Christopher Quinten) (also in 1979).\nFor eleven weeks, between August and October 1979, industrial action forced \"Coronation Street\" and the entire ITV network (apart from the Channel Islands) off the air. When ITV did return, its first evening schedule included a special \"catch-up\" edition of \"Coronation Street\". This included storylines which would have taken place during the strike, and they were explained in the form of a narrative chat between Bet Lynch and popular character Len Fairclough (Peter Adamson). For several weeks the channel had very few fresh episodes to show, and episodes of the game show \"3-2-1\" were screened in its place. \"Coronation Street\" returned to ITV screens with a regular scheduled time closer to the end of 1979.\n\"Coronation Street\" had little competition within its prime time slot, and certain critics suggested that the programme had grown complacent, moving away from socially viable storylines and again presenting a dated view of working class life.\n1980s.\nBetween 1980 and 1989, \"Coronation Street\" underwent some of the biggest changes since its launch. By May 1984, William Roache (Ken Barlow) stood as the only original cast member, after the departures of Violet Carson (Ena Sharples) in 1980, Doris Speed (Annie Walker) in 1983, and both Pat Phoenix (Elsie Tanner) and Jack Howarth (Albert Tatlock) in 1984. In 1983, antihero Len Fairclough (Peter Adamson), one of the show's central male characters since 1961, was killed off, and in 1984, Stan Ogden (Bernard Youens) died. While the press predicted the end of \"Corrie\", H. V. Kershaw declared that \"There are no stars in \"Coronation Street\".\" Writers drew on the show's many archetypes, with established characters stepping into the roles left by the original cast. Phyllis Pearce (Jill Summers) was hailed as the new Ena Sharples in 1982, the Duckworths moved into No.9 in 1983 and slipped into the role once held by the Ogdens, while Percy Sugden (Bill Waddington) appeared in 1983 and took over the grumpy war veteran role from Albert Tatlock. The question of who would take over the Rovers Return after Annie Walker's 1983 exit was answered in 1985 when Bet Lynch (who also mirrored the vulnerability and strength of Elsie Tanner) was installed as landlady. In 1983, Shirley Armitage (Lisa Lewis) became the first major black character in her role as machinist at Baldwin's Casuals.\nKen Barlow married Deirdre Langton (Anne Kirkbride) on 27 July 1981. The episode was watched by over 15\u00a0million viewers\u00a0\u2013 more ITV viewers than the wedding of Prince Charles and Lady Diana two days later. In the 1980s relationships were cemented between established characters: Alf Roberts (Bryan Mosley) married Audrey Potter (Sue Nicholls) in 1985; Kevin Webster (Michael Le Vell) married Sally Seddon (Sally Whittaker) in 1986; Bet Lynch married Alec Gilroy (Roy Barraclough) in 1987; and 1988 saw the marriages of both Ivy Tilsley and Don Brennan (Geoffrey Hinsliff), and the long-awaited union of Mavis Riley and Derek Wilton (Peter Baldwin), after over a decade of on-off romances and a failed marriage attempt in 1984.\nIn 1982, the arrival of Channel 4, and its edgy new soap opera \"Brookside\", was one of the biggest changes for \"Coronation Street\". Unlike \"Coronation Street\", which had a very nostalgic view of working-class life, \"Brookside\" brought together working and middle-class families in a more contemporary environment. The dialogue often included expletives and the stories were more hard-hitting, and of the current Zeitgeist. Whereas stories at this time in \"Coronation Street\" were largely about family affairs, \"Brookside\" concentrated on social affairs such as industrial action, unemployment, and the black market. The BBC also introduced a new prime time soap opera, \"EastEnders\" in 1985. Like \"Brookside\", \"EastEnders\" had a more gritty premise than \"Coronation Street\", although unlike \"Brookside\" it tended to steer clear of blue language and politicised stories.\nWhile ratings for \"Coronation Street\" remained consistent throughout the decade, \"EastEnders\" regularly obtained higher viewing figures due to its omnibus episodes shown at weekends. The \"Coronation Street\" episode broadcast on 2 January 1985 attracted 21.40 million viewers, making it the most-watched episode in the shows history based on a single showing. Subsequent episodes would achieve higher figures when the original broadcast and omnibus edition figures were combined. With prime time competition, \"Corrie\" was again seen as being old fashioned, with the introduction of the 'normal' Clayton family in 1985 being a failure with viewers. Between 1988 and 1989, many aspects of the show were modernised by new producer David Liddiment. A new exterior set had been built in 1982, and in 1989 it was redeveloped to include new houses and shops. Production techniques were also changed with a new studio being built, and the inclusion of more location filming, which had moved the show from being shot on film to videotape in 1988. Due to new pressures, an introduction of the third weekly episode aired on 20 October 1989, to broadcast each Friday at 7:30\u00a0pm.\nThe 1980s featured some of the most prominent storylines in the programme's history, such as Deirdre Barlow's affair with Mike Baldwin (Johnny Briggs) in 1983, the first soap storyline to receive widespread media attention. The feud between Ken Barlow and Mike Baldwin would continue for many years, with Mike even marrying Ken's daughter, Susan (Wendy Jane Walker). In 1986, there was a fire at the Rovers Return. The episode that aired on 25 December 1987, attracted a combined audience (original and omnibus) of 26.65\u00a0million \u2013 a figure helped by the fact that this episode heralded the departure of immensely-popular character Hilda Ogden (Jean Alexander). Between 1986 and 1989, the story of Rita Fairclough's (Barbara Knox) psychological abuse at the hands of Alan Bradley (Mark Eden), and then his subsequent death under the wheels of a Blackpool tram, was played out. This storyline gave the show its highest combined viewing figure in its history with 26.93\u00a0million for the episode that aired on 15 (and 19) March 1989, where Alan is hiding from the police after trying to kill Rita in the previous episode. This rating is sometimes incorrectly credited to the 8 December 1989 tram death episode. Other stories included the birth of Nicky Tilsley (Warren Jackson) in 1980, Elsie Tanner's departure and Stan Ogden's funeral in 1984, the birth of Sarah-Louise Tilsley (Lynsay King) in 1987, and Brian Tilsley's murder in 1989.\nNew characters were introduced, such as Terry Duckworth (Nigel Pivaro), Curly Watts (Kevin Kennedy), Martin Platt (Sean Wilson), Reg Holdsworth (Ken Morley), and the McDonald family; one of whom, Simon Gregson, started on the show as Steve McDonald a week after his 15th birthday, and has been on the show ever since.\n1990s.\nIn spite of updated sets and production changes, \"Coronation Street\" still received criticism. In 1992, chairman of the Broadcasting Standards Council, Lord Rees-Mogg, criticised the low representation of ethnic minorities, and the programme's portrayal of the cosy familiarity of a bygone era. Some newspapers ran headlines such as \"\"Coronation Street\" shuts out blacks\" (\"The Times\"), and \"'Put colour in t'Street\" (\"Daily Mirror\"). Patrick Stoddart of \"The Times\" wrote: \"The millions who watch \"Coronation Street\"\u00a0\u2013 and who will continue to do so despite Lord Rees-Mogg\u00a0\u2013 know real life when they see it\u00a0... in the most confident and accomplished soap opera television has ever seen\". Black and Asian characters had appeared, but it was not until 1999 that the show featured its first regular non-white family, the Desai family.\nNew characters Des (Philip Middlemiss) and Steph Barnes (Amelia Bullmore) moved into one of the new houses in 1990, being dubbed by the media as Yuppies. Raquel Wolstenhulme (Sarah Lancashire) first appeared in 1991 and went on to become one of the most popular characters. The McDonald family were developed and the fiery relationships between Liz (Beverly Callard), Jim (Charles Lawson), Steve (Simon Gregson) and Andy (Nicholas Cochrane) interested viewers. Other newcomers were Maud Grimes (Elizabeth Bradley), Roy Cropper (David Neilson), Gary and Judy Mallett (Ian Mercer and Gaynor Faye), as well as Fred Elliott (John Savident) and Ashley Peacock (Steven Arnold). The amount of slapstick and physical humour in storylines increased during the 1990s, with comical characters such as Reg Holdsworth (Ken Morley) and his water bed.\nIn the early 1990s storylines included the death of newborn Katie McDonald in 1992, Mike Baldwin's (Johnny Briggs) wedding to Alma Sedgewick (Amanda Barrie) in 1992, Tommy Duckworth being sold by his father Terry (Nigel Pivaro) in 1993, Deirdre Barlow's (Anne Kirkbride) marriage to Moroccan Samir Rachid (Al Nedjari), and the rise of Tanya Pooley (Eva Pope) between 1993 and 1994.\nIn 1995, Julie Goodyear (Bet Lynch) left the show. She made brief return appearances in 2002 and 2003.\nIn 1997, Brian Park took over as producer, with the idea of promoting young characters as opposed to the older cast. On his first day, he cut the characters of Derek Wilton (Peter Baldwin), Don Brennan (Geoffrey Hinsliff), Percy Sugden (Bill Waddington), Bill Webster (Peter Armitage), Billy Williams (Frank Mills) and Maureen Holdsworth (Sherrie Hewson). Thelma Barlow, who played Derek's wife Mavis, was angered by the firing of her co-star and resigned. The production team lost some of its key writers when Barry Hill, Adele Rose and Julian Roach all resigned as well.\nIn line with Park's suggestion, younger characters were introduced: Nick Tilsley was recast, played by Adam Rickitt, single mother Zoe Tattersall (Joanne Froggatt) first appeared, and the Battersbys moved into No.5. Storylines focussed on tackling 'issues', such as drug dealers, eco-warriors, religious cults, and a transsexual woman. Park quit in 1998, after deciding that he had done what he intended to do; he maintained that his biggest achievement was the introduction of Hayley Patterson (Julie Hesmondhalgh), the first transsexual character in a British soap.\nSome viewers were alienated by the new \"Coronation Street\", and sections of the media voiced their disapproval. Having received criticism of being too out of touch, \"Corrie\" now struggled to emulate the more modern \"Brookside\" and \"EastEnders\". In the \"Daily Mirror\", Victor Lewis-Smith wrote: \"Apparently it doesn't matter that this is a first-class soap opera, superbly scripted and flawlessly performed by a seasoned repertory company.\"\nOne of \"Coronation Street\"'s best known storylines took place in March/April 1998, with Deirdre Rachid (Anne Kirkbride) being wrongfully imprisoned after a relationship with con-man Jon Lindsay (Owen Aaronovitch). The episode in which Deirdre was sent to prison had an audience of 19\u00a0million viewers, and 'Free the Weatherfield One' campaigns sprung up in a media frenzy. Then Prime Minister Tony Blair even passed comment on Deirdre's sentencing in Parliament. Deirdre was freed after three weeks, with Granada stating that they had always intended for her to be released, in spite of the media interest.\n2000s.\nOn 8 December 2000, the show celebrated its fortieth year by broadcasting a live, hour-long . The Prince of Wales appeared as himself in an ITV News bulletin report. Earlier in the year, 13-year-old Sarah-Louise Platt (Tina O'Brien) had become pregnant and given birth to a baby girl, Bethany, on 4 June. The episode where Gail (Helen Worth) was told of her daughter's pregnancy was watched by 15\u00a0million viewers. In September 2000, Mike Baldwin married Linda Sykes but shortly afterwards, his drunken son Mark confessed he and Linda had been having an affair behind his dad's back. The episode attracted an audience of 16.8\u00a0million and won the award for Best Storyline at the 2000 British Soap Awards.\nFrom 1999 to 2001, issue-led storylines were introduced such as Toyah Battersby's (Georgia Taylor) rape, Roy and Hayley Cropper (David Neilson and Julie Hesmondhalgh) abducting their foster child, Sarah Platt's Internet chat room abduction and Alma Halliwell's (Amanda Barrie) death from cervical cancer. Such storylines were unpopular with viewers and ratings dropped and in October 2001, Macnaught was abruptly moved to another Granada department and Carolyn Reynolds took over. In 2002, Kieran Roberts was appointed as producer and aimed to re-introduce \"gentle storylines and humour\", after deciding that \"the Street\" should not try to compete with other soaps. In 2002, Gail married Richard Hillman (Brian Capron), a financial advisor who would go on to leave Duggie Ferguson (John Bowe) to die; murder both his ex-wife Patricia (Annabelle Apsion) and local neighbour Maxine Peacock (Tracy Shaw); and attempt to kill both his mother-in-law Audrey Roberts (Sue Nicholls) and her longtime friend, Emily Bishop (Eileen Derbyshire). After confessing his crimes to Gail in a two-episode handler, Hillman left the street for two weeks before returning with a suicidal impact on himself and his stepfamily; he kidnapped Gail, her children Sarah and David (Jack P. Shepherd), and granddaughter Bethany, before driving them into a canal \u2013 though the Platt family survived whilst Richard drowned. The storyline received wide press attention, and viewing figures peaked at 19.4\u00a0million, with Hillman dubbed a \"serial killer\" by the media. Todd Grimshaw (Bruno Langley) became \"Corrie's\" first regular homosexual character. In 2003, another gay male character was introduced, Sean Tully (Antony Cotton). The bigamy of Peter Barlow (Chris Gascoyne) and his addiction to alcohol, later in the decade, Maya Sharma's (Sasha Behar) revenge on former lover Dev Alahan (Jimmi Harkishin), Charlie Stubbs's (Bill Ward) psychological abuse of Shelley Unwin (Sally Lindsay), and the deaths of Mike Baldwin (Johnny Briggs), Vera Duckworth (Liz Dawn) and Fred Elliott (John Savident). In 2007, Tracy Barlow (Kate Ford) murdered Charlie Stubbs and claiming it was self-defence; the audience during this storyline peaked at 13.3\u00a0million. At the 2007 British Soap Awards, it won Best Storyline, and Ford was voted Best Actress for her portrayal. Other storylines included Leanne Battersby (Jane Danson) becoming a prostitute and the show's first bisexual love triangle (between Michelle Connor (Kym Marsh), Sonny Dhillon (Pal Aron), and Sean Tully (Antony Cotton)).\nIn July 2007, after 34 years in the role of Vera Duckworth, Liz Dawn left the show due to ill health. After conversation between Dawn and producers Kieran Roberts and Steve Frost, the decision was made to kill Vera off. In January 2008, shortly before plans to retire to Blackpool, Vera's husband Jack (William Tarmey) found that she had died in her armchair.\nTina O'Brien revealed in the British press on 4 April 2007 that she would be leaving \"Coronation Street\". Sarah-Louise, who was involved in some of the decade's most controversial stories, left in December 2007 with her daughter, Bethany. In 2008, Michelle learning that Ryan (Ben Thompson) was not her biological son, having been accidentally swapped at birth with Alex Neeson (Dario Coates). Carla Connor (Alison King) turned to Liam for comfort and developed feelings for him. In spite of knowing about her feelings, Liam married Maria Sutherland (Samia Longchambon). Maria and Liam's baby son was stillborn in April, and during an estrangement from Maria upon the death of their baby, Liam had a one-night stand with Carla, a story which helped pave the way for his departure. Gail Platt's (Helen Worth) son David (Jack P. Shepherd) pushed her down the stairs. Enraged that Gail refused to press charges, David vandalised the Street and was sent to a young offenders' facility for several months. In May 2008, Gail finally met Ted Page (Michael Byrne), the father she had never known and in 2009, Gail's boyfriend Joe McIntyre (Reece Dinsdale) became addicted to painkillers, which came to a head when he broke into the medical centre. In August 2008, Jed Stone (Kenneth Cope) returned after 42 years. Liam Connor and his ex-sister-in-law Carla gave into their feelings for each other and began an affair. Carla's fianc\u00e9e Tony Gordon (Gray O'Brien) discovered the affair and had Liam killed in a hit-and-run in October. Carla struggled to come to terms with Liam's death, but decided she still loved Tony and married him on 3 December, in an episode attracting 10.3\u00a0million viewers. In April 2009 it was revealed that Eileen Grimshaw's (Sue Cleaver) father, Colin (Edward de Souza) \u2013 the son of Elsie Tanner's (Pat Phoenix) cousin Arnley \u2013 had slept with Eileen's old classmate, Paula Carp (Sharon Duce) while she was still at school, and that Paula's daughter Julie (Katy Cavanagh) was in fact also Colin's daughter. Other stories in 2009 included Maria giving birth to Liam's son and her subsequent relationship with Liam's killer Tony, Steve McDonald's (Simon Gregson) marriage to Becky Granger (Katherine Kelly) and Kevin Webster's (Michael Le Vell) affair with Molly Dobbs (Vicky Binns). On Christmas Day 2009, Sally Webster (Sally Dynevor) told husband Kevin that she had breast cancer, just as he was about to leave her for lover Molly.\n2010s.\nThe show began broadcasting in high-definition in May 2010, and on 17 September that year, \"Coronation Street\" entered \"Guinness World Records\" as the world's longest-running television soap opera after the American soap opera \"As the World Turns\" concluded. William Roache was listed as the world's longest-running soap actor.\n\"Coronation Street\" 50th anniversary week was celebrated with seven episodes, plus a special one-hour live episode, broadcast from 6\u201310 December. The episodes averaged 14\u00a0million viewers, a 52.1% share of the audience. The anniversary was also publicised with ITV specials and news broadcasts. In the storyline, Nick Tilsley and Leanne Battersby's bar\u2014The Joinery\u2014exploded during Peter Barlow's stag party. As a result, the viaduct was destroyed, sending a Metrolink tram careering onto the street, destroying D&amp;S Alahan's Corner Shop and The Kabin. Two characters, Ashley Peacock (Steven Arnold) and Molly Dobbs (Vicky Binns), along with an unknown taxi driver, were killed as a result of the disaster. Rita Sullivan (Barbara Knox) survived, despite being trapped under the rubble of her destroyed shop. Fiz Stape (Jennie McAlpine) prematurely gave birth to a baby girl, Hope. The episode of \"EastEnders\" broadcast on the same day as \"Coronation Street\" 50th anniversary episode included a tribute, with the character Dot Branning (June Brown) saying that she never misses an episode of \"Coronation Street\".\n2020s.\nOn Friday 7 February 2020, \"Coronation Street\" aired its landmark 10,000th episode, the runtime of which was extended to 60 minutes. Producers stated that the episode would contain \"a nostalgic trip down memory lane\" and \"a nod to its own past\". A month later, it was announced that production on the soap would have to be suspended, due to the impact of the COVID-19 pandemic on television. After an 11-week intermission on filming, they began filming new episodes in June 2020. The episodes would feature social distancing to adhere to the guidelines set by the government, and it was confirmed that actors over 70, as well as those with underlying health conditions, would not be allowed to be on set until it was safe to do so. On Wednesday 9 December 2020, the soap celebrated its 60th anniversary, with original plans for the episode forced to change due to COVID-19 guidelines. The anniversary week saw the conclusion of a long-running coercive control storyline that began in May 2019, with Geoff Metcalfe (Ian Bartholomew) abusing Yasmeen Nazir (Shelley King). The showdown, which resulted in the death of Geoff allowed social distancing rules to be relaxed on the condition that the crew members involved formed a social bubble prior to the filming.\nCharacters.\nSince 1960, \"Coronation Street\" has featured many characters whose popularity with viewers and critics has differed greatly. The original cast was created by Tony Warren, with the characters of Ena Sharples (Violet Carson), Elsie Tanner (Pat Phoenix) and Annie Walker (Doris Speed) as central figures. These three women remained with the show for at least 20 years, and became archetypes of British soap opera, often being emulated by other serials. Ena was the street's busybody, battle-axe and self-proclaimed moral voice. Elsie was the tart with a heart, who was constantly hurt by men in the search for true love. Annie Walker, landlady of the Rovers Return Inn, had delusions of grandeur and saw herself as better than the other residents.\n\"Coronation Street\" became known for the portrayal of strong female characters, including original cast characters like Ena, Annie and Elsie, and later Hilda Ogden (Jean Alexander), who first appeared in 1964; all four became household names during the 1960s. Warren's programme was largely matriarchal, which some commentators put down to the female-dominant environment in which he grew up. Consequently, the show has a long tradition of psychologically-abused husbands, most famously Stan Ogden (Bernard Youens) and Jack Duckworth (Bill Tarmey), husbands of Hilda and Vera Duckworth (Liz Dawn), respectively.\nKen Barlow (William Roache) entered the storyline as a young radical, reflecting the youth of 1960s Britain, where figures like the Beatles, the Rolling Stones and the model Twiggy were to reshape the concept of youthful rebellion. Though the rest of the original Barlow family were killed off before the end of the 1970s, Ken, who for 27 years was the only character from the first episode remaining, has remained the constant link throughout the entire series. In 2011, Dennis Tanner (Philip Lowrie), another character from the first episode, returned to \"Coronation Street\" after a 43-year absence. Since 1984, Ken Barlow has been the show's only remaining original character. Emily Bishop (Eileen Derbyshire) had appeared in the series since late-January 1961, when the show was just weeks old, and was the show's longest-serving female character before she departed on 1 January 2016. Rita Tanner (Barbara Knox) appeared on the show for one episode in December 1964, before returning as a full-time cast member in January 1972. She is currently the second longest-serving original cast member on the show.\nStan and Hilda Ogden were introduced in 1964, with Hilda becoming one of the most famous British soap opera characters of all time. In a 1982 poll, she was voted fourth-most recognisable woman in Britain, after Queen Elizabeth The Queen Mother, Queen Elizabeth II and Diana, Princess of Wales. Hilda's best-known attributes were her pinny, hair curlers, and the \"muriel\" in her living room with three \"flying\" duck ornaments. Hilda Ogden's departure on Christmas Day 1987, remains the highest-rated episode of \"Coronation Street\" ever, with nearly 27,000,000 viewers. Stan Ogden had been killed off in 1984 following the death of actor Bernard Youens after a long illness which had restricted his appearances towards the end.\nBet Lynch (Julie Goodyear) first appeared in 1966, before becoming a regular in 1970, and went on to become one of the most famous \"Corrie\" characters. Bet stood as the central character of the show from 1985 until departing in 1995, often being dubbed as \"Queen of the Street\" by the media, and indeed herself. The character briefly returned in June 2002.\n\"Coronation Street\" and its characters often rely heavily on archetypes, with the characterisation of some of its current and recent cast based loosely on former characters. Phyllis Pearce (Jill Summers), Blanche Hunt (Maggie Jones) and Sylvia Goodwin (Stephanie Cole) embodied the role of the acid-tongued busybody originally held by Ena, Sally Webster (Sally Dynevor) has grown snobbish, like Annie, and a number of the programme's female characters, such as Carla Connor (Alison King), mirror the vulnerability of Elsie and Bet. Other recurring archetypes include the war veteran such as Albert Tatlock (Jack Howarth), Percy Sugden (Bill Waddington) and Gary Windass (Mikey North), the bumbling retail manager like Leonard Swindley (Arthur Lowe), Reg Holdsworth (Ken Morley), Norris Cole (Malcolm Hebden), quick-tempered, tough tradesmen like Len Fairclough (Peter Adamson), Jim McDonald (Charles Lawson), Tommy Harris (Thomas Craig) and Owen Armstrong (Ian Puleston-Davies), and the perennial losers such as Stan and Hilda, Jack and Vera, Les Battersby (Bruce Jones), Beth Tinker (Lisa George) and Kirk Sutherland (Andrew Whyment).\nVillains are also common character types, such as Tracy Barlow (Kate Ford), Alan Bradley (Mark Eden), Jenny Bradley (Sally Ann Matthews), Rob Donovan (Marc Baylis), Frank Foster (Andrew Lancel), Tony Gordon (Gray O'Brien), Caz Hammond (Rhea Bailey), Richard Hillman (Brian Capron), Greg Kelly (Stephen Billington), Will Chatterton (Leon Ockenden), Nathan Curtis (Christopher Harper), Callum Logan (Sean Ward), Karl Munro (John Michie), Pat Phelan (Connor McIntyre), David Platt (Jack P. Shepherd), Maya Sharma (Sasha Behar), Kirsty Soames (Natalie Gumede), John Stape (Graeme Hawley), Geoff Metcalfe (Ian Bartholomew) and Gary Windass (Mikey North). The show's former archivist and scriptwriter Daran Little disagreed with the characterisation of the show as a collection of stereotypes. \"Rather, remember that Elsie, Ena and others were the first of their kind ever seen on British television. If later characters are stereotypes, it's because they are from the same original mould. It is the hundreds of programmes that have followed which have copied \"Coronation Street\".\"\nProduction.\nBroadcast format.\nBetween 9 December 1960 and 3 March 1961, \"Coronation Street\" was broadcast twice weekly, on Wednesday and Friday. During this period, the Friday episode was broadcast live, with the Wednesday episode being pre-recorded 15\u00a0minutes later. When the programme went fully networked on 6 March 1961, broadcast days changed to Monday and Wednesday. The last regular episode to be shown live was broadcast on 3 February 1961.\nThe series was transmitted in black and white for the majority of the 1960s. Preparations were made to film episode 923, to be transmitted Wednesday 29 October 1969, in colour. This instalment featured the street's residents on a coach trip to the Lake District. In the end, suitable colour film stock for the cameras could not be found and the footage was shot in black and white. The following episode, transmitted Monday 3 November, was videotaped in colour but featured black and white film inserts and title sequence. Like BBC1, the ITV network was officially broadcast in black and white at this point (though programmes were actually broadcast in colour as early as July that year for colour transmission testing and adjustment) so the episode was seen by most in black and white.\nThe ITV network, like BBC1, began full colour transmissions on 15 November 1969. Daran Little, for many years the official programme archivist, claims that the first episode to be transmitted in colour was episode 930 shown on 24 November 1969.\nIn October 1970 a technicians' dispute turned into a work-to-rule when sound staff were denied a pay rise given to camera staff the year before for working with colour recording equipment. The terms of the work-to-rule were that staff refused to work with the new equipment (though the old black and white equipment had been disposed of by then) and therefore programmes were recorded and transmitted in black and white, including \"Coronation Street\" The dispute was resolved in early 1971 and the last black and white episode was broadcast on 10 February 1971, although the episodes transmitted on 22 and 24 February 1971 had contained black and white location inserts.\nEpisode 5191, originally broadcast on 7 January 2002, was the first to be broadcast in widescreen format. \"Coronation Street\" was the last UK-wide soap to make the switch to 16:9 (\"Take the High Road\" remained in until it finished in 2003).\nFrom 22 March 2010, \"Coronation Street\" was produced in 1080/50i for transmission on HDTV platforms on ITV HD. The first transmission in this format was episode 7351 on 31 May 2010 with a new set of titles and re-recorded theme tune. On 26 May 2010 ITV previewed the new HD titles on the \"Coronation Street\" website. Due to copyright reasons only viewers residing in the UK could see them on the ITV site.\nProduction staff.\n\"Coronation Street's\" creator, Tony Warren, wrote the first 13 episodes of the programme in 1960, and continued to write for the programme intermittently until 1976. He had retained links with \"Coronation Street\" up to his death in 2016, often advising on storylines.\nHarry Kershaw was the script editor for \"Coronation Street\" when the programme began in 1960, working alongside Tony Warren. Kershaw was also a script writer for the programme and the show's producer between 1962 and 1971. He remains the only person, along with John Finch, to have held the three posts of script editor, writer and producer. Kershaw continued to write for the programme until his retirement in January 1988.\nAdele Rose was the longest-serving \"Coronation Street\" writer, completing 455 scripts between 1961 and 1998. She also created \"Byker Grove\".\nBill Podmore was the show's longest serving producer. By the time he stepped down in 1988 he had completed 13 years at the production helm. Nicknamed the \"godfather\" by the tabloid press, he was renowned for his tough, uncompromising style and was feared by both crew and cast alike. He is known for sacking Peter Adamson, the show's Len Fairclough, in 1983. Iain MacLeod is the current series producer.\nMichael Apted, best known for the \"Up!\" series of documentaries was a director on the programme in the early 1960s. This period of his career marked the first of his many collaborations with writer Jack Rosenthal. Rosenthal, noted for such television plays as \"Bar Mitzvah Boy\", began his career on the show, writing over 150 episodes between 1961 and 1969. Paul Abbott was a story editor on the programme in the 1980s and began writing episodes in 1989, but left in 1993 to produce \"Cracker\", for which he later wrote, before creating his own dramas such as \"Touching Evil\" and \"Shameless\". Russell T Davies was briefly a storyliner on the programme in the mid-1990s, also writing the script for the direct-to-video special \"\" He, too, has become a noted writer of his own high-profile television drama programmes, including \"Queer as Folk\" and the 2005 revival of \"Doctor Who\". Jimmy McGovern also wrote some episodes.\nTheme music.\nThe show's theme music, a cornet piece, accompanied by a brass band plus clarinet and double bass, reminiscent of northern band music, was written by Eric Spear.\nThe identity of the trumpeter was not public knowledge until 1994, when jazz musician and journalist Ron Simmonds revealed that it was the Surrey musician Ronnie Hunt. He added, \"an attempt was made in later years to re-record that solo, using Stan Roderick, but it sounded too good, and they reverted to the old one.\" In 2004, the \"Manchester Evening News\" published a contradictory story that a young musician from Wilmslow called David Browning played the trumpet on both the original recording of the theme in 1960 and a re-recording in 1964, for a one-off payment of \u00a336.\nA new, completely re-recorded version of the theme tune replaced the original when the series started broadcasting in HD on 31 May 2010. It accompanied a new montage-style credits sequence featuring images of Manchester and Weatherfield.\nA reggae version of the theme tune was recorded by The I-Royals and released by Media Marvels and WEA in 1983.\nOn 31 March 2017, it was revealed on the YouTube channel of Corrie that some of the soap's cast would sing a specially-written lyric, of which will be added to the new theme song that will be played, as of the first episode of the evening of Monday, 3 April 2017, but it turned out to be an April Fools joke.\nViewing figures.\nEpisodes in the 1960s, 70s, and 80s, regularly attracted figures of between 18 and 21\u00a0million viewers, and during the 1990s and early 2000s, 14 to 16\u00a0million per episode would be typical. Like most terrestrial television in the UK, a decline in viewership has taken place and the show posts an average audience of just under 9\u00a0million per episode , remaining one of the highest rated programmes in the UK. Since \"EastEnders\" began airing in 1985 on the BBC, the two programmes have constantly battled it out for first place in the ratings.\n\"Coronation Street\" rates as one of the most watched programmes on UK television for every day it is aired. The episode that aired on 2 January 1985, where Bet Lynch (Julie Goodyear) finds out she has got the job as manager of the Rovers Return, is the highest-rated single episode in the show's history, attracting 21.40 million viewers. 25 December 1987 episode, where Hilda Ogden (Jean Alexander) leaves the street to start a new life as a housekeeper for long-term employer Dr Lowther, attracted a combined audience of 26.65 million for its original airing and omnibus repeat on 27 December 1987. This is the second-highest combined rating in the show's history. The show attracted its highest-ever combined rating of 26.93 million for the episode that aired on 15 (and 19) March 1989, where Rita Fairclough (Barbara Knox) is in hospital and Alan Bradley (Mark Eden) is hiding from the police after trying to kill Rita in the previous episode.\nSets.\nThe regular exterior buildings shown in \"Coronation Street\" include a row of terrace houses, several townhouses, and communal areas including a newsagents (\"The Kabin\"), a caf\u00e9 (\"Roy's Rolls\"), a general grocery shop (\"D&amp;S Alahan's\"), a factory (\"Underworld\") and \"Rovers Return Inn\" public house. The Rovers Return Inn is the main meeting place for the show's characters.\nBetween 1960 and 1968, street scenes were filmed before a set constructed in a studio, with the house fronts reduced in scale to 3/4 and constructed from wood. In 1968 Granada built an outside set not all that different from the interior version previously used, with the wooden fa\u00e7ades from the studio simply being erected on the new site. These were replaced with brick fa\u00e7ades, and back yards were added in the 1970s.\nIn 1982, a permanent full-street set was built in the Granada backlot, an area between Quay Street and Liverpool Road in Manchester. The set was constructed from reclaimed Salford brick. The set was updated in 1989 with the construction of a new factory, two shop units and three modern town houses on the south side of the street.\nBetween 1989 and 1999, the Granada Studios Tour allowed members of the public to visit the set. The exterior set was extended and updated in 1999. This update added to the Rosamund Street and Victoria Street fa\u00e7ades, and added a viaduct on Rosamund Street. Most interior scenes are shot in the adjoining purpose-built studio.\nIn 2008, \"Victoria Court\", an apartment building full of luxury flats, was started on Victoria Street.\nIn 2014, production moved to a new site at Trafford Wharf, a former dock area about two miles to the east, part of the MediaCityUK complex. The Trafford Wharf backlot is built upon a former truck stop site next to the Imperial War Museum North. It took two years from start to finish to recreate the iconic Street. The houses were built to almost full scale after previously being three-quarter size.\nOn 5 April 2014, the staff began to allow booked public visits to the old Quay Street set. An advert, with a voiceover from Victoria Wood, appeared on TV to advertise the tour. The tour was discontinued in December 2015.\nOn 12 March 2018, the extension of the \" Victoria Street\" set was officially unveiled. The new set features a garden, featuring a memorial bench paying tribute to the 22 victims of the Manchester Arena bombing, including \"Coronation Street\" super fan Martyn Hett. The precinct includes a Greater Manchester Police station called \"Weatherfield Police station\". As part of a product placement deal between three companies and ITV Studios, new additions include a Tram stop station which is named \"Weatherfield North\" with \"Transport for Greater Manchester\" \"Metrolink\" branding, and shop front facades of Costa Coffee and the Weatherfield branded Co-op Food store interior scenes have been screened and exterior scenes at the new set first aired on 20 April 2018.\nOn 20 April 2018, ITV announced that they had been granted official approval of planning permission to allow booked public visits to the MediaCityUK Trafford Wharf set. Tours commenced on weekends from 26 May 2018 onwards.\nBroadcast.\nUnited Kingdom.\nFor 60 years, \"Coronation Street\" has remained at the centre of ITV's prime time schedule. The programme is usually shown in the UK in six episodes, over three evenings a week on ITV. Additional episodes have been broadcast at other times, such as between 22 and 26 November 2004, when eight episodes were shown. Occasional late night episodes of \"Coronation Street\" begin at 10\u00a0pm, due to the watershed.\nFrom Friday 9 December 1960 until Friday 3 March 1961, the programme was shown in two episodes broadcast Wednesday and Friday at 7\u00a0pm. Schedules were changed and from Monday 6 March 1961 until Wednesday 11 October 1989, the programme was shown in two episodes broadcast Monday and Wednesday at 7:30\u00a0pm. A third weekly episode was introduced on Friday 20 October 1989, broadcast at 7:30\u00a0pm. From 1996, an extra episode was broadcast at 7:30\u00a0pm on Sunday nights.\nAside from Granada, the programme originally appeared on the following stations of the ITV network: Anglia Television, Associated-Rediffusion, Television Wales and the West, Scottish Television, Southern Television and Ulster Television. From episode 14 on Wednesday 25 January 1961, Tyne Tees Television broadcast the programme. That left ATV in the Midlands as the only ITV station not carrying the show. When they decided to broadcast the programme, national transmission was changed from Wednesday and Friday at 7\u00a0pm to Monday and Wednesday at 7:30\u00a0pm and the programme became fully networked under this new arrangement from episode 25 on Monday 6 March 1961.\nAs the ITV network grew over the next few years, the programme was transmitted by these new stations on these dates onward: Westward Television from episode 40 on 1 May 1961, Border Television from episode 76 on 4 September 1961, Grampian Television from episode 84 on 2 October 1961, Channel Television from episode 180 on 3 September 1962 and Teledu Cymru (north and west Wales) from episode 184 on 17 September 1962. At this point, the ITV network became complete and the programme was broadcast almost continuously across the country at 7:30\u00a0pm on Monday and Wednesday for the next twenty-eight years.\nFrom episode 2981 on Friday 20 October 1989 at 7:30\u00a0pm, a third weekly episode was introduced and this increased to four episodes a week from episode 4096 on Sunday 24 November 1996, again at 7:30\u00a0pm. A second Monday episode was introduced in 2002 and was broadcast at 7:30\u00a0pm to usher in the return of Bet Lynch. The Monday 8:30\u00a0pm episode was used intermittently during the popular Richard Hillman storyline and became a regular feature from episode 5568 on Monday 25 August 2003.\nIn January 2008, ITV axed the Sunday episode and instead aired a second episode on Fridays, at 8:30\u00a0pm, with the final Sunday episode airing on 6 January 2008. From 23 July 2009 to September 2012 the Wednesday show was replaced with an episode at 8:30\u00a0pm on Thursdays. A sixth weekly episode was added on Wednesdays at 8:30\u00a0pm from 20 September 2017.\nIn March 2020, it was revealed that episodes that were currently filming for future broadcast (as episodes are filmed a few weeks in advance) during the COVID-19 pandemic would be shown differently. Instead of six episodes a week, only three episodes would be broadcast, airing as normal on a Monday, Wednesday and Friday at the normal timeslot of 7:30\u00a0pm. The actions provided would be made effective starting from 30 March. Simultaneously, the announcement also mentioned that the elderly cast of the show would be \"written off\" due to health advice issued by Public Health England and the NHS. On 22 March, ITV released a statement confirming that filming of both \"Coronation Street\" and \"Emmerdale\" was suspended.\nIn June 2020 ITV announced that filming will resume on 9 June. However, due to the new health and safety measures, cast members over the age of 70 or with underlying health conditions did not come back on set, until the production could determine it is safe for them to return.\nIn July 2020 ITV announced Coronation Street would return to the normal output of six episodes a week in September 2020.\nIn October 2020 Maureen Lipman and David Neilson made their first appearances since July as all cast members over the age of 70 had temporarily left the series earlier in the year. William Roache, Barbara Knox and Sue Nicholls returned in December.\nOn 22 January 2021, ITV announced that filming would be suspended from 25 January in order to rewrite \"stories and scripts as a consequence of the coronavirus pandemic\" and to \"review all health and safety requirements\". ITV also confirmed that this decision would not affect their ability to deliver six episodes a week.\nRepeats and classic episodes.\nRepeat episodes, omnibus broadcasts and specials have been shown on various ITV channels. After several years on ITV2, in January 2008 the omnibus returned to the main ITV channel where it was aired on Saturday mornings/afternoons depending on the schedule and times. In May 2008 it moved to Sunday mornings until August 2008 when it returned to Saturdays. In January 2009 it moved back to Sunday mornings usually broadcasting at around 9.25am until December 2010. In January 2011 the omnibus moved to Saturday mornings on ITV at 9.25am. During the Rugby World Cup, which took place in New Zealand, matches had to be broadcast on a Saturday morning, so the omnibus moved to Saturday lunchtimes/afternoons during September and October 2011. On 22 October 2011 the omnibus moved back to Saturday mornings at 9.25am on ITV. In January 2012 the omnibus moved to ITV2 and then moved to ITV3 in January 2020.\nOlder episodes were broadcast by satellite and cable channel Granada Plus from its launch in 1996. The first episodes shown were from episode 1588 (originally transmitted on Monday 5 April 1976) onwards. Originally listed and promoted as \"Classic Coronation Street\", the \"classic\" was dropped in early 2002, at which stage the episodes were from late 1989. By the time of the channel's closure in 2004, the repeats had reached February 1994.\nIn addition to this, \"specials\" were broadcast on Saturday afternoons in the early years of the channel with several episodes based on a particular theme or character(s) were shown. The latest episode shown in these specials was from 1991. In addition, on 27 and 28 December 2003, several Christmas Day editions of the show were broadcast.\nITV3 began airing afternoon timeslot sequential reruns of \"Classic Coronation Street\" from 2 October 2017. Two classic episodes were retransmitted from Mondays to Fridays at 2:40\u00a0pm until 3:45\u00a0pm, starting from episode 2587 (originally transmitted on Wednesday 15 January 1986) onwards.\nTo mark the 60th Anniversary of \"Coronation Street\" between 7 and 11 December 2020 at 10:00pm\u201311:05pm ITV3 aired special episodes of the soap including: \"Episode 1 (Coronation Street)\", the tenth anniversary episode from December 1970, two episodes from the twentieth anniversary in December 1980, two episodes from the thirtieth anniversary in December 1990, the \"Coronation Street Live (2000 episode)\" from the fortieth anniversary in December 2000, and the fiftieth anniversary episode \"Coronation Street Live (2010 episode)\" which aired after a repeat of \"The Road to Coronation Street\".\nInternational.\n\"Coronation Street\" is shown in various countries worldwide. YouTube has the first episode and many others available as reruns.\nThe programme was first aired in Australia in 1963 on TCN-9 Sydney, GTV-9 Melbourne and NWS-9 Adelaide, and by 1966 \"Coronation Street\" was more popular in Australia than in the UK. The show eventually left free-to-air television in Australia in the 1970s. It briefly returned to the Nine Network in a daytime slot during 1994\u20131995. In 2005 STW-9 Perth began to show episodes before the 6\u00a0pm news to improve the lead in to Nine News Perth, but this did not work and the show was cancelled a few months later. In 1996, pay-TV began and Arena began screening the series in one-hour instalments on Saturdays and Sundays at 6:30\u00a0pm EST. The series was later moved to pay-TV channel UKTV (now BBC UKTV) where it is still shown. \"Coronation Street\" is shown Mon-Thu at 7:20\u00a0pm EST and a double episode on Fridays, with episodes on the channel being one week behind UK broadcast.\nIn Canada, \"Coronation Street\" is broadcast on CBC Television. Until 2011, episodes were shown in Canada approximately 10 months after they aired in Britain; however, beginning in the fall of 2011, the CBC began showing two episodes every weekday, in order to catch up with the ITV showings, at 6:30\u00a0pm and 7\u00a0pm local time Monday-Friday, with an omnibus on Sundays at 7.30am. By May 2014, the CBC was only two weeks behind Britain, so the show was reduced to a single showing weeknights at 6:30\u00a0pm local time. The show debuted on Toronto's CBLT in July 1966. The 2002 edition of the \"Guinness Book of Records\" recognises the 1,144 episodes sold to the now-defunct CBC-owned Saskatoon, Saskatchewan, TV station CBKST by Granada TV on 31 May 1971 to be the largest number of TV shows ever purchased in one transaction. The show traditionally aired on weekday afternoons in Canada, with a Sunday morning omnibus. In 2004, CBC moved the weekday airings from their daytime slot to prime time. In light of austerity measures imposed on the CBC in 2012, which includes further cutbacks on non-Canadian programming, one of the foreign shows to remain on the CBC schedule is \"Coronation Street\", according to the CBC's director of content planning Christine Wilson, who commented: \"Unofficially I can tell you \"Coronation Street\" is coming back. If it didn't come back, something would happen on Parliament Hill.\" Kirstine Stewart, the head of the CBC's English-language division, once remarked: \"\"Coronation Street\" fans are the most loyal, except maybe for curling viewers, of all CBC viewers.\" As of mid 2020, Canada is about two weeks behind the UK and airs four episodes per week.\nIn the Republic of Ireland, \"Coronation Street\" is currently shown on Virgin Media One. The show was first aired in 1978, when RT\u00c92 began showing episodes from 1976, although Ireland caught up with the current UK episodes in 1983. In 1992 it moved to RT\u00c9 One, but in 2001 Granada TV bought 45 percent of TV3, and so TV3 broadcast the series from 2001 to 2014. In 2006, ITV sold its share of the channel but TV3 continued to buy the soap until the end of 2014 when it moved to UTV Ireland. Coronation Street has broadcast on each of the main Irish networks, except for the Irish language network TG4. In December 2016, \"Coronation Street\" returned to TV3 (now Virgin Media One). The show is consistently the channels most viewed programme every week.\nTwo Dutch stations have broadcast \"Coronation Street\": VARA showed 428 episodes between 1967 and 1975, and SBS6 ran the show for a period starting in 2010. From 2006 the series was also broadcast by Vitaya, a small Flemish Belgian channel.\nIn New Zealand, \"Coronation Street\" has been shown locally since 1964, first on NZBC television until 1975, and then on TV One, which broadcasts it in a 4-episode/2-hour block on Fridays from 7:30\u00a0pm. Since September 2014, TV One has added a 2-episode/1-hour block on Saturday from 8:30\u00a0pm. Because TV One has never upgraded to showing the equivalent of five or six episodes per week, New Zealand continues to fall further and further behind with episodes, and is 23 months behind Britain (as of 28 March 2014). During the weekday nights of the week ending 11 April 2014 and previous weeks, Coronation Street was the least watched programme on TV One in the 7:30\u00a0pm slot by a considerable margin in comparison to other weeknights, The serial aired on Tuesdays and Thursdays at 7:30\u00a0pm until October 2011, when the show moved to a 5:30\u00a0pm half-hour slot every weekday. The move proved unpopular with fans, and the series was quickly moved into its present prime-time slot within weeks. Episodes 7883, 7884, 7885 and 7886 were screened on 16 May 2014. These were originally aired in the UK between 4 and 11 June 2012. On 10 May 2018 it was announced that the current 2016 episodes would be moved to 1 p.m. Monday-Friday titled 'Catch-up Episodes' and for primetime Wednesday-Friday express episodes would be airing in New Zealand a week behind The United Kingdom titled '2018 Episodes' these changes would be taking place from 11 June 2018.\nIn South Africa, \"Coronation Street\" episodes were broadcast three days after the UK air date on ITV Choice until the channel ceased broadcasting in June 2020, episodes temporarily went off the air until they moved to M-Net City starting October 2020.\nIn the United States, \"Coronation Street\" is available by broadcast or cable only in northern markets where CBC coverage from Canada overlaps the border or is available on local cable systems. It was broadcast on CBC's US cable channel, Trio until the CBC sold its stake in the channel to Universal, before it was shut down in 2006. Beginning in 2009, episodes were available in the United States through Amazon.com's on-demand service, one month behind their original UK airdates. The final series of shows available from Amazon appears to be from November 2012, as no new episodes have been uploaded. On 15 January 2013, online distributor Hulu began airing episodes of the show, posting a new episode daily, two weeks after their original airdates. For a time, Hulu's website stated: \"New episodes of \"Coronation Street\" will be unavailable as of April 7th, 2016\", with the same being said for British soap \"Hollyoaks\", but Hulu is once again showing new episodes of \"Coronation Street\" as of April 2017, two weeks behind the UK airdate. The BBC/ITV service Britbox shows new episodes on the same day as the UK airing. \"Coronation Street\" was also shown on USA Network for an unknown period starting in 1982.\nHM Forces and their families stationed overseas can watch \"Coronation Street\" on ITV, carried by the British Forces Broadcasting Service, which is also available to civilians in the Falkland Islands. It used to be shown on BFBS1.\nSatellite channel ITV Choice showed the programme in Asia, Middle East, Cyprus, and Malta, before the channel ceased broadcasting in 2019.\nMerchandise.\n\"The Street\", a magazine dedicated to the show, was launched in 1989. Edited by Bill Hill, the magazine contained a summary of recent storylines, interviews, articles about classic episodes, and stories that occurred from before 1960. The format was initially A5 size, expanding to A4 from the seventh issue. The magazine folded after issue 23 in 1993 when the publisher's contract with Granada Studios Tour expired and Granada wanted to produce their own magazine.\nOn 25 June 2010, a video game of the show was released on Nintendo DS. The game was developed by Mindscape, and allowed players to complete tasks in the fictitious town of Weatherfield.\nDiscography.\nIn 1995, to commemorate the programme's 35th anniversary, a CD titled \"The Coronation Street Album\" was released, featuring cover versions of modern songs and standards by contemporary cast members.\nThe album charted a Top 40 hit when \"The Coronation Street Single\" (a double a-side featuring a cover of Monty Python's \"Always Look on the Bright Side of Life\" by Bill Waddington - with various cast members on backing vocals - on one side and \"Something Stupid\" by Johnny Briggs &amp; Amanda Barrie on the other) reached number 35 in the Official UK charts.\nIn 2010, an album featuring songs sung by cast members was released to celebrate 50 years of \"Coronation Street\". The album is titled \"Rogues, Angels, Heroes &amp; Fools\", and was later developed into a musical.\nSpin-offs.\nTelevision.\nGranada launched one spin-off in 1965, \"Pardon the Expression\", following the story of clothing store manager Leonard Swindley (Arthur Lowe) after he left Weatherfield. Swindley's management experience was tested when he was appointed assistant manager at a fictional department store, Dobson and Hawks. Granada produced two series of the spin-off, which ended in 1966.\nIn 1967, Arthur Lowe returned as Leonard Swindley in \"Turn Out the Lights\", a short-lived sequel to \"Pardon the Expression\". It ran for just one series of six episodes before it was cancelled.\nFrom 1985 to 1988 Granada TV produced a sitcom called \"The Brothers McGregor\" featuring a pair of half-brothers (one black, one white) who had appeared in a single episode of \"Coronation Street\" as old friends of Eddie Yeats and guests at his wedding. The original actors were unavailable so the characters were recast with Paul Barber and Philip Whitchurch. The show ran for 26 episodes over four series.\nIn 1985, a sister series, \"Albion Market\" was launched. It ran for one year, with 100 episodes produced.\nCrossovers.\nIn 2010, several actors from the show appeared on \"The Jeremy Kyle Show\" as their soap characters: David Platt (Jack P. Shepherd), Nick Tilsley (Ben Price) and Tina McIntyre (Michelle Keegan). In the fictional, semi-improvised scenario, David accused Nick (his brother) and Tina (his ex-girlfriend) of sleeping together.\n\"Coronation Street\" and rival soap opera \"EastEnders\" had a crossover for \"Children in Need\" in November 2010 called \"East Street\". \"EastEnders\" stars that visited Weatherfield include Laurie Brett as Jane Beale, Charlie G. Hawkins as Darren Miller, Kylie Babbington as Jodie Gold, Nina Wadia as Zainab Masood and John Partridge as Christian Clarke.\nOn 21 December 2012, \"Coronation Street\" produced a Text Santa special entitled \"A Christmas Corrie\" which featured Norris Cole in the style of Scrooge, being visited by the ghosts of dead characters. The ghosts were Mike Baldwin, Maxine Peacock, Derek Wilton and Vera Duckworth. Other special guests include Torvill and Dean, Lorraine Kelly and Sheila Reid. The episode concluded with Norris learning the error of his ways and dancing on the cobbles. The original plan for this feature was to have included Jack Duckworth, along with Vera, but actor Bill Tarmey died before filming commenced. In the end a recording of his voice was played.\nDocumentaries.\n\"Coronation Street: Family Album\" was several documentaries about various families living on the street.\n\"Farewell\u00a0...\" was several documentaries featuring the best moments of a single character who had recently left the series\u2014most notably, Farewell Mike (Baldwin), Farewell Vera (Duckworth), Farewell Blanche (Hunt), Farewell Jack (Duckworth), Farewell Janice (Battersby), Farewell Liz (McDonald), Farewell Becky (McDonald), and Farewell Tina (McIntyre). Most of these were broadcast on the same day as the character's final scenes in the series.\n\"Stars on the Street\" was aired around Christmas 2009. It featured actors from the soap talking about the famous guest stars who had appeared in the series including people who were in it before they were famous.\nIn December 2010, ITV made a few special programmes to mark the 50th anniversary. \"Coronation Street Uncovered: Live\", hosted by Stephen Mulhern was shown after the episode with the tram crash was aired on ITV 2. On 7 and 9 December a countdown on the greatest Corrie moments, \"Coronation Street: 50 Years, 50 Moments\", the viewers voted \"The Barlows at Alcoholics Anonymous\" as the greatest moment. On 10 December Paul O'Grady hosted a quiz show, \"Coronation Street: The Big 50\" with three teams from the soap and a celebrity team answering questions about Coronation Street and other soaps. Also, \"Come Dine with Me\" and \"Celebrity Juice\" aired Coronation Street specials in the anniversary week.\nInternational adaptation.\nThe German TV series \"Lindenstra\u00dfe\" took \"Coronation Street\" as the model. \"Lindenstra\u00dfe\" started in 1985 and broadcast its final episode on 29 March 2020, after airing for nearly 35 years.\nFilms.\nOver the years \"Coronation Street\" has released several straight-to-video films. Unlike other soaps which often used straight-to-video films to cover more contentious plot lines that may not be allowed by the broadcaster, \"Coronation Street\" has largely used these films to reset their characters in other locations.\nIn 1995, \"Coronation Street: The Cruise\" also known as \"Coronation Street: The Feature Length Special\" was released on VHS to celebrate the 35th anniversary of the show, featuring Rita Sullivan, Mavis Wilton, Alec Gilroy, Curly Watts and Raquel Watts. ITV heavily promoted the programme as a direct-to-video exclusive but broadcast a brief version of it on 24 March 1996. The Independent Television Commission investigated the broadcast, as viewers complained that ITV misled them.\nIn 1997, following the controversial cruise spin-off, \"Coronation Street: Viva Las Vegas!\" was released on VHS, featuring Vera Duckworth, Jack Duckworth, Fiona Middleton and Maxine Peacock on a trip to Las Vegas, which included the temporary return of Ray Langton.\nIn 1999, six special episodes of \"Coronation Street\" were produced, following the story of Steve McDonald and Vikram Desai in Brighton, which included the temporary returns of, Bet Gilroy, Reg Holdsworth and Vicky McDonald. This video was titled \"Coronation Street: Open All Hours\" and released on VHS.\nIn 2008, ITV announced filming was to get underway for a new special DVD episode, \", featuring Kirk Sutherland, Fiz Brown, Chesney Brown, which included the temporary return of Cilla Battersby-Brown. Sophie Webster, Becky Granger and Tina McIntyre also make brief appearances.\nIn 2009, another DVD special, \", was released. The feature-length comedy drama followed Roy, Hayley and Becky as they travelled to Romania for the wedding of a face from their past. Eddie Windass also briefly appears.\nThe BBC commissioned a one-off drama called \"The Road to Coronation Street\", about how the series first came into being. Jessie Wallace plays Pat Phoenix (Elsie Tanner) with Lynda Baron as Violet Carson (Ena Sharples), Celia Imrie as Doris Speed (Annie Walker) and James Roache as his own father William Roache (Ken Barlow). It was broadcast on 16 September 2010 on BBC Four.\nOn 1 November 2010, \"Coronation Street: A Knight's Tale\" was released. Reg Holdsworth and Curly Watts returned in the film. Mary tries to take Norris to an apparently haunted castle where she hoped to seduce him. Rosie gets a job there and she takes Jason with her. Brian Capron also guest starred as an assumed relative of Richard Hillman. He rises out of a lake with a comedic \"wink to the audience\" after Hillman drowned in 2003. Rita Sullivan also briefly appears.\nOnline.\nOn 21 December 2008, a web-based miniseries ran on ITV.com; called \"Corrie Confidential\"; the first episode featured the characters Rosie and Sophie Webster in \"Underworld\".\nITV.com launched a small spin-off drama series called 'Gary's Army Diaries' which revolves around Gary Windass's experiences in Afghanistan and the loss of his best friend, Quinny. Due to their popularity, the three five-minute episodes were recut into a single 30-minute episode, which was broadcast on ITV2.\nWilliam Roache and Anne Kirkbride starred as Ken and Deirdre in a series of ten three-minute internet 'webisodes'. The first episode of the series titled, \"Ken and Deirdre's Bedtime Stories\" was activated on Valentine's Day 2011.\nIn 2011, an internet based spin-off starring Helen Flanagan as Rosie Webster followed her on her quest to be a supermodel called \"Just Rosie\".\nOn 3 February 2014, another web-based miniseries ran on ITV.com; called \"Streetcar Stories\". It showed what Steve and Lloyd get up to during the late nights in their Streetcar cab office. The first episode shows Steve and Lloyd making a cup of tea with \"The Stripper\" playing in the background, referencing Morecambe and Wise's Breakfast Sketch. The second episode involves the pair having a biscuit dunking competition.\nDuring the 'Who Attacked Ken' storyline, a mini series of police files was run on the official Coronation Street YouTube channel. They outlined the suspects' details and possible motives.\nStage.\nIn August 2010, many \"Coronation Street\" characters were brought to the stage in Jonathan Harvey's comedy play \"Corrie!\". The play was commissioned to celebrate the 50th Anniversary of the TV series and was presented at The Lowry in Salford, England by ITV Studios and Phil McIntyre Entertainments. Featuring a cast of six actors who alternate roles of favourite characters including Ena Sharples, Hilda Ogden, Hayley and Roy, Richard Hillman, Jack and Vera, Bet Lynch, Steve, Karen and Becky, the play weaves together some of the most memorable moments from the TV show. It toured UK theatres between February 2011 and July 2011 with guest star narrators including Roy Barraclough, Ken Morley and Gaynor Faye.\nIn popular culture.\nThe British rock band Queen produced a single \"I Want to Break Free\" in 1984 which reached number 3 position in UK charts and which is largely known for its music video for which all the band members dressed in women's clothes, which parodied the characters and is considered an homage to the show. The video depicts Freddie Mercury as a housewife, loosely based on Bet Lynch, who wants to \"break free\" from his life. Although Lynch was a blonde in the soap opera, Mercury thought he would look too silly as a blonde and chose a dark wig. Guitarist Brian May plays another, more relaxed housewife based on Hilda Ogden.\nAs an April Fools' Day joke in 2019, TheJournal.ie claimed that Leader of the Opposition and Labour Jeremy Corbyn had made an attempt to appear in an episode of \"Coronation Street\" in response to Prime Minister Theresa May's supposed appearance in a special live episode, where she was to issue a final plea for unity on Brexit. In the joke, Corbyn's plan had not come to fruition, with members of \"Coronation Street\"'s crew deeming his request inappropriate in light of the devastation already wreaked upon the soap opera's characters following its most recent knicker factory tragedy.\nSponsorship.\nCadbury was the first sponsor of \"Coronation Street\" beginning in July 1996. In the summer of 2006, Cadbury Trebor Bassetts had to recall over one million chocolate bars, due to suspected salmonella contamination, and \"Coronation Street\" stopped the sponsorship for several months. In 2006, Cadbury did not renew their contract, but agreed to sponsor the show until \"Coronation Street\" found a new sponsor.\nHarveys then sponsored \"Coronation Street\" from 30 September 2007 until December 2012. In the \"Coronation Street: Romanian Holiday\" film, Roy and Hayley Cropper are filmed in front of a Harveys store, and in \"Coronation Street: A Knights Tale\", a Harveys truck can be seen driving past Mary Taylor's motorhome. Compare The Market took over as sponsor from 26 November 2012 until 30 November 2020. On 10 December 2020, it was announced that Argos would be the new sponsor of \"Coronation Street\", starting on 1 January 2021.\nIn November 2011, a Nationwide Building Society ATM in Dev Alahan's corner shop became the first use of paid-for product placement in a UK primetime show. In 2018, the shop fronts of Co-Op and Costa Coffee were added to the sets, along with characters using shopping bags with the respective logos on as props.\nHyundai have been the sponsor since January 2015 in the Republic of Ireland, aired on Virgin Media One.\nAwards and nominations.\n\"Coronation Street\" is the second most award-winning British soap opera in the UK, behind rival soap \"EastEnders\" and just ahead of \"Emmerdale\"."}
{"id": "6852", "revid": "39999250", "url": "https://en.wikipedia.org/wiki?curid=6852", "title": "Caligula", "text": "Caligula (; 31 August 12 \u2013 24 January 41 AD), formally known as Gaius (Gaius Caesar Augustus Germanicus), was the third Roman emperor, ruling from 37 to 41. The son of the popular Roman general Germanicus and Augustus's granddaughter Agrippina the Elder, Caligula was born into the first ruling family of the Roman Empire, conventionally known as the Julio-Claudian dynasty.\nGermanicus's uncle and adoptive father, Tiberius, succeeded Augustus as emperor of Rome in AD14. Although Gaius was named after Gaius Julius Caesar, he acquired the nickname \"Caligula\" (meaning \"little [soldier's] boot\") from his father's soldiers during their campaign in Germania. When Germanicus died at Antioch in 19, Agrippina returned with her six children to Rome, where she became entangled in a bitter feud with Tiberius. The conflict eventually led to the destruction of her family, with Caligula as the sole male survivor. Untouched by the deadly intrigues, Caligula accepted an invitation in 31 to join the emperor on the island of Capri, where Tiberius had withdrawn five years earlier. Following the death of Tiberius, Caligula succeeded his adoptive grandfather as emperor in 37.\nThere are few surviving sources about the reign of Caligula, though he is described as a noble and moderate emperor during the first six months of his rule. After this, the sources focus upon his cruelty, sadism, extravagance, and sexual perversion, presenting him as an insane tyrant. While the reliability of these sources is questionable, it is known that during his brief reign, Caligula worked to increase the unconstrained personal power of the emperor, as opposed to countervailing powers within the principate. He directed much of his attention to ambitious construction projects and luxurious dwellings for himself, and initiated the construction of two aqueducts in Rome: the Aqua Claudia and the Anio Novus. During his reign, the empire annexed the client kingdom of Mauretania as a province.\nIn early 41, Caligula was assassinated as a result of a conspiracy by officers of the Praetorian Guard, senators, and courtiers. The conspirators' attempt to use the opportunity to restore the Roman Republic was thwarted, however. On the day of the assassination of Caligula, the Praetorians declared Caligula's uncle, Claudius, the next Roman emperor. Although the Julio-Claudian dynasty continued to rule the empire until the fall of his nephew Nero in 68, Caligula's death marked the official end of the Julii Caesares in the male line.\nEarly life.\nGaius Julius Caesar (named in honour of his famous relative) was born in Antium (modern Anzio and Nettuno) on 31 August 12 AD, the third of six surviving children born to Germanicus and his second cousin Agrippina the Elder, who was the daughter of Marcus Vipsanius Agrippa and Julia the Elder; making her the granddaughter of Augustus. Gaius had two older brothers, Nero and Drusus, as well as three younger sisters, Agrippina the Younger, Julia Drusilla and Julia Livilla. He was also a nephew of Claudius, Germanicus' younger brother and the future emperor.\nAs a boy of just two or three, Gaius accompanied his father, Germanicus, on campaigns in the north of Germania. The soldiers were amused that Gaius was dressed in a miniature soldier's outfit, including boots and armour. He was soon given an affectionate nickname, \"Caligula\", meaning \"little (soldier's) boot\" in Latin, after the small boots (caligae) he wore. Gaius, though, reportedly grew to dislike this nickname.\nSuetonius claims that Germanicus was poisoned in Syria by an agent of Tiberius, who viewed Germanicus as a political rival. After the death of his father, Caligula lived with his mother until her relations with Tiberius deteriorated. Tiberius would not allow Agrippina to remarry for fear her husband would be a rival. Agrippina and Caligula's brother, Nero, were banished in 29 on charges of treason.\nThe adolescent Caligula was then sent to live with his great-grandmother (and Tiberius's mother), Livia. After her death, he was sent to live with his grandmother Antonia Minor. In 30, his brother Drusus was imprisoned on charges of treason and his brother Nero died in exile from either starvation or suicide. Suetonius writes that after the banishment of his mother and brothers, Caligula and his sisters were nothing more than prisoners of Tiberius under the close watch of soldiers.\nIn 31, Caligula was remanded to the personal care of Tiberius on Capri, where he lived for six years. To the surprise of many, Caligula was spared by Tiberius. According to historians, Caligula was an excellent natural actor and, recognizing danger, hid all his resentment towards Tiberius. An observer said of Caligula, \"Never was there a better servant or a worse master!\"\nCaligula claimed to have planned to kill Tiberius with a dagger to avenge his mother and brother: however, having brought the weapon into Tiberius's bedroom he did not kill the Emperor but instead threw the dagger down on the floor. Supposedly Tiberius knew of this but never dared to do anything about it. Suetonius claims that Caligula was already cruel and vicious: he writes that, when Tiberius brought Caligula to Capri, his purpose was to allow Caligula to live in order that he \"prove the ruin of himself and of all men, and that he was rearing a viper for the Roman people and a Phaethon for the world.\"\nIn 33, Tiberius gave Caligula an honorary quaestorship, a position he held until his rise to emperor. Meanwhile, both Caligula's mother and his brother Drusus died in prison. Caligula was briefly married to Junia Claudilla in 33, though she died in childbirth the following year. Caligula spent time befriending the Praetorian prefect, Naevius Sutorius Macro, an important ally. Macro spoke well of Caligula to Tiberius, attempting to quell any ill will or suspicion the Emperor felt towards Caligula.\nIn 35, Caligula was named joint heir to Tiberius's estate along with Tiberius Gemellus.\nEmperor.\nEarly reign.\nWhen Tiberius died on 16 March 37 AD, his estate and the titles of the principate were left to Caligula and Tiberius's own grandson, Gemellus, who were to serve as joint heirs. Although Tiberius was 77 and on his death bed, some ancient historians still conjecture that he was murdered. Tacitus writes that Macro smothered Tiberius with a pillow to hasten Caligula's accession, much to the joy of the Roman people, while Suetonius writes that Caligula may have carried out the killing, though this is not recorded by any other ancient historian. Seneca the Elder and Philo, who both wrote during Tiberius's reign, as well as Josephus, record Tiberius as dying a natural death. Backed by Macro, Caligula had Tiberius's will nullified with regard to Gemellus on grounds of insanity, but otherwise carried out Tiberius's wishes.\nCaligula accepted the powers of the principate as conferred by the Senate and entered Rome on 28 March amid a crowd that hailed him as \"our baby\" and \"our star\", among other nicknames. Caligula is described as the first emperor who was admired by everyone in \"all the world, from the rising to the setting sun.\" Caligula was loved by many for being the beloved son of the popular Germanicus, and because he was not Tiberius. Suetonius said that over 160,000 animals were sacrificed during three months of public rejoicing to usher in the new reign. Philo describes the first seven months of Caligula's reign as completely blissful.\nCaligula's first acts were said to be generous in spirit, though many were political in nature. To gain support, he granted bonuses to the military, including the Praetorian Guard, city troops and the army outside Italy. He destroyed Tiberius's treason papers, declared that treason trials were a thing of the past, and recalled those who had been sent into exile. He helped those who had been harmed by the imperial tax system, banished certain sexual deviants, and put on lavish spectacles for the public, including gladiatorial games. Caligula collected and brought back the bones of his mother and of his brothers and deposited their remains in the tomb of Augustus.\nIn October 37, Caligula fell seriously ill, or perhaps was poisoned. He soon recovered from his illness, but many believed that the illness turned the young emperor toward the diabolical: he started to kill off or exile those who were close to him or whom he saw as a serious threat. Perhaps his illness reminded him of his mortality and of the desire of others to advance into his place. He had his cousin and adopted son Tiberius Gemellus executed \u2013 an act that outraged Caligula's and Gemellus's mutual grandmother Antonia Minor. She is said to have committed suicide, although Suetonius hints that Caligula actually poisoned her. He had his father-in-law Marcus Junius Silanus and his brother-in-law Marcus Lepidus executed as well. His uncle Claudius was spared only because Caligula preferred to keep him as a laughing stock. His favourite sister, Julia Drusilla, died in 38 of a fever: his other two sisters, Livilla and Agrippina the Younger, were exiled. He hated being the grandson of Agrippa and slandered Augustus by repeating a falsehood that his mother was actually conceived as the result of an incestuous relationship between Augustus and his daughter Julia the Elder.\nPublic reform.\nIn 38, Caligula focused his attention on political and public reform. He published the accounts of public funds, which had not been made public during the reign of Tiberius. He aided those who lost property in fires, abolished certain taxes, and gave out prizes to the public at gymnastic events. He allowed new members into the equestrian and senatorial orders.\nPerhaps most significantly, he restored the practice of elections. Cassius Dio said that this act \"though delighting the rabble, grieved the sensible, who stopped to reflect, that if the offices should fall once more into the hands of the many\u00a0... many disasters would result\".\nDuring the same year, though, Caligula was criticized for executing people without full trials and for forcing the Praetorian prefect, Macro, to commit suicide. Macro had fallen out of favor with the emperor, probably due to an attempt to ally himself with Gemellus when it appeared that Caligula might die of fever.\nFinancial crisis and famine.\nAccording to Cassius Dio, a financial crisis emerged in 39. Suetonius places the beginning of this crisis in 38. Caligula's political payments for support, generosity and extravagance had exhausted the state's treasury. Ancient historians state that Caligula began falsely accusing, fining and even killing individuals for the purpose of seizing their estates.\nHistorians describe a number of Caligula's other desperate measures. To gain funds, Caligula asked the public to lend the state money. He levied taxes on lawsuits, weddings and prostitution. Caligula began auctioning the lives of the gladiators at shows. Wills that left items to Tiberius were reinterpreted to leave the items instead to Caligula. Centurions who had acquired property by plunder were forced to turn over spoils to the state.\nThe current and past highway commissioners were accused of incompetence and embezzlement and forced to repay money. According to Suetonius, in the first year of Caligula's reign he squandered 2.7\u00a0billion sesterces that Tiberius had amassed. His nephew Nero both envied and admired the fact that Gaius had run through the vast wealth Tiberius had left him in so short a time.\nHowever, some historians have shown scepticism towards the large number of sesterces quoted by Suetonius and Dio. According to Wilkinson, Caligula's use of precious metals to mint coins throughout his principate indicates that the treasury most likely never fell into bankruptcy. He does point out, however, that it is difficult to ascertain whether the purported 'squandered wealth' was from the treasury alone due to the blurring of \"the division between the private wealth of the emperor and his income as head of state.\" Furthermore, Alston points out that Caligula's successor, Claudius, was able to donate 15,000 sesterces to each member of the praetorian guard in 41, suggesting the Roman treasury was solvent.\nA brief famine of unknown extent occurred, perhaps caused by this financial crisis, but Suetonius claims it resulted from Caligula's seizure of public carriages; according to Seneca, grain imports were disrupted because Caligula re-purposed grain boats for a pontoon bridge.\nConstruction.\nDespite financial difficulties, Caligula embarked on a number of construction projects during his reign. Some were for the public good, though others were for himself.\nJosephus describes Caligula's improvements to the harbours at Rhegium and Sicily, allowing increased grain imports from Egypt, as his greatest contributions. These improvements may have been in response to the famine.\nCaligula completed the temple of Augustus and the theatre of Pompey and began an amphitheatre beside the Saepta. He expanded the imperial palace. He began the aqueducts Aqua Claudia and Anio Novus, which Pliny the Elder considered engineering marvels. He built a large racetrack known as the \"circus of Gaius and Nero\" and had an Egyptian obelisk (now known as the \"Vatican Obelisk\") transported by sea and erected in the middle of Rome.\nAt Syracuse, he repaired the city walls and the temples of the gods. He had new roads built and pushed to keep roads in good condition. He had planned to rebuild the palace of Polycrates at Samos, to finish the temple of Didymaean Apollo at Ephesus and to found a city high up in the Alps. He planned to dig a canal through the Isthmus of Corinth in Greece and sent a chief centurion to survey the work.\nIn 39, Caligula performed a spectacular stunt by ordering a temporary floating bridge to be built using ships as pontoons, stretching for over two miles from the resort of Baiae to the neighbouring port of Puteoli. It was said that the bridge was to rival the Persian king Xerxes' pontoon bridge crossing of the Hellespont. Caligula, who could not swim, then proceeded to ride his favourite horse Incitatus across, wearing the breastplate of Alexander the Great. This act was in defiance of a prediction by Tiberius's soothsayer Thrasyllus of Mendes that Caligula had \"no more chance of becoming emperor than of riding a horse across the Bay of Baiae\".\nCaligula had two large ships constructed for himself (which were recovered from the bottom of Lake Nemi around 1930). The ships were among the largest vessels in the ancient world. The smaller ship was designed as a temple dedicated to Diana. The larger ship was essentially an elaborate floating palace with marble floors and plumbing. The ships burned in 1944 after an attack in the Second World War; almost nothing remains of their hulls, though many archaeological treasures remain intact in the museum at Lake Nemi and in the Museo Nazionale Romano (Palazzo Massimo) at Rome.\nFeud with the senate.\nIn 39, relations between Caligula and the Roman Senate deteriorated. The subject of their disagreement is unknown. A number of factors, though, aggravated this feud. The Senate had become accustomed to ruling without an emperor between the departure of Tiberius for Capri in 26 and Caligula's accession. Additionally, Tiberius' treason trials had eliminated a number of pro-Julian senators such as Asinius Gallus.\nCaligula reviewed Tiberius' records of treason trials and decided, based on their actions during these trials, that numerous senators were not trustworthy. He ordered a new set of investigations and trials. He replaced the consul and had several senators put to death. Suetonius reports that other senators were degraded by being forced to wait on him and run beside his chariot.\nSoon after his break with the Senate, Caligula faced a number of additional conspiracies against him. A conspiracy involving his brother-in-law was foiled in late 39. Soon afterwards, the Governor of Germany, Gnaeus Cornelius Lentulus Gaetulicus, was executed for connections to a conspiracy.\nWestern expansion.\nIn 40, Caligula expanded the Roman Empire into Mauretania and made a significant attempt at expanding into Britannia. (Due to the novel \"I, Claudius\", it is commonly believed that Caligula attempted war against Neptune at this time. This is not mentioned in any ancient source, however.) The conquest of Britannia was later achieved during the reign of his successor, Claudius.\nMauretania.\nMauretania was a client kingdom of Rome ruled by Ptolemy of Mauretania. Caligula invited Ptolemy to Rome and then suddenly had him executed. Mauretania was annexed by Caligula and subsequently divided into two provinces, Mauretania Tingitana and Mauretania Caesariensis, separated by the river Malua. Pliny claims that division was the work of Caligula, but Dio states that in 42 an uprising took place, which was subdued by Gaius Suetonius Paulinus and Gnaeus Hosidius Geta, and the division only took place after this. This confusion might mean that Caligula decided to divide the province, but the division was postponed because of the rebellion. The first known equestrian governor of the two provinces was Marcus Fadius Celer Flavianus, in office in 44.\nDetails on the Mauretanian events of 39\u201344 are unclear. Cassius Dio wrote an entire chapter on the annexation of Mauretania by Caligula, but it is now lost. Caligula's move seemingly had a strictly personal political motive \u2013 fear and jealousy of his cousin Ptolemy \u2013 and thus the expansion may not have been prompted by pressing military or economic needs. However, the rebellion of Tacfarinas had shown how exposed Africa Proconsularis was to its west and how the Mauretanian client kings were unable to provide protection to the province, and it is thus possible that Caligula's expansion was a prudent response to potential future threats.\nBritannia.\nThere seems to have been a northern campaign to Britannia that was aborted. This campaign is derided by ancient historians with accounts of Gauls dressed up as Germanic tribesmen at his triumph and Roman troops ordered to collect seashells as \"spoils of the sea\". The few primary sources disagree on what precisely occurred. Modern historians have put forward numerous theories in an attempt to explain these actions. This trip to the English Channel could have merely been a training and scouting mission. The mission may have been to accept the surrender of the British chieftain Adminius. \"Seashells\", or \"conchae\" in Latin, may be a metaphor for something else such as female genitalia (perhaps the troops visited brothels) or boats (perhaps they captured several small British boats).\nClaims of divinity.\nWhen several client kings came to Rome to pay their respects to him and argued about their nobility of descent, he allegedly cried out the Homeric line: \"Let there be one lord, one king.\" In 40, Caligula began implementing very controversial policies that introduced religion into his political role. Caligula began appearing in public dressed as various gods and demigods such as Hercules, Mercury, Venus and Apollo. Reportedly, he began referring to himself as a god when meeting with politicians and he was referred to as \"Jupiter\" on occasion in public documents.\nA sacred precinct was set apart for his worship at Miletus in the province of Asia and two temples were erected for worship of him in Rome. The Temple of Castor and Pollux on the forum was linked directly to the imperial residence on the Palatine and dedicated to Caligula. He would appear there on occasion and present himself as a god to the public. Caligula had the heads removed from various statues of gods located across Rome and replaced them with his own. It is said that he wished to be worshipped as \"Neos Helios\", the \"New Sun\". Indeed, he was represented as a sun god on Egyptian coins.\nCaligula's religious policy was a departure from that of his predecessors. According to Cassius Dio, living emperors could be worshipped as divine in the east and dead emperors could be worshipped as divine in Rome. Augustus had the public worship his spirit on occasion, but Dio describes this as an extreme act that emperors generally shied away from. Caligula took things a step further and had those in Rome, including senators, worship him as a tangible, living god.\nEastern policy.\nCaligula needed to quell several riots and conspiracies in the eastern territories during his reign. Aiding him in his actions was his good friend, Herod Agrippa, who became governor of the territories of Batanaea and Trachonitis after Caligula became emperor in 37.\nThe cause of tensions in the east was complicated, involving the spread of Greek culture, Roman law and the rights of Jews in the empire.\nCaligula did not trust the prefect of Egypt, Aulus Avilius Flaccus. Flaccus had been loyal to Tiberius, had conspired against Caligula's mother and had connections with Egyptian separatists. In 38, Caligula sent Agrippa to Alexandria unannounced to check on Flaccus. According to Philo, the visit was met with jeers from the Greek population who saw Agrippa as the king of the Jews. As a result, riots broke out in the city. Caligula responded by removing Flaccus from his position and executing him.\nIn 39, Agrippa accused Herod Antipas, the tetrarch of Galilee and Perea, of planning a rebellion against Roman rule with the help of Parthia. Herod Antipas confessed and Caligula exiled him. Agrippa was rewarded with his territories.\nRiots again erupted in Alexandria in 40 between Jews and Greeks. Jews were accused of not honouring the emperor. Disputes occurred in the city of Jamnia. Jews were angered by the erection of a clay altar and destroyed it. In response, Caligula ordered the erection of a statue of himself in the Jewish Temple of Jerusalem, a demand in conflict with Jewish monotheism. In this context, Philo wrote that Caligula \"regarded the Jews with most especial suspicion, as if they were the only persons who cherished wishes opposed to his\".\nThe Governor of Syria, Publius Petronius, fearing civil war if the order were carried out, delayed implementing it for nearly a year. Agrippa finally convinced Caligula to reverse the order. However, Caligula issued a second order to have his statue erected in the Temple of Jerusalem. In Rome, another statue of himself, of colossal size, was made of gilt brass for the purpose. The Temple of Jerusalem was then transformed into a temple for Caligula, and it was called the Temple of Illustrious Gaius the New Jupiter.\nScandals.\nPhilo of Alexandria and Seneca the Younger, contemporaries of Caligula, describe him as an insane emperor who was self-absorbed, short-tempered, killed on a whim, and indulged in too much spending and sex. He is accused of sleeping with other men's wives and bragging about it, killing for mere amusement, deliberately wasting money on his bridge, causing starvation, and wanting a statue of himself in the Temple of Jerusalem for his worship. Once, at some games at which he was presiding, he was said to have ordered his guards to throw an entire section of the audience into the arena during the intermission to be eaten by the wild beasts because there were no prisoners to be used and he was bored.\nWhile repeating the earlier stories, the later sources of Suetonius and Cassius Dio provide additional tales of insanity. They accuse Caligula of incest with his sisters, Agrippina the Younger, Drusilla, and Livilla, and say he prostituted them to other men. They state he sent troops on illogical military exercises, turned the palace into a brothel, and, most famously, planned or promised to make his horse, Incitatus, a consul,\nand actually appointed him a priest.\nThe validity of these accounts is debatable. In Roman political culture, insanity and sexual perversity were often presented hand-in-hand with poor government.\nAssassination and aftermath.\nCaligula's actions as emperor were described as being especially harsh to the Senate, to the nobility and to the equestrian order. According to Josephus, these actions led to several failed conspiracies against Caligula. Eventually, officers within the Praetorian Guard led by Cassius Chaerea succeeded in murdering the emperor. The plot is described as having been planned by three men, but many in the senate, army and equestrian order were said to have been informed of it and involved in it.\nThe situation had escalated when, in 40, Caligula announced to the Senate that he planned to leave Rome permanently and to move to Alexandria in Egypt, where he hoped to be worshipped as a living god. The prospect of Rome losing its emperor and thus its political power was the final straw for many. Such a move would have left both the Senate and the Praetorian Guard powerless to stop Caligula's repression and debauchery. With this in mind Chaerea convinced his fellow conspirators, who included Marcus Vinicius and Lucius Annius Vinicianus, to put their plot into action quickly.\nAccording to Josephus, Chaerea had political motivations for the assassination. Suetonius sees the motive in Caligula calling Chaerea derogatory names. Caligula considered Chaerea effeminate because of a weak voice and for not being firm with tax collection. Caligula would mock Chaerea with names like \"Priapus\" and \"Venus\".\nOn 22 January 41 (Suetonius gives the date as 24 January), Cassius Chaerea and other guardsmen accosted Caligula as he addressed an acting troupe of young men beneath the palace, during a series of games and dramatics being held for the Divine Augustus. Details recorded on the events vary somewhat from source to source, but they agree that Chaerea stabbed Caligula first, followed by a number of conspirators. Suetonius records that Caligula's death resembled that of Julius Caesar. He states that both the elder Gaius Julius Caesar (Julius Caesar) and the younger Gaius Julius Caesar (Caligula) were stabbed 30 times by conspirators led by a man named Cassius (Cassius Longinus and Cassius Chaerea respectively). By the time Caligula's loyal Germanic guard responded, the Emperor was already dead. The Germanic guard, stricken with grief and rage, responded with a rampaging attack on the assassins, conspirators, innocent senators and bystanders alike. These wounded conspirators were treated by the physician Arcyon.\nThe \"cryptoporticus\" (underground corridor) beneath the imperial palaces on the Palatine Hill where this event took place was discovered by archaeologists in 2008.\nThe senate attempted to use Caligula's death as an opportunity to restore the Republic. Chaerea tried to persuade the military to support the Senate. The military, though, remained loyal to the idea of imperial monarchy. Uncomfortable with lingering imperial support, the assassins sought out and killed Caligula's wife, Caesonia, and killed their young daughter, Julia Drusilla, by smashing her head against a wall. They were unable to reach Caligula's uncle, Claudius. After a soldier, Gratus, found Claudius hiding behind a palace curtain, he was spirited out of the city by a sympathetic faction of the Praetorian Guard to their nearby camp.\nClaudius became emperor after procuring the support of the Praetorian Guard. Claudius granted a general amnesty, although he executed a few junior officers involved in the conspiracy, including Chaerea.\nAccording to Suetonius, Caligula's body was placed under turf until it was burned and entombed by his sisters. He was buried within the Mausoleum of Augustus; in 410, during the Sack of Rome, the ashes in the tomb were scattered.\nLegacy.\nHistoriography.\nThe facts and circumstances of Caligula's reign are mostly lost to history. Only two sources contemporary with Caligula have survived \u2013 the works of Philo and Seneca. Philo's works, \"On the Embassy to Gaius\" and \"Flaccus\", give some details on Caligula's early reign, but mostly focus on events surrounding the Jewish population in Judea and Egypt with whom he sympathizes. Seneca's various works give mostly scattered anecdotes on Caligula's personality. Seneca was almost put to death by Caligula in AD 39 likely due to his associations with conspirators.\nAt one time, there were detailed contemporaneous histories on Caligula, but they are now lost. Additionally, the historians who wrote them are described as biased, either overly critical or praising of Caligula. Nonetheless, these lost primary sources, along with the works of Seneca and Philo, were the basis of surviving secondary and tertiary histories on Caligula written by the next generations of historians. A few of the contemporaneous historians are known by name. Fabius Rusticus and Cluvius Rufus both wrote condemning histories on Caligula that are now lost. Fabius Rusticus was a friend of Seneca who was known for historical embellishment and misrepresentation. Cluvius Rufus was a senator involved in the assassination of Caligula.\nCaligula's sister, Agrippina the Younger, wrote an autobiography that certainly included a detailed explanation of Caligula's reign, but it too is lost. Agrippina was banished by Caligula for her connection to Marcus Lepidus, who conspired against him. The inheritance of Nero, Agrippina's son and the future emperor, was seized by Caligula. Gaetulicus, a poet, produced a number of flattering writings about Caligula, but they are lost.\nThe bulk of what is known of Caligula comes from Suetonius and Cassius Dio. Suetonius wrote his history on Caligula 80 years after his death, while Cassius Dio wrote his history over 180 years after Caligula's death. Cassius Dio's work is invaluable because it alone gives a loose chronology of Caligula's reign.\nA handful of other sources add a limited perspective on Caligula. Josephus gives a detailed description of Caligula's assassination. Tacitus provides some information on Caligula's life under Tiberius. In a now lost portion of his \"Annals\", Tacitus gave a detailed history of Caligula. Pliny the Elder's \"Natural History\" has a few brief references to Caligula.\nThere are few surviving sources on Caligula and none of them paints Caligula in a favourable light. The paucity of sources has resulted in significant gaps in modern knowledge of the reign of Caligula. Little is written on the first two years of Caligula's reign. Additionally, there are only limited details on later significant events, such as the annexation of Mauretania, Caligula's military actions in Britannia, and his feud with the Roman Senate. According to legend, during his military actions in Britannia Caligula grew addicted to a steady diet of European sea eels, which led to their Latin name being \"Coluber caligulensis\".\nHealth.\nAll surviving sources, except Pliny the Elder, characterize Caligula as insane. However, it is not known whether they are speaking figuratively or literally. Additionally, given Caligula's unpopularity among the surviving sources, it is difficult to separate fact from fiction. Recent sources are divided in attempting to ascribe a medical reason for his behavior, citing as possibilities encephalitis, epilepsy or meningitis. The question of whether Caligula was insane (especially after his illness early in his reign) remains unanswered.\nPhilo of Alexandria, Josephus and Seneca state that Caligula was insane, but describe this madness as a personality trait that came through experience. Seneca states that Caligula became arrogant, angry and insulting once he became emperor and uses his personality flaws as examples his readers can learn from. According to Josephus, power made Caligula incredibly conceited and led him to think he was a god. Philo of Alexandria reports that Caligula became ruthless after nearly dying of an illness in the eighth month of his reign in 37. Juvenal reports he was given a magic potion that drove him insane.\nSuetonius said that Caligula suffered from \"falling sickness\", or epilepsy, when he was young. Modern historians have theorized that Caligula lived with a daily fear of seizures. Despite swimming being a part of imperial education, Caligula could not swim. Epileptics are discouraged from swimming in open waters because unexpected fits could lead to death because a timely rescue would be difficult. Caligula reportedly talked to the full moon: Epilepsy was long associated with the moon.\nSuetonius described Caligula as sickly-looking, skinny and pale: \"he was tall, very pale, ill-shaped, his neck and legs very slender, his eyes and temples hollow, his brows broad and knit, his hair thin, and the crown of the head bald. The other parts of his body were much covered with hair ... He was crazy both in body and mind, being subject, when a boy, to the falling sickness. When he arrived at the age of manhood he endured fatigue tolerably well. Occasionally he was liable to faintness, during which he remained incapable of any effort\". Based on scientific reconstructions of his official painted busts, Caligula had brown hair, brown eyes, and fair skin.\nSome modern historians think that Caligula suffered from hyperthyroidism. This diagnosis is mainly attributed to Caligula's irritability and his \"stare\" as described by Pliny the Elder.\nPossible rediscovery of burial site.\nOn 17 January 2011, police in Nemi, Italy, announced that they believed they had discovered the site of Caligula's burial, after arresting a thief caught smuggling a statue which they believed to be of the emperor. The claim has been met with scepticism by Cambridge historian Mary Beard.\nExternal links.\n "}
{"id": "6854", "revid": "1021821595", "url": "https://en.wikipedia.org/wiki?curid=6854", "title": "Church\u2013Turing thesis", "text": "In computability theory, the Church\u2013Turing thesis (also known as computability thesis, the Turing\u2013Church thesis, the Church\u2013Turing conjecture, Church's thesis, Church's conjecture, and Turing's thesis) is a hypothesis about the nature of computable functions. It states that a function on the natural numbers can be calculated by an effective method if and only if it is computable by a Turing machine. The thesis is named after American mathematician Alonzo Church and the British mathematician Alan Turing. Before the precise definition of computable function, mathematicians often used the informal term effectively calculable to describe functions that are computable by paper-and-pencil methods. In the 1930s, several independent attempts were made to formalize the notion of computability:\nChurch, Kleene, and Turing proved that these three formally defined classes of computable functions coincide: a function is \u03bb-computable if and only if it is Turing computable, and if and only if it is \"general recursive\". This has led mathematicians and computer scientists to believe that the concept of computability is accurately characterized by these three equivalent processes. Other formal attempts to characterize computability have subsequently strengthened this belief (see below).\nOn the other hand, the Church\u2013Turing thesis states that the above three formally-defined classes of computable functions coincide with the \"informal\" notion of an effectively calculable function. Since, as an informal notion, the concept of effective calculability does not have a formal definition, the thesis, although it has near-universal acceptance, cannot be formally proven.\nSince its inception, variations on the original thesis have arisen, including statements about what can physically be realized by a computer in our universe (physical Church-Turing thesis) and what can be efficiently computed (Church\u2013Turing thesis (complexity theory)). These variations are not due to Church or Turing, but arise from later work in complexity theory and digital physics. The thesis also has implications for the philosophy of mind (see below).\nStatement in Church's and Turing's words.\n addresses the notion of \"effective computability\" as follows: \"Clearly the existence of CC and RC (Church's and Rosser's proofs) presupposes a precise definition of 'effective'. 'Effective method' is here used in the rather special sense of a method each step of which is precisely predetermined and which is certain to produce the answer in a finite number of steps\". Thus the adverb-adjective \"effective\" is used in a sense of \"1a: producing a decided, decisive, or desired effect\", and \"capable of producing a result\".\nIn the following, the words \"effectively calculable\" will mean \"produced by any intuitively 'effective' means whatsoever\" and \"effectively computable\" will mean \"produced by a Turing-machine or equivalent mechanical device\". Turing's \"definitions\" given in a footnote in his 1938 Ph.D. thesis \"Systems of Logic Based on Ordinals\", supervised by Church, are virtually the same:\n We shall use the expression \"computable function\" to mean a function calculable by a machine, and let \"effectively calculable\" refer to the intuitive idea without particular identification with any one of these definitions.\nThe thesis can be stated as: \"Every effectively calculable function is a computable function\".\nChurch also stated that \"No computational procedure will be considered as an algorithm unless it can be represented as a Turing Machine\".\nTuring stated it this way:\nIt was stated\u00a0... that \"a function is effectively calculable if its values can be found by some purely mechanical process\". We may take this literally, understanding that by a purely mechanical process one which could be carried out by a machine. The development\u00a0... leads to\u00a0... an identification of computability with effective calculability. [ is the footnote quoted above.]\nHistory.\nOne of the important problems for logicians in the 1930s was the Entscheidungsproblem of David Hilbert and Wilhelm Ackermann, which asked whether there was a mechanical procedure for separating mathematical truths from mathematical falsehoods. This quest required that the notion of \"algorithm\" or \"effective calculability\" be pinned down, at least well enough for the quest to begin. But from the very outset Alonzo Church's attempts began with a debate that continues to this day. the notion of \"effective calculability\" to be (i) an \"axiom or axioms\" in an axiomatic system, (ii) merely a \"definition\" that \"identified\" two or more propositions, (iii) an \"empirical hypothesis\" to be verified by observation of natural events, or (iv) just \"a proposal\" for the sake of argument (i.e. a \"thesis\").\nCirca 1930\u20131952.\nIn the course of studying the problem, Church and his student Stephen Kleene introduced the notion of \u03bb-definable functions, and they were able to prove that several large classes of functions frequently encountered in number theory were \u03bb-definable. The debate began when Church proposed to G\u00f6del that one should define the \"effectively computable\" functions as the \u03bb-definable functions. G\u00f6del, however, was not convinced and called the proposal \"thoroughly unsatisfactory\". Rather, in correspondence with Church (c. 1934\u201335), G\u00f6del proposed \"axiomatizing\" the notion of \"effective calculability\"; indeed, in a 1935 letter to Kleene, Church reported that:\nBut G\u00f6del offered no further guidance. Eventually, he would suggest his recursion, modified by Herbrand's suggestion, that G\u00f6del had detailed in his 1934 lectures in Princeton NJ (Kleene and Rosser transcribed the notes). But he did not think that the two ideas could be satisfactorily identified \"except heuristically\".\nNext, it was necessary to identify and prove the equivalence of two notions of effective calculability. Equipped with the \u03bb-calculus and \"general\" recursion, Stephen Kleene with help of Church and J. Barkley Rosser produced proofs (1933, 1935) to show that the two calculi are equivalent. Church subsequently modified his methods to include use of Herbrand\u2013G\u00f6del recursion and then proved (1936) that the Entscheidungsproblem is unsolvable: there is no algorithm that can determine whether a well formed formula \nMany years later in a letter to Davis (c. 1965), G\u00f6del said that \"he was, at the time of these [1934] lectures, not at all convinced that his concept of recursion comprised all possible recursions\". By 1963\u201364 G\u00f6del would disavow Herbrand\u2013G\u00f6del recursion and the \u03bb-calculus in favor of the Turing machine as the definition of \"algorithm\" or \"mechanical procedure\" or \"formal system\".\nA hypothesis leading to a natural law?: In late 1936 Alan Turing's paper (also proving that the Entscheidungsproblem is unsolvable) was delivered orally, but had not yet appeared in print. On the other hand, Emil Post's 1936 paper had appeared and was certified independent of Turing's work. Post strongly disagreed with Church's \"identification\" of effective computability with the \u03bb-calculus and recursion, stating:\nRather, he regarded the notion of \"effective calculability\" as merely a \"working hypothesis\" that might lead by inductive reasoning to a \"natural law\" rather than by \"a definition or an axiom\". This idea was \"sharply\" criticized by Church.\nThus Post in his 1936 paper was also discounting Kurt G\u00f6del's suggestion to Church in 1934\u201335 that the thesis might be expressed as an axiom or set of axioms.\nTuring adds another definition, Rosser equates all three: Within just a short time, Turing's 1936\u201337 paper \"On Computable Numbers, with an Application to the Entscheidungsproblem\" appeared. In it he stated another notion of \"effective computability\" with the introduction of his a-machines (now known as the Turing machine abstract computational model). And in a proof-sketch added as an \"Appendix\" to his 1936\u201337 paper, Turing showed that the classes of functions defined by \u03bb-calculus and Turing machines coincided. Church was quick to recognise how compelling Turing's analysis was. In his review of Turing's paper he made clear that Turing's notion made \"the identification with effectiveness in the ordinary (not explicitly defined) sense evident immediately\".\nIn a few years (1939) Turing would propose, like Church and Kleene before him, that \"his\" formal definition of mechanical computing agent was the correct one. Thus, by 1939, both Church (1934) and Turing (1939) had individually proposed that their \"formal systems\" should be \"definitions\" of \"effective calculability\"; neither framed their statements as \"theses\".\nRosser (1939) formally identified the three notions-as-definitions:\nKleene proposes \"Thesis I\": This left the overt expression of a \"thesis\" to Kleene. In his 1943 paper \"Recursive Predicates and Quantifiers\" Kleene proposed his \"THESIS I\":\nreferences Church 1936; (23) references Turing 1936\u20137\nKleene goes on to note that:\n(24) references Post 1936 of Post and Church's \"Formal definitions in the theory of ordinal numbers\", \"Fund. Math\". vol 28 (1936) pp.\u00a011\u201321 (see ref. #2, ).\nThe Church\u2013Turing Thesis: Stephen Kleene, in \"Introduction To Metamathematics\", finally goes on to formally name \"Church's Thesis\" and \"Turing's Thesis\", using his theory of recursive realizability. Kleene having switched from presenting his work in the terminology of Church-Kleene lambda definability, to that of G\u00f6del-Kleene recursiveness (partial recursive functions). In this transition, Kleene modified G\u00f6del's general recursive functions to allow for proofs of the unsolvability of problems in the Intuitionism of E. J. Brouwer. In his graduate textbook on logic, \"Church's thesis\" is introduced and basic mathematical results are demonstrated to be unrealizable. Next, Kleene proceeds to present \"Turing's thesis\", where results are shown to be uncomputable, using his simplified derivation of a Turing machine based off of the work of Emil Post. Both theses are proven equivalent by use of \"Theorem XXX\"."}
{"id": "6856", "revid": "1430004", "url": "https://en.wikipedia.org/wiki?curid=6856", "title": "Chomsky (surname)", "text": "Chomsky (, , , , \"from (Vyoska) (nearby Brest, now Belarus)\") is a surname of Belarusian-Ukrainian origin. Notable people with the surname include:"}
{"id": "6857", "revid": "5661201", "url": "https://en.wikipedia.org/wiki?curid=6857", "title": "Computer multitasking", "text": "In computing, multitasking is the concurrent execution of multiple tasks (also known as processes) over a certain period of time. New tasks can interrupt already started ones before they finish, instead of waiting for them to end. As a result, a computer executes segments of multiple tasks in an interleaved manner, while the tasks share common processing resources such as central processing units (CPUs) and main memory. Multitasking automatically interrupts the running program, saving its state (partial results, memory contents and computer register contents) and loading the saved state of another program and transferring control to it. This \"context switch\" may be initiated at fixed time intervals (pre-emptive multitasking), or the running program may be coded to signal to the supervisory software when it can be interrupted (cooperative multitasking).\nMultitasking does not require parallel execution of multiple tasks at exactly the same time; instead, it allows more than one task to advance over a given period of time. Even on multiprocessor computers, multitasking allows many more tasks to be run than there are CPUs.\nMultitasking is a common feature of computer operating systems. It allows more efficient use of the computer hardware; where a program is waiting for some external event such as a user input or an input/output transfer with a peripheral to complete, the central processor can still be used with another program. In a time-sharing system, multiple human operators use the same processor as if it was dedicated to their use, while behind the scenes the computer is serving many users by multitasking their individual programs. In multiprogramming systems, a task runs until it must wait for an external event or until the operating system's scheduler forcibly swaps the running task out of the CPU. Real-time systems such as those designed to control industrial robots, require timely processing; a single processor might be shared between calculations of machine movement, communications, and user interface.\nOften multitasking operating systems include measures to change the priority of individual tasks, so that important jobs receive more processor time than those considered less significant. Depending on the operating system, a task might be as large as an entire application program, or might be made up of smaller threads that carry out portions of the overall program.\nA processor intended for use with multitasking operating systems may include special hardware to securely support multiple tasks, such as memory protection, and protection rings that ensure the supervisory software cannot be damaged or subverted by user-mode program errors.\nThe term \"multitasking\" has become an international term, as the same word is used in many other languages such as German, Italian, Dutch, Danish and Norwegian.\nMultiprogramming.\nIn the early days of computing, CPU time was expensive, and peripherals were very slow. When the computer ran a program that needed access to a peripheral, the central processing unit (CPU) would have to stop executing program instructions while the peripheral processed the data. This was usually very inefficient.\nThe first computer using a multiprogramming system was the British \"Leo III\" owned by J. Lyons and Co. During batch processing, several different programs were loaded in the computer memory, and the first one began to run. When the first program reached an instruction waiting for a peripheral, the context of this program was stored away, and the second program in memory was given a chance to run. The process continued until all programs finished running.\nThe use of multiprogramming was enhanced by the arrival of virtual memory and virtual machine technology, which enabled individual programs to make use of memory and operating system resources as if other concurrently running programs were, for all practical purposes, nonexistent.\nMultiprogramming gives no guarantee that a program will run in a timely manner. Indeed, the first program may very well run for hours without needing access to a peripheral. As there were no users waiting at an interactive terminal, this was no problem: users handed in a deck of punched cards to an operator, and came back a few hours later for printed results. Multiprogramming greatly reduced wait times when multiple batches were being processed.\nCooperative multitasking.\nEarly multitasking systems used applications that voluntarily ceded time to one another. This approach, which was eventually supported by many computer operating systems, is known today as cooperative multitasking. Although it is now rarely used in larger systems except for specific applications such as CICS or the JES2 subsystem, cooperative multitasking was once the only scheduling scheme employed by Microsoft Windows and Classic Mac OS to enable multiple applications to run simultaneously. Cooperative multitasking is still used today on RISC OS systems.\nAs a cooperatively multitasked system relies on each process regularly giving up time to other processes on the system, one poorly designed program can consume all of the CPU time for itself, either by performing extensive calculations or by busy waiting; both would cause the whole system to hang. In a server environment, this is a hazard that makes the entire environment unacceptably fragile.\nPreemptive multitasking.\nPreemptive multitasking allows the computer system to more reliably guarantee to each process a regular \"slice\" of operating time. It also allows the system to deal rapidly with important external events like incoming data, which might require the immediate attention of one or another process. Operating systems were developed to take advantage of these hardware capabilities and run multiple processes preemptively. Preemptive multitasking was implemented in the PDP-6 Monitor and MULTICS in 1964, in OS/360 MFT in 1967, and in Unix in 1969, and was available in some operating systems for computers as small as DEC's PDP-8; it is a core feature of all Unix-like operating systems, such as Linux, Solaris and BSD with its derivatives, as well as modern versions of Windows.\nAt any specific time, processes can be grouped into two categories: those that are waiting for input or output (called \"I/O bound\"), and those that are fully utilizing the CPU (\"CPU bound\"). In primitive systems, the software would often \"poll\", or \"busywait\" while waiting for requested input (such as disk, keyboard or network input). During this time, the system was not performing useful work. With the advent of interrupts and preemptive multitasking, I/O bound processes could be \"blocked\", or put on hold, pending the arrival of the necessary data, allowing other processes to utilize the CPU. As the arrival of the requested data would generate an interrupt, blocked processes could be guaranteed a timely return to execution.\nThe earliest preemptive multitasking OS available to home users was Sinclair QDOS on the Sinclair QL, released in 1984, but very few people bought the machine. Commodore's Amiga, released the following year, was the first commercially successful home computer to use the technology, and its multimedia abilities make it a clear ancestor of contemporary multitasking personal computers. Microsoft made preemptive multitasking a core feature of their flagship operating system in the early 1990s when developing Windows NT 3.1 and then Windows 95. It was later adopted on the Apple Macintosh by Mac OS X that, as a Unix-like operating system, uses preemptive multitasking for all native applications.\nA similar model is used in Windows 9x and the Windows NT family, where native 32-bit applications are multitasked preemptively. 64-bit editions of Windows, both for the x86-64 and Itanium architectures, no longer support legacy 16-bit applications, and thus provide preemptive multitasking for all supported applications.\nReal time.\nAnother reason for multitasking was in the design of real-time computing systems, where there are a number of possibly unrelated external activities needed to be controlled by a single processor system. In such systems a hierarchical interrupt system is coupled with process prioritization to ensure that key activities were given a greater share of available process time.\nMultithreading.\nAs multitasking greatly improved the throughput of computers, programmers started to implement applications as sets of cooperating processes (e.\u00a0g., one process gathering input data, one process processing input data, one process writing out results on disk). This, however, required some tools to allow processes to efficiently exchange data.\nThreads were born from the idea that the most efficient way for cooperating processes to exchange data would be to share their entire memory space. Thus, threads are effectively processes that run in the same memory context and share other resources with their parent processes, such as open files. Threads are described as \"lightweight processes\" because switching between threads does not involve changing the memory context.\nWhile threads are scheduled preemptively, some operating systems provide a variant to threads, named \"fibers\", that are scheduled cooperatively. On operating systems that do not provide fibers, an application may implement its own fibers using repeated calls to worker functions. Fibers are even more lightweight than threads, and somewhat easier to program with, although they tend to lose some or all of the benefits of threads on machines with multiple processors.\nSome systems directly support multithreading in hardware.\nMemory protection.\nEssential to any multitasking system is to safely and effectively share access to system resources. Access to memory must be strictly managed to ensure that no process can inadvertently or deliberately read or write to memory locations outside the process's address space. This is done for the purpose of general system stability and data integrity, as well as data security.\nIn general, memory access management is a responsibility of the operating system kernel, in combination with hardware mechanisms that provide supporting functionalities, such as a memory management unit (MMU). If a process attempts to access a memory location outside its memory space, the MMU denies the request and signals the kernel to take appropriate actions; this usually results in forcibly terminating the offending process. Depending on the software and kernel design and the specific error in question, the user may receive an access violation error message such as \"segmentation fault\".\nIn a well designed and correctly implemented multitasking system, a given process can never directly access memory that belongs to another process. An exception to this rule is in the case of shared memory; for example, in the System V inter-process communication mechanism the kernel allocates memory to be mutually shared by multiple processes. Such features are often used by database management software such as PostgreSQL.\nInadequate memory protection mechanisms, either due to flaws in their design or poor implementations, allow for security vulnerabilities that may be potentially exploited by malicious software.\nMemory swapping.\nUse of a swap file or swap partition is a way for the operating system to provide more memory than is physically available by keeping portions of the primary memory in secondary storage. While multitasking and memory swapping are two completely unrelated techniques, they are very often used together, as swapping memory allows more tasks to be loaded at the same time. Typically, a multitasking system allows another process to run when the running process hits a point where it has to wait for some portion of memory to be reloaded from secondary storage.\nProgramming.\nProcesses that are entirely independent are not much trouble to program in a multitasking environment. Most of the complexity in multitasking systems comes from the need to share computer resources between tasks and to synchronize the operation of co-operating tasks.\nVarious concurrent computing techniques are used to avoid potential problems caused by multiple tasks attempting to access the same resource.\nBigger systems were sometimes built with a central processor(s) and some number of I/O processors, a kind of asymmetric multiprocessing.\nOver the years, multitasking systems have been refined. Modern operating systems generally include detailed mechanisms for prioritizing processes, while symmetric multiprocessing has introduced new complexities and capabilities."}
{"id": "6859", "revid": "23551833", "url": "https://en.wikipedia.org/wiki?curid=6859", "title": "Chiang Kai-shek", "text": "Chiang Kai-shek (31 October 1887 \u2013 5 April 1975), also known as Chiang Chung-cheng and romanized via Mandarin as Chiang Chieh-shih and Jiang Jieshi, was a Chinese Nationalist politician, revolutionary and military leader who served as the leader of the Republic of China between 1928 and 1975, first in mainland China until 1949 and then in Taiwan until his death.\nBorn in Chekiang (Zhejiang) Province, Chiang was a member of the Kuomintang (KMT) and a lieutenant of Sun Yat-sen in the revolution to overthrow the Beiyang government and reunify China. With help from the Soviets and the Communist Party of China (CPC, commonly known as the Chinese Communist Party or CCP), Chiang organized the military for Sun's Canton Nationalist Government and headed the Whampoa Military Academy. Commander in chief of the National Revolutionary Army (from which he came to be known as Generalissimo), he led the Northern Expedition from 1926 to 1928, before defeating a coalition of warlords and nominally reunifying China under a new Nationalist government. Midway through the Northern Expedition, the KMT\u2013CPC alliance broke down and Chiang purged the communists inside the party, triggering a civil war with the CPC, which he eventually lost in 1949.\nAs leader of the Republic of China in the Nanjing decade, Chiang sought to strike a difficult balance between modernizing China while also devoting resources to defending the nation against the CPC, warlords, and the impending Japanese threat. Trying to avoid a war with Japan while hostilities with the CPC continued, he was kidnapped in the Xi'an Incident and obliged to form an Anti-Japanese United Front with the CPC. Following the Marco Polo Bridge Incident in 1937, he mobilized China for the Second Sino-Japanese War. For eight years he led the war of resistance against a vastly superior enemy, mostly from the wartime capital Chongqing. As the leader of a major Allied power, Chiang met with British Prime Minister Winston Churchill and U.S. President Franklin D. Roosevelt in the Cairo Conference to discuss terms for Japanese surrender. No sooner had the Second World War ended than the Civil War with the communists, by then led by Mao Zedong, resumed. Chiang's nationalists were mostly defeated in a few decisive battles in 1948.\nIn 1949 Chiang's government and army retreated to Taiwan, where Chiang imposed martial law and persecuted critics during the White Terror. Presiding over a period of social reforms and economic prosperity, Chiang won five elections to six-year terms as President of the Republic of China and was Director-General of the Kuomintang until his death in 1975, three years into his fifth term as President and just one year before Mao's death.\nOne of the longest-serving non-royal heads of state in the 20th century, Chiang was the longest-serving non-royal ruler of China having held the post for 46 years. Like Mao, he is regarded as a controversial figure. Supporters credit him with playing a major part in unifying the nation and leading the Chinese resistance against Japan, as well as with countering Soviet-communist encroachment. Detractors and critics denounce him as a dictator at the front of a corrupt authoritarian regime who suppressed opponents.\nNames.\nLike many other Chinese historical figures, Chiang used several names throughout his life. The name inscribed in the genealogical records of his family is Chiang Chou-t\u2018ai (). This so-called \"register name\" () is the one under which his extended relatives knew him, and the one he used in formal occasions, such as when he got married. In deference to tradition, family members did not use the register name in conversation with people outside of the family. The concept of a \"real\" or original name is/was not as clear-cut in China as it is in the Western world. In honor of tradition, Chinese families waited a number of years before officially naming their children. In the meantime, they used a \"milk name\" (), given to the infant shortly after his birth and known only to the close family. So the actual name that Chiang received at birth was Chiang Jui-y\u00fcan ().\nIn 1903, the 16-year-old Chiang went to Ningpo to be a student, and he chose a \"school name\" (). This was actually the formal name of a person, used by older people to address him, and the one he would use the most in the first decades of his life (as the person grew older, younger generations would have to use one of the courtesy names instead). Colloquially, the school name is called \"big name\" (), whereas the \"milk name\" is known as the \"small name\" (). The school name that Chiang chose for himself was Zhiqing (, which means \"purity of aspirations\"). For the next fifteen years or so, Chiang was known as Jiang Zhiqing (Wade-Giles: Chiang Chi-ch\u2018ing). This is the name under which Sun Yat-sen knew him when Chiang joined the republicans in Kwangtung in the 1910s.\nIn 1912, when Jiang Zhiqing was in Japan, he started to use the name Chiang Kai-shek () as a pen name for the articles that he published in a Chinese magazine he founded: \"Voice of the Army\" (). \"Jieshi\" is the Pinyin romanization of this name, based on Mandarin, but the most recognized romanized rendering is \"Kai-shek\" which is in Cantonese romanization. Because the Republicans were based in Canton (a Cantonese-speaking area, now known as Guangdong), Chiang (who never spoke Cantonese) became known by Westerners under the Cantonese romanization of his courtesy name, while the family name as known in English seems to be the Mandarin pronunciation of his Chinese family name, transliterated in Wade-Giles.\n\"Kai-shek\"/\"Jieshi\" soon became Chiang's courtesy name (). Some think the name was chosen from the classic Chinese book the \"I Ching\"; , is the beginning of line 2 of Hexagram 16, \"\". Others note that the first character of his courtesy name is also the first character of the courtesy name of his brother and other male relatives on the same generation line, while the second character of his courtesy name \"shi\" (\u2014meaning \"stone\") suggests the second character of his \"register name\" \"tai\" (\u2014the famous Mount Tai). Courtesy names in China often bore a connection with the personal name of the person. As the courtesy name is the name used by people of the same generation to address the person, Chiang soon became known under this new name.\nSometime in 1917 or 1918, as Chiang became close to Sun Yat-sen, he changed his name from Jiang Zhiqing to Chiang Chung-cheng (). By adopting the name Chung-cheng (\"central uprightness\"), he was choosing a name very similar to the name of Sun Yat-sen, who was (and still is) known among Chinese as Zhongshan (\u2014meaning \"central mountain\"), thus establishing a link between the two. The meaning of uprightness, rectitude, or orthodoxy, implied by his name, also positioned him as the legitimate heir of Sun Yat-sen and his ideas. It was readily accepted by members of the Chinese Nationalist Party and is the name under which Chiang Kai-shek is still commonly known in Taiwan. However, the name was often rejected by the Chinese Communists and is not as well known in mainland China. Often the name is shortened to \"Chung-cheng\" only (\"Zhongzheng\" in Pinyin). Many public places in Taiwan are named Chungcheng after Chiang. For many years passengers arriving at the Chiang Kai-shek International Airport were greeted by signs in Chinese welcoming them to the \"Chung Cheng International Airport\". Similarly, the monument erected to Chiang's memory in Taipei, known in English as Chiang Kai-shek Memorial Hall, was literally named \"Chung Cheng Memorial Hall\" in Chinese. In Singapore, Chung Cheng High School was named after him.\nHis name is also written in Taiwan as \"The Late President Honorable Chiang\" (), where the one-character-wide space in front of his name known as nuo tai shows respect. He is often called \"Honorable Chiang\" () (without the title or space), or his name Chiang Chung-cheng, in Taiwan.\nIn this context, his surname \"Chiang\" in this article is spelled using the Wade-Giles system of transliteration for Standard Chinese as opposed to Hanyu Pinyin (which is spelled as \"Jiang\") though the latter was adopted by the ROC government in 2009 as its official romanization.\nEarly life.\nChiang was born on October 31, 1887 in Xikou (Chikow, Ch'i-k'ou), a town in Fenghua (Fenghwa), Zhejiang (Chekiang), China, about west of central Ningbo. He was born into a family of Wu Chinese-speaking people with their ancestral home\u2014a concept important in Chinese society\u2014in Heqiao (), a town in Yixing, Jiangsu, about southwest of central Wuxi and from the shores of Lake Tai. He was the third child and second son of his father (also Chiang Su-an; 1842\u20131895; ) and the first child of his father's third wife (1863\u20131921; ) who were members of a prosperous family of salt merchants. Chiang lost his father when he was eight, and he wrote of his mother as the \"embodiment of Confucian virtues\". The young Chiang was inspired throughout his youth by the realisation that the reputation of an honored family rested upon his shoulders. He was a naughty child. At a young age he was interested in war. As he grew older, Chiang became more aware of the issues that surrounded him and in his speech to the Kuomintang in 1945 said:\nIn early 1906, Chiang cut off his queue, the required hairstyle of men during the Qing Dynasty, and had it sent home from school, shocking the people in his hometown.\nEducation in Japan.\nChiang grew up at a time in which military defeats, natural disasters, famines, revolts, unequal treaties and civil wars had left the Manchu-dominated Qing dynasty destabilized and in debt. Successive demands of the Western powers and Japan since the Opium War had left China owing millions of taels of silver. During his first visit to Japan to pursue a military career from April 1906 to later that year, he describes himself having strong nationalistic feelings with a desire among other things to, 'expel the Manchu Qing and to restore China'. In a 1969 speech, Chiang related a story about his boat trip to Japan at nineteen years old. Another passenger on the ship, a Chinese fellow student who was in the habit of spitting on the floor, was chided by a Chinese sailor who said that Japanese people did not spit on the floor, but instead would spit into a handkerchief. Chiang used the story as an example of how the common man in 1969 Taiwan had not developed the spirit of public sanitation that Japan had. Chiang decided to pursue a military career. He began his military training at the Baoding Military Academy in 1906, the same year Japan left its bimetallic currency standard, devaluing its yen. He left for Tokyo Shinbu Gakko, a preparatory school for the Imperial Japanese Army Academy intended for Chinese students, in 1907. There, he came under the influence of compatriots to support the revolutionary movement to overthrow the Manchu-dominated Qing dynasty and to set up a Han-dominated Chinese republic. He befriended Chen Qimei, and in 1908 Chen brought Chiang into the Tongmenghui, an important revolutionary brotherhood of the era. Finishing his military schooling at Tokyo Shinbu Gakko, Chiang served in the Imperial Japanese Army from 1909 to 1911.\nReturning to China.\nAfter learning of the Wuchang Uprising, Chiang returned to China in 1911, intending to fight as an artillery officer. He served in the revolutionary forces, leading a regiment in Shanghai under his friend and mentor Chen Qimei, as one of Chen's chief lieutenants. In early 1912 a dispute arose between Chen and Tao Chen-chang, an influential member of the Revolutionary Alliance who opposed both Sun Yat-sen and Chen. Tao sought to avoid escalating the quarrel by hiding in a hospital, but Chiang discovered him there. Chen dispatched assassins. Chiang may not have taken part in the assassination, but would later assume responsibility to help Chen avoid trouble. Chen valued Chiang despite Chiang's already legendary temper, regarding such bellicosity as useful in a military leader.\nChiang's friendship with Chen Qimei signaled an association with Shanghai's criminal syndicate (the Green Gang headed by Du Yuesheng and Huang Jinrong). During Chiang's time in Shanghai, the Shanghai International Settlement police observed him and eventually charged him with various felonies. These charges never resulted in a trial, and Chiang was never jailed.\nChiang became a founding member of the Nationalist Party (a forerunner of the KMT) after the success (February 1912) of the 1911 Revolution. After the takeover of the Republican government by Yuan Shikai and the failed Second Revolution in 1913, Chiang, like his KMT comrades, divided his time between exile in Japan and the havens of the Shanghai International Settlement. In Shanghai, Chiang cultivated ties with the city's underworld gangs, which were dominated by the notorious Green Gang and its leader Du Yuesheng. On 18 May 1916 agents of Yuan Shikai assassinated Chen Qimei. Chiang then succeeded Chen as leader of the Chinese Revolutionary Party in Shanghai. Sun Yat-sen's political career reached its lowest point during this time - most of his old Revolutionary Alliance comrades refused to join him in the exiled Chinese Revolutionary Party.\nEstablishing the Kuomintang's position.\nIn 1917 Sun Yat-sen moved his base of operations to Canton (now known as Guangzhou), and Chiang joined him in 1918. At this time Sun remained largely sidelined \u2013 without arms or money, he was soon expelled from Guangdong (Canton province) and exiled again to Shanghai. He was restored to Guangdong with mercenary help in 1920. After his return to Guangdong, a rift developed between Sun, who sought to militarily unify China under the KMT, and Guangdong Governor Chen Jiongming, who wanted to implement a federalist system with Guangdong as a model province. On 16 June 1922 Ye Ju, a general of Chen's whom Sun had attempted to exile, led an assault on Guangdong's Presidential Palace. Sun had already fled to the naval yard and boarded the SS\u00a0\"Haiqi\", but his wife narrowly evaded shelling and rifle-fire as she fled. They met on the SS \"Yongfeng\", where Chiang joined them as swiftly as he could return from Shanghai, where he was ritually mourning his mother's death. For about 50 days, Chiang stayed with Sun, protecting and caring for him and earning his lasting trust. They abandoned their attacks on Chen on 9 August, taking a British ship to Hong Kong and traveling to Shanghai by steamer.\nSun regained control of Guangdong in early 1923, again with the help of mercenaries from Yunnan and of the Comintern. Undertaking a reform of the KMT, he established a revolutionary government aimed at unifying China under the KMT. That same year Sun sent Chiang to spend three months in Moscow studying the Soviet political and military system. During his trip in Russia, Chiang met Leon Trotsky and other Soviet leaders, but quickly came to the conclusion that the Russian model of government was not suitable for China. Chiang later sent his eldest son, Ching-kuo, to study in Russia. After his father's split from the First United Front in 1927, Ching-kuo was forced to stay there, as a hostage, until 1937. Chiang wrote in his diary, \"It is not worth it to sacrifice the interest of the country for the sake of my son.\" Chiang even refused to negotiate a prisoner swap for his son in exchange for the Chinese Communist Party leader. His attitude remained consistent, and he continued to maintain, by 1937, that \"I would rather have no offspring than sacrifice our nation's interests.\" Chiang had absolutely no intention of ceasing the war against the Communists.\nChiang Kai-shek returned to Guangdong and in 1924 Sun appointed him Commandant of the Whampoa Military Academy. Chiang resigned from the office after one month in disagreement with Sun's extremely close cooperation with the Comintern, but returned at Sun's demand. The early years at Whampoa allowed Chiang to cultivate a cadre of young officers loyal both to the KMT and to himself.\nThroughout his rise to power, Chiang also benefited from membership within the nationalist Tiandihui fraternity, to which Sun Yat-sen also belonged, and which remained a source of support during his leadership of the Kuomintang.\nCompetition with Wang Jingwei.\nSun Yat-sen died on 12 March 1925, creating a power vacuum in the Kuomintang. A contest ensued among Wang Jingwei, Liao Zhongkai, and Hu Hanmin. In August, Liao was assassinated and Hu arrested for his connections to the murderers. Wang Jingwei, who had succeeded Sun as chairman of the Kwangtung regime, seemed ascendant but was forced into exile by Chiang following the Canton Coup. The , renamed the \"Zhongshan\" in Sun's honour, had appeared off Changzhou\u2014the location of the Whampoa Academy\u2014on apparently falsified orders and amid a series of unusual phone calls trying to ascertain Chiang's location. He initially considered fleeing Kwangtung and even booked passage on a Japanese steamer, but then decided to use his military connections to declare martial law on 20 March 1926, and crack down on Communist and Soviet influence over the NRA, the military academy, and the party. The right wing of the party supported him and Stalin\u2014anxious to maintain Soviet influence in the area\u2014had his lieutenants agree to Chiang's demands regarding a reduced Communist presence in the KMT leadership in exchange for certain other concessions. The rapid replacement of leadership enabled Chiang to effectively end civilian oversight of the military after 15 May, though his authority was somewhat limited by the army's own regional composition and divided loyalties. On 5 June 1926, he was named commander-in-chief of the National Revolutionary Army and, on 27 July, he finally launched Sun's long-delayed Northern Expedition, aimed at conquering the northern warlords and bringing China together under the KMT.\nThe NRA branched into three divisions: to the west was the returned Wang Jingwei, who led a column to take Wuhan; Bai Chongxi's column went east to take Shanghai; Chiang himself led in the middle route, planning to take Nanjing before pressing ahead to capture Beijing. However, in January 1927, Wang Jingwei and his KMT leftist allies took the city of Wuhan amid much popular mobilization and fanfare. Allied with a number of Chinese Communists and advised by Soviet agent Mikhail Borodin, Wang declared the National Government as having moved to Wuhan. Having taken Nanjing in March (and briefly visited Shanghai, now under the control of his close ally Bai Chongxi), Chiang halted his campaign and prepared a violent break with Wang's leftist elements, which he believed threatened his control of the KMT.\nNow with an established national government in Nanjing, and supported by conservative allies including Hu Hanmin, Chiang's expulsion of the Communists and their Soviet advisers led to the beginning of the Chinese Civil War. Wang Jingwei's National Government was weak militarily, and was soon ended by Chiang with the support of a local warlord (Li Zongren of Guangxi). Eventually, Wang and his leftist party surrendered to Chiang and joined him in Nanjing. In the Central Plains War, Beijing was taken on June 1928, from an alliance of the warlords Feng Yuxiang and Yan Xishan. In December, the Manchurian warlord Zhang Xueliang pledged allegiance to Chiang's government, completing Chiang's nominal unification of China and ending the Warlord Era.\nIn 1927, when he was setting up the Nationalist government in Nanjing, he was preoccupied with \"the elevation of our leader Dr. Sun Yat-sen to the rank of 'Father of our Chinese Republic'. Dr. Sun worked for 40 years to lead our people in the Nationalist cause, and we cannot allow any other personality to usurp this honored position\". He asked Chen Guofu to purchase a photograph that had been taken in Japan around 1895 or 1898. It showed members of the Revive China Society with Yeung Kui-wan ( or , pinyin Y\u00e1ng Q\u00fay\u00fan) as President, in the place of honor, and Sun, as secretary, on the back row, along with members of the Japanese Chapter of the Revive China Society. When told that it was not for sale, Chiang offered a million dollars to recover the photo and its negative. \"The party must have this picture and the negative at any price. They must be destroyed as soon as possible. It would be embarrassing to have our Father of the Chinese Republic shown in a subordinate position\". Chiang never obtained either the photo or its negative.\nChiang made great efforts to gain recognition as the official successor of Sun Yat-sen. In a pairing of great political significance, Chiang was Sun's brother-in-law: he had married Soong Mei-ling, the younger sister of Soong Ching-ling, Sun's widow, on 1 December 1927. Originally rebuffed in the early 1920s, Chiang managed to ingratiate himself to some degree with Soong Mei-ling's mother by first divorcing his wife and concubines and promising to sincerely study the precepts of Christianity. He read the copy of the Bible that May-ling had given him twice before making up his mind to become a Christian, and three years after his marriage he was baptized in the Soong's Methodist church. Although some observers felt that he adopted Christianity as a political move, studies of his recently opened diaries suggest that his faith was strong and sincere and that he felt that Christianity reinforced Confucian moral teachings.\nUpon reaching Beijing, Chiang paid homage to Sun Yat-sen and had his body moved to the new capital of Nanjing to be enshrined in a mausoleum, the Sun Yat-sen Mausoleum.\nRising power.\nIn the West and in the Soviet Union, Chiang Kai-shek was known as the \"Red General\". Movie theaters in the Soviet Union showed newsreels and clips of Chiang. At Moscow, Sun Yat-sen University portraits of Chiang were hung on the walls; and, in the Soviet May Day Parades that year, Chiang's portrait was to be carried along with the portraits of Karl Marx, Friedrich Engels, Vladimir Lenin, Joseph Stalin, Mao Zedong, Ho Chi Minh and other Communist leaders. The United States consulate and other Westerners in Shanghai were concerned about the approach of \"Red General\" Chiang as his army was seizing control of large areas of the country in the Northern Expedition.\nOn 12 April 1927, Chiang carried out a purge of thousands of suspected Communists and dissidents in Shanghai, and began large-scale massacres across the country collectively known as the \"White Terror\". During April, more than people were killed in Shanghai. The killings drove most Communists from urban cities and into the rural countryside, where the KMT was less powerful. In the year after April 1927, over 300,000 people died across China in anti-Communist suppression campaigns, executed by the KMT. One of the most famous quotes from Chiang (during that time) was that he would rather mistakenly kill 1,000 innocent people rather than allow one Communist to escape. Some estimates claim the White Terror in China took millions of lives, most of them in the rural areas. No concrete number can be verified. Chiang allowed Soviet agent and advisor Mikhail Borodin and Soviet general Vasily Bl\u00fccher (Galens) to \"escape\" to safety after the purge.\nRule.\nHaving gained control of China, Chiang's party remained surrounded by \"surrendered\" warlords who remained relatively autonomous within their own regions. On 10 October 1928, Chiang was named director of the State Council, the equivalent to President of the country, in addition to his other titles. As with his predecessor Sun Yat-sen, the Western media dubbed him \"Generalissimo\".\nAccording to Sun Yat-sen's plans, the Kuomintang (KMT) was to rebuild China in three steps: military rule, political tutelage, and constitutional rule. The ultimate goal of the KMT revolution was democracy, which was not considered to be feasible in China's fragmented state. Since the KMT had completed the first step of revolution through seizure of power in 1928, Chiang's rule thus began a period of what his party considered to be \"political tutelage\" in Sun Yat-sen's name. During this so-called Republican Era, many features of a modern, functional Chinese state emerged and developed.\nFrom 1928 to 1937, a time period known as the Nanjing decade, some aspects of foreign imperialism, concessions and privileges in China were moderated through diplomacy. The government acted to modernize the legal and penal systems, attempted to stabilize prices, amortize debts, reform the banking and currency systems, build railroads and highways, improve public health facilities, legislate against traffic in narcotics, and augment industrial and agricultural production. Not all of these projects were successfully completed. Efforts were made towards improving education standards, and in an effort to unify Chinese society, the New Life Movement was launched to encourage Confucian moral values and personal discipline. \"Guoyu\" (\"national language\") was promoted as a standard tongue, and the establishment of communications facilities (including radio) were used to encourage a sense of Chinese nationalism in a way that was not possible when the nation lacked an effective central government.\nAny successes that the Nationalists did make, however, were met with constant political and military upheavals. While much of the urban areas were now under the control of the KMT, much of the countryside remained under the influence of weakened yet undefeated warlords and Communists. Chiang often resolved issues of warlord obstinacy through military action, but such action was costly in terms of men and material. The 1930 Central Plains War alone nearly bankrupted the Nationalist government and caused almost casualties on both sides. In 1931, Hu Hanmin, Chiang's old supporter, publicly voiced a popular concern that Chiang's position as both premier and president flew in the face of the democratic ideals of the Nationalist government. Chiang had Hu put under house arrest, but he was released after national condemnation, after which he left Nanjing and supported a rival government in Canton. The split resulted in a military conflict between Hu's Kwangtung government and Chiang's Nationalist government. Chiang only won the campaign against Hu after a shift in allegiance by Zhang Xueliang, who had previously supported Hu Hanmin.\nThroughout his rule, complete eradication of the Communists remained Chiang's dream. After assembling his forces in Jiangxi, Chiang led his armies against the newly established Chinese Soviet Republic. With help from foreign military advisers, Chiang's Fifth Campaign finally surrounded the Chinese Red Army in 1934. The Communists, tipped off that a Nationalist offensive was imminent, retreated in the Long March, during which Mao Zedong rose from a mere military official to the most influential leader of the Chinese Communist Party.\nChiang, as a nationalist and a Confucianist, was against the iconoclasm of the May Fourth Movement. Motivated by his sense of nationalism, he viewed some Western ideas as foreign, and he believed that the great introduction of Western ideas and literature that the May Fourth Movement promoted was not beneficial to China. He and Dr. Sun criticized the May Fourth intellectuals as corrupting the morals of China's youth.\nContrary to Communist propaganda that he was pro-capitalism, Chiang antagonized the capitalists of Shanghai, often attacking them and confiscating their capital and assets for the use of the government. Chiang confiscated the wealth of capitalists even while he denounced and fought against communists. Chiang crushed pro-communist worker and peasant organizations and rich Shanghai capitalists at the same time. Chiang continued the anti-capitalist ideology of Sun Yat-sen, directing Kuomintang media to openly attack capitalists and capitalism, while demanding government controlled industry instead.\nChiang has often been interpreted as being pro-capitalism, but this conclusion may be problematic. Shanghai capitalists did briefly support him out of fear of communism in 1927, but this support eroded in 1928 when Chiang turned his tactics of intimidation on them. The relationship between Chiang Kai-shek and Chinese capitalists remained poor throughout the period of his administration. Chiang blocked Chinese capitalists from gaining any political power or voice within his regime. Once Chiang Kai-shek was done with his White Terror on pro-communist laborers, he proceeded to turn on the capitalists. Gangster connections allowed Chiang to attack them in the International Settlement, successfully forcing capitalists to back him up with their assets for his military expeditions.\nChiang viewed all of the foreign great powers with suspicion, writing in a letter that they \"all have it in their minds to promote the interests of their own respective countries at the cost of other nations\" and seeing it as hypocritical for any of them to condemn each other's foreign policy. He utilized diplomatic persuasion on the United States, Germany, and the Soviet Union to regain lost Chinese territories as he viewed all foreign powers as imperialists who were attempting to curtail and suppress China's power and national resurrection.\nMass deaths under Nationalist rule.\nSome sources attribute Chiang Kai-shek with responsibility for millions of deaths in scattered mass death events caused by the Nationalist Government of China. He has been deemed partially responsible for the man-made 1938 Yellow River flood, which killed hundreds of thousands of Chinese civilians in order to fend off a Japanese advance. This accusation is usually sourced from Rudolph Rummel who was referring to the Nationalist regime as whole rather than Chiang Kai-Shek in particular. Regardless, the Nationalist government of China has been accused by Rummel of mass killings; he alleged that, based on various claims, the Nationalist government of China was responsible for between 6 and 18.5 million deaths.\nHe attributes this death toll to a few major causes, for example:\nFirst phase of the Chinese Civil War.\nIn Nanjing, on April 1931, Chiang Kai-shek attended a national leadership conference with Zhang Xueliang and General Ma Fuxiang, in which Chiang and Zhang dauntlessly upheld that Manchuria was part of China in the face of the Japanese invasion. After the Japanese invasion of Manchuria in 1931, Chiang resigned as Chairman of the National Government. He returned shortly afterwards, adopting the slogan \"first internal pacification, then external resistance\". However, this policy of avoiding a frontal war against the Japanese was widely unpopular. In 1932, while Chiang was seeking first to defeat the Communists, Japan launched an advance on Shanghai and bombarded Nanjing. This disrupted Chiang's offensives against the Communists for a time, although it was the northern factions of Hu Hanmin's Kwangtung government (notably the 19th Route Army) that primarily led the offensive against the Japanese during this skirmish. Brought into the Nationalist army immediately after the battle, the 19th Route Army's career under Chiang would be cut short after it was disbanded for demonstrating socialist tendencies.\nIn December 1936, Chiang flew to Xi'an to coordinate a major assault on the Red Army and the Communist Republic that had retreated into Yan'an. However, Chiang's allied commander Zhang Xueliang, whose forces were used in his attack and whose homeland of Manchuria had been recently invaded by the Japanese, did not support the attack on the Communists. On 12 December, Zhang and several other Nationalist generals headed by Yang Hucheng of Shaanxi kidnapped Chiang for two weeks in what is known as the Xi'an Incident. They forced Chiang into making a \"Second United Front\" with the Communists against Japan. After releasing Chiang and returning to Nanjing with him, Zhang was placed under house arrest and the generals who had assisted him were executed. Chiang's commitment to the Second United Front was nominal at best, and it was all but broken up in 1941.\nSecond Sino-Japanese War.\nThe Second Sino-Japanese War broke out in July 1937, and in August of that year Chiang sent of his best-trained and equipped soldiers to defend Shanghai. With over 200,000 Chinese casualties, Chiang lost the political cream of his Whampoa-trained officers. Although Chiang lost militarily, the battle dispelled Japanese claims that it could conquer China in three months and demonstrated to the Western powers that the Chinese would continue the fight. By December, the capital city of Nanjing had fallen to the Japanese resulting in the Nanking Massacre. Chiang moved the government inland, first to Wuhan and later to Chongqing.\nHaving lost most of China's economic and industrial centers, Chiang withdrew into the hinterlands, stretching the Japanese supply lines and bogging down Japanese soldiers in the vast Chinese interior. As part of a policy of protracted resistance, Chiang authorized the use of scorched earth tactics, resulting in many civilian deaths. During the Nationalists' retreat from Zhengzhou, the dams around the city were deliberately destroyed by the Nationalist army in order to delay the Japanese advance, killing 500,000 people in the subsequent 1938 Yellow River flood.\nAfter heavy fighting, the Japanese occupied Wuhan in the fall of 1938 and the Nationalists retreated farther inland, to Chongqing. While en route to Chongqing, the Nationalist army intentionally started the \"fire of Changsha\", as a part of the scorched earth policy. The fire destroyed much of the city, killed twenty thousand civilians, and left hundreds of thousands of people homeless. Due to an organizational error (it was claimed), the fire was begun without any warning to the residents of the city. The Nationalists eventually blamed three local commanders for the fire and executed them. Newspapers across China blamed the fire on (non-KMT) arsonists, but the blaze contributed to a nationwide loss of support for the KMT.\nIn 1939 Muslim leaders Isa Yusuf Alptekin and Ma Fuliang were sent by Chiang to several Middle Eastern countries, including Egypt, Turkey, and Syria, to gain support for the Chinese War against Japan, and to express his support for Muslims.\nThe Japanese, controlling the puppet-state of Manchukuo and much of China's eastern seaboard, appointed Wang Jingwei as a Quisling-ruler of the occupied Chinese territories around Nanjing. Wang named himself President of the Executive Yuan and Chairman of the National Government (not the same 'National Government' as Chiang's), and led a surprisingly large minority of anti-Chiang/anti-Communist Chinese against his old comrades. He died in 1944, within a year of the end of World War II.\nThe Hui Muslim Xidaotang sect pledged allegiance to the Kuomintang after their rise to power and Hui Muslim General Bai Chongxi acquainted Chiang Kaishek with the Xidaotang jiaozhu Ma Mingren in 1941 in Chongqing.\nIn 1942 Generalissimo Chiang Kai-shek went on tour in northwestern China in Xinjiang, Gansu, Ningxia, Shaanxi, and Qinghai, where he met both Muslim Generals Ma Buqing and Ma Bufang. He also met the Muslim Generals Ma Hongbin and Ma Hongkui separately.\nA border crisis erupted with Tibet in 1942. Under orders from Chiang, Ma Bufang repaired Yushu airport to prevent Tibetan separatists from seeking independence. Chiang also ordered Ma Bufang to put his Muslim soldiers on alert for an invasion of Tibet in 1942. Ma Bufang complied and moved several thousand troops to the border with Tibet. Chiang also threatened the Tibetans with aerial bombardment if they worked with the Japanese. Ma Bufang attacked the Tibetan Buddhist Tsang monastery in 1941. He also constantly attacked the Labrang monastery.\nWith the attack on Pearl Harbor and the opening of the Pacific War, China became one of the Allied Powers. During and after World War II, Chiang and his American-educated wife Soong Mei-ling, known in the United States as \"Madame Chiang\", held the support of the China Lobby in the United States, which saw in them the hope of a Christian and democratic China. Chiang was even named the Supreme Commander of Allied forces in the China war zone. He was appointed Knight Grand Cross of the Order of the Bath in 1942.\nGeneral Joseph Stilwell, an American military adviser to Chiang during World War II, strongly criticized Chiang and his generals for what he saw as their incompetence and corruption. In 1944, the United States Army Air Corps commenced Operation Matterhorn in order to bomb Japan's steel industry from bases to be constructed in mainland China. This was meant to fulfill President Roosevelt's promise to Chiang Kai-shek to begin bombing operations against Japan by November 1944. However, Chiang Kai-shek's subordinates refused to take airbase construction seriously until enough capital had been delivered to permit embezzlement on a massive scale. Stilwell estimated that at least half of the $100\u00a0million spent on construction of airbases was embezzled by Nationalist party officials.\nChiang played the Soviets and Americans against each other during the war. He first told the Americans that they would be welcome in talks between the Soviet Union and China, then secretly told the Soviets that the Americans were unimportant and that their opinions would not be considered. Chiang also used American support and military power in China against the ambitions of the Soviet Union to dominate the talks, stopping the Soviets from taking full advantage of the situation in China with the threat of American military action against the Soviets.\nFrench Indochina.\nU.S. President Franklin D. Roosevelt, through General Stilwell, privately made it clear that they preferred that the French not reacquire French Indochina (modern day Vietnam, Cambodia and Laos) after the war was over. Roosevelt offered Chiang control of all of Indochina. It was said that Chiang replied: \"Under no circumstances!\"\nAfter the war, 200,000 Chinese troops under General Lu Han were sent by Chiang Kai-shek to northern Indochina (north of the 16th parallel) to accept the surrender of Japanese occupying forces there, and remained in Indochina until 1946, when the French returned. The Chinese used the VNQDD, the Vietnamese branch of the Chinese Kuomintang, to increase their influence in Indochina and to put pressure on their opponents. Chiang Kai-shek threatened the French with war in response to maneuvering by the French and Ho Chi Minh's forces against each other, forcing them to come to a peace agreement. In February 1946 he also forced the French to surrender all of their concessions in China and to renounce their extraterritorial privileges in exchange for the Chinese withdrawing from northern Indochina and allowing French troops to reoccupy the region. Following France's agreement to these demands, the withdrawal of Chinese troops began in March 1946.\nRyukyus.\nDuring the Cairo Conference in 1943, Chiang said that Roosevelt asked him whether China would like to claim the Ryukyu Islands from Japan in addition to retaking Taiwan, the Pescadores, and Manchuria. Chiang claims that he said he was in favor of an international presence on the islands. However, the U.S. became the sole protector of the Ryukyus in 1945, and reverted it to the Japanese in 1972 while securing US military presence there.\nSecond phase of the Chinese Civil War.\nTreatment and use of Japanese soldiers.\nIn 1945, when Japan surrendered, Chiang's Chongqing government was ill-equipped and ill-prepared to reassert its authority in formerly Japanese-occupied China, and it asked the Japanese to postpone their surrender until Kuomintang (KMT) authority could arrive to take over. American troops and weapons soon bolstered KMT forces, allowing them to reclaim cities. The countryside, however, remained largely under Communist control.\nFor over a year after the Japanese surrender, rumors circulated throughout China that the Japanese had entered into a secret agreement with Chiang, in which the Japanese would assist the Nationalists in fighting the Communists in exchange for the protection of Japanese persons and property there. Many top nationalist generals, including Chiang, had studied and trained in Japan before the Nationalists had returned to the mainland in the 1920s, and maintained close personal friendships with top Japanese officers. The Japanese general in charge of all forces in China, General Yasuji Okamura, had personally trained officers who later became generals in Chiang's staff. Reportedly, General Okamura, before surrendering command of all Japanese military forces in Nanjing, offered Chiang control of all 1.5\u00a0million Japanese military and civilian support staff then present in China. Reportedly, Chiang seriously considered accepting this offer, but declined only in the knowledge that the United States would certainly be outraged by the gesture. Even so, armed Japanese troops remained in China well into 1947, with some noncommissioned officers finding their way into the Nationalist officer corps. That the Japanese in China came to regard Chiang as a magnanimous figure to whom many Japanese owed their lives and livelihoods was a fact attested by both Nationalist and Communist sources.\nConditions during the Chinese Civil War.\nWestad says the Communists won the Civil War because they made fewer military mistakes than Chiang Kai-Shek, and because in his search for a powerful centralized government, Chiang antagonized too many interest groups in China. Furthermore, his party was weakened in the war against Japan. Meanwhile, the Communists told different groups, such as peasants, exactly what they wanted to hear, and cloaked themselves in the cover of Chinese Nationalism.\nFollowing the war, the United States encouraged peace talks between Chiang and Communist leader Mao Zedong in Chongqing. Due to concerns about widespread and well-documented corruption in Chiang's government throughout his rule, the U.S. government limited aid to Chiang for much of the period of 1946 to 1948, in the midst of fighting against the People's Liberation Army led by Mao Zedong. Alleged infiltration of the U.S. government by Chinese Communist agents may have also played a role in the suspension of American aid.\nChiang's right-hand man, the secret police Chief Dai Li, was both anti-American and anti-Communist. Dai ordered Kuomintang agents to spy on American officers. Earlier, Dai had been involved with the Blue Shirts Society, a fascist-inspired paramilitary group within the Kuomintang, which wanted to expel Western and Japanese imperialists, crush the Communists, and eliminate feudalism. Dai Li died in a plane crash, which was suspected to be an assassination orchestrated by Chiang.\nAlthough Chiang had achieved status abroad as a world leader, his government deteriorated as the result of corruption and inflation. In his diary on June 1948, Chiang wrote that the KMT had failed, not because of external enemies but because of rot from within. The war had severely weakened the Nationalists, while the Communists were strengthened by their popular land-reform policies, and by a rural population that supported and trusted them. The Nationalists initially had superiority in arms and men, but their lack of popularity, infiltration by Communist agents, low morale, and disorganization soon allowed the Communists to gain the upper hand in the civil war.\nCompetition with Li Zongren.\nA new Constitution was promulgated in 1947, and Chiang was elected by the National Assembly as the first term President of the Republic of China on 20 May 1948. This marked the beginning of what was termed the \"democratic constitutional government\" period by the KMT political orthodoxy, but the Communists refused to recognize the new Constitution, and its government, as legitimate. Chiang resigned as President on 21 January 1949, as KMT forces suffered terrible losses and defections to the Communists. After Chiang's resignation the vice-president of the ROC, Li Zongren, became China's acting president.\nShortly after Chiang's resignation the Communists halted their advances and attempted to negotiate the virtual surrender of the ROC. Li attempted to negotiate milder terms that would have ended the civil war, but without success. When it became clear that Li was unlikely to accept Mao's terms, the Communists issued an ultimatum in April 1949, warning that they would resume their attacks if Li did not agree within five days. Li refused.\nLi's attempts to carry out his policies faced varying degrees of opposition from Chiang's supporters, and were generally unsuccessful. Chiang especially antagonized Li by taking possession of (and moving to Taiwan) US$200\u00a0million of gold and US dollars belonging to the central government that Li desperately needed to cover the government's soaring expenses. When the Communists captured the Nationalist capital of Nanjing in April 1949, Li refused to accompany the central government as it fled to Guangdong, instead expressing his dissatisfaction with Chiang by retiring to Guangxi.\nThe former warlord Yan Xishan, who had fled to Nanjing only one month before, quickly insinuated himself within the Li-Chiang rivalry, attempting to have Li and Chiang reconcile their differences in the effort to resist the Communists. At Chiang's request Yan visited Li in order to convince Li not to withdraw from public life. Yan broke down in tears while talking of the loss of his home province of Shanxi to the Communists, and warned Li that the Nationalist cause was doomed unless Li went to Guangdong. Li agreed to return under the condition that Chiang surrender most of the gold and US dollars in his possession that belonged to the central government, and that Chiang stop overriding Li's authority. After Yan communicated these demands and Chiang agreed to comply with them, Li departed for Guangdong.\nIn Guangdong, Li attempted to create a new government composed of both Chiang supporters and those opposed to Chiang. Li's first choice of premier was Chu Cheng, a veteran member of the Kuomintang who had been virtually driven into exile due to his strong opposition to Chiang. After the Legislative Yuan rejected Chu, Li was obliged to choose Yan Xishan instead. By this time Yan was well known for his adaptability and Chiang welcomed his appointment.\nConflict between Chiang and Li persisted. Although he had agreed to do so as a prerequisite of Li's return, Chiang refused to surrender more than a fraction of the wealth that he had sent to Taiwan. Without being backed by gold or foreign currency, the money issued by Li and Yan quickly declined in value until it became virtually worthless.\nAlthough he did not hold a formal executive position in the government, Chiang continued to issue orders to the army, and many officers continued to obey Chiang rather than Li. The inability of Li to coordinate KMT military forces led him to put into effect a plan of defense that he had contemplated in 1948. Instead of attempting to defend all of southern China, Li ordered what remained of the Nationalist armies to withdraw to Guangxi and Guangdong, hoping that he could concentrate all available defenses on this smaller, and more easily defensible, area. The object of Li's strategy was to maintain a foothold on the Chinese mainland in the hope that the United States would eventually be compelled to enter the war in China on the Nationalist side.\nFinal Communist advance.\nChiang opposed Li's plan of defense because it would have placed most of the troops still loyal to Chiang under the control of Li and Chiang's other opponents in the central government. To overcome Chiang's intransigence Li began ousting Chiang's supporters within the central government. Yan Xishan continued in his attempts to work with both sides, creating the impression among Li's supporters that he was a \"stooge\" of Chiang, while those who supported Chiang began to bitterly resent Yan for his willingness to work with Li. Because of the rivalry between Chiang and Li, Chiang refused to allow Nationalist troops loyal to him to aid in the defense of Kwangsi and Canton, with the result that Communist forces occupied Canton in October 1949.\nAfter Canton fell to the Communists, Chiang relocated the government to Chongqing, while Li effectively surrendered his powers and flew to New York for treatment of his chronic duodenum illness at the Hospital of Columbia University. Li visited the President of the United States, Harry S. Truman, and denounced Chiang as a dictator and an usurper. Li vowed that he would \"return to crush\" Chiang once he returned to China. Li remained in exile, and did not return to Taiwan.\nIn the early morning of 10 December 1949, Communist troops laid siege to Chengdu, the last KMT-controlled city in mainland China, where Chiang Kai-shek and his son Chiang Ching-kuo directed the defense at the Chengtu Central Military Academy. Flying out of Chengdu Fenghuangshan Airport, Chiang Kai-shek, father and son, were evacuated to Taiwan via Guangdong on an aircraft called \"May-ling\" and arrived the same day. Chiang Kai-shek would never return to the mainland.\nChiang did not re-assume the presidency until 1 March 1950. On January 1952, Chiang commanded the Control Yuan, now in Taiwan, to impeach Li in the \"Case of Li Zongren's Failure to carry out Duties due to Illegal Conduct\" (\u674e\u5b97\u4ec1\u9055\u6cd5\u5931\u8077\u6848). Chiang relieved Li of the position as vice-president in the National Assembly in March 1954.\nOn Taiwan.\nPreparations to retake the mainland.\nChiang moved the government to Taipei, Taiwan, where he resumed his duties as President of the Republic of China on 1 March 1950. Chiang was reelected by the National Assembly to be the President of the Republic of China (ROC) on 20 May 1954, and again in 1960, 1966, and 1972. He continued to claim sovereignty over all of China, including the territories held by his government and the People's Republic, as well as territory the latter ceded to foreign governments, such as Tuva and Outer Mongolia. In the context of the Cold War, most of the Western world recognized this position and the ROC represented China in the United Nations and other international organizations until the 1970s.\nDuring his presidency on Taiwan, Chiang continued making preparations in order to take back mainland China. He developed the ROC army in order to prepare for an invasion of the mainland, and to defend Taiwan in case of an attack by the Communist forces. He also financed armed groups in mainland China, such as Muslim soldiers of the ROC Army left in Yunnan under Li Mi, who continued to fight. It was not until the 1980s that these troops were finally airlifted to Taiwan. He promoted the Uyghur Yulbars Khan to Governor during the Islamic insurgency on the mainland for resisting the Communists, even though the government had already evacuated to Taiwan. He planned an invasion of the mainland in 1962. In the 1950s Chiang's airplanes dropped supplies to Kuomintang Muslim insurgents in Amdo.\nRegime.\nDespite the democratic constitution, the government under Chiang was a one-party state, consisting almost completely of mainlanders; the \"Temporary Provisions Effective During the Period of Communist Rebellion\" greatly enhanced executive powers, and the goal of retaking mainland China allowed the KMT to maintain a monopoly on power and the prohibition of opposition parties. The government's official line for these martial law provisions stemmed from the claim that emergency provisions were necessary, since the Communists and KMT were still in a state of war. Seeking to promote Chinese nationalism, Chiang's government actively ignored and suppressed local cultural expression, even forbidding the use of local languages in mass media broadcasts or during class sessions. As a result of Taiwan's anti-government uprising in 1947, known as the February 28 incident, the KMT-led political repression resulted in the death or disappearance of over 30,000 Taiwanese intellectuals, activists, and people suspected of opposition to the KMT.\nThe first decades after the Nationalists moved the seat of government to the province of Taiwan are associated with the organized effort to resist Communism known as the \"White Terror\", during which about 140,000 Taiwanese were imprisoned for their real or perceived opposition to the Kuomintang. Most of those prosecuted were labeled by the Kuomintang as \"bandit spies\" (\u532a\u8adc), meaning spies for Chinese Communists, and punished as such.\nUnder Chiang, the government recognized limited civil liberties, economic freedoms, property rights (personal and intellectual) and other liberties. Despite these restrictions, free debate within the confines of the legislature was permitted. Under the pretext that new elections could not be held in Communist-occupied constituencies, the National Assembly, Legislative Yuan, and Control Yuan members held their posts indefinitely. The Temporary Provisions also allowed Chiang to remain as president beyond the two-term limit in the Constitution. He was reelected by the National Assembly as president four times\u2014doing so in 1954, 1960, 1966, and 1972.\nBelieving that corruption and a lack of morals were key reasons that the KMT lost mainland China to the Communists, Chiang attempted to purge corruption by dismissing members of the KMT accused of graft. Some major figures in the previous mainland Chinese government, such as Chiang's brothers-in-law H. H. Kung and T. V. Soong, exiled themselves to the United States. Although politically authoritarian and, to some extent, dominated by government-owned industries, Chiang's new Taiwanese state also encouraged economic development, especially in the export sector. A popular sweeping Land Reform Act, as well as American foreign aid during the 1950s, laid the foundation for Taiwan's economic success, becoming one of the Four Asian Tigers.\nChiang personally had the power to review the rulings of all military tribunals which during the martial law period tried civilians as well. In 1950 Lin Pang-chun and two other men were arrested on charges of financial crimes and sentenced to 3\u201310 years in prison. Chiang reviewed the sentences of all three and ordered them executed instead. In 1954 Changhua monk Kao Chih-te and two others were sentenced to 12 years in prison for providing aid to accused communists, Chiang sentenced them to death after reviewing the case. This control over the decision of military tribunals violated the ROC constitution.\nAfter Chiang's death, the next president, his son, Chiang Ching-kuo, and Chiang Ching-kuo's successor, Lee Teng-hui, a native Taiwanese, would in the 1980s and 1990s increase native Taiwanese representation in the government and loosen the many authoritarian controls of the early era of ROC control in Taiwan.\nRelationship with Japan.\nIn 1971, the Australian Opposition Leader Gough Whitlam, who became Prime Minister in 1972 and swiftly relocated the Australian mission from Taipei to Beijing, visited Japan. After meeting with the Japanese Prime Minister, Eisaku Sato, Whitlam observed that the reason Japan at that time was hesitant to withdraw recognition from the Nationalist government was \"the presence of a treaty between the Japanese government and that of Chiang Kai-shek\". Sato explained that the continued recognition of Japan towards the Nationalist government was due largely to the personal relationship that various members of the Japanese government felt towards Chiang. This relationship was rooted largely in the generous and lenient treatment of Japanese prisoners-of-war by the Nationalist government in the years immediately following the Japanese surrender in 1945, and was felt especially strongly as a bond of personal obligation by the most senior members then in power.\nAlthough Japan recognized the People's Republic in 1972, shortly after Kakuei Tanaka succeeded Sato as Prime Minister of Japan, the memory of this relationship was strong enough to be reported by \"The New York Times\" (15 April 1978) as a significant factor inhibiting trade between Japan and the mainland. There is speculation that a clash between Communist forces and a Japanese warship in 1978 was caused by Chinese anger after Prime Minister Takeo Fukuda attended Chiang's funeral. Historically, Japanese attempts to normalize their relationship with the People's Republic were met with accusations of ingratitude in Taiwan.\nRelationship with the United States.\nChiang was suspicious that covert operatives of the United States plotted a coup against him.\nIn 1950, Chiang Ching-kuo became director of the secret police (Bureau of Investigation and Statistics), which he remained until 1965. Chiang was also suspicious of politicians who were overly friendly to the United States, and considered them his enemies. In 1953, seven days after surviving an assassination attempt, Wu Kuo-chen lost his position as governor of Taiwan Province to Chiang Ching-kuo. After fleeing to United States the same year, he became a vocal critic of Chiang's family and government.\nChiang Ching-kuo, educated in the Soviet Union, initiated Soviet-style military organization in the Republic of China Military. He reorganized and Sovietized the political officer corps, and propagated Kuomintang ideology throughout the military. Sun Li-jen, who was educated at the American Virginia Military Institute, was opposed to this.\nChiang Ching-kuo orchestrated the controversial court-martial and arrest of General Sun Li-jen in August 1955, for plotting a coup d'\u00e9tat with the American Central Intelligence Agency (CIA) against his father Chiang Kai-shek and the Kuomintang. The CIA allegedly wanted to help Sun take control of Taiwan and declare its independence.\nDeath.\nIn 1975, 26 years after Chiang came to Taiwan, he died in Taipei at the age of 87. He had suffered a heart attack and pneumonia in the foregoing months and died from renal failure aggravated with advanced cardiac failure on 5 April. Chiang's funeral was held on April 16.\nA month of mourning was declared. Chinese music composer Hwang Yau-tai wrote the Chiang Kai-shek Memorial Song. In mainland China, however, Chiang's death was met with little apparent mourning and Communist state-run newspapers gave the brief headline \"Chiang Kai-shek Has Died.\" Chiang's body was put in a copper coffin and temporarily interred at his favorite residence in Cihu, Daxi, Taoyuan. His funeral was attended by dignitaries from many nations, including American Vice President Nelson Rockefeller, South Korean Prime Minister Kim Jong-pil and two former Japanese prime ministers : Nobusuke Kishi and Eisaku Sato. Chiang Kai-shek Memorial Day () was established on April 5. The memorial day was disestablished in 2007.\nWhen his son Chiang Ching-kuo died in 1988, he was entombed in a separate mausoleum in nearby Touliao (\u982d\u5bee). The hope was to have both buried at their birthplace in Fenghua if and when it was possible. In 2004, Chiang Fang-liang, the widow of Chiang Ching-kuo, asked that both father and son be buried at Wuzhi Mountain Military Cemetery in Xizhi, Taipei County (now New Taipei City). Chiang's ultimate funeral ceremony became a political battle between the wishes of the state and the wishes of his family.\nChiang was succeeded as President by Vice President Yen Chia-kan and as Kuomintang party ruler by his son Chiang Ching-kuo, who retired Chiang Kai-shek's title of Director-General and instead assumed the position of Chairman. Yen's presidency was interim; Chiang Ching-kuo, who was the Premier, became President after Yen's term ended three years later.\nCult of personality.\nChiang's portrait hung over Tiananmen Square before Mao's portrait was set up in its place. People also put portraits of Chiang in their homes and in public on the streets.\nAfter his death, the Chiang Kai-shek Memorial Song was written in 1988 to commemorate Chiang Kai-shek.\nIn Cihu, there are several statues of Chiang Kai-shek.\nChiang was popular among many people and dressed in plain, simple clothes, unlike contemporary Chinese warlords who dressed extravagantly.\nQuotes from the Quran and Hadith were used by Muslims in the Kuomintang-controlled Muslim publication, the \"Yuehua\", to justify Chiang Kai-shek's rule over China.\nWhen the Muslim General and Warlord Ma Lin was interviewed, Ma Lin was described as having \"high admiration for and unwavering loyalty to Chiang Kai-shek\".\nIn the Philippines, a school was named in his honour in 1939. Today, Chiang Kai-shek College is the largest educational institution for the Chinoy community in the country.\nPhilosophy.\nThe Kuomintang used traditional Chinese religious ceremonies, and promulgated/practised martyrdom in Chinese culture. Kuomintang ideology subserved and promulgated the view that the souls of Party martyrs who died fighting for the Kuomintang, the revolution, and the party founder Dr. Sun Yat-sen were sent to heaven. Chiang Kai-shek believed that these martyrs witnessed events on Earth from heaven after their deaths.\nWhen the Northern Expedition was complete, Kuomintang Generals led by Chiang Kai-shek paid tribute to Dr. Sun's soul in heaven with a sacrificial ceremony at the Xiangshan Temple in Beijing in July 1928. Among the Kuomintang Generals present were the Muslim Generals Bai Chongxi and Ma Fuxiang.\nChiang Kai-shek considered both Han Chinese and all ethnic minorities of China, the Five Races Under One Union, as descendants of the Yellow Emperor, the mythical founder of the Chinese nation, and belonging to the Chinese Nation Zhonghua Minzu and he introduced this into Kuomintang ideology, which was propagated into the educational system of the Republic of China.\nContemporary public perception.\nChiang's legacy has been the target of heated debates because of the different views held about him. For some, Chiang was a national hero who led the victorious Northern Expedition against the Beiyang Warlords in 1927, achieving Chinese unification, and who subsequently led China to ultimate victory against Japan in 1945. Some blamed him for not doing enough against the Japanese forces in the lead-up to, and during, the Second Sino-Japanese War, preferring to withhold his armies for the fight against the Communists, or merely waiting and hoping that the United States would get involved. Some also see him as a champion of anti-Communism, being a key figure during the formative years of the World Anti-Communist League. During the Cold War, he was also seen as the leader who led Free China and the bulwark against a possible Communist invasion. However, Chiang presided over purges, political authoritarianism, and graft during his tenure in mainland China, and ruled throughout a period of imposed martial law. His governments were accused of being corrupt even before he even took power in 1928. He also allied with known criminals like Du Yuesheng for political and financial gains. Some opponents charge that Chiang's efforts in developing Taiwan were mostly to make the island a strong base from which to one day return to mainland China, and that Chiang had little regard for the long-term prosperity and well-being of the Taiwanese people.\nToday, Chiang's popularity in Taiwan is divided along political lines, enjoying greater support among Kuomintang (KMT) supporters. He is generally unpopular among Democratic Progressive Party (DPP) voters and supporters who blame him for the thousands killed during the February 28 Incident and criticise his subsequent dictatorial rule. In sharp contrast to his son, Chiang Ching-kuo, and to Sun Yat-sen, his memory is rarely invoked by current political parties, including the Kuomintang. In contrast, his image has been rehabilitated in contemporary Mainland China. Until recently portrayed as a villain who fought against the \"liberation\" of China by the Communists, since the 2000s, he has been portrayed by the media in a neutral or slightly positive light as a Chinese nationalist who tried to bring about national unification and resisted the Japanese invasion during World War II. This shift is largely in response to current political landscape of Taiwan, in relation to Chiang's commitment to a unified China and his stance against Taiwanese separatism during his rule of the island, along with the recent d\u00e9tente between the Chinese Communist Party (CCP) and Chiang's KMT. In contrast to efforts to remove his public monuments in Taiwan, his ancestral home in Fenghua, Zhejiang on the Mainland has become a commemorative museum and major tourist attraction.\nIn the United States and Europe, Chiang was often perceived negatively as the one who lost China to the Communists. His constant demands for Western support and funding also earned him the nickname of \"General Cash-My-Check\". In the West he has been criticized for his poor military skills. He had a record of issuing unrealistic orders and persistently attempting to fight unwinnable battles, leading to the loss of his best troops.\nIn recent years, there has been an attempt to find a more moderate interpretation of Chiang. Chiang is now increasingly perceived as a man simply overwhelmed by the events in China, having to fight simultaneously Communists, Japanese, and provincial warlords while having to reconstruct and unify the country. His sincere, albeit often unsuccessful attempts to build a more powerful nation have been noted by scholars such as Jonathan Fenby and Rana Mitter. Mitter has observed that, ironically, today's China is closer to Chiang's vision than to Mao Zedong's. He argues that the Communists, since the 1980s, have essentially created the state envisioned by Chiang in the 1930s. Mitter concludes by writing that \"one can imagine Chiang Kai-shek's ghost wandering round China today nodding in approval, while Mao's ghost follows behind him, moaning at the destruction of his vision\". Liang Shuming opined that Chiang Kai-shek's \"greatest contribution was to make the CCP successful. If he had been a bit more trustworthy, if his character was somewhat better, the CCP would have been unable to beat him\".\n\"Formosa Betrayed\", one of the few American movies concerning the process of democratization in Taiwan, depicts Chiang Kai-shek as a brutal dictator, responsible for the execution of thousands of native Taiwanese during the days following the February 28 Incident.\nFamily.\nWives.\nIn 1901 in an arranged marriage at age 14, Chiang was married to a fellow villager named Mao Fumei who was illiterate and five years his senior. While married to Mao, Chiang adopted two concubines (concubinage was still a common practice for well-to-do, non-Christian males in China): he took Yao Yecheng (, 1887\u20131966) as concubine in late 1912 and married Chen Jieru (\u9673\u6f54\u5982, 1906\u20131971) in December 1921. While he was still living in Shanghai, Chiang and Yao adopted a son, Wei-kuo. Chen adopted a daughter in 1924, named Yaoguang (\u7464\u5149), who later adopted her mother's surname. Chen's autobiography refuted the idea that she was a concubine. Chen claiming that, by the time she married Chiang, he had already divorced Yao, and that Chen was therefore his wife. Chiang and Mao had a son, Ching-kuo.\nAccording to the memoirs of Chen Jieru, Chiang's second wife, she contracted gonorrhea from Chiang soon after their marriage. He told her that he acquired this disease after separating from his first wife and living with his concubine Yao Yecheng, as well as with many other women he consorted with. His doctor explained to her that Chiang had sex with her before completing his treatment for the disease. As a result, both Chiang and Ch'en Chieh-ju believed they had become sterile, which would explain why he had only one child, by his first wife; however, a purported miscarriage by Soong Mei-ling in August 1928 would, if it actually occurred, cast serious doubt on whether this was true.\nFamily tree.\nThe Xikou (Chikow) Chiangs were descended from Chiang Shih-chieh who during the 1600s (17th century) moved there from Fenghua district, whose ancestors in turn came to southeastern China's Zhejiang (Chekiang) province after moving out of Northern China in the 13th century AD. The 12th century BC Duke of Zhou's (Duke of Chou) third son was the ancestors of the Chiangs.\nHis great grandfather was Chiang Qi-zeng (Jiang Qizeng) \u8523\u7948\u589e, his grandfather was Chiang Si-qian \u8523\u65af\u5343, his uncle was Chiang Zhao-hai \u8523\u8087\u6d77, and his father was Chiang Zhao-cong (Jiang Zhaocong) \u8523\u8087\u8070.\nReligion and relationships with religious communities.\nChiang personally dealt extensively with religions and power figures in China during his regime.\nReligious views.\nChiang Kai-shek was born and raised as a Buddhist, but became a Methodist upon his marriage to his fourth wife, Soong Mei-ling. It was previously believed that this was a political move, but studies of his recently opened diaries suggest that his faith was sincere.\nRelationship with Muslims.\nChiang developed relationships with other generals. Chiang became a sworn brother of the Chinese Muslim general Ma Fuxiang and appointed him to high ranking positions. Chiang addressed Ma Fuxiang's son Ma Hongkui as Shao Yun Shixiong Ma Fuxiang attended national leadership conferences with Chiang during battles against Japan. Ma Hongkui was eventually scapegoated for the failure of the Ningxia Campaign against the Communists, so he moved to the US instead of remaining in Taiwan with Chiang.\nWhen Chiang became President of China after the Northern Expedition, he carved out Ningxia and Qinghai out of Gansu province, and appointed Muslim generals as military governors of all three provinces: Ma Hongkui, Ma Hongbin, and Ma Qi. The three Muslim governors, known as Xibei San Ma (lit. \"the three Mas of the Northwest\"), controlled armies composed entirely of Muslims. Chiang called on the three and their subordinates to wage war against the Soviet peoples, Tibetans, Communists, and the Japanese. Chiang continued to appoint Muslims as governors of the three provinces, including Ma Lin and Ma Fushou. Chiang's appointments, the first time that Muslims had been appointed as governors of Gansu, increased the prestige of Muslim officials in northwestern China. The armies raised by this \"Ma Clique\", most notably their Muslim cavalry, were incorporated into the KMT army. Chiang appointed a Muslim general, Bai Chongxi, as the Minister of National Defence of the Republic of China, which controlled the ROC military.\nChiang also supported the Muslim General Ma Zhongying, whom he had trained at Whampoa Military Academy during the Kumul Rebellion, in a Jihad against Jin Shuren, Sheng Shicai, and the Soviet Union during the Soviet Invasion of Xinjiang. Chiang designated Ma's Muslim army as the 36th Division (National Revolutionary Army) and gave his troops Kuomintang flags and uniforms. Chiang then supported Muslim General Ma Hushan against Sheng Shicai and the Soviet Union in the Xinjiang War (1937). All Muslim generals commissioned by Chiang in the National Revolutionary Army swore allegiance to him. Several, like Ma Shaowu and Ma Hushan were loyal to Chiang and Kuomintang hardliners.\nThe Ili Rebellion and Pei-ta-shan Incident plagued relations with the Soviet Union during Chiang's rule and caused trouble with the Uyghurs. During the Ili Rebellion and Peitashan incident, Chiang deployed Hui troops against Uyghur mobs in Turfan, and against Soviet Russian and Mongols at Peitashan.\nDuring Chiang's rule, attacks on foreigners by Kuomintang forces flared up in several incidents. One of these was the Battle of Kashgar where a Muslim army loyal to the Kuomintang massacred 4,500 Uyghurs, and killed several Britons at the British consulate in Kashgar.\nHu Songshan, a Muslim Imam, backed Chiang Kai-shek's regime and gave prayers for his government. ROC flags were saluted by Muslims in Ningxia during prayer along with exhortations to nationalism during Chiang's rule. Chiang sent Muslim students abroad to study at places like Al-Azhar University and Muslim schools throughout China taught loyalty to his regime.\nThe Yuehua, a Chinese Muslim publication, quoted the Quran and Hadith to justify submitting to Chiang Kai-shek as the leader of China, and as justification for Jihad in the war against Japan.\nThe Yihewani (Ikhwan al Muslimun a.k.a. Muslim brotherhood) was the predominant Muslim sect backed by the Chiang government during Chiang's regime. Other Muslim sects, like the Xidaotang and Sufi brotherhoods like Jahriyya and Khuffiya were also supported by his regime. The Chinese Muslim Association, a pro-Kuomintang and anti-Communist organization, was set up by Muslims working in his regime. Salafism attempted to gain a foothold in China during his regime, but the Yihewani and Hanafi Sunni Gedimu denounced the Salafis as radicals, engaged in fights against them, and declared them heretics, forcing the Salafis to form a separate sect. Ma Ching-chiang, a Muslim General, served as an advisor to Chiang Kai-shek. Ma Buqing was another Muslim General who fled to Taiwan along with Chiang. His government donated money to build the Taipei Grand Mosque on Taiwan.\nRelationship with Buddhists and Christians.\nChiang had uneasy relations with the Tibetans. He fought against them in the Sino-Tibetan War, and he supported the Muslim General Ma Bufang in his war against Tibetan rebels in Qinghai. Chiang ordered Ma Bufang to prepare his Islamic army to invade Tibet several times, to deter Tibetan independence, and threatened them with aerial bombardment. After the war, Chiang appointed Ma Bufang as ambassador to Saudi Arabia.\nChiang incorporated Methodist values into the New Life Movement under the influence of his wife. Dancing and Western music were discouraged. In one incident, several youths splashed acid on people wearing Western clothing, although Chiang was not directly responsible for these incidents. Despite being a Methodist, he made reference to the Buddha in his diary, and encouraged the establishment of a Buddhist political party under Master Taixu.\nAccording to Jehovah's Witnesses some of their members travelled to Chonqqing and spoke to him personally while distributing their literature there during the Second World War."}
{"id": "6863", "revid": "1015982206", "url": "https://en.wikipedia.org/wiki?curid=6863", "title": "Compression ratio", "text": "The compression ratio is the ratio between the volume of the cylinder and combustion chamber in an internal combustion engine at their maximum and minimum values.\nA fundamental specification for such engines, it is measured two ways: the static compression ratio, calculated based on the relative volumes of the combustion chamber and the cylinder when the piston is at the bottom of its stroke, and the volume of the combustion chamber when the piston is at the top of its stroke. \nThe dynamic compression ratio is a more advanced calculation which also takes into account gasses entering and exiting the cylinder during the compression phase. \nEffect and typical ratios.\nA high compression ratio is desirable because it allows an engine to extract more mechanical energy from a given mass of air\u2013fuel mixture due to its higher thermal efficiency. This occurs because internal combustion engines are heat engines, and higher compression ratios permit the same combustion temperature to be reached with less fuel, while giving a longer expansion cycle, creating more mechanical power output and lowering the exhaust temperature. \nPetrol engines.\nIn petrol (gasoline) engines used in passenger cars for the past 20 years, compression ratios have typically been between 8\u22361 and 12\u22361. Several production engines have used higher compression ratios, including:\nWhen forced induction (e.g. a turbocharger or supercharger) is used, the compression ratio is often lower than naturally aspirated engines. This is due to the turbocharger/supercharger already having compressed the air before it enters the cylinders. Engines using port fuel-injection typically run lower boost pressures and/or compression ratios than direct injected engines because port fuel injection causes the air/fuel mixture to be heated together, leading to detonation. Conversely, directly injected engines can run higher boost because heated air will not detonate without a fuel being present.\nHigher compression ratios can make gasoline (petrol) engines subject to engine knocking (also known as \"detonation\", \"pre-ignition\" or \"pinging\") if lower octane-rated fuel is used. This can reduce efficiency or damage the engine if knock sensors are not present to modify the ignition timing.\nDiesel engines.\nDiesel engines use higher compression ratios than petrol engines, because the lack of a spark plug means that the compression ratio must increase the temperature of the air in the cylinder sufficiently to ignite the diesel using compression ignition. Compression ratios are often between 14\u22361 and 23\u22361 for direct injection diesel engines, and between 18\u22361 and 23\u22361 for indirect injection diesel engines.\nOther fuels.\nThe compression ratio may be higher in engines running exclusively on liquefied petroleum gas (LPG or \"propane autogas\") or compressed natural gas, due to the higher octane rating of these fuels.\nKerosene engines typically use a compression ratio of 6.5 or lower. The petrol-paraffin engine version of the Ferguson TE20 tractor had a compression ratio of 4.5\u22361 for operation on tractor vaporising oil with an octane rating between 55 and 70.\nMotorsport engines.\nMotorsport engines often run on high octane petrol and can therefore use higher compression ratios. For example, motorcycle racing engines can use compression ratios as high as 14.7\u22361, and it is common to find motorcycles with compression ratios above 12.0\u22361 designed for 86 or 87 octane fuel.\nEthanol and methanol can take significantly higher compression ratios than gasoline. Racing engines burning methanol and ethanol fuel often have a compression ratio of 14\u22361 to 16\u22361.\nMathematical formula.\nIn a piston engine, the static compression ratio (formula_1) is the ratio between the volume of the cylinder and combustion chamber when the piston is at the bottom of its stroke, and the volume of the combustion chamber when the piston is at the top of its stroke. It is therefore calculated by the formula\nWhere:\nformula_3 can be estimated by the cylinder volume formula\nWhere:\nBecause of the complex shape of formula_4 it is usually measured directly. This is often done by filling the cylinder with liquid and then measuring the volume of the used liquid.\nVariable compression ratio engines.\nMost engines use a fixed compression ratio, however a variable compression ratio engine is able to adjust the compression ratio while the engine is in operation. The first production engine with a variable compression ratio was introduced in 2019.\nVariable compression ratio is a technology to adjust the compression ratio of an internal combustion engine while the engine is in operation. This is done to increase fuel efficiency while under varying loads. Variable compression engines allow the volume above the piston at top dead centre to be changed.\nHigher loads require lower ratios to increase power, while lower loads need higher ratios to increase efficiency, i.e. to lower fuel consumption. For automotive use this needs to be done as the engine is running in response to the load and driving demands.\nThe 2019 Infiniti QX50 is the first commercially available car that uses a variable compression ratio engine.\nRelationship with the pressure ratio.\nBased on the assumptions that adiabatic compression is carried out (i.e. that no heat energy is supplied to the gas being compressed, and that any temperature rise is solely due to the compression) and that air is a perfect gas, the relationship between the compression ratio and overall pressure ratio is as follows:\nThis relationship is derived from the following equation:\nHowever, in most real-life internal combustion engines, the ratio of specific heats changes with temperature and that significant deviations from adiabatic behavior will occur.\nDynamic compression ratio.\nThe \"static compression ratio\" discussed above \u2014 calculated solely based on the cylinder and combustion chamber volumes \u2014 does not take into account any gasses entering or exiting the cylinder during the compression phase. In most automotive engines, the intake valve closure (which seals the cylinder) takes place during the compression phase (i.e. after bottom dead centre, BDC), which can cause some of the gasses to be pushed back out through the intake valve. On the other hand, intake port tuning and scavenging can cause a greater amount of gas to be trapped in the cylinder than the static volume would suggest. The \"dynamic compression ratio\" accounts for these factors.\nThe dynamic compression ratio is higher with more conservative intake camshaft timing (i.e. soon after BDC), and lower with more radical intake camshaft timing (i.e. later after BDC). Regardless, the dynamic compression ratio is always lower than the static compression ratio.\nThe absolute cylinder pressure is used to calculate the dynamic compression ratio, using the following formula:\nUnder ideal (adiabatic) conditions, the ratio of specific heats would be 1.4, but a lower value, generally between 1.2 and 1.3 is used, since the amount of heat lost will vary among engines based on design, size and materials used. For example, if the static compression ratio is 10\u22361, and the dynamic compression ratio is 7.5\u22361, a useful value for cylinder pressure would be 7.51.3 \u00d7 atmospheric pressure, or 13.7\u00a0bar (relative to atmospheric pressure).\nThe two corrections for dynamic compression ratio affect cylinder pressure in opposite directions, but not in equal strength. An engine with high static compression ratio and late intake valve closure will have a dynamic compression ratio similar to an engine with lower compression but earlier intake valve closure."}
{"id": "6864", "revid": "194203", "url": "https://en.wikipedia.org/wiki?curid=6864", "title": "Chromosome walking", "text": ""}
{"id": "6865", "revid": "6112901", "url": "https://en.wikipedia.org/wiki?curid=6865", "title": "Concordat of Worms", "text": " "}
{"id": "6867", "revid": "17350134", "url": "https://en.wikipedia.org/wiki?curid=6867", "title": "Context-free language", "text": "In formal language theory, a context-free language (CFL) is a language generated by a context-free grammar (CFG).\nContext-free languages have many applications in programming languages, in particular, most arithmetic expressions are generated by context-free grammars.\nBackground.\nContext-free grammar.\nDifferent context-free grammars can generate the same context-free language. Intrinsic properties of the language can be distinguished from extrinsic properties of a particular grammar by comparing multiple grammars that describe the language.\nAutomata.\nThe set of all context-free languages is identical to the set of languages accepted by pushdown automata, which makes these languages amenable to parsing. Further, for a given CFG, there is a direct way to produce a pushdown automaton for the grammar (and thereby the corresponding language), though going the other way (producing a grammar given an automaton) is not as direct.\nExamples.\nAn example context-free language is formula_1, the language of all non-empty even-length strings, the entire first halves of which are 's, and the entire second halves of which are 's. is generated by the grammar formula_2.\nThis language is not regular.\nIt is accepted by the pushdown automaton formula_3 where formula_4 is defined as follows:\nUnambiguous CFLs are a proper subset of all CFLs: there are inherently ambiguous CFLs. An example of an inherently ambiguous CFL is the union of formula_6 with formula_7. This set is context-free, since the union of two context-free languages is always context-free. But there is no way to unambiguously parse strings in the (non-context-free) subset formula_8 which is the intersection of these two languages.\nDyck language.\nThe language of all properly matched parentheses is generated by the grammar formula_9.\nProperties.\nContext-free parsing.\nThe context-free nature of the language makes it simple to parse with a pushdown automaton.\nDetermining an instance of the membership problem; i.e. given a string formula_10, determine whether formula_11 where formula_12 is the language generated by a given grammar formula_13; is also known as \"recognition\". Context-free recognition for Chomsky normal form grammars was shown by Leslie G. Valiant to be reducible to boolean matrix multiplication, thus inheriting its complexity upper bound of \"O\"(\"n\"2.3728639).\nConversely, Lillian Lee has shown \"O\"(\"n\"3\u2212\u03b5) boolean matrix multiplication to be reducible to \"O\"(\"n\"3\u22123\u03b5) CFG parsing, thus establishing some kind of lower bound for the latter.\nPractical uses of context-free languages require also to produce a derivation tree that exhibits the structure that the grammar associates with the given string. The process of producing this tree is called \"parsing\". Known parsers have a time complexity that is cubic in the size of the string that is parsed.\nFormally, the set of all context-free languages is identical to the set of languages accepted by pushdown automata (PDA). Parser algorithms for context-free languages include the CYK algorithm and Earley's Algorithm.\nA special subclass of context-free languages are the deterministic context-free languages which are defined as the set of languages accepted by a deterministic pushdown automaton and can be parsed by a LR(k) parser.\nSee also parsing expression grammar as an alternative approach to grammar and parser.\nClosure.\nThe class of context-free languages is closed under the following operations. That is, if \"L\" and \"P\" are context-free languages, the following languages are context-free as well:\nNonclosure under intersection, complement, and difference.\nThe context-free languages are not closed under intersection. This can be seen by taking the languages formula_22 and formula_23, which are both context-free. Their intersection is formula_24, which can be shown to be non-context-free by the pumping lemma for context-free languages. As a consequence, context-free languages cannot be closed under complementation, as for any languages \"A\" and \"B\", their intersection can be expressed by union and complement: formula_25. In particular, context-free language cannot be closed under difference, since complement can be expressed by difference: formula_26.\nHowever, if \"L\" is a context-free language and \"D\" is a regular language then both their intersection formula_27 and their difference formula_28 are context-free languages.\nDecidability.\nIn formal language theory, questions about regular languages are usually decidable, but ones about context-free languages are often not. It is decidable whether such a language is finite, but not whether it contains every possible string, is regular, is unambiguous, or is equivalent to a language with a different grammar.\nThe following problems are undecidable for arbitrarily given context-free grammars A and B:\nThe following problems are \"decidable\" for arbitrary context-free languages:\nAccording to Hopcroft, Motwani, Ullman (2003), \nmany of the fundamental closure and (un)decidability properties of context-free languages were shown in the 1961 paper of Bar-Hillel, Perles, and Shamir\nLanguages that are not context-free.\nThe set formula_8 is a context-sensitive language, but there does not exist a context-free grammar generating this language. So there exist context-sensitive languages which are not context-free. To prove that a given language is not context-free, one may employ the pumping lemma for context-free languages or a number of other methods, such as Ogden's lemma or Parikh's theorem."}
